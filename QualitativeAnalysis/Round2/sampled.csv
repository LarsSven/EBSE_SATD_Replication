project,pull_number,pull_type,id,text,classification,indicator
spark,17130,review,104006906,"~I think it is better to explicitly declare the data instead of manipulating strings, that way it is very clear what the input data is for the example.~ On second thought, never mind this comment - it's pretty clear the way it is",code_debt,low_quality_code
spark,9867,review,46597229,"You should be able to have a single run with ""-Pkinesis-asl -Pyarn -Phive -Phive-thriftserver"" - I even think ""-Phive"" is unnecessary, I think it only affects packaging right now.
""-Phadoop2.2"" is unnecessary, that's the default.",code_debt,complex_code
airflow,13929,review,570530609,This exception is too broad,code_debt,low_quality_code
trafficcontrol,4959,review,470844261,I hope someone can figure out why I couldn't get that to work. It was *very* confusing.,code_debt,low_quality_code
flink,1640,review,52993965,"I think you can create the callback once in the open method and then pass the instance to all async calls.
This way, you save a lot of instance creations",code_debt,low_quality_code
flink,6159,review,195443441,"@Nonnegative int keyGroupId, for consistency",code_debt,low_quality_code
zookeeper,924,review,299043313,Unused default constructor.,code_debt,dead_code
druid,3570,review,87488947,"TreeMap was used in the original GroupByEngine code being moved, my goal with this PR was to create the interface and move type-specific code but not change functionality generally/target performance optimizations",code_debt,slow_algorithm
openwhisk,1071,review,75486973,"As noted in personal discussion:
I found it hard to grasp the code because we use `Unit` returning functions which resolve a `Promise` at some point. This reads like it blocks the code until the result is there (which makes no sense at this point).
I'ld prefer to use `Future` composition if possible so it becomes more apparent that this is in fact returning a Future which is resolved as soon as the ack-message is there.",code_debt,low_quality_code
nifi-minifi-cpp,788,review,428031207,Unnecessary semicolon at the end of the line.,code_debt,low_quality_code
ambari,1646,review,199117523,This is unnecessary.,code_debt,complex_code
spark,31721,review,589378403,"nit: please use the upper case where possible, `LIST ARCHIVES`.",code_debt,low_quality_code
beam,1974,review,100887469,"What is the relationship between ""dataflow counters"" and ""metric updates""?  This comment refers to counters, while the code below refers to metric update protos.  Should this comment instead mention translating accumulators for metric updates so that this class should be renamed accordingly?
Also, the naming of the methods below is confusing: two arguments are passed, e.g. set_boolean(accumulator, metric_update_proto).  Just reading this signature suggests that the accumulator will somehow have a boolean set from metric_update_proto, which is the opposite of what is intended.  Can you instead rename these methods translate_*, e.g. for translate_boolean(accumulator, metric_update_proto)?  This would make it clear that we are translating accumulator into metric_update_proto.  If you do this, can you rename set_scalar and set_mean in this file as well?",code_debt,low_quality_code
tvm,5144,review,397530214,letlist is everywhere. can you put this in some common file?,code_debt,low_quality_code
flink,9890,review,335896695,Keep four spaces indentation for these parameters. Same for method `createProjectionRexProgram`,code_debt,low_quality_code
spark,22006,review,207876249,nit: 2 space indentation,code_debt,low_quality_code
incubator-heron,176,review,56283550,"instead of string formatter - can we use string builder so that we don't have to count the number of formatting arguments - often it takes a couple of iterations to get this right?  String Builder now will be good especially with the CLI options, thoughts?",code_debt,low_quality_code
kafka,9007,review,454569003,"That's great point. At the moment, I think that we are not consistent about this. Some are package private and some are not. The advantage of keeping it public is that it allows to use the class in unit tests which resides in other packages.",code_debt,low_quality_code
apisix,2329,review,495666587,"my fault,I should remove irrelevant code,actually,test_base.py has nothing to do with this PR",code_debt,dead_code
tvm,2292,review,241858156,using `unwrap` in libraries is generally a bad idea if it's possible to panic. please use `?` since you're already returning a `Result`,code_debt,low_quality_code
netbeans,2324,review,511329375,Using `Logger` would be more standard. See [Logging in NetBeans](http://bits.netbeans.org/dev/javadoc/org-openide-util/org/openide/util/doc-files/logging.html) document.,code_debt,low_quality_code
kafka,2320,review,94887536,"I thought about it before, but it is a bit tricky to do since it could be dynamic based on which class the `toString` function is triggered first.  Let me think about it more and see if I can come with a clean solution.",code_debt,low_quality_code
spark,6558,review,31485428,"oh, I just realized that when we reuse the Decimal value, we do not really need to use the returned value. But, we have another place that needs the returned value. Can we add a comment at here?",code_debt,low_quality_code
iceberg,933,review,411434730,I think it makes sense to reuse the definition.,code_debt,low_quality_code
beam,5028,review,181501125,"yes, if max input is sys.maxint, then we will get 57. I increase bucket size by 1 just for safe purpose, maybe unnecessary. But I don't think one more bucket per counter will cost too many memory.",code_debt,low_quality_code
spark,5511,review,28394051,Origin code ignore the `newName`. Is this intended?,code_debt,low_quality_code
pulsar,2101,review,202403205,"if using an Optional, this becomes:
Looks cleaner to me.",code_debt,low_quality_code
storm,2433,review,152902841,Two lines looks duplicated. We could remove duplicated two lines via following:,code_debt,duplicated_code
beam,4910,review,175947778,At this pointm it may be worth wrapping the getXOrThrow calls to actually return a legible error message since the generated code does not print the input ids.,code_debt,low_quality_code
kafka,6163,review,252942686,"nit: since it's just an accessor, maybe we could drop the parenthesis?",code_debt,low_quality_code
druid,2524,review,81665494,"Would prefer `List<KeyValueMap>` here, it's generally easier to work with.",code_debt,low_quality_code
incubator-pinot,141,review,65645131,"Sharing is fine for children of the same parent. It makes the 'remove' redundant, but saves a lot of garbage.",code_debt,low_quality_code
spark,21356,review,189349209,Not used anymore.,code_debt,dead_code
storm,2911,review,283128941,Unnecessary whitespace,code_debt,low_quality_code
spark,15009,review,84790527,You can simplify all this by doing:,code_debt,complex_code
dubbo,4526,review,303318487,"it is a bad idea to have two *isSetter* methods, pls. consider to combine both into one single isSetter method",code_debt,low_quality_code
iceberg,2294,review,596510752,nit: also `equals` here,code_debt,low_quality_code
spark,26682,review,371318137,"it's for correctness.  to allow users to manipulate the ExecutorResourceRequests multiple times.  The original intent was all of these classes would be immutable, but that made things less user friendly so in the original PR this class got created and users are allowed to modify multiple times and they could do it from multiple threads.  It's something I missed in the original pr rework.",code_debt,low_quality_code
openwhisk,4870,review,399976882,"I'd think we explicitly do not want to have the prewarm pool survive, if other actions would benefit from using that space. After all, it's a performance optimization, not a guarantee.
Wouldn't this also be plumbed into the controller for it to not send requests down a path where they might not get executed?
I think this warrants a dev-list discussion ðŸ¤”",code_debt,slow_algorithm
spark,8785,review,48715367,"This call is effectively just cloning the properties, but we're already doing the clone inside of `.jdbc()` itself, so we don't need this.",code_debt,complex_code
kafka,3765,review,144588126,"Btw, there are some really long lines in this PR. Our convention is that lines should not be longer than the GitHub review window.",code_debt,low_quality_code
incubator-mxnet,15161,review,292706143,Are you using any functions in this library? if not please get rid of this line.,build_debt,over-declared_dependencies
beam,7237,comment,447180932,"I am just starting to review, but I want to get some principles out beforehand:
1. The shaded path should absolutely never be used. It is derived from the module name just to make it unique. The reason we shade is as a way to isolate ""implementation detail"" dependencies. If this ends up on an API surface that is a bug. We had some tests for this, but they have rotted.
2. We work pretty hard to avoid Guava on the API surface, since the risk of diamond dependency conflicts is very high.
3. It is OK for an IO to have its own esoteric dependencies - including Guava - if the thing it is connecting to requires it. So if it is _Cassandra_ that requires Gauva on the API surface, then it can be included in the deps.
4. For those situations where Beam wants to use Guava internally, we are (slowly) moving to depend on `beam-vendored-guava-20_0`",design_debt,non-optimal_design
cloudstack,1224,comment,164271374,"@bhaisaab I don't like maven but we are using it! cherry-picking is really not an argument and backporting is difficult for worse reasons then this one.
Using maven we better adhere to the conventions in the maven world as keeping our diversions from it correct will become increasingly difficult over time. I will meet you half way so we can abandon 4.5 first and continue to prove our fwd-merge schedule over several versions. We will face issues in this respect as well, btw, if at the time of 4.11 we will be fixing things in 4.6 ;)",design_debt,non-optimal_design
jena,151,comment,252431461,"Should we take a step back and reconsider whether updating the current API in HttpOp is the right thing to do.
Maybe we ought to
- introduce a different style more fluid
- reconsider a design where the caller is responsible for setting up more of the `HttpClient` and `HttpOp` provides operations for nothing special (no auth) + ops that use a redefined `HttpClient`. This is to reduce method bloat.
On (1): something like (quick sketch)
where there are implicit builder objects from, `.get(url)`, `.post(url)`, `.put(url)`, `'delete(url)`.",design_debt,non-optimal_design
spark,12474,comment,211507927,"Thanks for the pull request. We can't just change a private to public like this, because it can make the API more difficult to maintain in the long run. Can you justify more why this is needed, and why you can't work around it from the user side?",design_debt,non-optimal_design
nifi,1800,comment,303611024,"couple of quick thoughts.
- we'll need to get all the version numbers aligned with whatever nifi version this would be committed into.  Currently that would be 1.3.0-SNAPSHOT.
- It would probably be a good idea to have the notion of 'nifi-leaderelection-api' which is not about zookeeper but rather just generic election/tracking of a leader for a given thing (a partition?) Then there would be zookeeper based implementations of those.  Processors then can leverage the api for their code but users can select whichever types of services exist (zookeeper being the obvious initial example).  The structure appears already in place for this other than the current naming and perhaps the API referencing zookeeper.  Thoughts?
- It would be good to have a processor which leverages this or some docs that go along with it to show suggested usage.",design_debt,non-optimal_design
spark,708,summary,0,Converted bang to ask to avoid scary warning when a block is removed,code_debt,low_quality_code
flink,15389,summary,0,[FLINK-21609][tests] Remove usage of LocalCollectionOutpuFormat from SimpleRecoveryITCaseBase,code_debt,low_quality_code
zeppelin,2753,summary,0,ZEPPELIN-3138. checkstyle for zeppelin-interpreter,code_debt,low_quality_code
trafficserver,7138,summary,0,Remove useless shortopt,code_debt,dead_code
spark,25628,review,319461063,Seems like it doesn't support special characters in the column name now. Can we keep the support?,requirement_debt,requirement_partially_implemented
cloudstack,4574,comment,763102959,"@DaanHoogland I would limit it to ""4.15.0.0 to 4.15.1.0"", because adding it also to 4.14.1 will conflict with the the insert's in table `cloud.guest_os` during upgrade to 4.15.0.
I noticed that there is an `com.cloud.upgrade.dao` package still needed, but I hope, someone other will implement this ðŸ¤ž ðŸ˜„",requirement_debt,requirement_partially_implemented
spark,12241,comment,207105529,"To fix MiMa, you need to add a line to the `mimaProjects` definition to temporarily exclude the new project: https://github.com/dbtsai/spark/blob/b9870d6c62d75cd59698bd72751bc4f7854cd2e3/project/SparkBuild.scala#L254
Also, add a TODO and followup task for post-2.0-release to remove the exclude once 2.0 has been published and there is a previous artifact for MiMa to compare against.",requirement_debt,requirement_partially_implemented
hudi,1115,comment,567470696,Will add more test cases to cover complex dag.,test_debt,low_coverage
nutch,484,comment,555061506,"Well, the previous non-REST test implemented a client which did not send anything to the server but just returned a successful response or (if `clusterSaturated` was set to true) a temporary failure.
But I'm ok to remove the Test class if it's too much work to rewrite it for the REST client.
I've tested the PR but the initial rounds failed for about 50% of the pages/documents:
I got it fixed by using XContentBuilder to pass document as JSON to ES client, you'll find the necessary changes in [this branch](https://github.com/sebastian-nagel/nutch/tree/NUTCH-2739). Also:
- updated the description how to upgrade the dependencies in the plugin.xml and added few exclusions of dependencies already provided by Nutch core.
- changed the default properties in index-writers.xml.template so that the indexer-elastic plugin works out-of-the-box with default settings
So far, I didn't run any tests at scale. Should be to make sure we are able to index millions of documents with the given settings.",test_debt,lack_of_tests
commons-lang,261,comment,289800588,@yasserzamani I thinks because you added more conditional branches in the latest commit and that is why less LOC are covered,test_debt,low_coverage
kafka,841,comment,177319309,@ijuma Do you mean adding it to the comments or update the ticket description? I did not test Java 1.7 CRC32 performance. I only tested the one we used to use and the CRC32 performance in Java 1.8.,test_debt,lack_of_tests
ignite,6420,review,273863106,Nanoseconds is too much. Milliseconds will be enough.,design_debt,non-optimal_design
ignite,5635,review,241036804,"Hmm... We will avoid boilerplate, but seems like it will make code more error prone. Developer can forget to override this method for trainer which potentially supports updating and get an error while trying to update this model in the future whereas keeping it abstract forces developer to think if this trainer supports update and insert `NotImplementedException` more cautiously.",design_debt,non-optimal_design
samza,103,review,110061958,I prefer addressing non SEP-1 related suggestions in a separate PR. This is an awfully large change and should not be bloated with other important changes.,design_debt,non-optimal_design
samza,235,review,124903942,"It will be cleaner to simply pass the metrics registry associated with this component and register more granular group of metrics under `ZkUtilsMetrics`. Overloading it with `ZkJobCoordinatorMetrics` is confusing as this component - ZkUtils is also accessed from CoordinationService. 
HTH. Thanks!",design_debt,non-optimal_design
gobblin,2015,review,129176332,"The configuration options are not symmetric here, which can lead to confusion and does not allow all override possibilities. The code is ignoring the config store whitelist tag when a job-level whitelist is specified, but it is adding the job-level blacklist to the tag-based blacklist.",design_debt,non-optimal_design
beam,12645,review,486156062,@abhiy13 short javadoc please.,documentation_debt,outdated_documentation
tvm,2773,review,283191720,Doc formatting.,documentation_debt,low_quality_documentation
hbase,1482,review,416140357,What does this function do? Favor SSD? Needs comment.,documentation_debt,low_quality_documentation
airflow,5661,review,307279581,"Enter is required. Otherwise, documentation is not rendered correctly.",documentation_debt,low_quality_documentation
incubator-pinot,4047,review,288787662,"Instead of these 3 comment lines, just point to the design document",documentation_debt,low_quality_documentation
flink,10017,review,349058826,To check whether a file is zip-format we must read its actual content. If user specifies a DFS url the check will introduce additional IO. Suffix checking is also hard because there are too many file formats are actually zip format. Maybe rewriting the doc string in detail to tell users what file format are actually supported is a better choice?,documentation_debt,low_quality_documentation
airflow,5010,review,272785021,Can you share how you derive `yesterday_ds` with `execution_date` with macros in the docs?,documentation_debt,outdated_documentation
kafka,764,review,51615946,"Could we put those comments in a more prominent place like the beginning of the class? With v1 message format, we are adding a timestamp, a timestamp type attribute, and are using a relative for inner message. It would be useful to document the format in a bit more details for both the outer and the inner message. For example, should the timestamp type attribute be set for inner messages?",documentation_debt,low_quality_documentation
trafficserver,3903,comment,402768113,"I think it's good to take opportunities like this to do more general code cleanup. I'm on vacation this week, I will look at splitting it in to two commits when I get  back.",code_debt,low_quality_code
spark,5434,comment,92291279,"Also, could you make the stats at the top of the page ""Waiting batches"" and ""Processed batches"" links to the corresponding sections? And the names should be consistent, so please rename them here, keep them as ""Active Batches"" and ""Completed Batches"".",code_debt,low_quality_code
openwhisk,3449,comment,373702523,"What a mess...
On Mar 16, 2018 5:12 AM, ""Carlos Santana"" <notifications@github.com> wrote:",code_debt,low_quality_code
trafodion,604,comment,234079094,"The code seems fine, however, it seems like it would be good to at least log the transid with the exceptions so we can better track down/correlate issues after the fact.",code_debt,low_quality_code
rocketmq,64,comment,280278200,"Can you provide some test data, say before/after applying this patch, how many duplications are found respectively?
IMHO, we should make the API as concise as possible.",code_debt,duplicated_code
spark,12836,comment,216750713,"Ok - if the behavior we get from `dapply(repartition(df, cols))` is the same as `groupByKey().flatMap` then I'm fine with going with the simpler implementation. 
But I think we should have a high level `gapply(df, cols, function(group))` API in SparkR that is clearly specified. The internal implementation we should go with whatever is simpler.",code_debt,complex_code
activemq-artemis,2558,comment,472853473,"I see you added a test, but you still haven't addressed my question about synchronized on .class.
Why is that needed?",code_debt,complex_code
pulsar,366,comment,296908563,"@rdhabalia Maybe the name `NonDurableCursor` doesn't fully convey the intended semantic for the new class. The context here is just to have a way to read through a topic (eg: support `TopicReader`) and reuse as much code as possible from the regular cursor implementation. Basically all the cache code and the logic for how to switch to ""next valid position"", plus the asyncReadOrWait stuff.
About non impeding messages to be deleted, consider that in case of non-durable topic, during a disconnection the cursor will go away and data will get potentially deleted anyway. So I prefer it to be explicitly ingrained into the API. Same thing about naming the cursor. It will go away in any case after a restart, so I don't see the advantage of naming it.
When data gets deleted, the cursor will just skip over it. The intended usage for the non-durable cursor and topic reader is in conjunction with the message retention, to make sure data sticks around for the intended amount of time",code_debt,low_quality_code
beam,13435,comment,747291549,"@rHermes yes general good practice is to separate PRs that deal with different subjects. But for cleaning PRs, it is the same subject. There a lot of leftovers in nexmark what I would like to avoid is tens of PRs that remove only a couple of fields.",code_debt,dead_code
incubator-mxnet,10819,summary,0,[MXNET-367] update mkldnn to v0.14 and disable building test examples,test_debt,lack_of_tests
tvm,4144,summary,0,Fix typo,documentation_debt,low_quality_documentation
tvm,4251,summary,0,Fix typo in err msg,documentation_debt,low_quality_documentation
spark,27165,comment,572924850,"For fixing examples and documentation, I will do it separately.",documentation_debt,low_quality_documentation
hadoop,1900,comment,601190652,"Thanx @vinayakumarb  for checking. Seems comment isn't coming, some problem, will check. it isn't coming for patches too.
Anyway the build seems cleans.",documentation_debt,outdated_documentation
spark,3165,comment,62288954,I'm actually happy to just drop this though if we can update the documentation in our wiki to suggest people use hub. @JoshRosen or @rxin would one of you guys be able to put a few lines in https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools with the process you use? I can then verify and if it's all good I can just drip this PR.,documentation_debt,outdated_documentation
ignite,6392,summary,0,IGNITE-11654: [ML] Memory leak in KNNClassificationModel,design_debt,non-optimal_design
pulsar,2241,description,0,"In #2237, `administration-auth` is removed. However it is not removed from sidebard. It is causing failures on building website.
Remove `administration-auth` from the sidebar. Also remove codebase page, which doesn't make sense to be there because code changes are happening very frequently. The page quickly becomes out-of-dated.
Additionally cleanup a few things in the sidebar.",code_debt,dead_code
spark,15573,description,0,"Jira: https://issues.apache.org/jira/browse/SPARK-18035
In HiveInspectors, I saw that converting Java map to Spark's `ArrayBasedMapData` spent quite sometime in buffer copying : https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala#L658
The reason being `map.toSeq` allocates a new buffer and copies the map entries to it: https://github.com/scala/scala/blob/2.11.x/src/library/scala/collection/MapLike.scala#L323
This copy is not needed as we get rid of it once we extract the key and value arrays.
Here is the call trace:
Also, earlier code was populating keys and values arrays separately by iterating twice. The PR avoids double iteration of the map and does it in one iteration.
EDIT: During code review, there were several more places in the code which were found to do similar thing. The PR dedupes those instances and introduces convenient APIs which are performant and memory efficient
The number is subjective and depends on how many map columns are accessed in the query and average entries per map. For one the queries that I tried out, I saw 3% CPU savings (end-to-end) for the query.
This does not change the end result produced so relying on existing tests.",code_debt,duplicated_code
cloudstack,2594,description,0,"While working on other issues, I found this empty class. I am proposing its removal as it is not used and can only cause confusion.
Locally
Testing",code_debt,dead_code
flink,9363,description,0,"-->
Currently, there are some transformation names are not set in blink planner. For example, LookupJoin transformation uses ""LookupJoin"" directly which loses a lot of informatoion.
1. Introduces a RelWriter `RelDisplayNameWriterImpl` to reuse code of ""explainTerms"" to generate operator names
2. Fix some operator names are not set in blink planner
This change is a trivial rework / code cleanup without any test coverage.",code_debt,low_quality_code
incubator-heron,2295,description,0,"New commands:
  heron examples list
  heron examples run <cluster> <example-id>
This patch is to provide easier commands to get the heron examples up and running.",design_debt,non-optimal_design
qpid-dispatch,1047,description,0,"* Do not write new buffers if connection is CLOSED_WRITE
* Do not call connection_wake if CLOSED_READ or CLOSED_WRITE
This fixes crashes but there is still work left with leaking messages and buffers when server connections close before client connections.",design_debt,non-optimal_design
kafka,3530,review,130078682,It would be nice to allow the staging receives to complete and verify that the closing channel is also empty like in the other test.,test_debt,expensive_tests
kafka,6363,review,280294974,"It'd be really great to have unit tests for many of these methods. The `performTaskAssignment(...)` method is already pretty lengthy, and there are just a few unit tests whereas there seem to be lots of permutations and branches. Not only would they help with confidence, but they'd help with regression testing if/when we have to get back into this code.",test_debt,lack_of_tests
samza,103,review,109215517,"This is a bit concerning that we are commenting out a good number of tests here. I would prefer to fix them, before check-in.",test_debt,lack_of_tests
superset,12739,description,0,"""Environment"" was misspelled on line 348, I have corrected this typo.",documentation_debt,low_quality_documentation
incubator-heron,1893,description,0,These tests all have to duplicate the same verbose boilerplate. Centralizing that in `SlaveTester`.,test_debt,expensive_tests
kafka,1664,review,77421658,Can you restructure this to use `val` - it helps to have a single block on the RHS that encapsulates the full assignment logic (as opposed to being exposed to the method's entire scope).,architecture_debt,violation_of_modularity
spark,20923,comment,383571843,"@vanzin : The followup to this is #21066; I could move the compile time changes there but if you are going to have POMs playing with dependencies, seems best to have it all in one place...the other one just setting up the compile and tests
@jerryshao what do you suggest? It was your proposal to split things into pom and source for ease of reviewal, after all?",architecture_debt,violation_of_modularity
