diff --git a/cpp/src/arrow/adapters/orc/adapter.cc b/cpp/src/arrow/adapters/orc/adapter.cc
index ce5c1550c51c..5418123049a1 100644
--- a/cpp/src/arrow/adapters/orc/adapter.cc
+++ b/cpp/src/arrow/adapters/orc/adapter.cc
@@ -524,6 +524,10 @@ class ORCFileWriter::Impl {
       writer_ = liborc::createWriter(*orc_schema, out_stream_.get(), *orc_options);
     } catch (const liborc::ParseError& e) {
       return Status::IOError(e.what());
+    } catch (const liborc::InvalidArgument& e) {
+      return ::arrow::Status::Invalid(e.what());
+    } catch (const liborc::NotImplementedYet& e) {
+      return ::arrow::Status::NotImplemented(e.what());
     }
     int64_t num_rows = table.num_rows();
     const int num_cols_ = table.num_columns();
@@ -536,8 +540,8 @@ class ORCFileWriter::Impl {
     while (num_rows > 0) {
       for (int i = 0; i < num_cols_; i++) {
         RETURN_NOT_OK(adapters::orc::WriteBatch(
-            (root->fields)[i], &(arrow_index_offset[i]), &(arrow_chunk_offset[i]),
-            kOrcWriterBatchSize, *(table.column(i))));
+            *(table.column(i)), kOrcWriterBatchSize, &(arrow_chunk_offset[i]),
+            &(arrow_index_offset[i]), (root->fields)[i]));
       }
       root->numElements = (root->fields)[0]->numElements;
       writer_->add(*batch);
diff --git a/cpp/src/arrow/adapters/orc/adapter_test.cc b/cpp/src/arrow/adapters/orc/adapter_test.cc
index 28a221f679c0..17adf41770d6 100644
--- a/cpp/src/arrow/adapters/orc/adapter_test.cc
+++ b/cpp/src/arrow/adapters/orc/adapter_test.cc
@@ -116,29 +116,6 @@ std::shared_ptr<Array> CastInt64ArrayToTemporalArray(
   return std::make_shared<TargetArrayType>(new_array_data);
 }
 
-/// \brief Construct a random weak composition of a nonnegative integer
-/// i.e. a way of writing it as the sum of a sequence of n non-negative
-/// integers.
-///
-/// \param[in] n the number of integers in the weak composition
-/// \param[in] sum the integer of which a random weak composition is generated
-/// \param[out] out The generated weak composition
-template <typename T, typename U>
-void RandWeakComposition(int64_t n, T sum, std::vector<U>* out) {
-  const int random_seed = 0;
-  std::default_random_engine gen(random_seed);
-  out->resize(n, static_cast<T>(0));
-  T remaining_sum = sum;
-  std::generate(out->begin(), out->end() - 1, [&gen, &remaining_sum] {
-    std::uniform_int_distribution<T> d(static_cast<T>(0), remaining_sum);
-    auto res = d(gen);
-    remaining_sum -= res;
-    return static_cast<U>(res);
-  });
-  (*out)[n - 1] += remaining_sum;
-  std::random_shuffle(out->begin(), out->end());
-}
-
 Result<std::shared_ptr<Array>> GenerateRandomDate64Array(int64_t size,
                                                          double null_probability) {
   arrow::random::RandomArrayGenerator rand(kRandomSeed);
@@ -177,6 +154,29 @@ Result<std::shared_ptr<Array>> GenerateRandomTimestampArray(int64_t size,
   }
 }
 
+/// \brief Construct a random weak composition of a nonnegative integer
+/// i.e. a way of writing it as the sum of a sequence of n non-negative
+/// integers.
+///
+/// \param[in] n the number of integers in the weak composition
+/// \param[in] sum the integer of which a random weak composition is generated
+/// \param[out] out The generated weak composition
+template <typename T, typename U>
+void RandWeakComposition(int64_t n, T sum, std::vector<U>* out) {
+  const int random_seed = 0;
+  std::default_random_engine gen(random_seed);
+  out->resize(n, static_cast<T>(0));
+  T remaining_sum = sum;
+  std::generate(out->begin(), out->end() - 1, [&gen, &remaining_sum] {
+    std::uniform_int_distribution<T> d(static_cast<T>(0), remaining_sum);
+    auto res = d(gen);
+    remaining_sum -= res;
+    return static_cast<U>(res);
+  });
+  (*out)[n - 1] += remaining_sum;
+  std::random_shuffle(out->begin(), out->end());
+}
+
 std::shared_ptr<ChunkedArray> GenerateRandomChunkedArray(
     const std::shared_ptr<DataType>& data_type, int64_t size, int64_t min_num_chunks,
     int64_t max_num_chunks, double null_probability) {
@@ -186,22 +186,22 @@ std::shared_ptr<ChunkedArray> GenerateRandomChunkedArray(
   arrow::randint<int64_t, int64_t>(1, min_num_chunks, max_num_chunks, &num_chunks);
   int64_t current_num_chunks = num_chunks[0];
   ArrayVector arrays(current_num_chunks, nullptr);
-  RandWeakComposition(current_num_chunks, size, &current_size_chunks);
+  arrow::RandWeakComposition(current_num_chunks, size, &current_size_chunks);
   for (int j = 0; j < current_num_chunks; j++) {
     switch (data_type->id()) {
       case arrow::Type::type::DATE64: {
-        arrays[j] = GenerateRandomDate64Array(current_size_chunks[j], null_probability)
-                        .ValueOrDie();
+        EXPECT_OK_AND_ASSIGN(arrays[j], GenerateRandomDate64Array(current_size_chunks[j],
+                                                                  null_probability));
         break;
       }
       case arrow::Type::type::TIMESTAMP: {
-        arrays[j] =
+        EXPECT_OK_AND_ASSIGN(
+            arrays[j],
             GenerateRandomTimestampArray(
                 current_size_chunks[j],
                 arrow::internal::checked_pointer_cast<arrow::TimestampType>(data_type)
                     ->unit(),
-                null_probability)
-                .ValueOrDie();
+                null_probability));
         break;
       }
       default:
@@ -228,13 +228,13 @@ std::shared_ptr<Table> GenerateRandomTable(const std::shared_ptr<Schema>& schema
 void AssertTableWriteReadEqual(const std::shared_ptr<Table>& input_table,
                                const std::shared_ptr<Table>& expected_output_table,
                                const int64_t max_size = kDefaultSmallMemStreamSize) {
-  std::shared_ptr<io::BufferOutputStream> buffer_output_stream =
-      io::BufferOutputStream::Create(max_size).ValueOrDie();
-  std::unique_ptr<adapters::orc::ORCFileWriter> writer =
-      adapters::orc::ORCFileWriter::Open(buffer_output_stream.get()).ValueOrDie();
+  EXPECT_OK_AND_ASSIGN(auto buffer_output_stream,
+                       io::BufferOutputStream::Create(max_size));
+  EXPECT_OK_AND_ASSIGN(auto writer,
+                       adapters::orc::ORCFileWriter::Open(buffer_output_stream.get()));
   ARROW_EXPECT_OK(writer->Write(*input_table));
   ARROW_EXPECT_OK(writer->Close());
-  std::shared_ptr<Buffer> buffer = buffer_output_stream->Finish().ValueOrDie();
+  EXPECT_OK_AND_ASSIGN(auto buffer, buffer_output_stream->Finish());
   std::shared_ptr<io::RandomAccessFile> in_stream(new io::BufferReader(buffer));
   std::unique_ptr<adapters::orc::ORCFileReader> reader;
   ARROW_EXPECT_OK(
@@ -489,9 +489,9 @@ class TestORCWriterWithConversion : public ::testing::Test {
         GenerateRandomTable(input_schema, num_rows, 1, 1, null_possibility);
     ArrayVector av(num_cols);
     for (int i = 0; i < num_cols - 2; i++) {
-      av[i] = arrow::compute::Cast(*(input_table->column(i)->chunk(0)),
-                                   output_schema->field(i)->type())
-                  .ValueOrDie();
+      EXPECT_OK_AND_ASSIGN(av[i],
+                           arrow::compute::Cast(*(input_table->column(i)->chunk(0)),
+                                                output_schema->field(i)->type()));
     }
     for (int i = num_cols - 2; i < num_cols; i++) {
       av[i] = CastFixedSizeBinaryArrayToBinaryArray(input_table->column(i)->chunk(0));
@@ -562,12 +562,12 @@ TEST_F(TestORCWriterSingleArray, WriteLargeList) {
   int64_t num_rows = 10000;
   auto value_array = rand.ArrayOf(int32(), 5 * num_rows, 0.5);
   auto output_offsets = rand.Offsets(num_rows + 1, 0, 5 * num_rows, 0.6, false);
-  auto input_offsets = arrow::compute::Cast(*output_offsets, int64()).ValueOrDie();
-  std::shared_ptr<Array>
-      input_array =
-          arrow::LargeListArray::FromArrays(*input_offsets, *value_array).ValueOrDie(),
-      output_array =
-          arrow::ListArray::FromArrays(*output_offsets, *value_array).ValueOrDie();
+  EXPECT_OK_AND_ASSIGN(auto input_offsets,
+                       arrow::compute::Cast(*output_offsets, int64()));
+  EXPECT_OK_AND_ASSIGN(auto input_array,
+                       arrow::LargeListArray::FromArrays(*input_offsets, *value_array));
+  EXPECT_OK_AND_ASSIGN(auto output_array,
+                       arrow::ListArray::FromArrays(*output_offsets, *value_array));
   AssertArrayWriteReadEqual(input_array, output_array, kDefaultSmallMemStreamSize * 10);
 }
 TEST_F(TestORCWriterSingleArray, WriteFixedSizeList) {
diff --git a/cpp/src/arrow/adapters/orc/adapter_util.cc b/cpp/src/arrow/adapters/orc/adapter_util.cc
index 9f62117dba56..80419e7b4355 100644
--- a/cpp/src/arrow/adapters/orc/adapter_util.cc
+++ b/cpp/src/arrow/adapters/orc/adapter_util.cc
@@ -356,7 +356,8 @@ arrow::Status WriteBatch(const arrow::Array& parray, int64_t orc_offset,
                          liborc::ColumnVectorBatch* column_vector_batch);
 
 // Make sure children of StructArray have appropriate null.
-std::shared_ptr<arrow::Array> NormalizeArray(const std::shared_ptr<arrow::Array>& array) {
+Result<std::shared_ptr<arrow::Array>> NormalizeArray(
+    const std::shared_ptr<arrow::Array>& array) {
   arrow::Type::type kind = array->type_id();
   switch (kind) {
     case arrow::Type::type::STRUCT: {
@@ -375,10 +376,11 @@ std::shared_ptr<arrow::Array> NormalizeArray(const std::shared_ptr<arrow::Array>
           if (child_bitmap == nullptr) {
             final_child_bitmap = bitmap;
           } else {
-            final_child_bitmap = arrow::internal::BitmapAnd(
-                                     arrow::default_memory_pool(), bitmap->data(), 0,
-                                     child_bitmap->data(), 0, struct_array->length(), 0)
-                                     .ValueOrDie();
+            ARROW_ASSIGN_OR_RAISE(
+                final_child_bitmap,
+                arrow::internal::BitmapAnd(arrow::default_memory_pool(), bitmap->data(),
+                                           0, child_bitmap->data(), 0,
+                                           struct_array->length(), 0));
           }
           std::shared_ptr<arrow::ArrayData> child_array_data = child->data();
           std::vector<std::shared_ptr<arrow::Buffer>> child_buffers =
@@ -387,7 +389,8 @@ std::shared_ptr<arrow::Array> NormalizeArray(const std::shared_ptr<arrow::Array>
           std::shared_ptr<arrow::ArrayData> new_child_array_data = arrow::ArrayData::Make(
               child->type(), child->length(), child_buffers, child_array_data->child_data,
               child_array_data->dictionary);
-          new_children[i] = NormalizeArray(arrow::MakeArray(new_child_array_data));
+          ARROW_ASSIGN_OR_RAISE(new_children[i],
+                                NormalizeArray(arrow::MakeArray(new_child_array_data)));
         }
         return std::make_shared<arrow::StructArray>(struct_type, struct_array->length(),
                                                     new_children, bitmap);
@@ -395,28 +398,32 @@ std::shared_ptr<arrow::Array> NormalizeArray(const std::shared_ptr<arrow::Array>
     }
     case arrow::Type::type::LIST: {
       auto list_array = checked_pointer_cast<arrow::ListArray>(array);
-      return std::make_shared<arrow::ListArray>(
-          list_array->type(), list_array->length(), list_array->value_offsets(),
-          NormalizeArray(list_array->values()), list_array->null_bitmap());
+      ARROW_ASSIGN_OR_RAISE(auto value_array, NormalizeArray(list_array->values()));
+      return std::make_shared<arrow::ListArray>(list_array->type(), list_array->length(),
+                                                list_array->value_offsets(), value_array,
+                                                list_array->null_bitmap());
     }
     case arrow::Type::type::LARGE_LIST: {
       auto list_array = checked_pointer_cast<arrow::LargeListArray>(array);
+      ARROW_ASSIGN_OR_RAISE(auto value_array, NormalizeArray(list_array->values()));
       return std::make_shared<arrow::LargeListArray>(
           list_array->type(), list_array->length(), list_array->value_offsets(),
-          NormalizeArray(list_array->values()), list_array->null_bitmap());
+          value_array, list_array->null_bitmap());
     }
     case arrow::Type::type::FIXED_SIZE_LIST: {
       auto list_array = checked_pointer_cast<arrow::FixedSizeListArray>(array);
+      ARROW_ASSIGN_OR_RAISE(auto value_array, NormalizeArray(list_array->values()));
       return std::make_shared<arrow::FixedSizeListArray>(
-          list_array->type(), list_array->length(), NormalizeArray(list_array->values()),
+          list_array->type(), list_array->length(), value_array,
           list_array->null_bitmap());
     }
     case arrow::Type::type::MAP: {
       auto map_array = checked_pointer_cast<arrow::MapArray>(array);
-      return std::make_shared<arrow::MapArray>(
-          map_array->type(), map_array->length(), map_array->value_offsets(),
-          NormalizeArray(map_array->keys()), NormalizeArray(map_array->items()),
-          map_array->null_bitmap());
+      ARROW_ASSIGN_OR_RAISE(auto key_array, NormalizeArray(map_array->keys()));
+      ARROW_ASSIGN_OR_RAISE(auto item_array, NormalizeArray(map_array->items()));
+      return std::make_shared<arrow::MapArray>(map_array->type(), map_array->length(),
+                                               map_array->value_offsets(), key_array,
+                                               item_array, map_array->null_bitmap());
     }
     default: {
       return array;
@@ -932,14 +939,14 @@ arrow::Result<ORC_UNIQUE_PTR<liborc::Type>> GetOrcType(const arrow::DataType& ty
 }
 }  // namespace
 
-Status WriteBatch(liborc::ColumnVectorBatch* column_vector_batch,
-                  int64_t* arrow_index_offset, int* arrow_chunk_offset, int64_t length,
-                  const ChunkedArray& chunked_array) {
+Status WriteBatch(const ChunkedArray& chunked_array, int64_t length,
+                  int* arrow_chunk_offset, int64_t* arrow_index_offset,
+                  liborc::ColumnVectorBatch* column_vector_batch) {
   int num_batch = chunked_array.num_chunks();
   int64_t orc_offset = 0;
   while (*arrow_chunk_offset < num_batch && orc_offset < length) {
-    std::shared_ptr<Array> array =
-        NormalizeArray(chunked_array.chunk(*arrow_chunk_offset));
+    ARROW_ASSIGN_OR_RAISE(auto array,
+                          NormalizeArray(chunked_array.chunk(*arrow_chunk_offset)));
     int64_t num_written_elements =
         std::min(length - orc_offset, array->length() - *arrow_index_offset);
     if (num_written_elements > 0) {
diff --git a/cpp/src/arrow/adapters/orc/adapter_util.h b/cpp/src/arrow/adapters/orc/adapter_util.h
index bb33852bbd51..3e6d0fcc6603 100644
--- a/cpp/src/arrow/adapters/orc/adapter_util.h
+++ b/cpp/src/arrow/adapters/orc/adapter_util.h
@@ -39,9 +39,18 @@ Result<ORC_UNIQUE_PTR<liborc::Type>> GetOrcType(const Schema& schema);
 Status AppendBatch(const liborc::Type* type, liborc::ColumnVectorBatch* batch,
                    int64_t offset, int64_t length, arrow::ArrayBuilder* builder);
 
-Status WriteBatch(liborc::ColumnVectorBatch* column_vector_batch,
-                  int64_t* arrow_index_offset, int* arrow_chunk_offset, int64_t length,
-                  const ChunkedArray& chunked_array);
+/// \brief Write a chunked array to an orc::ColumnVectorBatch
+///
+/// \param[in] chunked_array the chunked array
+/// \param[in] length the orc::ColumnVectorBatch size limit
+/// \param[in,out] arrow_chunk_offset The current chunk being processed
+/// \param[in,out] arrow_index_offset The index of the arrow_chunk_offset array
+/// before or after a process
+/// \param[in,out] column_vector_batch the orc::ColumnVectorBatch to be filled
+/// \return Status
+Status WriteBatch(const ChunkedArray& chunked_array, int64_t length,
+                  int* arrow_chunk_offset, int64_t* arrow_index_offset,
+                  liborc::ColumnVectorBatch* column_vector_batch);
 
 }  // namespace orc
 }  // namespace adapters
