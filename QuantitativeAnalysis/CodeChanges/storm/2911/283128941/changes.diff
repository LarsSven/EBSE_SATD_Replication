diff --git a/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/FirstPollOffsetStrategy.java b/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/FirstPollOffsetStrategy.java
index 949ca54511..9184bc3c06 100644
--- a/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/FirstPollOffsetStrategy.java
+++ b/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/FirstPollOffsetStrategy.java
@@ -33,7 +33,7 @@ public enum FirstPollOffsetStrategy {
     LATEST,
     /**
      * The kafka spout polls records starting at the earliest offset whose timestamp is greater than or equal to the given startTimestamp.
-     * This setting only takes effect on topology deployment
+     * This setting only takes effect on topology deployment. This option is currently available only for the Trident Spout
      */
     TIMESTAMP,
     /**
@@ -45,7 +45,8 @@ public enum FirstPollOffsetStrategy {
      */
     UNCOMMITTED_LATEST,
     /**
-     * The kafka spout polls records from the last committed offset, if any. If no offset has been committed it behaves as TIMESTAMP
+     * The kafka spout polls records from the last committed offset, if any. If no offset has been committed it behaves as TIMESTAMP.
+     * This option is currently available only for the Trident Spout
      */
     UNCOMMITTED_TIMESTAMP;
 }
diff --git a/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpoutConfig.java b/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpoutConfig.java
index ce7fbe9af6..a51e14cff2 100644
--- a/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpoutConfig.java
+++ b/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpoutConfig.java
@@ -369,7 +369,6 @@ public int getMetricsTimeBucketSizeInSecs() {
 
     @Override
     public String toString() {
-
         return new ToStringBuilder(this, ToStringStyle.SHORT_PREFIX_STYLE)
             .append("offsetCommitPeriodMs", offsetCommitPeriodMs)
             .append("maxUncommittedOffsets", maxUncommittedOffsets)
diff --git a/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/trident/KafkaTridentSpoutEmitter.java b/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/trident/KafkaTridentSpoutEmitter.java
index 9f1041a8c9..db95c82843 100644
--- a/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/trident/KafkaTridentSpoutEmitter.java
+++ b/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/trident/KafkaTridentSpoutEmitter.java
@@ -246,7 +246,6 @@ private void emitTuple(TridentCollector collector, ConsumerRecord<K, V> record)
      * @return the offset of the next fetch
      */
     private long seek(TopicPartition tp, KafkaTridentSpoutBatchMetadata lastBatchMeta) {
-
         if (isFirstPollSinceExecutorStarted(tp)) {
             boolean isFirstPollSinceTopologyWasDeployed = lastBatchMeta == null 
                 || !topologyContext.getStormId().equals(lastBatchMeta.getTopologyId());
diff --git a/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/trident/KafkaTridentSpoutEmitterEmitTest.java b/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/trident/KafkaTridentSpoutEmitterEmitTest.java
index 33aa6712e0..1eedcfd7b4 100644
--- a/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/trident/KafkaTridentSpoutEmitterEmitTest.java
+++ b/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/trident/KafkaTridentSpoutEmitterEmitTest.java
@@ -322,8 +322,7 @@ public void testTimeStampStrategyWhenTopologyIsRedeployed() {
         long timeStampStartOffset = 2L;
         long pollTimeout = 1L;
         KafkaTridentSpoutBatchMetadata preExecutorRestartLastMeta = new KafkaTridentSpoutBatchMetadata(preRestartEmittedOffset, preRestartEmittedOffset + preRestartEmittedRecords - 1, "Some older topology");
-
-
+        
         KafkaConsumer<String, String> kafkaConsumer = Mockito.mock(KafkaConsumer.class);
         when(kafkaConsumer.assignment()).thenReturn(Collections.singleton(partition));
         OffsetAndTimestamp offsetAndTimestamp = new OffsetAndTimestamp(timeStampStartOffset, startTimeStamp);
