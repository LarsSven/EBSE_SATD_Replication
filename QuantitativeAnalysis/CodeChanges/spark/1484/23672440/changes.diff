diff --git a/mllib/src/main/scala/org/apache/spark/mllib/feature/ChiSqSelector.scala b/mllib/src/main/scala/org/apache/spark/mllib/feature/ChiSqSelector.scala
index 75917cf38e655..e98c142894f5d 100644
--- a/mllib/src/main/scala/org/apache/spark/mllib/feature/ChiSqSelector.scala
+++ b/mllib/src/main/scala/org/apache/spark/mllib/feature/ChiSqSelector.scala
@@ -18,8 +18,7 @@
 package org.apache.spark.mllib.feature
 
 import org.apache.spark.annotation.Experimental
-import org.apache.spark.mllib.linalg
-import org.apache.spark.mllib.linalg.{Vectors, Vector}
+import org.apache.spark.mllib.linalg.{DenseVector, SparseVector, Vectors, Vector}
 import org.apache.spark.mllib.regression.LabeledPoint
 import org.apache.spark.mllib.stat.Statistics
 import org.apache.spark.rdd.RDD
@@ -31,14 +30,14 @@ import org.apache.spark.rdd.RDD
  * @param indices list of indices to select (filter)
  */
 @Experimental
-class ChiSqSelectorModel(indices: IndexedSeq[Int]) extends VectorTransformer {
+class ChiSqSelectorModel(indices: Array[Int]) extends VectorTransformer {
   /**
    * Applies transformation on a vector.
    *
    * @param vector vector to be transformed.
    * @return transformed vector.
    */
-  override def transform(vector: linalg.Vector): linalg.Vector = {
+  override def transform(vector: Vector): Vector = {
     Compress(vector, indices)
   }
 }
@@ -46,20 +45,22 @@ class ChiSqSelectorModel(indices: IndexedSeq[Int]) extends VectorTransformer {
 /**
  * :: Experimental ::
  * Creates a ChiSquared feature selector.
+ * @param numTopFeatures number of features that selector will select
+ *                       (ordered by statistic value descending)
  */
 @Experimental
-object ChiSqSelector {
+class ChiSqSelector (val numTopFeatures: Int) {
 
   /**
    * Returns a ChiSquared feature selector.
    *
    * @param data data used to compute the Chi Squared statistic.
-   * @param numTopFeatures number of features that selector will select
-   *                       (ordered by statistic value descending)
    */
-  def fit(data: RDD[LabeledPoint], numTopFeatures: Int): ChiSqSelectorModel = {
-    val (_, indices) = Statistics.chiSqTest(data).zipWithIndex.sortBy{ case(res, index) =>
-      -res.statistic}.take(numTopFeatures).unzip
+  def fit(data: RDD[LabeledPoint]): ChiSqSelectorModel = {
+    val indices = Statistics.chiSqTest(data)
+      .zipWithIndex.sortBy { case(res, _) => -res.statistic }
+      .take(numTopFeatures)
+      .map{ case(_, indices) => indices }
     new ChiSqSelectorModel(indices)
   }
 }
@@ -71,16 +72,45 @@ object ChiSqSelector {
 @Experimental
 object Compress {
   /**
-   * Returns a vector with features filtered
+   * Returns a vector with features filtered.
+   * Preserves the order of filtered features the same as their indices are stored.
    * @param features vector
-   * @param indexes indexes of features to filter
+   * @param filterIndices indices of features to filter
    */
-  def apply(features: Vector, indexes: IndexedSeq[Int]): Vector = {
-    val (values, _) =
-      features.toArray.zipWithIndex.filter { case (value, index) =>
-        indexes.contains(index)}.unzip
-    /**  probably make a sparse vector if it was initially sparse */
-    Vectors.dense(values.toArray)
+  def apply(features: Vector, filterIndices: Array[Int]): Vector = {
+    features match {
+      case SparseVector(size, indices, values) =>
+        val filterMap = filterIndices.zipWithIndex.toMap
+        val newSize = filterIndices.length
+        var k = 0
+        var intersectionSize = 0
+        while (k < indices.length) {
+          if( filterMap.contains(indices(k))) {
+            intersectionSize += 1
+          }
+          k += 1
+        }
+        val newIndices = new Array[Int](intersectionSize)
+        val newValues = new Array[Double](intersectionSize)
+        k = 0
+        var m = 0
+        while (k < indices.length) {
+          if( filterMap.contains(indices(k))) {
+            newIndices(m) = filterMap(indices(k))
+            newValues(m) = values(k)
+            m += 1
+          }
+          k += 1
+        }
+        /** Sparse representation might be ineffective if newIndices is small */
+        Vectors.sparse(newSize, newIndices, newValues)
+      case DenseVector(values) =>
+        val values = features.toArray
+        Vectors.dense(filterIndices.map(i => values(i)))
+      case other =>
+        throw new UnsupportedOperationException(
+          s"Only sparse and dense vectors are supported but got ${other.getClass}.")
+    }
   }
 }
 
diff --git a/mllib/src/test/scala/org/apache/spark/mllib/feature/ChiSqSelectorSuite.scala b/mllib/src/test/scala/org/apache/spark/mllib/feature/ChiSqSelectorSuite.scala
index 788ff651f66ec..05864aeb9f0f8 100644
--- a/mllib/src/test/scala/org/apache/spark/mllib/feature/ChiSqSelectorSuite.scala
+++ b/mllib/src/test/scala/org/apache/spark/mllib/feature/ChiSqSelectorSuite.scala
@@ -17,19 +17,13 @@
 
 package org.apache.spark.mllib.feature
 
-import org.apache.spark.mllib.linalg.Vectors
-import org.apache.spark.mllib.regression.LabeledPoint
-import org.apache.spark.mllib.util.LocalSparkContext
 import org.scalatest.FunSuite
 
-class ChiSqSelectorSuite extends FunSuite with LocalSparkContext {
+import org.apache.spark.mllib.linalg.Vectors
+import org.apache.spark.mllib.regression.LabeledPoint
+import org.apache.spark.mllib.util.MLlibTestSparkContext
 
-  lazy val labeledDiscreteData = sc.parallelize(
-    Seq( new LabeledPoint(0.0, Vectors.dense(Array(8.0, 7.0, 0.0))),
-      new LabeledPoint(1.0, Vectors.dense(Array(0.0, 9.0, 6.0))),
-      new LabeledPoint(1.0, Vectors.dense(Array(0.0, 9.0, 8.0))),
-      new LabeledPoint(2.0, Vectors.dense(Array(8.0, 9.0, 5.0)))
-    ), 2)
+class ChiSqSelectorSuite extends FunSuite with MLlibTestSparkContext {
 
   /*
    *  Contingency tables
@@ -53,16 +47,23 @@ class ChiSqSelectorSuite extends FunSuite with LocalSparkContext {
    *  Use chi-squared calculator from Internet
    */
 
-  test("ChiSqSelector transform test") {
+  test("ChiSqSelector transform test (sparse & dense vector)") {
+    val labeledDiscreteData = sc.parallelize(
+      Seq(new LabeledPoint(0.0, Vectors.sparse(3, Array((0, 8.0), (1, 7.0)))),
+        new LabeledPoint(1.0, Vectors.sparse(3, Array((1, 9.0), (2, 6.0)))),
+        new LabeledPoint(1.0, Vectors.dense(Array(0.0, 9.0, 8.0))),
+        new LabeledPoint(2.0, Vectors.dense(Array(8.0, 9.0, 5.0)))
+      ), 2)
     val preFilteredData =
-      Set( new LabeledPoint(0.0, Vectors.dense(Array(0.0))),
+      Set(new LabeledPoint(0.0, Vectors.dense(Array(0.0))),
         new LabeledPoint(1.0, Vectors.dense(Array(6.0))),
         new LabeledPoint(1.0, Vectors.dense(Array(8.0))),
         new LabeledPoint(2.0, Vectors.dense(Array(5.0)))
       )
-    val model = ChiSqSelector.fit(labeledDiscreteData, 1)
-    val filteredData = labeledDiscreteData.map(lp =>
-      new LabeledPoint(lp.label, model.transform(lp.features))).collect().toSet
+    val model = new ChiSqSelector(1).fit(labeledDiscreteData)
+    val filteredData = labeledDiscreteData.map { lp =>
+      new LabeledPoint(lp.label, model.transform(lp.features))
+    }.collect().toSet
     assert(filteredData == preFilteredData)
   }
 }
