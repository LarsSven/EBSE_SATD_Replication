diff --git a/processing/src/main/java/io/druid/query/InsufficientResourcesException.java b/processing/src/main/java/io/druid/query/InsufficientResourcesException.java
new file mode 100644
index 00000000000..993379c2f88
--- /dev/null
+++ b/processing/src/main/java/io/druid/query/InsufficientResourcesException.java
@@ -0,0 +1,31 @@
+/*
+ * Licensed to Metamarkets Group Inc. (Metamarkets) under one
+ * or more contributor license agreements. See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership. Metamarkets licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied. See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package io.druid.query;
+
+/**
+ * This exception is thrown when the requested operation cannot be completed due to a lack of available resources.
+ */
+public class InsufficientResourcesException extends Exception
+{
+  public InsufficientResourcesException(String message)
+  {
+    super(message);
+  }
+}
diff --git a/processing/src/main/java/io/druid/query/groupby/GroupByQueryQueryToolChest.java b/processing/src/main/java/io/druid/query/groupby/GroupByQueryQueryToolChest.java
index fa952540272..1255b1756e0 100644
--- a/processing/src/main/java/io/druid/query/groupby/GroupByQueryQueryToolChest.java
+++ b/processing/src/main/java/io/druid/query/groupby/GroupByQueryQueryToolChest.java
@@ -55,7 +55,7 @@
 import io.druid.query.dimension.DefaultDimensionSpec;
 import io.druid.query.dimension.DimensionSpec;
 import io.druid.query.extraction.ExtractionFn;
-import io.druid.query.groupby.resource.GroupByQueryBrokerResource;
+import io.druid.query.groupby.resource.GroupByQueryResource;
 import io.druid.query.groupby.strategy.GroupByStrategy;
 import io.druid.query.groupby.strategy.GroupByStrategySelector;
 import org.joda.time.DateTime;
@@ -127,7 +127,7 @@ private Sequence<Row> initAndMergeGroupByResults(
   )
   {
     final GroupByStrategy groupByStrategy = strategySelector.strategize(query);
-    final GroupByQueryBrokerResource resource = groupByStrategy.prepareResource(query, false);
+    final GroupByQueryResource resource = groupByStrategy.prepareResource(query, false);
 
     return Sequences.withBaggage(
         mergeGroupByResults(
@@ -144,7 +144,7 @@ private Sequence<Row> initAndMergeGroupByResults(
   private Sequence<Row> mergeGroupByResults(
       GroupByStrategy groupByStrategy,
       final GroupByQuery query,
-      GroupByQueryBrokerResource brokerResource,
+      GroupByQueryResource resource,
       QueryRunner<Row> runner,
       Map<String, Object> context
   )
@@ -186,7 +186,7 @@ private Sequence<Row> mergeGroupByResults(
                   false
               )
           ),
-          brokerResource,
+          resource,
           runner,
           context
       );
@@ -204,7 +204,7 @@ private Sequence<Row> mergeGroupByResults(
         finalizingResults = subqueryResult;
       }
 
-      return groupByStrategy.processSubqueryResult(subquery, query, brokerResource, finalizingResults);
+      return groupByStrategy.processSubqueryResult(subquery, query, resource, finalizingResults);
     } else {
       return groupByStrategy.mergeResults(runner, query, context);
     }
diff --git a/processing/src/main/java/io/druid/query/groupby/epinephelinae/GroupByRowProcessor.java b/processing/src/main/java/io/druid/query/groupby/epinephelinae/GroupByRowProcessor.java
index 9ac1d4fdfa3..37e0b810615 100644
--- a/processing/src/main/java/io/druid/query/groupby/epinephelinae/GroupByRowProcessor.java
+++ b/processing/src/main/java/io/druid/query/groupby/epinephelinae/GroupByRowProcessor.java
@@ -41,7 +41,7 @@
 import io.druid.query.groupby.GroupByQueryConfig;
 import io.druid.query.groupby.RowBasedColumnSelectorFactory;
 import io.druid.query.groupby.epinephelinae.RowBasedGrouperHelper.RowBasedKey;
-import io.druid.query.groupby.resource.GroupByQueryBrokerResource;
+import io.druid.query.groupby.resource.GroupByQueryResource;
 import io.druid.segment.column.ValueType;
 import io.druid.segment.filter.BooleanValueMatcher;
 import io.druid.segment.filter.Filters;
@@ -63,7 +63,7 @@ public static Sequence<Row> process(
       final Sequence<Row> rows,
       final Map<String, ValueType> rowSignature,
       final GroupByQueryConfig config,
-      final GroupByQueryBrokerResource brokerResource,
+      final GroupByQueryResource resource,
       final ObjectMapper spillMapper,
       final String processingTmpDir
   )
@@ -147,7 +147,7 @@ public CloseableGrouperIterator<RowBasedKey, Row> make()
                     @Override
                     public ByteBuffer get()
                     {
-                      final ResourceHolder<ByteBuffer> mergeBufferHolder = brokerResource.getMergeBuffer();
+                      final ResourceHolder<ByteBuffer> mergeBufferHolder = resource.getMergeBuffer();
                       closeOnExit.add(mergeBufferHolder);
                       return mergeBufferHolder.get();
                     }
diff --git a/processing/src/main/java/io/druid/query/groupby/resource/GroupByQueryBrokerResource.java b/processing/src/main/java/io/druid/query/groupby/resource/GroupByQueryResource.java
similarity index 63%
rename from processing/src/main/java/io/druid/query/groupby/resource/GroupByQueryBrokerResource.java
rename to processing/src/main/java/io/druid/query/groupby/resource/GroupByQueryResource.java
index 131c8e901af..fa993af9c30 100644
--- a/processing/src/main/java/io/druid/query/groupby/resource/GroupByQueryBrokerResource.java
+++ b/processing/src/main/java/io/druid/query/groupby/resource/GroupByQueryResource.java
@@ -19,51 +19,49 @@
 
 package io.druid.query.groupby.resource;
 
-import com.google.common.base.Preconditions;
-import com.google.common.collect.Lists;
 import com.metamx.common.logger.Logger;
 import io.druid.collections.ResourceHolder;
 
 import java.io.Closeable;
 import java.nio.ByteBuffer;
+import java.util.ArrayDeque;
+import java.util.Deque;
 import java.util.List;
 
 /**
- * This class contains all resources required by the Broker during executing a group-by query.
+ * This class contains resources required for a groupBy query execution.
  * Currently, it contains only merge buffers, but any additional resources can be added in the future.
  */
-public class GroupByQueryBrokerResource implements Closeable
+public class GroupByQueryResource implements Closeable
 {
-  private static final Logger log = new Logger(GroupByQueryBrokerResource.class);
+  private static final Logger log = new Logger(GroupByQueryResource.class);
 
   private final ResourceHolder<List<ByteBuffer>> mergeBuffersHolder;
-  private final List<ByteBuffer> mergeBuffers;
+  private final Deque<ByteBuffer> mergeBuffers;
 
-  public GroupByQueryBrokerResource()
+  public GroupByQueryResource()
   {
     this.mergeBuffersHolder = null;
-    this.mergeBuffers = null;
+    this.mergeBuffers = new ArrayDeque<>();
   }
 
-  public GroupByQueryBrokerResource(ResourceHolder<List<ByteBuffer>> mergeBuffersHolder)
+  public GroupByQueryResource(ResourceHolder<List<ByteBuffer>> mergeBuffersHolder)
   {
     this.mergeBuffersHolder = mergeBuffersHolder;
-    this.mergeBuffers = Lists.newArrayList(mergeBuffersHolder.get());
+    this.mergeBuffers = new ArrayDeque<>(mergeBuffersHolder.get());
   }
 
   /**
-   * Get a merge buffer from the pre-acquired broker resources.
+   * Get a merge buffer from the pre-acquired resources.
    *
    * @return a resource holder containing a merge buffer
    *
-   * @throws IllegalStateException if this resource is not initialized with available merge buffers, or
+   * @throws IllegalStateException if this resource is initialized with empty merge buffers, or
    *                               there isn't any available merge buffers
    */
   public ResourceHolder<ByteBuffer> getMergeBuffer()
   {
-    Preconditions.checkState(mergeBuffers != null, "Resource is initialized with empty merge buffers");
-    Preconditions.checkState(mergeBuffers.size() > 0, "No available merge buffers");
-    final ByteBuffer buffer = mergeBuffers.remove(mergeBuffers.size() - 1);
+    final ByteBuffer buffer = mergeBuffers.pop();
     return new ResourceHolder<ByteBuffer>()
     {
       @Override
@@ -85,7 +83,7 @@ public void close()
   {
     if (mergeBuffersHolder != null) {
       if (mergeBuffers.size() != mergeBuffersHolder.get().size()) {
-        log.warn((mergeBuffersHolder.get().size() - mergeBuffers.size()) + " resources are not returned yet");
+        log.warn("%d resources are not returned yet", mergeBuffersHolder.get().size() - mergeBuffers.size());
       }
       mergeBuffersHolder.close();
     }
diff --git a/processing/src/main/java/io/druid/query/groupby/strategy/GroupByStrategy.java b/processing/src/main/java/io/druid/query/groupby/strategy/GroupByStrategy.java
index e5ad57c9822..7513fd0286b 100644
--- a/processing/src/main/java/io/druid/query/groupby/strategy/GroupByStrategy.java
+++ b/processing/src/main/java/io/druid/query/groupby/strategy/GroupByStrategy.java
@@ -25,7 +25,7 @@
 import io.druid.query.QueryRunner;
 import io.druid.query.QueryRunnerFactory;
 import io.druid.query.groupby.GroupByQuery;
-import io.druid.query.groupby.resource.GroupByQueryBrokerResource;
+import io.druid.query.groupby.resource.GroupByQueryResource;
 import io.druid.segment.StorageAdapter;
 
 import java.util.Map;
@@ -39,7 +39,7 @@
    * @param query a groupBy query to be processed
    * @return broker resource
    */
-  GroupByQueryBrokerResource prepareResource(GroupByQuery query, boolean willMergeRunners);
+  GroupByQueryResource prepareResource(GroupByQuery query, boolean willMergeRunners);
 
   /**
    * Indicates this strategy is cacheable or not.
@@ -60,7 +60,7 @@ Sequence<Row> mergeResults(
   Sequence<Row> processSubqueryResult(
       GroupByQuery subquery,
       GroupByQuery query,
-      GroupByQueryBrokerResource resource,
+      GroupByQueryResource resource,
       Sequence<Row> subqueryResult
   );
 
diff --git a/processing/src/main/java/io/druid/query/groupby/strategy/GroupByStrategyV1.java b/processing/src/main/java/io/druid/query/groupby/strategy/GroupByStrategyV1.java
index fb5062def37..abd6fcc32e6 100644
--- a/processing/src/main/java/io/druid/query/groupby/strategy/GroupByStrategyV1.java
+++ b/processing/src/main/java/io/druid/query/groupby/strategy/GroupByStrategyV1.java
@@ -46,7 +46,7 @@
 import io.druid.query.groupby.GroupByQueryEngine;
 import io.druid.query.groupby.GroupByQueryHelper;
 import io.druid.query.groupby.GroupByQueryQueryToolChest;
-import io.druid.query.groupby.resource.GroupByQueryBrokerResource;
+import io.druid.query.groupby.resource.GroupByQueryResource;
 import io.druid.query.spec.MultipleIntervalSegmentSpec;
 import io.druid.segment.StorageAdapter;
 import io.druid.segment.incremental.IncrementalIndex;
@@ -79,9 +79,9 @@ public GroupByStrategyV1(
   }
 
   @Override
-  public GroupByQueryBrokerResource prepareResource(GroupByQuery query, boolean willMergeRunners)
+  public GroupByQueryResource prepareResource(GroupByQuery query, boolean willMergeRunners)
   {
-    return new GroupByQueryBrokerResource();
+    return new GroupByQueryResource();
   }
 
   @Override
@@ -137,7 +137,7 @@ public Sequence<Row> mergeResults(
 
   @Override
   public Sequence<Row> processSubqueryResult(
-      GroupByQuery subquery, GroupByQuery query, GroupByQueryBrokerResource resource, Sequence<Row> subqueryResult
+      GroupByQuery subquery, GroupByQuery query, GroupByQueryResource resource, Sequence<Row> subqueryResult
   )
   {
     final Set<AggregatorFactory> aggs = Sets.newHashSet();
diff --git a/processing/src/main/java/io/druid/query/groupby/strategy/GroupByStrategyV2.java b/processing/src/main/java/io/druid/query/groupby/strategy/GroupByStrategyV2.java
index 440729da890..d69047898da 100644
--- a/processing/src/main/java/io/druid/query/groupby/strategy/GroupByStrategyV2.java
+++ b/processing/src/main/java/io/druid/query/groupby/strategy/GroupByStrategyV2.java
@@ -51,6 +51,7 @@
 import io.druid.query.QueryRunner;
 import io.druid.query.QueryWatcher;
 import io.druid.query.ResourceLimitExceededException;
+import io.druid.query.InsufficientResourcesException;
 import io.druid.query.ResultMergeQueryRunner;
 import io.druid.query.aggregation.PostAggregator;
 import io.druid.query.groupby.GroupByQuery;
@@ -60,20 +61,21 @@
 import io.druid.query.groupby.epinephelinae.GroupByMergingQueryRunnerV2;
 import io.druid.query.groupby.epinephelinae.GroupByQueryEngineV2;
 import io.druid.query.groupby.epinephelinae.GroupByRowProcessor;
-import io.druid.query.groupby.resource.GroupByQueryBrokerResource;
+import io.druid.query.groupby.resource.GroupByQueryResource;
 import io.druid.segment.StorageAdapter;
 import org.joda.time.DateTime;
 
 import java.nio.ByteBuffer;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.TimeoutException;
 
 public class GroupByStrategyV2 implements GroupByStrategy
 {
   public static final String CTX_KEY_FUDGE_TIMESTAMP = "fudgeTimestamp";
   public static final String CTX_KEY_OUTERMOST = "groupByOutermost";
 
+  private static final int MAX_MERGE_BUFFER_NUM = 2;
+
   private final DruidProcessingConfig processingConfig;
   private final Supplier<GroupByQueryConfig> configSupplier;
   private final StupidPool<ByteBuffer> bufferPool;
@@ -123,16 +125,10 @@ public static DateTime getUniversalTimestamp(final GroupByQuery query)
   }
 
   @Override
-  public GroupByQueryBrokerResource prepareResource(GroupByQuery query, boolean willMergeRunners)
+  public GroupByQueryResource prepareResource(GroupByQuery query, boolean willMergeRunners)
   {
     if (!willMergeRunners) {
-      // Note: A broker requires merge buffers for processing the groupBy layers beyond the inner-most one.
-      // For example, the number of required merge buffers for a nested groupBy (groupBy -> groupBy -> table) is 1.
-      // If the broker processes an outer groupBy which reads input from an inner groupBy,
-      // it requires two merge buffers for inner and outer groupBys to keep the intermediate result of inner groupBy
-      // until the outer groupBy processing completes.
-      // This is same for subsequent groupBy layers, and thus the maximum number of required merge buffers becomes 2.
-      final int requiredMergeBufferNum = countRequiredMergeBufferNum(query, 2, 1);
+      final int requiredMergeBufferNum = countRequiredMergeBufferNum(query, 1);
 
       if (requiredMergeBufferNum > mergeBufferPool.maxSize()) {
         throw new ResourceLimitExceededException(
@@ -140,7 +136,7 @@ public GroupByQueryBrokerResource prepareResource(GroupByQuery query, boolean wi
             + mergeBufferPool.maxSize() + " merge buffers are configured"
         );
       } else if (requiredMergeBufferNum == 0) {
-        return new GroupByQueryBrokerResource();
+        return new GroupByQueryResource();
       } else {
         final Number timeout = query.getContextValue(QueryContextKeys.TIMEOUT, JodaUtils.MAX_INSTANT);
         final ResourceHolder<List<ByteBuffer>> mergeBufferHolders;
@@ -149,9 +145,9 @@ public GroupByQueryBrokerResource prepareResource(GroupByQuery query, boolean wi
           mergeBufferHolders = mergeBufferPool.drain(requiredMergeBufferNum, timeout.longValue());
           if (mergeBufferHolders.get().size() < requiredMergeBufferNum) {
             mergeBufferHolders.close();
-            throw new TimeoutException("Cannot acquire enough merge buffers");
+            throw new InsufficientResourcesException("Cannot acquire enough merge buffers");
           } else {
-            return new GroupByQueryBrokerResource(mergeBufferHolders);
+            return new GroupByQueryResource(mergeBufferHolders);
           }
         }
         catch (Exception e) {
@@ -159,17 +155,24 @@ public GroupByQueryBrokerResource prepareResource(GroupByQuery query, boolean wi
         }
       }
     } else {
-      return new GroupByQueryBrokerResource();
+      return new GroupByQueryResource();
     }
   }
 
-  private static int countRequiredMergeBufferNum(Query query, int maxBufferNum, int foundNum)
+  private static int countRequiredMergeBufferNum(Query query, int foundNum)
   {
+    // Note: A broker requires merge buffers for processing the groupBy layers beyond the inner-most one.
+    // For example, the number of required merge buffers for a nested groupBy (groupBy -> groupBy -> table) is 1.
+    // If the broker processes an outer groupBy which reads input from an inner groupBy,
+    // it requires two merge buffers for inner and outer groupBys to keep the intermediate result of inner groupBy
+    // until the outer groupBy processing completes.
+    // This is same for subsequent groupBy layers, and thus the maximum number of required merge buffers becomes 2.
+
     final DataSource dataSource = query.getDataSource();
-    if (foundNum == maxBufferNum + 1 || !(dataSource instanceof QueryDataSource)) {
+    if (foundNum == MAX_MERGE_BUFFER_NUM + 1 || !(dataSource instanceof QueryDataSource)) {
       return foundNum - 1;
     } else {
-      return countRequiredMergeBufferNum(((QueryDataSource) dataSource).getQuery(), maxBufferNum, foundNum + 1);
+      return countRequiredMergeBufferNum(((QueryDataSource) dataSource).getQuery(), foundNum + 1);
     }
   }
 
@@ -271,7 +274,7 @@ public Row apply(final Row row)
   public Sequence<Row> processSubqueryResult(
       GroupByQuery subquery,
       GroupByQuery query,
-      GroupByQueryBrokerResource resource,
+      GroupByQueryResource resource,
       Sequence<Row> subqueryResult
   )
   {
