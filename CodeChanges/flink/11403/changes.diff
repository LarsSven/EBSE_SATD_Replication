diff --git a/flink-libraries/flink-state-processing-api/src/main/java/org/apache/flink/state/api/output/BoundedStreamTask.java b/flink-libraries/flink-state-processing-api/src/main/java/org/apache/flink/state/api/output/BoundedStreamTask.java
index 60f195882fb6d..488740e9f5c1d 100644
--- a/flink-libraries/flink-state-processing-api/src/main/java/org/apache/flink/state/api/output/BoundedStreamTask.java
+++ b/flink-libraries/flink-state-processing-api/src/main/java/org/apache/flink/state/api/output/BoundedStreamTask.java
@@ -81,7 +81,7 @@ protected void init() throws Exception {
 				configuration,
 				new CollectorWrapper<>(collector));
 		headOperator = headOperatorAndTimeService.f0;
-		headOperator.initializeState();
+		headOperator.initializeState(createStreamTaskStateInitializer());
 		headOperator.open();
 	}
 
diff --git a/flink-libraries/flink-state-processing-api/src/test/java/org/apache/flink/state/api/output/SnapshotUtilsTest.java b/flink-libraries/flink-state-processing-api/src/test/java/org/apache/flink/state/api/output/SnapshotUtilsTest.java
index 01bcbbc776654..35266ef8c314c 100644
--- a/flink-libraries/flink-state-processing-api/src/test/java/org/apache/flink/state/api/output/SnapshotUtilsTest.java
+++ b/flink-libraries/flink-state-processing-api/src/test/java/org/apache/flink/state/api/output/SnapshotUtilsTest.java
@@ -26,9 +26,9 @@
 import org.apache.flink.runtime.state.CheckpointStorageWorkerView;
 import org.apache.flink.runtime.state.CheckpointStreamFactory;
 import org.apache.flink.runtime.state.ttl.mock.MockStateBackend;
-import org.apache.flink.streaming.api.operators.ChainingStrategy;
 import org.apache.flink.streaming.api.operators.OperatorSnapshotFutures;
 import org.apache.flink.streaming.api.operators.StreamOperator;
+import org.apache.flink.streaming.api.operators.StreamTaskStateInitializer;
 import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
 
 import org.junit.Assert;
@@ -99,7 +99,7 @@ public OperatorSnapshotFutures snapshotState(long checkpointId, long timestamp,
 		}
 
 		@Override
-		public void initializeState() throws Exception {
+		public void initializeState(StreamTaskStateInitializer streamTaskStateManager) throws Exception {
 			ACTUAL_ORDER_TRACKING.add("initializeState");
 		}
 
@@ -113,17 +113,6 @@ public void setKeyContextElement2(StreamRecord<?> record) throws Exception {
 			ACTUAL_ORDER_TRACKING.add("setKeyContextElement2");
 		}
 
-		@Override
-		public ChainingStrategy getChainingStrategy() {
-			ACTUAL_ORDER_TRACKING.add("getChainingStrategy");
-			return null;
-		}
-
-		@Override
-		public void setChainingStrategy(ChainingStrategy strategy) {
-			ACTUAL_ORDER_TRACKING.add("setChainingStrategy");
-		}
-
 		@Override
 		public MetricGroup getMetricGroup() {
 			ACTUAL_ORDER_TRACKING.add("getMetricGroup");
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/state/AbstractKeyedStateBackend.java b/flink-runtime/src/main/java/org/apache/flink/runtime/state/AbstractKeyedStateBackend.java
index a06030cfa7ae0..27cd0586dee76 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/state/AbstractKeyedStateBackend.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/state/AbstractKeyedStateBackend.java
@@ -356,6 +356,11 @@ public StreamCompressionDecorator getKeyGroupCompressionDecorator() {
 	@VisibleForTesting
 	public abstract int numKeyValueStateEntries();
 
+	@VisibleForTesting
+	public int numKeyValueStatesByName() {
+		return keyValueStatesByName.size();
+	}
+
 	// TODO remove this once heap-based timers are working with RocksDB incremental snapshots!
 	public boolean requiresLegacySynchronousTimerSnapshots() {
 		return false;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/state/StateSnapshotContextSynchronousImpl.java b/flink-runtime/src/main/java/org/apache/flink/runtime/state/StateSnapshotContextSynchronousImpl.java
index 1e5267693884c..1f19d32b84638 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/state/StateSnapshotContextSynchronousImpl.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/state/StateSnapshotContextSynchronousImpl.java
@@ -59,8 +59,8 @@ public class StateSnapshotContextSynchronousImpl implements StateSnapshotContext
 	/** Output stream for the raw operator state. */
 	private OperatorStateCheckpointOutputStream operatorStateCheckpointOutputStream;
 
-	private RunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateCheckpointClosingFuture;
-	private RunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateCheckpointClosingFuture;
+	protected RunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateCheckpointClosingFuture;
+	protected RunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateCheckpointClosingFuture;
 
 	@VisibleForTesting
 	public StateSnapshotContextSynchronousImpl(long checkpointId, long checkpointTimestamp) {
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/ExpectedTestException.java b/flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/ExpectedTestException.java
index e4a714a8fb5d7..5cb67e57a67ab 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/ExpectedTestException.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/ExpectedTestException.java
@@ -26,7 +26,9 @@
 @SuppressWarnings("serial")
 public class ExpectedTestException extends RuntimeException
 {
+	public static final String MESSAGE = "Expected Test Exception";
+
 	public ExpectedTestException() {
-		super("Expected Test Exception");
+		super(MESSAGE);
 	}
 }
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperatorFactory.java
index 559fd9ef119b7..97a367321d6f9 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperatorFactory.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperatorFactory.java
@@ -20,15 +20,13 @@
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.io.FileInputFormat;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
-import org.apache.flink.streaming.api.graph.StreamConfig;
 import org.apache.flink.streaming.api.operators.AbstractStreamOperatorFactory;
 import org.apache.flink.streaming.api.operators.ChainingStrategy;
 import org.apache.flink.streaming.api.operators.MailboxExecutor;
 import org.apache.flink.streaming.api.operators.OneInputStreamOperatorFactory;
-import org.apache.flink.streaming.api.operators.Output;
 import org.apache.flink.streaming.api.operators.StreamOperator;
+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;
 import org.apache.flink.streaming.api.operators.YieldingOperatorFactory;
-import org.apache.flink.streaming.runtime.tasks.StreamTask;
 
 /**
  * {@link ContinuousFileReaderOperator} factory.
@@ -58,11 +56,11 @@ public void setMailboxExecutor(MailboxExecutor mailboxExecutor) {
 	}
 
 	@Override
-	public StreamOperator createStreamOperator(StreamTask containingTask, StreamConfig config, Output output) {
+	public <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorParameters<OUT> parameters) {
 		ContinuousFileReaderOperator<OUT> operator = new ContinuousFileReaderOperator<>(inputFormat, processingTimeService, mailboxExecutor);
-		operator.setup(containingTask, config, output);
+		operator.setup(parameters.getContainingTask(), parameters.getStreamConfig(), parameters.getOutput());
 		operator.setOutputType(type, executionConfig);
-		return operator;
+		return (T) operator;
 	}
 
 	@Override
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperator.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperator.java
index 532c57f1be529..61925f4138374 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperator.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperator.java
@@ -29,53 +29,36 @@
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.MetricOptions;
 import org.apache.flink.core.fs.CloseableRegistry;
-import org.apache.flink.core.memory.DataOutputViewStreamWrapper;
-import org.apache.flink.metrics.Counter;
 import org.apache.flink.metrics.MetricGroup;
-import org.apache.flink.runtime.checkpoint.CheckpointException;
-import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;
 import org.apache.flink.runtime.checkpoint.CheckpointOptions;
 import org.apache.flink.runtime.execution.Environment;
 import org.apache.flink.runtime.jobgraph.OperatorID;
 import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;
 import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;
 import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;
-import org.apache.flink.runtime.state.AbstractKeyedStateBackend;
 import org.apache.flink.runtime.state.CheckpointStreamFactory;
-import org.apache.flink.runtime.state.DefaultKeyedStateStore;
-import org.apache.flink.runtime.state.KeyGroupRange;
-import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;
-import org.apache.flink.runtime.state.KeyGroupsList;
 import org.apache.flink.runtime.state.KeyedStateBackend;
-import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;
 import org.apache.flink.runtime.state.OperatorStateBackend;
 import org.apache.flink.runtime.state.StateInitializationContext;
-import org.apache.flink.runtime.state.StateInitializationContextImpl;
-import org.apache.flink.runtime.state.StatePartitionStreamProvider;
 import org.apache.flink.runtime.state.StateSnapshotContext;
-import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;
 import org.apache.flink.runtime.state.VoidNamespace;
 import org.apache.flink.runtime.state.VoidNamespaceSerializer;
 import org.apache.flink.streaming.api.graph.StreamConfig;
+import org.apache.flink.streaming.api.operators.StreamOperatorStateHandler.CheckpointedStreamOperator;
 import org.apache.flink.streaming.api.watermark.Watermark;
 import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;
 import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
 import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;
 import org.apache.flink.streaming.runtime.tasks.StreamTask;
 import org.apache.flink.streaming.util.LatencyStats;
-import org.apache.flink.util.CloseableIterable;
-import org.apache.flink.util.ExceptionUtils;
-import org.apache.flink.util.IOUtils;
-import org.apache.flink.util.OutputTag;
 import org.apache.flink.util.Preconditions;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import java.io.Closeable;
-import java.io.IOException;
 import java.io.Serializable;
 import java.util.Locale;
+import java.util.Optional;
 
 /**
  * Base class for all stream operators. Operators that contain a user function should extend the class
@@ -89,11 +72,15 @@
  * the timer service, timer callbacks are also guaranteed not to be called concurrently with
  * methods on {@code StreamOperator}.
  *
- * @param <OUT> The output type of the operator
+ * <p>Note, this class is going to be removed and replaced in the future by {@link AbstractStreamOperatorV2}.
+ * However as {@link AbstractStreamOperatorV2} is currently experimental, {@link AbstractStreamOperator}
+ * has not been deprecated just yet.
+ *
+ * @param <OUT> The output type of the operator.
  */
 @PublicEvolving
 public abstract class AbstractStreamOperator<OUT>
-		implements StreamOperator<OUT>, SetupableStreamOperator<OUT>, Serializable {
+		implements StreamOperator<OUT>, SetupableStreamOperator<OUT>, CheckpointedStreamOperator, Serializable {
 
 	private static final long serialVersionUID = 1L;
 
@@ -135,16 +122,9 @@
 	 */
 	private transient KeySelector<?, ?> stateKeySelector2;
 
-	/** Backend for keyed state. This might be empty if we're not on a keyed stream. */
-	private transient AbstractKeyedStateBackend<?> keyedStateBackend;
-
-	/** Keyed state store view on the keyed backend. */
-	private transient DefaultKeyedStateStore keyedStateStore;
+	private transient StreamOperatorStateHandler stateHandler;
 
-	// ---------------- operator state ------------------
-
-	/** Operator state backend / store. */
-	private transient OperatorStateBackend operatorStateBackend;
+	private transient InternalTimeServiceManager<?> timeServiceManager;
 
 	// --------------- Metrics ---------------------------
 
@@ -156,7 +136,6 @@
 	// ---------------- time handler ------------------
 
 	protected transient ProcessingTimeService processingTimeService;
-	protected transient InternalTimeServiceManager<?> timeServiceManager;
 
 	// ---------------- two-input operator watermarks ------------------
 
@@ -227,7 +206,13 @@ public void setup(StreamTask<?, ?> containingTask, StreamConfig config, Output<S
 				LatencyStats.Granularity.SINGLE);
 		}
 
-		this.runtimeContext = new StreamingRuntimeContext(this, environment, environment.getAccumulatorRegistry().getUserMap());
+		this.runtimeContext = new StreamingRuntimeContext(
+			environment,
+			environment.getAccumulatorRegistry().getUserMap(),
+			getMetricGroup(),
+			getOperatorID(),
+			getProcessingTimeService(),
+			null);
 
 		stateKeySelector1 = config.getStatePartitioner(0, getUserCodeClassloader());
 		stateKeySelector2 = config.getStatePartitioner(1, getUserCodeClassloader());
@@ -248,7 +233,7 @@ public MetricGroup getMetricGroup() {
 	}
 
 	@Override
-	public final void initializeState() throws Exception {
+	public final void initializeState(StreamTaskStateInitializer streamTaskStateManager) throws Exception {
 
 		final TypeSerializer<?> keySerializer = config.getStateKeySerializer(getUserCodeClassloader());
 
@@ -256,8 +241,6 @@ public final void initializeState() throws Exception {
 			Preconditions.checkNotNull(getContainingTask());
 		final CloseableRegistry streamTaskCloseableRegistry =
 			Preconditions.checkNotNull(containingTask.getCancelables());
-		final StreamTaskStateInitializer streamTaskStateManager =
-			Preconditions.checkNotNull(containingTask.createStreamTaskStateInitializer());
 
 		final StreamOperatorStateContext context =
 			streamTaskStateManager.streamOperatorStateContext(
@@ -269,37 +252,10 @@ public final void initializeState() throws Exception {
 				streamTaskCloseableRegistry,
 				metrics);
 
-		this.operatorStateBackend = context.operatorStateBackend();
-		this.keyedStateBackend = context.keyedStateBackend();
-
-		if (keyedStateBackend != null) {
-			this.keyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, getExecutionConfig());
-		}
-
+		stateHandler = new StreamOperatorStateHandler(context, getExecutionConfig(), streamTaskCloseableRegistry);
 		timeServiceManager = context.internalTimerServiceManager();
-
-		CloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();
-		CloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();
-
-		try {
-			StateInitializationContext initializationContext = new StateInitializationContextImpl(
-				context.isRestored(), // information whether we restore or start for the first time
-				operatorStateBackend, // access to operator state backend
-				keyedStateStore, // access to keyed state backend
-				keyedStateInputs, // access to keyed state stream
-				operatorStateInputs); // access to operator state stream
-
-			initializeState(initializationContext);
-		} finally {
-			closeFromRegistry(operatorStateInputs, streamTaskCloseableRegistry);
-			closeFromRegistry(keyedStateInputs, streamTaskCloseableRegistry);
-		}
-	}
-
-	private static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {
-		if (registry.unregisterCloseable(closeable)) {
-			IOUtils.closeQuietly(closeable);
-		}
+		stateHandler.initializeOperatorState(this);
+		runtimeContext.setKeyedStateStore(stateHandler.getKeyedStateStore().orElse(null));
 	}
 
 	/**
@@ -337,50 +293,8 @@ public void close() throws Exception {}
 	 */
 	@Override
 	public void dispose() throws Exception {
-
-		Exception exception = null;
-
-		StreamTask<?, ?> containingTask = getContainingTask();
-		CloseableRegistry taskCloseableRegistry = containingTask != null ?
-			containingTask.getCancelables() :
-			null;
-
-		try {
-			if (taskCloseableRegistry == null ||
-				taskCloseableRegistry.unregisterCloseable(operatorStateBackend)) {
-				operatorStateBackend.close();
-			}
-		} catch (Exception e) {
-			exception = e;
-		}
-
-		try {
-			if (taskCloseableRegistry == null ||
-				taskCloseableRegistry.unregisterCloseable(keyedStateBackend)) {
-				keyedStateBackend.close();
-			}
-		} catch (Exception e) {
-			exception = ExceptionUtils.firstOrSuppressed(e, exception);
-		}
-
-		try {
-			if (operatorStateBackend != null) {
-				operatorStateBackend.dispose();
-			}
-		} catch (Exception e) {
-			exception = ExceptionUtils.firstOrSuppressed(e, exception);
-		}
-
-		try {
-			if (keyedStateBackend != null) {
-				keyedStateBackend.dispose();
-			}
-		} catch (Exception e) {
-			exception = ExceptionUtils.firstOrSuppressed(e, exception);
-		}
-
-		if (exception != null) {
-			throw exception;
+		if (stateHandler != null) {
+			stateHandler.dispose();
 		}
 	}
 
@@ -391,58 +305,19 @@ public void prepareSnapshotPreBarrier(long checkpointId) throws Exception {
 	}
 
 	@Override
-	public final OperatorSnapshotFutures snapshotState(long checkpointId, long timestamp, CheckpointOptions checkpointOptions,
+	public final OperatorSnapshotFutures snapshotState(
+			long checkpointId,
+			long timestamp,
+			CheckpointOptions checkpointOptions,
 			CheckpointStreamFactory factory) throws Exception {
-
-		KeyGroupRange keyGroupRange = null != keyedStateBackend ?
-				keyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;
-
-		OperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();
-
-		StateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(
+		return stateHandler.snapshotState(
+			this,
+			Optional.ofNullable(timeServiceManager),
+			getOperatorName(),
 			checkpointId,
 			timestamp,
-			factory,
-			keyGroupRange,
-			getContainingTask().getCancelables());
-
-		try {
-			snapshotState(snapshotContext);
-
-			snapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());
-			snapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());
-
-			if (null != operatorStateBackend) {
-				snapshotInProgress.setOperatorStateManagedFuture(
-					operatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));
-			}
-
-			if (null != keyedStateBackend) {
-				snapshotInProgress.setKeyedStateManagedFuture(
-					keyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));
-			}
-		} catch (Exception snapshotException) {
-			try {
-				snapshotInProgress.cancel();
-			} catch (Exception e) {
-				snapshotException.addSuppressed(e);
-			}
-
-			String snapshotFailMessage = "Could not complete snapshot " + checkpointId + " for operator " +
-				getOperatorName() + ".";
-
-			if (!getContainingTask().isCanceled()) {
-				LOG.info(snapshotFailMessage, snapshotException);
-			}
-			try {
-				snapshotContext.closeExceptionally();
-			} catch (IOException e) {
-				snapshotException.addSuppressed(e);
-			}
-			throw new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);
-		}
-
-		return snapshotInProgress;
+			checkpointOptions,
+			factory);
 	}
 
 	/**
@@ -450,41 +325,8 @@ public final OperatorSnapshotFutures snapshotState(long checkpointId, long times
 	 *
 	 * @param context context that provides information and means required for taking a snapshot
 	 */
+	@Override
 	public void snapshotState(StateSnapshotContext context) throws Exception {
-		final KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();
-		//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots
-		if (keyedStateBackend instanceof AbstractKeyedStateBackend &&
-			((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {
-
-			KeyedStateCheckpointOutputStream out;
-
-			try {
-				out = context.getRawKeyedOperatorStateOutput();
-			} catch (Exception exception) {
-				throw new Exception("Could not open raw keyed operator state stream for " +
-					getOperatorName() + '.', exception);
-			}
-
-			try {
-				KeyGroupsList allKeyGroups = out.getKeyGroupList();
-				for (int keyGroupIdx : allKeyGroups) {
-					out.startNewKeyGroup(keyGroupIdx);
-
-					timeServiceManager.snapshotStateForKeyGroup(
-						new DataOutputViewStreamWrapper(out), keyGroupIdx);
-				}
-			} catch (Exception exception) {
-				throw new Exception("Could not write timer service of " + getOperatorName() +
-					" to checkpoint state stream.", exception);
-			} finally {
-				try {
-					out.close();
-				} catch (Exception closeException) {
-					LOG.warn("Could not close raw keyed operator state stream for {}. This " +
-						"might have prevented deleting some state data.", getOperatorName(), closeException);
-				}
-			}
-		}
 	}
 
 	/**
@@ -492,15 +334,13 @@ public void snapshotState(StateSnapshotContext context) throws Exception {
 	 *
 	 * @param context context that allows to register different states.
 	 */
+	@Override
 	public void initializeState(StateInitializationContext context) throws Exception {
-
 	}
 
 	@Override
 	public void notifyCheckpointComplete(long checkpointId) throws Exception {
-		if (keyedStateBackend != null) {
-			keyedStateBackend.notifyCheckpointComplete(checkpointId);
-		}
+		stateHandler.notifyCheckpointComplete(checkpointId);
 	}
 
 	// ------------------------------------------------------------------------
@@ -549,23 +389,27 @@ protected String getOperatorName() {
 	 * to interact with systems such as broadcast variables and managed state. This also allows
 	 * to register timers.
 	 */
+	@VisibleForTesting
 	public StreamingRuntimeContext getRuntimeContext() {
 		return runtimeContext;
 	}
 
 	@SuppressWarnings("unchecked")
+	@VisibleForTesting
 	public <K> KeyedStateBackend<K> getKeyedStateBackend() {
-		return (KeyedStateBackend<K>) keyedStateBackend;
+		return stateHandler.getKeyedStateBackend();
 	}
 
+	@VisibleForTesting
 	public OperatorStateBackend getOperatorStateBackend() {
-		return operatorStateBackend;
+		return stateHandler.getOperatorStateBackend();
 	}
 
 	/**
 	 * Returns the {@link ProcessingTimeService} responsible for getting the current
 	 * processing time and registering timers.
 	 */
+	@VisibleForTesting
 	public ProcessingTimeService getProcessingTimeService() {
 		return processingTimeService;
 	}
@@ -583,15 +427,7 @@ protected <S extends State> S getPartitionedState(StateDescriptor<S, ?> stateDes
 	protected <N, S extends State, T> S getOrCreateKeyedState(
 			TypeSerializer<N> namespaceSerializer,
 			StateDescriptor<S, T> stateDescriptor) throws Exception {
-
-		if (keyedStateStore != null) {
-			return keyedStateBackend.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);
-		}
-		else {
-			throw new IllegalStateException("Cannot create partitioned state. " +
-					"The keyed state backend has not been set." +
-					"This indicates that the operator is not partitioned/keyed.");
-		}
+		return stateHandler.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);
 	}
 
 	/**
@@ -604,20 +440,7 @@ protected <S extends State, N> S getPartitionedState(
 			N namespace,
 			TypeSerializer<N> namespaceSerializer,
 			StateDescriptor<S, ?> stateDescriptor) throws Exception {
-
-		/*
-	    TODO: NOTE: This method does a lot of work caching / retrieving states just to update the namespace.
-	    This method should be removed for the sake of namespaces being lazily fetched from the keyed
-	    state backend, or being set on the state directly.
-	    */
-
-		if (keyedStateStore != null) {
-			return keyedStateBackend.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);
-		} else {
-			throw new RuntimeException("Cannot create partitioned state. The keyed state " +
-				"backend has not been set. This indicates that the operator is not " +
-				"partitioned/keyed.");
-		}
+		return stateHandler.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);
 	}
 
 	@Override
@@ -641,30 +464,19 @@ private <T> void setKeyContextElement(StreamRecord<T> record, KeySelector<T, ?>
 
 	@SuppressWarnings({"unchecked", "rawtypes"})
 	public void setCurrentKey(Object key) {
-		if (keyedStateBackend != null) {
-			try {
-				// need to work around type restrictions
-				@SuppressWarnings("unchecked,rawtypes")
-				AbstractKeyedStateBackend rawBackend = (AbstractKeyedStateBackend) keyedStateBackend;
-
-				rawBackend.setCurrentKey(key);
-			} catch (Exception e) {
-				throw new RuntimeException("Exception occurred while setting the current key context.", e);
-			}
-		}
+		stateHandler.setCurrentKey(key);
 	}
 
 	@SuppressWarnings({"unchecked", "rawtypes"})
 	public Object getCurrentKey() {
-		if (keyedStateBackend != null) {
-			return keyedStateBackend.getCurrentKey();
-		} else {
-			throw new UnsupportedOperationException("Key can only be retrieved on KeyedStream.");
-		}
+		return stateHandler.getCurrentKey();
 	}
 
 	public KeyedStateStore getKeyedStateStore() {
-		return keyedStateStore;
+		if (stateHandler == null) {
+			return null;
+		}
+		return stateHandler.getKeyedStateStore().orElse(null);
 	}
 
 	// ------------------------------------------------------------------------
@@ -707,48 +519,6 @@ protected void reportOrForwardLatencyMarker(LatencyMarker marker) {
 		this.output.emitLatencyMarker(marker);
 	}
 
-	// ----------------------- Helper classes -----------------------
-
-	/**
-	 * Wrapping {@link Output} that updates metrics on the number of emitted elements.
-	 */
-	public static class CountingOutput<OUT> implements Output<StreamRecord<OUT>> {
-		private final Output<StreamRecord<OUT>> output;
-		private final Counter numRecordsOut;
-
-		public CountingOutput(Output<StreamRecord<OUT>> output, Counter counter) {
-			this.output = output;
-			this.numRecordsOut = counter;
-		}
-
-		@Override
-		public void emitWatermark(Watermark mark) {
-			output.emitWatermark(mark);
-		}
-
-		@Override
-		public void emitLatencyMarker(LatencyMarker latencyMarker) {
-			output.emitLatencyMarker(latencyMarker);
-		}
-
-		@Override
-		public void collect(StreamRecord<OUT> record) {
-			numRecordsOut.inc();
-			output.collect(record);
-		}
-
-		@Override
-		public <X> void collect(OutputTag<X> outputTag, StreamRecord<X> record) {
-			numRecordsOut.inc();
-			output.collect(outputTag, record);
-		}
-
-		@Override
-		public void close() {
-			output.close();
-		}
-	}
-
 	// ------------------------------------------------------------------------
 	//  Watermark handling
 	// ------------------------------------------------------------------------
@@ -778,15 +548,15 @@ public <K, N> InternalTimerService<N> getInternalTimerService(
 			String name,
 			TypeSerializer<N> namespaceSerializer,
 			Triggerable<K, N> triggerable) {
-
-		checkTimerServiceInitialization();
-
-		// the following casting is to overcome type restrictions.
-		KeyedStateBackend<K> keyedStateBackend = getKeyedStateBackend();
-		TypeSerializer<K> keySerializer = keyedStateBackend.getKeySerializer();
+		if (timeServiceManager == null) {
+			throw new RuntimeException("The timer service has not been initialized.");
+		}
 		InternalTimeServiceManager<K> keyedTimeServiceHandler = (InternalTimeServiceManager<K>) timeServiceManager;
-		TimerSerializer<K, N> timerSerializer = new TimerSerializer<>(keySerializer, namespaceSerializer);
-		return keyedTimeServiceHandler.getInternalTimerService(name, timerSerializer, triggerable);
+		return keyedTimeServiceHandler.getInternalTimerService(
+			name,
+			namespaceSerializer,
+			triggerable,
+			stateHandler.getKeyedStateBackend());
 	}
 
 	public void processWatermark(Watermark mark) throws Exception {
@@ -796,14 +566,6 @@ public void processWatermark(Watermark mark) throws Exception {
 		output.emitWatermark(mark);
 	}
 
-	private void checkTimerServiceInitialization() {
-		if (getKeyedStateBackend() == null) {
-			throw new UnsupportedOperationException("Timers can only be used on keyed operators.");
-		} else if (timeServiceManager == null) {
-			throw new RuntimeException("The timer service has not been initialized.");
-		}
-	}
-
 	public void processWatermark1(Watermark mark) throws Exception {
 		input1Watermark = mark.getTimestamp();
 		long newMin = Math.min(input1Watermark, input2Watermark);
@@ -829,13 +591,15 @@ public OperatorID getOperatorID() {
 
 	@VisibleForTesting
 	public int numProcessingTimeTimers() {
-		return timeServiceManager == null ? 0 :
-			timeServiceManager.numProcessingTimeTimers();
+		return timeServiceManager == null ? 0 : timeServiceManager.numProcessingTimeTimers();
 	}
 
 	@VisibleForTesting
 	public int numEventTimeTimers() {
-		return timeServiceManager == null ? 0 :
-			timeServiceManager.numEventTimeTimers();
+		return timeServiceManager == null ? 0 : timeServiceManager.numEventTimeTimers();
+	}
+
+	protected Optional<InternalTimeServiceManager<?>> getTimeServiceManager() {
+		return Optional.ofNullable(timeServiceManager);
 	}
 }
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorFactory.java
index f29c860a572a1..23fa40d75ebbf 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorFactory.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorFactory.java
@@ -17,6 +17,7 @@
 
 package org.apache.flink.streaming.api.operators;
 
+import org.apache.flink.annotation.Experimental;
 import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;
 import org.apache.flink.streaming.runtime.tasks.ProcessingTimeServiceAware;
 
@@ -25,6 +26,7 @@
  * {@link ProcessingTimeServiceAware} interface which enables stream operators to access
  * {@link ProcessingTimeService}.
  */
+@Experimental
 public abstract class AbstractStreamOperatorFactory<OUT> implements StreamOperatorFactory<OUT>, ProcessingTimeServiceAware {
 
 	protected ChainingStrategy chainingStrategy = ChainingStrategy.ALWAYS;
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java
new file mode 100644
index 0000000000000..a4ad021d2438d
--- /dev/null
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java
@@ -0,0 +1,507 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.api.operators;
+
+import org.apache.flink.annotation.Experimental;
+import org.apache.flink.annotation.VisibleForTesting;
+import org.apache.flink.api.common.ExecutionConfig;
+import org.apache.flink.api.common.state.KeyedStateStore;
+import org.apache.flink.api.common.state.State;
+import org.apache.flink.api.common.state.StateDescriptor;
+import org.apache.flink.api.common.typeutils.TypeSerializer;
+import org.apache.flink.api.java.functions.KeySelector;
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.MetricOptions;
+import org.apache.flink.core.fs.CloseableRegistry;
+import org.apache.flink.metrics.MetricGroup;
+import org.apache.flink.runtime.checkpoint.CheckpointOptions;
+import org.apache.flink.runtime.execution.Environment;
+import org.apache.flink.runtime.jobgraph.OperatorID;
+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;
+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;
+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;
+import org.apache.flink.runtime.state.CheckpointStreamFactory;
+import org.apache.flink.runtime.state.KeyedStateBackend;
+import org.apache.flink.runtime.state.OperatorStateBackend;
+import org.apache.flink.runtime.state.StateInitializationContext;
+import org.apache.flink.runtime.state.StateSnapshotContext;
+import org.apache.flink.runtime.state.VoidNamespace;
+import org.apache.flink.runtime.state.VoidNamespaceSerializer;
+import org.apache.flink.streaming.api.graph.StreamConfig;
+import org.apache.flink.streaming.api.operators.StreamOperatorStateHandler.CheckpointedStreamOperator;
+import org.apache.flink.streaming.api.watermark.Watermark;
+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;
+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;
+import org.apache.flink.streaming.runtime.tasks.StreamTask;
+import org.apache.flink.streaming.util.LatencyStats;
+import org.apache.flink.util.Preconditions;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.Locale;
+import java.util.Optional;
+
+/**
+ * New base class for all stream operators, intended to eventually replace {@link AbstractStreamOperator}.
+ * Currently intended to work smoothly just with {@link MultipleInputStreamOperator}.
+ *
+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of
+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation
+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.
+ *
+ * <p>Methods are guaranteed not to be called concurrently.
+ *
+ * @param <OUT> The output type of the operator
+ */
+@Experimental
+public abstract class AbstractStreamOperatorV2<OUT> implements StreamOperator<OUT>, CheckpointedStreamOperator {
+	/** The logger used by the operator class and its subclasses. */
+	protected static final Logger LOG = LoggerFactory.getLogger(AbstractStreamOperatorV2.class);
+
+	protected final StreamConfig config;
+	protected final Output<StreamRecord<OUT>> output;
+	private final StreamingRuntimeContext runtimeContext;
+	private final ExecutionConfig executionConfig;
+	private final ClassLoader userCodeClassLoader;
+	private final CloseableRegistry cancelables;
+	private final long[] inputWatermarks;
+
+	/** Metric group for the operator. */
+	protected final OperatorMetricGroup metrics;
+	protected final LatencyStats latencyStats;
+	protected final ProcessingTimeService processingTimeService;
+
+	private StreamOperatorStateHandler stateHandler;
+	private InternalTimeServiceManager<?> timeServiceManager;
+
+	// We keep track of watermarks from both inputs, the combined input is the minimum
+	// Once the minimum advances we emit a new watermark for downstream operators
+	private long combinedWatermark = Long.MIN_VALUE;
+
+	public AbstractStreamOperatorV2(StreamOperatorParameters<OUT> parameters, int numberOfInputs) {
+		inputWatermarks = new long[numberOfInputs];
+		Arrays.fill(inputWatermarks, Long.MIN_VALUE);
+		final Environment environment = parameters.getContainingTask().getEnvironment();
+		config = parameters.getStreamConfig();
+		CountingOutput<OUT> countingOutput;
+		OperatorMetricGroup operatorMetricGroup;
+		try {
+			operatorMetricGroup = environment.getMetricGroup().getOrAddOperator(config.getOperatorID(), config.getOperatorName());
+			countingOutput = new CountingOutput(parameters.getOutput(), operatorMetricGroup.getIOMetricGroup().getNumRecordsOutCounter());
+			if (config.isChainStart()) {
+				operatorMetricGroup.getIOMetricGroup().reuseInputMetricsForTask();
+			}
+			if (config.isChainEnd()) {
+				operatorMetricGroup.getIOMetricGroup().reuseOutputMetricsForTask();
+			}
+		} catch (Exception e) {
+			LOG.warn("An error occurred while instantiating task metrics.", e);
+			countingOutput = null;
+			operatorMetricGroup = null;
+		}
+
+		if (countingOutput == null || operatorMetricGroup == null) {
+			metrics = UnregisteredMetricGroups.createUnregisteredOperatorMetricGroup();
+			output = parameters.getOutput();
+		}
+		else {
+			metrics = operatorMetricGroup;
+			output = countingOutput;
+		}
+
+		latencyStats = createLatencyStats(
+			environment.getTaskManagerInfo().getConfiguration(),
+			parameters.getContainingTask().getIndexInSubtaskGroup());
+
+		processingTimeService = Preconditions.checkNotNull(parameters.getProcessingTimeService());
+		executionConfig = parameters.getContainingTask().getExecutionConfig();
+		userCodeClassLoader = parameters.getContainingTask().getUserCodeClassLoader();
+		cancelables = parameters.getContainingTask().getCancelables();
+
+		runtimeContext = new StreamingRuntimeContext(
+			environment,
+			environment.getAccumulatorRegistry().getUserMap(),
+			operatorMetricGroup,
+			getOperatorID(),
+			processingTimeService,
+			null);
+	}
+
+	private LatencyStats createLatencyStats(Configuration taskManagerConfig, int indexInSubtaskGroup) {
+		try {
+			int historySize = taskManagerConfig.getInteger(MetricOptions.LATENCY_HISTORY_SIZE);
+			if (historySize <= 0) {
+				LOG.warn("{} has been set to a value equal or below 0: {}. Using default.", MetricOptions.LATENCY_HISTORY_SIZE, historySize);
+				historySize = MetricOptions.LATENCY_HISTORY_SIZE.defaultValue();
+			}
+
+			final String configuredGranularity = taskManagerConfig.getString(MetricOptions.LATENCY_SOURCE_GRANULARITY);
+			LatencyStats.Granularity granularity;
+			try {
+				granularity = LatencyStats.Granularity.valueOf(configuredGranularity.toUpperCase(Locale.ROOT));
+			} catch (IllegalArgumentException iae) {
+				granularity = LatencyStats.Granularity.OPERATOR;
+				LOG.warn(
+					"Configured value {} option for {} is invalid. Defaulting to {}.",
+					configuredGranularity,
+					MetricOptions.LATENCY_SOURCE_GRANULARITY.key(),
+					granularity);
+			}
+			TaskManagerJobMetricGroup jobMetricGroup = this.metrics.parent().parent();
+			return new LatencyStats(jobMetricGroup.addGroup("latency"),
+				historySize,
+				indexInSubtaskGroup,
+				getOperatorID(),
+				granularity);
+		} catch (Exception e) {
+			LOG.warn("An error occurred while instantiating latency metrics.", e);
+			return new LatencyStats(
+				UnregisteredMetricGroups.createUnregisteredTaskManagerJobMetricGroup().addGroup("latency"),
+				1,
+				0,
+				new OperatorID(),
+				LatencyStats.Granularity.SINGLE);
+		}
+	}
+
+	@Override
+	public MetricGroup getMetricGroup() {
+		return metrics;
+	}
+
+	@Override
+	public final void initializeState(StreamTaskStateInitializer streamTaskStateManager) throws Exception {
+		final TypeSerializer<?> keySerializer = config.getStateKeySerializer(getUserCodeClassloader());
+
+		final StreamOperatorStateContext context =
+			streamTaskStateManager.streamOperatorStateContext(
+				getOperatorID(),
+				getClass().getSimpleName(),
+				getProcessingTimeService(),
+				this,
+				keySerializer,
+				cancelables,
+				metrics);
+
+		stateHandler = new StreamOperatorStateHandler(context, getExecutionConfig(), cancelables);
+		timeServiceManager = context.internalTimerServiceManager();
+		stateHandler.initializeOperatorState(this);
+	}
+
+	/**
+	 * This method is called immediately before any elements are processed, it should contain the
+	 * operator's initialization logic, e.g. state initialization.
+	 *
+	 * <p>The default implementation does nothing.
+	 *
+	 * @throws Exception An exception in this method causes the operator to fail.
+	 */
+	@Override
+	public void open() throws Exception {}
+
+	/**
+	 * This method is called after all records have been added to the operators via the methods
+	 * {@link OneInputStreamOperator#processElement(StreamRecord)}, or
+	 * {@link TwoInputStreamOperator#processElement1(StreamRecord)} and
+	 * {@link TwoInputStreamOperator#processElement2(StreamRecord)}.
+	 *
+	 * <p>The method is expected to flush all remaining buffered data. Exceptions during this flushing
+	 * of buffered should be propagated, in order to cause the operation to be recognized asa failed,
+	 * because the last data items are not processed properly.
+	 *
+	 * @throws Exception An exception in this method causes the operator to fail.
+	 */
+	@Override
+	public void close() throws Exception {}
+
+	/**
+	 * This method is called at the very end of the operator's life, both in the case of a successful
+	 * completion of the operation, and in the case of a failure and canceling.
+	 *
+	 * <p>This method is expected to make a thorough effort to release all resources
+	 * that the operator has acquired.
+	 */
+	@Override
+	public void dispose() throws Exception {
+		if (stateHandler != null) {
+			stateHandler.dispose();
+		}
+	}
+
+	@Override
+	public void prepareSnapshotPreBarrier(long checkpointId) throws Exception {
+		// the default implementation does nothing and accepts the checkpoint
+		// this is purely for subclasses to override
+	}
+
+	@Override
+	public final OperatorSnapshotFutures snapshotState(long checkpointId, long timestamp, CheckpointOptions checkpointOptions,
+			CheckpointStreamFactory factory) throws Exception {
+		return stateHandler.snapshotState(
+			this,
+			Optional.ofNullable(timeServiceManager),
+			getOperatorName(),
+			checkpointId,
+			timestamp,
+			checkpointOptions,
+			factory);
+	}
+
+	/**
+	 * Stream operators with state, which want to participate in a snapshot need to override this hook method.
+	 *
+	 * @param context context that provides information and means required for taking a snapshot
+	 */
+	@Override
+	public void snapshotState(StateSnapshotContext context) throws Exception {
+	}
+
+	/**
+	 * Stream operators with state which can be restored need to override this hook method.
+	 *
+	 * @param context context that allows to register different states.
+	 */
+	@Override
+	public void initializeState(StateInitializationContext context) throws Exception {
+	}
+
+	@Override
+	public void notifyCheckpointComplete(long checkpointId) throws Exception {
+		stateHandler.notifyCheckpointComplete(checkpointId);
+	}
+
+	// ------------------------------------------------------------------------
+	//  Properties and Services
+	// ------------------------------------------------------------------------
+
+	/**
+	 * Gets the execution config defined on the execution environment of the job to which this
+	 * operator belongs.
+	 *
+	 * @return The job's execution config.
+	 */
+	public ExecutionConfig getExecutionConfig() {
+		return executionConfig;
+	}
+
+	public StreamConfig getOperatorConfig() {
+		return config;
+	}
+
+	public ClassLoader getUserCodeClassloader() {
+		return userCodeClassLoader;
+	}
+
+	/**
+	 * Return the operator name. If the runtime context has been set, then the task name with
+	 * subtask index is returned. Otherwise, the simple class name is returned.
+	 *
+	 * @return If runtime context is set, then return task name with subtask index. Otherwise return
+	 * 			simple class name.
+	 */
+	protected String getOperatorName() {
+		if (runtimeContext != null) {
+			return runtimeContext.getTaskNameWithSubtasks();
+		} else {
+			return getClass().getSimpleName();
+		}
+	}
+
+	/**
+	 * Returns a context that allows the operator to query information about the execution and also
+	 * to interact with systems such as broadcast variables and managed state. This also allows
+	 * to register timers.
+	 */
+	public StreamingRuntimeContext getRuntimeContext() {
+		return runtimeContext;
+	}
+
+	@SuppressWarnings("unchecked")
+	@VisibleForTesting
+	public <K> KeyedStateBackend<K> getKeyedStateBackend() {
+		return (KeyedStateBackend<K>) stateHandler.getKeyedStateBackend();
+	}
+
+	@VisibleForTesting
+	public OperatorStateBackend getOperatorStateBackend() {
+		return stateHandler.getOperatorStateBackend();
+	}
+
+	/**
+	 * Returns the {@link ProcessingTimeService} responsible for getting the current
+	 * processing time and registering timers.
+	 */
+	@VisibleForTesting
+	public ProcessingTimeService getProcessingTimeService() {
+		return processingTimeService;
+	}
+
+	/**
+	 * Creates a partitioned state handle, using the state backend configured for this task.
+	 *
+	 * @throws IllegalStateException Thrown, if the key/value state was already initialized.
+	 * @throws Exception Thrown, if the state backend cannot create the key/value state.
+	 */
+	protected <S extends State> S getPartitionedState(StateDescriptor<S, ?> stateDescriptor) throws Exception {
+		return getPartitionedState(VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, stateDescriptor);
+	}
+
+	protected <N, S extends State, T> S getOrCreateKeyedState(
+		TypeSerializer<N> namespaceSerializer,
+		StateDescriptor<S, T> stateDescriptor) throws Exception {
+		return stateHandler.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);
+	}
+
+	/**
+	 * Creates a partitioned state handle, using the state backend configured for this task.
+	 *
+	 * @throws IllegalStateException Thrown, if the key/value state was already initialized.
+	 * @throws Exception Thrown, if the state backend cannot create the key/value state.
+	 */
+	protected <S extends State, N> S getPartitionedState(
+		N namespace,
+		TypeSerializer<N> namespaceSerializer,
+		StateDescriptor<S, ?> stateDescriptor) throws Exception {
+		return stateHandler.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);
+	}
+
+	protected <T> void internalSetKeyContextElement(StreamRecord<T> record, KeySelector<T, ?> selector) throws Exception {
+		if (selector != null) {
+			Object key = selector.getKey(record.getValue());
+			setCurrentKey(key);
+		}
+	}
+
+	@SuppressWarnings({"unchecked", "rawtypes"})
+	public void setCurrentKey(Object key) {
+		stateHandler.setCurrentKey(key);
+	}
+
+	@SuppressWarnings({"unchecked", "rawtypes"})
+	public Object getCurrentKey() {
+		return stateHandler.getCurrentKey();
+	}
+
+	public Optional<KeyedStateStore> getKeyedStateStore() {
+		if (stateHandler == null) {
+			return Optional.empty();
+		}
+		return stateHandler.getKeyedStateStore();
+	}
+
+	protected void reportOrForwardLatencyMarker(LatencyMarker marker) {
+		// all operators are tracking latencies
+		this.latencyStats.reportLatency(marker);
+
+		// everything except sinks forwards latency markers
+		this.output.emitLatencyMarker(marker);
+	}
+
+	// ------------------------------------------------------------------------
+	//  Watermark handling
+	// ------------------------------------------------------------------------
+
+	/**
+	 * Returns a {@link InternalTimerService} that can be used to query current processing time
+	 * and event time and to set timers. An operator can have several timer services, where
+	 * each has its own namespace serializer. Timer services are differentiated by the string
+	 * key that is given when requesting them, if you call this method with the same key
+	 * multiple times you will get the same timer service instance in subsequent requests.
+	 *
+	 * <p>Timers are always scoped to a key, the currently active key of a keyed stream operation.
+	 * When a timer fires, this key will also be set as the currently active key.
+	 *
+	 * <p>Each timer has attached metadata, the namespace. Different timer services
+	 * can have a different namespace type. If you don't need namespace differentiation you
+	 * can use {@link VoidNamespaceSerializer} as the namespace serializer.
+	 *
+	 * @param name The name of the requested timer service. If no service exists under the given
+	 *             name a new one will be created and returned.
+	 * @param namespaceSerializer {@code TypeSerializer} for the timer namespace.
+	 * @param triggerable The {@link Triggerable} that should be invoked when timers fire
+	 *
+	 * @param <N> The type of the timer namespace.
+	 */
+	@VisibleForTesting
+	public <K, N> InternalTimerService<N> getInternalTimerService(
+			String name,
+			TypeSerializer<N> namespaceSerializer,
+			Triggerable<K, N> triggerable) {
+		if (timeServiceManager == null) {
+			throw new RuntimeException("The timer service has not been initialized.");
+		}
+		InternalTimeServiceManager<K> keyedTimeServiceHandler = (InternalTimeServiceManager<K>) timeServiceManager;
+		return keyedTimeServiceHandler.getInternalTimerService(
+			name,
+			namespaceSerializer,
+			triggerable,
+			stateHandler.getKeyedStateBackend());
+	}
+
+	public void processWatermark(Watermark mark) throws Exception {
+		if (timeServiceManager != null) {
+			timeServiceManager.advanceWatermark(mark);
+		}
+		output.emitWatermark(mark);
+	}
+
+	protected void reportWatermark(Watermark mark, int inputId) throws Exception {
+		inputWatermarks[inputId] = mark.getTimestamp();
+		long newMin = mark.getTimestamp();
+		for (long inputWatermark : inputWatermarks) {
+			newMin = Math.min(inputWatermark, newMin);
+		}
+		if (newMin > combinedWatermark) {
+			combinedWatermark = newMin;
+			processWatermark(new Watermark(combinedWatermark));
+		}
+	}
+
+	@Override
+	public OperatorID getOperatorID() {
+		return config.getOperatorID();
+	}
+
+	@VisibleForTesting
+	public int numProcessingTimeTimers() {
+		return timeServiceManager == null ? 0 : timeServiceManager.numProcessingTimeTimers();
+	}
+
+	@VisibleForTesting
+	public int numEventTimeTimers() {
+		return timeServiceManager == null ? 0 : timeServiceManager.numEventTimeTimers();
+	}
+
+	@Override
+	public void setKeyContextElement1(StreamRecord<?> record) throws Exception {
+		throw new IllegalStateException("This method should never be called. Use Input class instead");
+	}
+
+	@Override
+	public void setKeyContextElement2(StreamRecord<?> record) throws Exception {
+		throw new IllegalStateException("This method should never be called. Use Input class instead");
+	}
+
+	protected Optional<InternalTimeServiceManager<?>> getTimeServiceManager() {
+		return Optional.ofNullable(timeServiceManager);
+	}
+}
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/CountingOutput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/CountingOutput.java
new file mode 100644
index 0000000000000..79acabb6461d7
--- /dev/null
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/CountingOutput.java
@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.api.operators;
+
+import org.apache.flink.metrics.Counter;
+import org.apache.flink.streaming.api.watermark.Watermark;
+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;
+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
+import org.apache.flink.util.OutputTag;
+
+/**
+ * Wrapping {@link Output} that updates metrics on the number of emitted elements.
+ */
+public class CountingOutput<OUT> implements Output<StreamRecord<OUT>> {
+	private final Output<StreamRecord<OUT>> output;
+	private final Counter numRecordsOut;
+
+	public CountingOutput(Output<StreamRecord<OUT>> output, Counter counter) {
+		this.output = output;
+		this.numRecordsOut = counter;
+	}
+
+	@Override
+	public void emitWatermark(Watermark mark) {
+		output.emitWatermark(mark);
+	}
+
+	@Override
+	public void emitLatencyMarker(LatencyMarker latencyMarker) {
+		output.emitLatencyMarker(latencyMarker);
+	}
+
+	@Override
+	public void collect(StreamRecord<OUT> record) {
+		numRecordsOut.inc();
+		output.collect(record);
+	}
+
+	@Override
+	public <X> void collect(OutputTag<X> outputTag, StreamRecord<X> record) {
+		numRecordsOut.inc();
+		output.collect(outputTag, record);
+	}
+
+	@Override
+	public void close() {
+		output.close();
+	}
+}
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/InternalTimeServiceManager.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/InternalTimeServiceManager.java
index ff48c3fae033f..87274b95cba23 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/InternalTimeServiceManager.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/InternalTimeServiceManager.java
@@ -20,20 +20,32 @@
 
 import org.apache.flink.annotation.Internal;
 import org.apache.flink.annotation.VisibleForTesting;
+import org.apache.flink.api.common.typeutils.TypeSerializer;
 import org.apache.flink.core.memory.DataOutputView;
+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;
+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;
 import org.apache.flink.runtime.state.KeyGroupRange;
 import org.apache.flink.runtime.state.KeyGroupedInternalPriorityQueue;
+import org.apache.flink.runtime.state.KeyGroupsList;
+import org.apache.flink.runtime.state.KeyedStateBackend;
+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;
 import org.apache.flink.runtime.state.PriorityQueueSetFactory;
+import org.apache.flink.runtime.state.StateSnapshotContext;
 import org.apache.flink.streaming.api.watermark.Watermark;
 import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;
 import org.apache.flink.util.Preconditions;
 
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 import java.io.IOException;
 import java.io.InputStream;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 
+import static org.apache.flink.util.Preconditions.checkNotNull;
+
 /**
  * An entity keeping all the time-related services available to all operators extending the
  * {@link AbstractStreamOperator}. Right now, this is only a
@@ -45,6 +57,7 @@
  */
 @Internal
 public class InternalTimeServiceManager<K> {
+	protected static final Logger LOG = LoggerFactory.getLogger(InternalTimeServiceManager.class);
 
 	@VisibleForTesting
 	static final String TIMER_STATE_PREFIX = "_timer_state";
@@ -78,6 +91,19 @@
 		this.timerServices = new HashMap<>();
 	}
 
+	public <N> InternalTimerService<N> getInternalTimerService(
+			String name,
+			TypeSerializer<N> namespaceSerializer,
+			Triggerable<K, N> triggerable,
+			KeyedStateBackend<K> keyedStateBackend) {
+		checkNotNull(keyedStateBackend, "Timers can only be used on keyed operators.");
+
+		TypeSerializer<K> keySerializer = keyedStateBackend.getKeySerializer();
+		// the following casting is to overcome type restrictions.
+		TimerSerializer<K, N> timerSerializer = new TimerSerializer<>(keySerializer, namespaceSerializer);
+		return getInternalTimerService(name, timerSerializer, triggerable);
+	}
+
 	@SuppressWarnings("unchecked")
 	public <N> InternalTimerService<N> getInternalTimerService(
 		String name,
@@ -131,6 +157,44 @@ public void advanceWatermark(Watermark watermark) throws Exception {
 
 	//////////////////				Fault Tolerance Methods				///////////////////
 
+	public void snapshotState(
+			KeyedStateBackend<?> keyedStateBackend,
+			StateSnapshotContext context,
+			String operatorName) throws Exception {
+		//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots
+		if (keyedStateBackend instanceof AbstractKeyedStateBackend &&
+			((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {
+
+			KeyedStateCheckpointOutputStream out;
+			try {
+				out = context.getRawKeyedOperatorStateOutput();
+			} catch (Exception exception) {
+				throw new Exception("Could not open raw keyed operator state stream for " +
+					operatorName + '.', exception);
+			}
+
+			try {
+				KeyGroupsList allKeyGroups = out.getKeyGroupList();
+				for (int keyGroupIdx : allKeyGroups) {
+					out.startNewKeyGroup(keyGroupIdx);
+
+					snapshotStateForKeyGroup(
+						new DataOutputViewStreamWrapper(out), keyGroupIdx);
+				}
+			} catch (Exception exception) {
+				throw new Exception("Could not write timer service of " + operatorName +
+					" to checkpoint state stream.", exception);
+			} finally {
+				try {
+					out.close();
+				} catch (Exception closeException) {
+					LOG.warn("Could not close raw keyed operator state stream for {}. This " +
+						"might have prevented deleting some state data.", operatorName, closeException);
+				}
+			}
+		}
+	}
+
 	public void snapshotStateForKeyGroup(DataOutputView stream, int keyGroupIdx) throws IOException {
 		Preconditions.checkState(useLegacySynchronousSnapshots);
 		InternalTimerServiceSerializationProxy<K> serializationProxy =
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SetupableStreamOperator.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SetupableStreamOperator.java
index 78fcf3077e2b8..0fe8348ebe91f 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SetupableStreamOperator.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SetupableStreamOperator.java
@@ -38,4 +38,8 @@
 	 * Initializes the operator. Sets access to the context and the output.
 	 */
 	void setup(StreamTask<?, ?> containingTask, StreamConfig config, Output<StreamRecord<OUT>> output);
+
+	ChainingStrategy getChainingStrategy();
+
+	void setChainingStrategy(ChainingStrategy strategy);
 }
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SimpleOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SimpleOperatorFactory.java
index d9ee68b1607db..1e3de6eb48f1f 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SimpleOperatorFactory.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SimpleOperatorFactory.java
@@ -23,9 +23,6 @@
 import org.apache.flink.api.java.typeutils.InputTypeConfigurable;
 import org.apache.flink.streaming.api.functions.sink.OutputFormatSinkFunction;
 import org.apache.flink.streaming.api.functions.source.InputFormatSourceFunction;
-import org.apache.flink.streaming.api.graph.StreamConfig;
-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
-import org.apache.flink.streaming.runtime.tasks.StreamTask;
 
 import static org.apache.flink.util.Preconditions.checkNotNull;
 
@@ -61,7 +58,9 @@ public static <OUT> SimpleOperatorFactory<OUT> of(StreamOperator<OUT> operator)
 
 	protected SimpleOperatorFactory(StreamOperator<OUT> operator) {
 		this.operator = checkNotNull(operator);
-		this.chainingStrategy = operator.getChainingStrategy();
+		if (operator instanceof SetupableStreamOperator) {
+			this.chainingStrategy = ((SetupableStreamOperator) operator).getChainingStrategy();
+		}
 	}
 
 	public StreamOperator<OUT> getOperator() {
@@ -70,13 +69,15 @@ public StreamOperator<OUT> getOperator() {
 
 	@SuppressWarnings("unchecked")
 	@Override
-	public <T extends StreamOperator<OUT>> T createStreamOperator(StreamTask<?, ?> containingTask,
-			StreamConfig config, Output<StreamRecord<OUT>> output) {
+	public <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorParameters<OUT> parameters) {
 		if (operator instanceof AbstractStreamOperator) {
 			((AbstractStreamOperator) operator).setProcessingTimeService(processingTimeService);
 		}
 		if (operator instanceof SetupableStreamOperator) {
-			((SetupableStreamOperator) operator).setup(containingTask, config, output);
+			((SetupableStreamOperator) operator).setup(
+				parameters.getContainingTask(),
+				parameters.getStreamConfig(),
+				parameters.getOutput());
 		}
 		return (T) operator;
 	}
@@ -84,7 +85,9 @@ public <T extends StreamOperator<OUT>> T createStreamOperator(StreamTask<?, ?> c
 	@Override
 	public void setChainingStrategy(ChainingStrategy strategy) {
 		this.chainingStrategy = strategy;
-		operator.setChainingStrategy(strategy);
+		if (operator instanceof SetupableStreamOperator) {
+			((SetupableStreamOperator) operator).setChainingStrategy(strategy);
+		}
 	}
 
 	@Override
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperator.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperator.java
index fded06129e270..69a505661b742 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperator.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperator.java
@@ -127,7 +127,7 @@ OperatorSnapshotFutures snapshotState(
 	/**
 	 * Provides a context to initialize all state in the operator.
 	 */
-	void initializeState() throws Exception;
+	void initializeState(StreamTaskStateInitializer streamTaskStateManager) throws Exception;
 
 	// ------------------------------------------------------------------------
 	//  miscellaneous
@@ -137,10 +137,6 @@ OperatorSnapshotFutures snapshotState(
 
 	void setKeyContextElement2(StreamRecord<?> record) throws Exception;
 
-	ChainingStrategy getChainingStrategy();
-
-	void setChainingStrategy(ChainingStrategy strategy);
-
 	MetricGroup getMetricGroup();
 
 	OperatorID getOperatorID();
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java
index 1d5268ee6e040..d1ea80c0ce53f 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java
@@ -17,12 +17,10 @@
 
 package org.apache.flink.streaming.api.operators;
 
-import org.apache.flink.annotation.Internal;
+import org.apache.flink.annotation.Experimental;
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
-import org.apache.flink.streaming.api.graph.StreamConfig;
 import org.apache.flink.streaming.api.graph.StreamGraph;
-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
 import org.apache.flink.streaming.runtime.tasks.StreamTask;
 
 import java.io.Serializable;
@@ -32,14 +30,13 @@
  *
  * @param <OUT> The output type of the operator
  */
-@Internal
+@Experimental
 public interface StreamOperatorFactory<OUT> extends Serializable {
 
 	/**
 	 * Create the operator. Sets access to the context and the output.
 	 */
-	<T extends StreamOperator<OUT>> T createStreamOperator(
-			StreamTask<?, ?> containingTask, StreamConfig config, Output<StreamRecord<OUT>> output);
+	<T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorParameters<OUT> parameters);
 
 	/**
 	 * Set the chaining strategy for operator factory.
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactoryUtil.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactoryUtil.java
index 6b8ab233b7361..11090f6d08932 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactoryUtil.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactoryUtil.java
@@ -57,7 +57,13 @@ public static <OUT, OP extends StreamOperator<OUT>> Tuple2<OP, Optional<Processi
 			((ProcessingTimeServiceAware) operatorFactory).setProcessingTimeService(processingTimeService);
 		}
 
-		OP op = operatorFactory.createStreamOperator(containingTask, configuration, output);
+		// TODO: what to do with ProcessingTimeServiceAware?
+		OP op = operatorFactory.createStreamOperator(
+			new StreamOperatorParameters<>(
+				containingTask,
+				configuration,
+				output,
+				processingTimeService));
 		return new Tuple2<>(op, Optional.ofNullable(processingTimeService));
 	}
 }
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorParameters.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorParameters.java
new file mode 100644
index 0000000000000..5aaffcc46a0d5
--- /dev/null
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorParameters.java
@@ -0,0 +1,67 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.api.operators;
+
+import org.apache.flink.annotation.Experimental;
+import org.apache.flink.streaming.api.graph.StreamConfig;
+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;
+import org.apache.flink.streaming.runtime.tasks.StreamTask;
+
+/**
+ * Helper  class to construct {@link AbstractStreamOperatorV2}. Wraps couple of internal parameters
+ * to simplify for users construction of classes extending {@link AbstractStreamOperatorV2} and to
+ * allow for backward compatible changes in the {@link AbstractStreamOperatorV2}'s constructor.
+ *
+ * @param <OUT> The output type of an operator that will be constructed using {@link StreamOperatorParameters}.
+ */
+@Experimental
+public class StreamOperatorParameters<OUT> {
+	private final StreamTask<?, ?> containingTask;
+	private final StreamConfig config;
+	private final Output<StreamRecord<OUT>> output;
+	private final ProcessingTimeService processingTimeService;
+
+	public StreamOperatorParameters(
+			StreamTask<?, ?> containingTask,
+			StreamConfig config,
+			Output<StreamRecord<OUT>> output,
+			ProcessingTimeService processingTimeService) {
+		this.containingTask = containingTask;
+		this.config = config;
+		this.output = output;
+		this.processingTimeService = processingTimeService;
+	}
+
+	public StreamTask<?, ?> getContainingTask() {
+		return containingTask;
+	}
+
+	public StreamConfig getStreamConfig() {
+		return config;
+	}
+
+	public Output<StreamRecord<OUT>> getOutput() {
+		return output;
+	}
+
+	public ProcessingTimeService getProcessingTimeService() {
+		return processingTimeService;
+	}
+}
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java
new file mode 100644
index 0000000000000..99123b1038cd4
--- /dev/null
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java
@@ -0,0 +1,310 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.api.operators;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.annotation.VisibleForTesting;
+import org.apache.flink.api.common.ExecutionConfig;
+import org.apache.flink.api.common.state.KeyedStateStore;
+import org.apache.flink.api.common.state.State;
+import org.apache.flink.api.common.state.StateDescriptor;
+import org.apache.flink.api.common.typeutils.TypeSerializer;
+import org.apache.flink.core.fs.CloseableRegistry;
+import org.apache.flink.runtime.checkpoint.CheckpointException;
+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;
+import org.apache.flink.runtime.checkpoint.CheckpointOptions;
+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;
+import org.apache.flink.runtime.state.CheckpointStreamFactory;
+import org.apache.flink.runtime.state.DefaultKeyedStateStore;
+import org.apache.flink.runtime.state.KeyGroupRange;
+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;
+import org.apache.flink.runtime.state.KeyedStateBackend;
+import org.apache.flink.runtime.state.OperatorStateBackend;
+import org.apache.flink.runtime.state.StateInitializationContext;
+import org.apache.flink.runtime.state.StateInitializationContextImpl;
+import org.apache.flink.runtime.state.StatePartitionStreamProvider;
+import org.apache.flink.runtime.state.StateSnapshotContext;
+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;
+import org.apache.flink.util.CloseableIterable;
+import org.apache.flink.util.IOUtils;
+
+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import javax.annotation.Nullable;
+
+import java.io.Closeable;
+import java.io.IOException;
+import java.util.Optional;
+
+import static org.apache.flink.util.Preconditions.checkState;
+
+/**
+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.
+ */
+@Internal
+public class StreamOperatorStateHandler {
+
+	protected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);
+
+	/** Backend for keyed state. This might be empty if we're not on a keyed stream. */
+	@Nullable
+	private final AbstractKeyedStateBackend<?> keyedStateBackend;
+	private final CloseableRegistry closeableRegistry;
+	@Nullable
+	private final DefaultKeyedStateStore keyedStateStore;
+	private final OperatorStateBackend operatorStateBackend;
+	private final StreamOperatorStateContext context;
+
+	public StreamOperatorStateHandler(
+			StreamOperatorStateContext context,
+			ExecutionConfig executionConfig,
+			CloseableRegistry closeableRegistry) {
+		this.context = context;
+		operatorStateBackend = context.operatorStateBackend();
+		keyedStateBackend = context.keyedStateBackend();
+		this.closeableRegistry = closeableRegistry;
+
+		if (keyedStateBackend != null) {
+			keyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);
+		}
+		else {
+			keyedStateStore = null;
+		}
+	}
+
+	public void initializeOperatorState(CheckpointedStreamOperator streamOperator) throws Exception {
+		CloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();
+		CloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();
+
+		try {
+			StateInitializationContext initializationContext = new StateInitializationContextImpl(
+				context.isRestored(), // information whether we restore or start for the first time
+				operatorStateBackend, // access to operator state backend
+				keyedStateStore, // access to keyed state backend
+				keyedStateInputs, // access to keyed state stream
+				operatorStateInputs); // access to operator state stream
+
+			streamOperator.initializeState(initializationContext);
+		} finally {
+			closeFromRegistry(operatorStateInputs, closeableRegistry);
+			closeFromRegistry(keyedStateInputs, closeableRegistry);
+		}
+	}
+
+	private static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {
+		if (registry.unregisterCloseable(closeable)) {
+			IOUtils.closeQuietly(closeable);
+		}
+	}
+
+	public void dispose() throws Exception {
+		try (Closer closer = Closer.create()) {
+			if (closeableRegistry.unregisterCloseable(operatorStateBackend)) {
+				closer.register(operatorStateBackend);
+			}
+			if (closeableRegistry.unregisterCloseable(keyedStateBackend)) {
+				closer.register(keyedStateBackend);
+			}
+			if (operatorStateBackend != null) {
+				closer.register(() -> operatorStateBackend.dispose());
+			}
+			if (keyedStateBackend != null) {
+				closer.register(() -> keyedStateBackend.dispose());
+			}
+		}
+	}
+
+	public OperatorSnapshotFutures snapshotState(
+			CheckpointedStreamOperator streamOperator,
+			Optional<InternalTimeServiceManager<?>> timeServiceManager,
+			String operatorName,
+			long checkpointId,
+			long timestamp,
+			CheckpointOptions checkpointOptions,
+			CheckpointStreamFactory factory) throws CheckpointException {
+		KeyGroupRange keyGroupRange = null != keyedStateBackend ?
+			keyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;
+
+		OperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();
+
+		StateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(
+			checkpointId,
+			timestamp,
+			factory,
+			keyGroupRange,
+			closeableRegistry);
+
+		snapshotState(
+			streamOperator,
+			timeServiceManager,
+			operatorName,
+			checkpointId,
+			timestamp,
+			checkpointOptions,
+			factory,
+			snapshotInProgress,
+			snapshotContext);
+
+		return snapshotInProgress;
+	}
+
+	@VisibleForTesting
+	void snapshotState(
+			CheckpointedStreamOperator streamOperator,
+			Optional<InternalTimeServiceManager<?>> timeServiceManager,
+			String operatorName,
+			long checkpointId,
+			long timestamp,
+			CheckpointOptions checkpointOptions,
+			CheckpointStreamFactory factory,
+			OperatorSnapshotFutures snapshotInProgress,
+			StateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {
+		try {
+			if (timeServiceManager.isPresent()) {
+				checkState(keyedStateBackend != null, "keyedStateBackend should be available with timeServiceManager");
+				timeServiceManager.get().snapshotState(keyedStateBackend, snapshotContext, operatorName);
+			}
+			streamOperator.snapshotState(snapshotContext);
+
+			snapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());
+			snapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());
+
+			if (null != operatorStateBackend) {
+				snapshotInProgress.setOperatorStateManagedFuture(
+					operatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));
+			}
+
+			if (null != keyedStateBackend) {
+				snapshotInProgress.setKeyedStateManagedFuture(
+					keyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));
+			}
+		} catch (Exception snapshotException) {
+			try {
+				snapshotInProgress.cancel();
+			} catch (Exception e) {
+				snapshotException.addSuppressed(e);
+			}
+
+			String snapshotFailMessage = "Could not complete snapshot " + checkpointId + " for operator " +
+				operatorName + ".";
+
+			try {
+				snapshotContext.closeExceptionally();
+			} catch (IOException e) {
+				snapshotException.addSuppressed(e);
+			}
+			throw new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);
+		}
+	}
+
+	public void notifyCheckpointComplete(long checkpointId) throws Exception {
+		if (keyedStateBackend != null) {
+			keyedStateBackend.notifyCheckpointComplete(checkpointId);
+		}
+	}
+
+	@SuppressWarnings("unchecked")
+	public <K> KeyedStateBackend<K> getKeyedStateBackend() {
+		return (KeyedStateBackend<K>) keyedStateBackend;
+	}
+
+	public OperatorStateBackend getOperatorStateBackend() {
+		return operatorStateBackend;
+	}
+
+	public <N, S extends State, T> S getOrCreateKeyedState(
+			TypeSerializer<N> namespaceSerializer,
+			StateDescriptor<S, T> stateDescriptor) throws Exception {
+
+		if (keyedStateStore != null) {
+			return keyedStateBackend.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);
+		}
+		else {
+			throw new IllegalStateException("Cannot create partitioned state. " +
+					"The keyed state backend has not been set." +
+					"This indicates that the operator is not partitioned/keyed.");
+		}
+	}
+
+	/**
+	 * Creates a partitioned state handle, using the state backend configured for this task.
+	 *
+	 * @throws IllegalStateException Thrown, if the key/value state was already initialized.
+	 * @throws Exception Thrown, if the state backend cannot create the key/value state.
+	 */
+	protected <S extends State, N> S getPartitionedState(
+			N namespace,
+			TypeSerializer<N> namespaceSerializer,
+			StateDescriptor<S, ?> stateDescriptor) throws Exception {
+
+		/*
+	    TODO: NOTE: This method does a lot of work caching / retrieving states just to update the namespace.
+	    This method should be removed for the sake of namespaces being lazily fetched from the keyed
+	    state backend, or being set on the state directly.
+	    */
+
+		if (keyedStateStore != null) {
+			return keyedStateBackend.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);
+		} else {
+			throw new RuntimeException("Cannot create partitioned state. The keyed state " +
+				"backend has not been set. This indicates that the operator is not " +
+				"partitioned/keyed.");
+		}
+	}
+
+	@SuppressWarnings({"unchecked", "rawtypes"})
+	public void setCurrentKey(Object key) {
+		if (keyedStateBackend != null) {
+			try {
+				// need to work around type restrictions
+				@SuppressWarnings("unchecked,rawtypes")
+				AbstractKeyedStateBackend rawBackend = (AbstractKeyedStateBackend) keyedStateBackend;
+
+				rawBackend.setCurrentKey(key);
+			} catch (Exception e) {
+				throw new RuntimeException("Exception occurred while setting the current key context.", e);
+			}
+		}
+	}
+
+	@SuppressWarnings({"unchecked", "rawtypes"})
+	public Object getCurrentKey() {
+		if (keyedStateBackend != null) {
+			return keyedStateBackend.getCurrentKey();
+		} else {
+			throw new UnsupportedOperationException("Key can only be retrieved on KeyedStream.");
+		}
+	}
+
+	public Optional<KeyedStateStore> getKeyedStateStore() {
+		return Optional.ofNullable(keyedStateStore);
+	}
+
+	/**
+	 * Custom state handling hooks to be invoked by {@link StreamOperatorStateHandler}.
+	 */
+	public interface CheckpointedStreamOperator {
+		void initializeState(StateInitializationContext context) throws Exception;
+
+		void snapshotState(StateSnapshotContext context) throws Exception;
+	}
+}
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamingRuntimeContext.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamingRuntimeContext.java
index 23cb82e374559..3fe540f0f528c 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamingRuntimeContext.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamingRuntimeContext.java
@@ -19,6 +19,7 @@
 package org.apache.flink.streaming.api.operators;
 
 import org.apache.flink.annotation.Internal;
+import org.apache.flink.annotation.VisibleForTesting;
 import org.apache.flink.api.common.accumulators.Accumulator;
 import org.apache.flink.api.common.functions.BroadcastVariableInitializer;
 import org.apache.flink.api.common.functions.util.AbstractRuntimeUDFContext;
@@ -36,17 +37,22 @@
 import org.apache.flink.api.common.state.StateDescriptor;
 import org.apache.flink.api.common.state.ValueState;
 import org.apache.flink.api.common.state.ValueStateDescriptor;
+import org.apache.flink.metrics.MetricGroup;
 import org.apache.flink.runtime.execution.Environment;
+import org.apache.flink.runtime.jobgraph.OperatorID;
 import org.apache.flink.runtime.jobgraph.tasks.InputSplitProvider;
 import org.apache.flink.runtime.taskexecutor.GlobalAggregateManager;
 import org.apache.flink.streaming.api.CheckpointingMode;
 import org.apache.flink.streaming.api.graph.StreamConfig;
 import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;
-import org.apache.flink.util.Preconditions;
+
+import javax.annotation.Nullable;
 
 import java.util.List;
 import java.util.Map;
 
+import static org.apache.flink.util.Preconditions.checkNotNull;
+
 /**
  * Implementation of the {@link org.apache.flink.api.common.functions.RuntimeContext},
  * for streaming operators.
@@ -54,29 +60,49 @@
 @Internal
 public class StreamingRuntimeContext extends AbstractRuntimeUDFContext {
 
-	/** The operator to which this function belongs. */
-	private final AbstractStreamOperator<?> operator;
-
 	/** The task environment running the operator. */
 	private final Environment taskEnvironment;
-
 	private final StreamConfig streamConfig;
-
 	private final String operatorUniqueID;
-
-	public StreamingRuntimeContext(AbstractStreamOperator<?> operator,
-									Environment env, Map<String, Accumulator<?, ?>> accumulators) {
-		super(env.getTaskInfo(),
+	private final ProcessingTimeService processingTimeService;
+	private @Nullable KeyedStateStore keyedStateStore;
+
+	@VisibleForTesting
+	public StreamingRuntimeContext(
+			AbstractStreamOperator<?> operator,
+			Environment env,
+			Map<String, Accumulator<?, ?>> accumulators) {
+		this(
+			env,
+			accumulators,
+			operator.getMetricGroup(),
+			operator.getOperatorID(),
+			operator.getProcessingTimeService(),
+			operator.getKeyedStateStore());
+	}
+
+	public StreamingRuntimeContext(
+			Environment env,
+			Map<String, Accumulator<?, ?>> accumulators,
+			MetricGroup operatorMetricGroup,
+			OperatorID operatorID,
+			ProcessingTimeService processingTimeService,
+			@Nullable KeyedStateStore keyedStateStore) {
+		super(checkNotNull(env).getTaskInfo(),
 				env.getUserClassLoader(),
-				operator.getExecutionConfig(),
+				env.getExecutionConfig(),
 				accumulators,
 				env.getDistributedCacheEntries(),
-				operator.getMetricGroup());
-
-		this.operator = operator;
+				operatorMetricGroup);
 		this.taskEnvironment = env;
 		this.streamConfig = new StreamConfig(env.getTaskConfiguration());
-		this.operatorUniqueID = operator.getOperatorID().toString();
+		this.operatorUniqueID = checkNotNull(operatorID).toString();
+		this.processingTimeService = processingTimeService;
+		this.keyedStateStore = keyedStateStore;
+	}
+
+	public void setKeyedStateStore(@Nullable KeyedStateStore keyedStateStore) {
+		this.keyedStateStore = keyedStateStore;
 	}
 
 	// ------------------------------------------------------------------------
@@ -91,7 +117,7 @@ public InputSplitProvider getInputSplitProvider() {
 	}
 
 	public ProcessingTimeService getProcessingTimeService() {
-		return operator.getProcessingTimeService();
+		return processingTimeService;
 	}
 
 	/**
@@ -180,9 +206,8 @@ public <UK, UV> MapState<UK, UV> getMapState(MapStateDescriptor<UK, UV> statePro
 	}
 
 	private KeyedStateStore checkPreconditionsAndGetKeyedStateStore(StateDescriptor<?, ?> stateDescriptor) {
-		Preconditions.checkNotNull(stateDescriptor, "The state properties must not be null");
-		KeyedStateStore keyedStateStore = operator.getKeyedStateStore();
-		Preconditions.checkNotNull(keyedStateStore, "Keyed state can only be used on a 'keyed stream', i.e., after a 'keyBy()' operation.");
+		checkNotNull(stateDescriptor, "The state properties must not be null");
+		checkNotNull(keyedStateStore, "Keyed state can only be used on a 'keyed stream', i.e., after a 'keyBy()' operation.");
 		return keyedStateStore;
 	}
 
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/YieldingOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/YieldingOperatorFactory.java
index 054ad8d51d220..c3563c5e79410 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/YieldingOperatorFactory.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/YieldingOperatorFactory.java
@@ -17,10 +17,13 @@
 
 package org.apache.flink.streaming.api.operators;
 
+import org.apache.flink.annotation.Experimental;
+
 /**
  * An operator that needs access to the {@link MailboxExecutor} to yield to downstream operators needs to be created
  * through a factory implementing this interface.
  */
+@Experimental
 public interface YieldingOperatorFactory<OUT> extends StreamOperatorFactory<OUT> {
 	void setMailboxExecutor(MailboxExecutor mailboxExecutor);
 }
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/async/AsyncWaitOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/async/AsyncWaitOperatorFactory.java
index c30fb2fba5c05..c51c68aacac59 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/async/AsyncWaitOperatorFactory.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/async/AsyncWaitOperatorFactory.java
@@ -19,15 +19,13 @@
 
 import org.apache.flink.streaming.api.datastream.AsyncDataStream;
 import org.apache.flink.streaming.api.functions.async.AsyncFunction;
-import org.apache.flink.streaming.api.graph.StreamConfig;
 import org.apache.flink.streaming.api.operators.AbstractStreamOperatorFactory;
 import org.apache.flink.streaming.api.operators.ChainingStrategy;
 import org.apache.flink.streaming.api.operators.MailboxExecutor;
 import org.apache.flink.streaming.api.operators.OneInputStreamOperatorFactory;
-import org.apache.flink.streaming.api.operators.Output;
 import org.apache.flink.streaming.api.operators.StreamOperator;
+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;
 import org.apache.flink.streaming.api.operators.YieldingOperatorFactory;
-import org.apache.flink.streaming.runtime.tasks.StreamTask;
 
 /**
  * The factory of {@link AsyncWaitOperator}.
@@ -61,7 +59,7 @@ public void setMailboxExecutor(MailboxExecutor mailboxExecutor) {
 	}
 
 	@Override
-	public StreamOperator createStreamOperator(StreamTask containingTask, StreamConfig config, Output output) {
+	public <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorParameters<OUT> parameters) {
 		AsyncWaitOperator asyncWaitOperator = new AsyncWaitOperator(
 				asyncFunction,
 				timeout,
@@ -69,8 +67,8 @@ public StreamOperator createStreamOperator(StreamTask containingTask, StreamConf
 				outputMode,
 				processingTimeService,
 				mailboxExecutor);
-		asyncWaitOperator.setup(containingTask, config, output);
-		return asyncWaitOperator;
+		asyncWaitOperator.setup(parameters.getContainingTask(), parameters.getStreamConfig(), parameters.getOutput());
+		return (T) asyncWaitOperator;
 	}
 
 	@Override
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java
index cb88ea0dbded1..81a6fd8028c20 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java
@@ -33,6 +33,7 @@
 
 import java.util.HashMap;
 import java.util.concurrent.ExecutorService;
+import java.util.function.Supplier;
 
 final class CheckpointingOperation {
 
@@ -48,7 +49,8 @@ static void execute(
 			CloseableRegistry closeableRegistry,
 			ExecutorService threadPool,
 			Environment environment,
-			AsyncExceptionHandler asyncExceptionHandler) throws Exception {
+			AsyncExceptionHandler asyncExceptionHandler,
+			Supplier<Boolean> isCanceled) throws Exception {
 
 		Preconditions.checkNotNull(checkpointMetaData);
 		Preconditions.checkNotNull(checkpointOptions);
@@ -66,11 +68,12 @@ static void execute(
 		try {
 			for (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {
 				StreamOperator<?> op = operatorWrapper.getStreamOperator();
-				OperatorSnapshotFutures snapshotInProgress = op.snapshotState(
-					checkpointMetaData.getCheckpointId(),
-					checkpointMetaData.getTimestamp(),
+				OperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(
+					op,
+					checkpointMetaData,
 					checkpointOptions,
-					storageLocation);
+					storageLocation,
+					isCanceled);
 				operatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);
 			}
 
@@ -133,4 +136,24 @@ static void execute(
 		}
 	}
 
+	private static OperatorSnapshotFutures checkpointStreamOperator(
+			StreamOperator<?> op,
+			CheckpointMetaData checkpointMetaData,
+			CheckpointOptions checkpointOptions,
+			CheckpointStreamFactory storageLocation,
+			Supplier<Boolean> isCanceled) throws Exception {
+		try {
+			return op.snapshotState(
+				checkpointMetaData.getCheckpointId(),
+				checkpointMetaData.getTimestamp(),
+				checkpointOptions,
+				storageLocation);
+		}
+		catch (Exception ex) {
+			if (!isCanceled.get()) {
+				LOG.info(ex.getMessage(), ex);
+			}
+			throw ex;
+		}
+	}
 }
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java
index 52c01747e6864..3e1e3f0fda928 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java
@@ -47,6 +47,7 @@
 import org.apache.flink.streaming.api.operators.StreamOperator;
 import org.apache.flink.streaming.api.operators.StreamOperatorFactory;
 import org.apache.flink.streaming.api.operators.StreamOperatorFactoryUtil;
+import org.apache.flink.streaming.api.operators.StreamTaskStateInitializer;
 import org.apache.flink.streaming.api.watermark.Watermark;
 import org.apache.flink.streaming.runtime.io.RecordWriterOutput;
 import org.apache.flink.streaming.runtime.metrics.WatermarkGauge;
@@ -282,15 +283,14 @@ public void endHeadOperatorInput(int inputId) throws Exception {
 	}
 
 	/**
-	 * Executes {@link StreamOperator#initializeState()} followed by {@link StreamOperator#open()}
-	 * of each operator in the chain of this {@link StreamTask}. State initialization and opening
-	 * happens from <b>tail to head</b> operator in the chain, contrary to {@link StreamOperator#close()}
-	 * which happens <b>head to tail</b>(see {@link #closeOperators(StreamTaskActionExecutor)}).
+	 * Initialize state and open all operators in the chain from <b>tail to head</b>,
+	 * contrary to {@link StreamOperator#close()} which happens <b>head to tail</b>
+	 * (see {@link #closeOperators(StreamTaskActionExecutor)}).
 	 */
-	protected void initializeStateAndOpenOperators() throws Exception {
+	protected void initializeStateAndOpenOperators(StreamTaskStateInitializer streamTaskStateInitializer) throws Exception {
 		for (StreamOperatorWrapper<?, ?> operatorWrapper : getAllOperators(true)) {
 			StreamOperator<?> operator = operatorWrapper.getStreamOperator();
-			operator.initializeState();
+			operator.initializeState(streamTaskStateInitializer);
 			operator.open();
 		}
 	}
@@ -298,7 +298,7 @@ protected void initializeStateAndOpenOperators() throws Exception {
 	/**
 	 * Closes all operators in a chain effect way. Closing happens from <b>head to tail</b> operator
 	 * in the chain, contrary to {@link StreamOperator#open()} which happens <b>tail to head</b>
-	 * (see {@link #initializeStateAndOpenOperators()}).
+	 * (see {@link #initializeStateAndOpenOperators(StreamTaskStateInitializer)}).
 	 */
 	protected void closeOperators(StreamTaskActionExecutor actionExecutor) throws Exception {
 		if (headOperatorWrapper != null) {
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java
index 82651ac892d87..171ed89bd82c0 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java
@@ -439,7 +439,7 @@ protected void beforeInvoke() throws Exception {
 			// both the following operations are protected by the lock
 			// so that we avoid race conditions in the case that initializeState()
 			// registers a timer, that fires before the open() is called.
-			operatorChain.initializeStateAndOpenOperators();
+			operatorChain.initializeStateAndOpenOperators(createStreamTaskStateInitializer());
 		});
 
 		isRunning = true;
@@ -915,7 +915,8 @@ private void checkpointState(
 			getCancelables(),
 			getAsyncOperationsThreadPool(),
 			getEnvironment(),
-			this);
+			this,
+			this::isCanceled);
 	}
 
 	// ------------------------------------------------------------------------
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorTest.java
index eafd410b82ee2..91ea7dd62573a 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorTest.java
@@ -41,6 +41,7 @@
 import org.apache.flink.streaming.api.operators.OutputTypeConfigurable;
 import org.apache.flink.streaming.api.operators.StreamOperator;
 import org.apache.flink.streaming.api.operators.StreamOperatorFactory;
+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;
 import org.apache.flink.streaming.api.operators.StreamSource;
 import org.apache.flink.streaming.api.operators.TwoInputStreamOperator;
 import org.apache.flink.streaming.api.transformations.MultipleInputTransformation;
@@ -671,10 +672,7 @@ protected boolean matchesSafely(ResourceSpec item) {
 
 	private static class MultipleInputOperatorFactory implements StreamOperatorFactory<String> {
 		@Override
-		public <T extends StreamOperator<String>> T createStreamOperator(
-				StreamTask<?, ?> containingTask,
-				StreamConfig config,
-				Output<StreamRecord<String>> output) {
+		public <T extends StreamOperator<String>> T createStreamOperator(StreamOperatorParameters<String> parameters) {
 			throw new UnsupportedOperationException();
 		}
 
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorTest.java
index f9d9aa5e503ea..ebd2ed10d9440 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorTest.java
@@ -23,74 +23,38 @@
 import org.apache.flink.api.common.typeutils.base.StringSerializer;
 import org.apache.flink.api.java.functions.KeySelector;
 import org.apache.flink.api.java.tuple.Tuple2;
-import org.apache.flink.core.fs.CloseableRegistry;
-import org.apache.flink.mock.Whitebox;
-import org.apache.flink.runtime.checkpoint.CheckpointOptions;
 import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;
-import org.apache.flink.runtime.state.AbstractKeyedStateBackend;
-import org.apache.flink.runtime.state.CheckpointStreamFactory;
 import org.apache.flink.runtime.state.KeyGroupRange;
 import org.apache.flink.runtime.state.KeyGroupRangeAssignment;
-import org.apache.flink.runtime.state.KeyedStateHandle;
-import org.apache.flink.runtime.state.OperatorStateBackend;
-import org.apache.flink.runtime.state.OperatorStateHandle;
-import org.apache.flink.runtime.state.SnapshotResult;
-import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;
 import org.apache.flink.runtime.state.VoidNamespace;
 import org.apache.flink.runtime.state.VoidNamespaceSerializer;
-import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;
 import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
-import org.apache.flink.streaming.runtime.tasks.StreamTask;
 import org.apache.flink.streaming.util.AbstractStreamOperatorTestHarness;
 import org.apache.flink.streaming.util.KeyedOneInputStreamOperatorTestHarness;
 import org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness;
 
 import org.junit.Test;
-import org.junit.runner.RunWith;
-import org.powermock.core.classloader.annotations.PowerMockIgnore;
-import org.powermock.core.classloader.annotations.PrepareForTest;
-import org.powermock.modules.junit4.PowerMockRunner;
 
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Random;
-import java.util.concurrent.RunnableFuture;
 
 import static junit.framework.TestCase.assertTrue;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.contains;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.fail;
-import static org.mockito.ArgumentMatchers.nullable;
-import static org.mockito.Matchers.any;
-import static org.mockito.Matchers.anyBoolean;
-import static org.mockito.Matchers.anyLong;
-import static org.mockito.Matchers.eq;
-import static org.mockito.Mockito.doCallRealMethod;
-import static org.mockito.Mockito.doThrow;
-import static org.mockito.Mockito.verify;
-import static org.powermock.api.mockito.PowerMockito.doReturn;
-import static org.powermock.api.mockito.PowerMockito.mock;
-import static org.powermock.api.mockito.PowerMockito.spy;
-import static org.powermock.api.mockito.PowerMockito.when;
-import static org.powermock.api.mockito.PowerMockito.whenNew;
 
 /**
  * Tests for the facilities provided by {@link AbstractStreamOperator}. This mostly
  * tests timers and state and whether they are correctly checkpointed/restored
  * with key-group reshuffling.
  */
-@RunWith(PowerMockRunner.class)
-@PrepareForTest(AbstractStreamOperator.class)
-@PowerMockIgnore({"java.*", "javax.*", "org.slf4j.*", "org.apache.log4j.*"})
 public class AbstractStreamOperatorTest {
-
 	@Test
 	public void testStateDoesNotInterfere() throws Exception {
 		TestOperator testOperator = new TestOperator();
 
 		KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String> testHarness =
-				new KeyedOneInputStreamOperatorTestHarness<>(testOperator, new TestKeySelector(), BasicTypeInfo.INT_TYPE_INFO);
+			new KeyedOneInputStreamOperatorTestHarness<>(testOperator, new TestKeySelector(), BasicTypeInfo.INT_TYPE_INFO);
 
 		testHarness.open();
 
@@ -101,8 +65,8 @@ public void testStateDoesNotInterfere() throws Exception {
 		testHarness.processElement(new Tuple2<>(0, "EMIT_STATE"), 0);
 
 		assertThat(
-				extractResult(testHarness),
-				contains("ON_ELEMENT:1:CIAO", "ON_ELEMENT:0:HELLO"));
+			extractResult(testHarness),
+			contains("ON_ELEMENT:1:CIAO", "ON_ELEMENT:0:HELLO"));
 	}
 
 	/**
@@ -114,7 +78,7 @@ public void testEventTimeTimersDontInterfere() throws Exception {
 		TestOperator testOperator = new TestOperator();
 
 		KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String> testHarness =
-				new KeyedOneInputStreamOperatorTestHarness<>(testOperator, new TestKeySelector(), BasicTypeInfo.INT_TYPE_INFO);
+			new KeyedOneInputStreamOperatorTestHarness<>(testOperator, new TestKeySelector(), BasicTypeInfo.INT_TYPE_INFO);
 
 		testHarness.open();
 
@@ -130,14 +94,14 @@ public void testEventTimeTimersDontInterfere() throws Exception {
 		testHarness.processWatermark(10L);
 
 		assertThat(
-				extractResult(testHarness),
-				contains("ON_EVENT_TIME:HELLO"));
+			extractResult(testHarness),
+			contains("ON_EVENT_TIME:HELLO"));
 
 		testHarness.processWatermark(20L);
 
 		assertThat(
-				extractResult(testHarness),
-				contains("ON_EVENT_TIME:CIAO"));
+			extractResult(testHarness),
+			contains("ON_EVENT_TIME:CIAO"));
 	}
 
 	/**
@@ -149,7 +113,7 @@ public void testProcessingTimeTimersDontInterfere() throws Exception {
 		TestOperator testOperator = new TestOperator();
 
 		KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String> testHarness =
-				new KeyedOneInputStreamOperatorTestHarness<>(testOperator, new TestKeySelector(), BasicTypeInfo.INT_TYPE_INFO);
+			new KeyedOneInputStreamOperatorTestHarness<>(testOperator, new TestKeySelector(), BasicTypeInfo.INT_TYPE_INFO);
 
 		testHarness.open();
 
@@ -165,14 +129,14 @@ public void testProcessingTimeTimersDontInterfere() throws Exception {
 		testHarness.setProcessingTime(10L);
 
 		assertThat(
-				extractResult(testHarness),
-				contains("ON_PROC_TIME:HELLO"));
+			extractResult(testHarness),
+			contains("ON_PROC_TIME:HELLO"));
 
 		testHarness.setProcessingTime(20L);
 
 		assertThat(
-				extractResult(testHarness),
-				contains("ON_PROC_TIME:CIAO"));
+			extractResult(testHarness),
+			contains("ON_PROC_TIME:CIAO"));
 	}
 
 	/**
@@ -183,7 +147,7 @@ public void testEnsureProcessingTimeTimerRegisteredOnRestore() throws Exception
 		TestOperator testOperator = new TestOperator();
 
 		KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String> testHarness =
-				new KeyedOneInputStreamOperatorTestHarness<>(testOperator, new TestKeySelector(), BasicTypeInfo.INT_TYPE_INFO);
+			new KeyedOneInputStreamOperatorTestHarness<>(testOperator, new TestKeySelector(), BasicTypeInfo.INT_TYPE_INFO);
 
 		testHarness.open();
 
@@ -201,10 +165,10 @@ public void testEnsureProcessingTimeTimerRegisteredOnRestore() throws Exception
 		TestOperator testOperator1 = new TestOperator();
 
 		KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String> testHarness1 =
-				new KeyedOneInputStreamOperatorTestHarness<>(
-						testOperator1,
-						new TestKeySelector(),
-						BasicTypeInfo.INT_TYPE_INFO);
+			new KeyedOneInputStreamOperatorTestHarness<>(
+				testOperator1,
+				new TestKeySelector(),
+				BasicTypeInfo.INT_TYPE_INFO);
 
 		testHarness1.setProcessingTime(0L);
 
@@ -215,14 +179,14 @@ public void testEnsureProcessingTimeTimerRegisteredOnRestore() throws Exception
 		testHarness1.setProcessingTime(10L);
 
 		assertThat(
-				extractResult(testHarness1),
-				contains("ON_PROC_TIME:HELLO"));
+			extractResult(testHarness1),
+			contains("ON_PROC_TIME:HELLO"));
 
 		testHarness1.setProcessingTime(20L);
 
 		assertThat(
-				extractResult(testHarness1),
-				contains("ON_PROC_TIME:CIAO"));
+			extractResult(testHarness1),
+			contains("ON_PROC_TIME:CIAO"));
 	}
 
 
@@ -234,7 +198,7 @@ public void testProcessingTimeAndEventTimeDontInterfere() throws Exception {
 		TestOperator testOperator = new TestOperator();
 
 		KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String> testHarness =
-				new KeyedOneInputStreamOperatorTestHarness<>(testOperator, new TestKeySelector(), BasicTypeInfo.INT_TYPE_INFO);
+			new KeyedOneInputStreamOperatorTestHarness<>(testOperator, new TestKeySelector(), BasicTypeInfo.INT_TYPE_INFO);
 
 		testHarness.open();
 
@@ -249,14 +213,14 @@ public void testProcessingTimeAndEventTimeDontInterfere() throws Exception {
 		testHarness.processWatermark(20L);
 
 		assertThat(
-				extractResult(testHarness),
-				contains("ON_EVENT_TIME:HELLO"));
+			extractResult(testHarness),
+			contains("ON_EVENT_TIME:HELLO"));
 
 		testHarness.setProcessingTime(10L);
 
 		assertThat(
-				extractResult(testHarness),
-				contains("ON_PROC_TIME:HELLO"));
+			extractResult(testHarness),
+			contains("ON_PROC_TIME:HELLO"));
 	}
 
 	/**
@@ -281,13 +245,13 @@ public void testStateAndTimerStateShufflingScalingUp() throws Exception {
 		TestOperator testOperator = new TestOperator();
 
 		KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String> testHarness =
-				new KeyedOneInputStreamOperatorTestHarness<>(
-						testOperator,
-						new TestKeySelector(),
-						BasicTypeInfo.INT_TYPE_INFO,
-						maxParallelism,
-						1, /* num subtasks */
-						0 /* subtask index */);
+			new KeyedOneInputStreamOperatorTestHarness<>(
+				testOperator,
+				new TestKeySelector(),
+				BasicTypeInfo.INT_TYPE_INFO,
+				maxParallelism,
+				1, /* num subtasks */
+				0 /* subtask index */);
 
 		testHarness.open();
 
@@ -314,13 +278,13 @@ public void testStateAndTimerStateShufflingScalingUp() throws Exception {
 		TestOperator testOperator1 = new TestOperator();
 
 		KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String> testHarness1 =
-				new KeyedOneInputStreamOperatorTestHarness<>(
-						testOperator1,
-						new TestKeySelector(),
-						BasicTypeInfo.INT_TYPE_INFO,
-						maxParallelism,
-						2, /* num subtasks */
-						0 /* subtask index */);
+			new KeyedOneInputStreamOperatorTestHarness<>(
+				testOperator1,
+				new TestKeySelector(),
+				BasicTypeInfo.INT_TYPE_INFO,
+				maxParallelism,
+				2, /* num subtasks */
+				0 /* subtask index */);
 
 		testHarness1.setup();
 		testHarness1.initializeState(initState1);
@@ -357,13 +321,13 @@ public void testStateAndTimerStateShufflingScalingUp() throws Exception {
 		TestOperator testOperator2 = new TestOperator();
 
 		KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String> testHarness2 =
-				new KeyedOneInputStreamOperatorTestHarness<>(
-						testOperator2,
-						new TestKeySelector(),
-						BasicTypeInfo.INT_TYPE_INFO,
-						maxParallelism,
-						2, /* num subtasks */
-						1 /* subtask index */);
+			new KeyedOneInputStreamOperatorTestHarness<>(
+				testOperator2,
+				new TestKeySelector(),
+				BasicTypeInfo.INT_TYPE_INFO,
+				maxParallelism,
+				2, /* num subtasks */
+				1 /* subtask index */);
 
 		testHarness2.setup();
 		testHarness2.initializeState(initState2);
@@ -494,169 +458,6 @@ public void testStateAndTimerStateShufflingScalingDown() throws Exception {
 		assertTrue(extractResult(testHarness3).isEmpty());
 	}
 
-	/**
-	 * Checks that the state snapshot context is closed after a successful snapshot operation.
-	 */
-	@Test
-	public void testSnapshotMethod() throws Exception {
-		final long checkpointId = 42L;
-		final long timestamp = 1L;
-
-		final CloseableRegistry closeableRegistry = new CloseableRegistry();
-
-		StateSnapshotContextSynchronousImpl context = spy(new StateSnapshotContextSynchronousImpl(0L, 0L));
-
-		whenNew(StateSnapshotContextSynchronousImpl.class).withAnyArguments().thenReturn(context);
-
-		StreamTask<Void, AbstractStreamOperator<Void>> containingTask = mock(StreamTask.class);
-		when(containingTask.getCancelables()).thenReturn(closeableRegistry);
-
-		AbstractStreamOperator<Void> operator = mock(AbstractStreamOperator.class);
-		when(operator.snapshotState(anyLong(), anyLong(), any(CheckpointOptions.class), any(CheckpointStreamFactory.class))).thenCallRealMethod();
-		doReturn(containingTask).when(operator).getContainingTask();
-
-		operator.snapshotState(
-				checkpointId,
-				timestamp,
-				CheckpointOptions.forCheckpointWithDefaultLocation(),
-				new MemCheckpointStreamFactory(Integer.MAX_VALUE));
-
-	}
-
-	/**
-	 * Tests that the created StateSnapshotContextSynchronousImpl is closed in case of a failing
-	 * Operator#snapshotState(StateSnapshotContextSynchronousImpl) call.
-	 */
-	@Test
-	public void testFailingSnapshotMethod() throws Exception {
-		final long checkpointId = 42L;
-		final long timestamp = 1L;
-
-		final Exception failingException = new Exception("Test exception");
-
-		final CloseableRegistry closeableRegistry = new CloseableRegistry();
-
-		StateSnapshotContextSynchronousImpl context = mock(StateSnapshotContextSynchronousImpl.class);
-
-		whenNew(StateSnapshotContextSynchronousImpl.class).withAnyArguments().thenReturn(context);
-
-		StreamTask<Void, AbstractStreamOperator<Void>> containingTask = mock(StreamTask.class);
-		when(containingTask.getCancelables()).thenReturn(closeableRegistry);
-
-		AbstractStreamOperator<Void> operator = mock(AbstractStreamOperator.class);
-		when(operator.snapshotState(anyLong(), anyLong(), any(CheckpointOptions.class), any(CheckpointStreamFactory.class))).thenCallRealMethod();
-		doReturn(containingTask).when(operator).getContainingTask();
-
-		// lets fail when calling the actual snapshotState method
-		doThrow(failingException).when(operator).snapshotState(eq(context));
-
-		try {
-			operator.snapshotState(
-					checkpointId,
-					timestamp,
-					CheckpointOptions.forCheckpointWithDefaultLocation(),
-					new MemCheckpointStreamFactory(Integer.MAX_VALUE));
-			fail("Exception expected.");
-		} catch (Exception e) {
-			assertEquals(failingException.getMessage(), e.getCause().getMessage());
-		}
-	}
-
-	/**
-	 * Tests that a failing snapshot method call to the keyed state backend will trigger the closing
-	 * of the StateSnapshotContextSynchronousImpl and the cancellation of the
-	 * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.
-	 */
-	@Test
-	public void testFailingBackendSnapshotMethod() throws Exception {
-		final long checkpointId = 42L;
-		final long timestamp = 1L;
-
-		final Exception failingException = new Exception("Test exception");
-
-		final CloseableRegistry closeableRegistry = new CloseableRegistry();
-
-		RunnableFuture<SnapshotResult<KeyedStateHandle>> futureKeyedStateHandle = mock(RunnableFuture.class);
-		RunnableFuture<SnapshotResult<OperatorStateHandle>> futureOperatorStateHandle = mock(RunnableFuture.class);
-
-		StateSnapshotContextSynchronousImpl context = spy(new StateSnapshotContextSynchronousImpl(checkpointId, timestamp));
-		when(context.getKeyedStateStreamFuture()).thenReturn(futureKeyedStateHandle);
-		when(context.getOperatorStateStreamFuture()).thenReturn(futureOperatorStateHandle);
-
-		OperatorSnapshotFutures operatorSnapshotResult = spy(new OperatorSnapshotFutures());
-
-		whenNew(StateSnapshotContextSynchronousImpl.class)
-			.withArguments(
-				anyLong(),
-				anyLong(),
-				any(CheckpointStreamFactory.class),
-				nullable(KeyGroupRange.class),
-				any(CloseableRegistry.class))
-			.thenReturn(context);
-		whenNew(OperatorSnapshotFutures.class).withAnyArguments().thenReturn(operatorSnapshotResult);
-
-		StreamTask<Void, AbstractStreamOperator<Void>> containingTask = mock(StreamTask.class);
-		when(containingTask.getCancelables()).thenReturn(closeableRegistry);
-
-		AbstractStreamOperator<Void> operator = mock(AbstractStreamOperator.class);
-		when(operator.snapshotState(anyLong(), anyLong(), any(CheckpointOptions.class), any(CheckpointStreamFactory.class))).thenCallRealMethod();
-
-		doCallRealMethod().when(operator).close();
-		doCallRealMethod().when(operator).dispose();
-
-		doReturn(containingTask).when(operator).getContainingTask();
-
-		RunnableFuture<SnapshotResult<OperatorStateHandle>> futureManagedOperatorStateHandle = mock(RunnableFuture.class);
-
-		OperatorStateBackend operatorStateBackend = mock(OperatorStateBackend.class);
-		when(operatorStateBackend.snapshot(
-			eq(checkpointId),
-			eq(timestamp),
-			any(CheckpointStreamFactory.class),
-			any(CheckpointOptions.class))).thenReturn(futureManagedOperatorStateHandle);
-
-		AbstractKeyedStateBackend<?> keyedStateBackend = mock(AbstractKeyedStateBackend.class);
-		when(keyedStateBackend.snapshot(
-			eq(checkpointId),
-			eq(timestamp),
-			any(CheckpointStreamFactory.class),
-			eq(CheckpointOptions.forCheckpointWithDefaultLocation()))).thenThrow(failingException);
-
-		closeableRegistry.registerCloseable(operatorStateBackend);
-		closeableRegistry.registerCloseable(keyedStateBackend);
-
-		Whitebox.setInternalState(operator, "operatorStateBackend", operatorStateBackend);
-		Whitebox.setInternalState(operator, "keyedStateBackend", keyedStateBackend);
-
-		try {
-			operator.snapshotState(
-					checkpointId,
-					timestamp,
-					CheckpointOptions.forCheckpointWithDefaultLocation(),
-					new MemCheckpointStreamFactory(Integer.MAX_VALUE));
-			fail("Exception expected.");
-		} catch (Exception e) {
-			assertEquals(failingException.getMessage(), e.getCause().getMessage());
-		}
-
-		// verify that the context has been closed, the operator snapshot result has been cancelled
-		// and that all futures have been cancelled.
-		verify(operatorSnapshotResult).cancel();
-
-		verify(futureKeyedStateHandle).cancel(anyBoolean());
-		verify(futureOperatorStateHandle).cancel(anyBoolean());
-		verify(futureKeyedStateHandle).cancel(anyBoolean());
-
-		operator.close();
-
-		operator.dispose();
-
-		verify(operatorStateBackend).close();
-		verify(keyedStateBackend).close();
-		verify(operatorStateBackend).dispose();
-		verify(keyedStateBackend).dispose();
-	}
-
 	/**
 	 * Extracts the result values form the test harness and clear the output queue.
 	 */
@@ -687,24 +488,24 @@ public Integer getKey(Tuple2<Integer, String> value) throws Exception {
 	 * state or setting timers.
 	 */
 	private static class TestOperator
-			extends AbstractStreamOperator<String>
-			implements OneInputStreamOperator<Tuple2<Integer, String>, String>, Triggerable<Integer, VoidNamespace> {
+		extends AbstractStreamOperator<String>
+		implements OneInputStreamOperator<Tuple2<Integer, String>, String>, Triggerable<Integer, VoidNamespace> {
 
 		private static final long serialVersionUID = 1L;
 
 		private transient InternalTimerService<VoidNamespace> timerService;
 
 		private final ValueStateDescriptor<String> stateDescriptor =
-				new ValueStateDescriptor<>("state", StringSerializer.INSTANCE);
+			new ValueStateDescriptor<>("state", StringSerializer.INSTANCE);
 
 		@Override
 		public void open() throws Exception {
 			super.open();
 
 			this.timerService = getInternalTimerService(
-					"test-timers",
-					VoidNamespaceSerializer.INSTANCE,
-					this);
+				"test-timers",
+				VoidNamespaceSerializer.INSTANCE,
+				this);
 		}
 
 		@Override
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/AbstractUdfStreamOperatorLifecycleTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/AbstractUdfStreamOperatorLifecycleTest.java
index 1c2240e70e390..5fb8830ef8a38 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/AbstractUdfStreamOperatorLifecycleTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/AbstractUdfStreamOperatorLifecycleTest.java
@@ -89,15 +89,13 @@ public class AbstractUdfStreamOperatorLifecycleTest {
 	private static final String ALL_METHODS_STREAM_OPERATOR = "[" +
 			"close[], " +
 			"dispose[], " +
-			"getChainingStrategy[], " +
 			"getCurrentKey[], " +
 			"getMetricGroup[], " +
 			"getOperatorID[], " +
-			"initializeState[], " +
+			"initializeState[interface org.apache.flink.streaming.api.operators.StreamTaskStateInitializer], " +
 			"notifyCheckpointComplete[long], " +
 			"open[], " +
 			"prepareSnapshotPreBarrier[long], " +
-			"setChainingStrategy[class org.apache.flink.streaming.api.operators.ChainingStrategy], " +
 			"setCurrentKey[class java.lang.Object], " +
 			"setKeyContextElement1[class org.apache.flink.streaming.runtime.streamrecord.StreamRecord], " +
 			"setKeyContextElement2[class org.apache.flink.streaming.runtime.streamrecord.StreamRecord], " +
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java
new file mode 100644
index 0000000000000..151dce1523f08
--- /dev/null
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java
@@ -0,0 +1,193 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.api.operators;
+
+import org.apache.flink.api.common.ExecutionConfig;
+import org.apache.flink.api.common.state.ListStateDescriptor;
+import org.apache.flink.api.common.state.ValueStateDescriptor;
+import org.apache.flink.api.common.typeutils.base.IntSerializer;
+import org.apache.flink.api.common.typeutils.base.LongSerializer;
+import org.apache.flink.core.fs.CloseableRegistry;
+import org.apache.flink.runtime.checkpoint.CheckpointException;
+import org.apache.flink.runtime.checkpoint.CheckpointOptions;
+import org.apache.flink.runtime.jobgraph.OperatorID;
+import org.apache.flink.runtime.metrics.util.InterceptingOperatorMetricGroup;
+import org.apache.flink.runtime.operators.testutils.ExpectedTestException;
+import org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder;
+import org.apache.flink.runtime.state.KeyGroupRange;
+import org.apache.flink.runtime.state.KeyedStateHandle;
+import org.apache.flink.runtime.state.OperatorStateHandle;
+import org.apache.flink.runtime.state.SnapshotResult;
+import org.apache.flink.runtime.state.StateInitializationContext;
+import org.apache.flink.runtime.state.StateSnapshotContext;
+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;
+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;
+import org.apache.flink.runtime.state.memory.MemoryStateBackend;
+import org.apache.flink.streaming.api.operators.StreamOperatorStateHandler.CheckpointedStreamOperator;
+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;
+import org.apache.flink.util.ExceptionUtils;
+
+import org.junit.Test;
+
+import java.util.Optional;
+import java.util.concurrent.FutureTask;
+import java.util.concurrent.RunnableFuture;
+
+import static junit.framework.TestCase.assertTrue;
+import static org.hamcrest.CoreMatchers.equalTo;
+import static org.hamcrest.CoreMatchers.is;
+import static org.hamcrest.CoreMatchers.not;
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.hamcrest.Matchers.empty;
+import static org.junit.Assert.fail;
+
+/**
+ * Tests for {@link StreamOperatorStateHandlerTest}.
+ */
+public class StreamOperatorStateHandlerTest {
+	/**
+	 * Tests that a failing snapshot method call to the keyed state backend will trigger the closing
+	 * of the StateSnapshotContextSynchronousImpl and the cancellation of the
+	 * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.
+	 */
+	@Test
+	public void testFailingBackendSnapshotMethod() throws Exception {
+		final long checkpointId = 42L;
+		final long timestamp = 1L;
+
+		try (CloseableRegistry closeableRegistry = new CloseableRegistry()) {
+			RunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateManagedFuture = new CancelableFuture<>();
+			RunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateRawFuture = new CancelableFuture<>();
+			RunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateManagedFuture = new CancelableFuture<>();
+			RunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateRawFuture = new CancelableFuture<>();
+
+			OperatorSnapshotFutures operatorSnapshotResult = new OperatorSnapshotFutures(
+				keyedStateManagedFuture,
+				keyedStateRawFuture,
+				operatorStateManagedFuture,
+				operatorStateRawFuture);
+
+			StateSnapshotContextSynchronousImpl context = new TestStateSnapshotContextSynchronousImpl(checkpointId, timestamp, closeableRegistry);
+			context.getRawKeyedOperatorStateOutput();
+			context.getRawOperatorStateOutput();
+
+			StreamTaskStateInitializerImpl stateInitializer =
+				new StreamTaskStateInitializerImpl(new MockEnvironmentBuilder().build(), new MemoryStateBackend());
+			StreamOperatorStateContext stateContext = stateInitializer.streamOperatorStateContext(
+				new OperatorID(),
+				"whatever",
+				new TestProcessingTimeService(),
+				new UnUsedKeyContext(),
+				IntSerializer.INSTANCE,
+				closeableRegistry,
+				new InterceptingOperatorMetricGroup());
+			StreamOperatorStateHandler stateHandler = new StreamOperatorStateHandler(stateContext, new ExecutionConfig(), closeableRegistry);
+
+			final String keyedStateField = "keyedStateField";
+			final String operatorStateField = "operatorStateField";
+
+			CheckpointedStreamOperator checkpointedStreamOperator = new CheckpointedStreamOperator() {
+				@Override
+				public void initializeState(StateInitializationContext context) throws Exception {
+					context.getKeyedStateStore()
+						.getState(new ValueStateDescriptor<>(keyedStateField, LongSerializer.INSTANCE))
+						.update(42L);
+					context.getOperatorStateStore()
+						.getListState(new ListStateDescriptor<>(operatorStateField, LongSerializer.INSTANCE))
+						.add(42L);
+				}
+
+				@Override
+				public void snapshotState(StateSnapshotContext context) throws Exception {
+					throw new ExpectedTestException();
+				}
+			};
+
+			stateHandler.setCurrentKey("44");
+			stateHandler.initializeOperatorState(checkpointedStreamOperator);
+
+			assertThat(stateContext.operatorStateBackend().getRegisteredStateNames(), is(not(empty())));
+			assertThat(stateContext.keyedStateBackend().numKeyValueStatesByName(), equalTo(1));
+
+			try {
+				stateHandler.snapshotState(
+					checkpointedStreamOperator,
+					Optional.of(stateContext.internalTimerServiceManager()),
+					"42",
+					42,
+					42,
+					CheckpointOptions.forCheckpointWithDefaultLocation(),
+					new MemCheckpointStreamFactory(1024),
+					operatorSnapshotResult,
+					context);
+				fail("Exception expected.");
+			} catch (CheckpointException e) {
+				// We can not check for ExpectedTestException class directly,
+				// as CheckpointException is wrapping the cause with SerializedThrowable
+				if (!ExceptionUtils.findThrowableWithMessage(e, ExpectedTestException.MESSAGE).isPresent()) {
+					throw e;
+				}
+			}
+
+			assertTrue(keyedStateManagedFuture.isCancelled());
+			assertTrue(keyedStateRawFuture.isCancelled());
+			assertTrue(context.getKeyedStateStreamFuture().isCancelled());
+			assertTrue(operatorStateManagedFuture.isCancelled());
+			assertTrue(operatorStateRawFuture.isCancelled());
+			assertTrue(context.getOperatorStateStreamFuture().isCancelled());
+
+			stateHandler.dispose();
+
+			assertThat(stateContext.operatorStateBackend().getRegisteredBroadcastStateNames(), is(empty()));
+			assertThat(stateContext.operatorStateBackend().getRegisteredStateNames(), is(empty()));
+			assertThat(stateContext.keyedStateBackend().numKeyValueStatesByName(), is(0));
+		}
+	}
+
+	private static class TestStateSnapshotContextSynchronousImpl extends StateSnapshotContextSynchronousImpl {
+		public TestStateSnapshotContextSynchronousImpl(
+				long checkpointId,
+				long timestamp,
+				CloseableRegistry closeableRegistry) {
+			super(checkpointId, timestamp, new MemCheckpointStreamFactory(1024), new KeyGroupRange(0, 2), closeableRegistry);
+			this.keyedStateCheckpointClosingFuture = new CancelableFuture<>();
+			this.operatorStateCheckpointClosingFuture = new CancelableFuture<>();
+		}
+	}
+
+	private static class CancelableFuture<T> extends FutureTask<T> {
+		public CancelableFuture() {
+			super(() -> {
+				throw new UnsupportedOperationException();
+			});
+		}
+	}
+
+	private static class UnUsedKeyContext implements KeyContext {
+		@Override
+		public void setCurrentKey(Object key) {
+			throw new UnsupportedOperationException();
+		}
+
+		@Override
+		public Object getCurrentKey() {
+			throw new UnsupportedOperationException();
+		}
+	}
+}
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamingRuntimeContextTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamingRuntimeContextTest.java
index 7b678c32bb81d..1c2390c90ed7a 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamingRuntimeContextTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamingRuntimeContextTest.java
@@ -21,7 +21,6 @@
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.JobID;
 import org.apache.flink.api.common.TaskInfo;
-import org.apache.flink.api.common.accumulators.Accumulator;
 import org.apache.flink.api.common.functions.AggregateFunction;
 import org.apache.flink.api.common.functions.FoldFunction;
 import org.apache.flink.api.common.functions.ReduceFunction;
@@ -38,6 +37,7 @@
 import org.apache.flink.api.common.typeutils.base.IntSerializer;
 import org.apache.flink.api.common.typeutils.base.ListSerializer;
 import org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer;
+import org.apache.flink.configuration.Configuration;
 import org.apache.flink.core.fs.CloseableRegistry;
 import org.apache.flink.core.fs.Path;
 import org.apache.flink.metrics.groups.UnregisteredMetricsGroup;
@@ -55,12 +55,19 @@
 import org.apache.flink.runtime.state.VoidNamespaceSerializer;
 import org.apache.flink.runtime.state.memory.MemoryStateBackend;
 import org.apache.flink.runtime.state.ttl.TtlTimeProvider;
+import org.apache.flink.streaming.api.graph.StreamConfig;
+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
+import org.apache.flink.streaming.runtime.tasks.StreamTask;
+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;
+import org.apache.flink.streaming.util.CollectorOutput;
+import org.apache.flink.streaming.util.MockStreamTaskBuilder;
 
 import org.junit.Test;
 import org.mockito.Matchers;
 import org.mockito.invocation.InvocationOnMock;
 import org.mockito.stubbing.Answer;
 
+import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicReference;
@@ -86,11 +93,7 @@ public void testValueStateInstantiation() throws Exception {
 
 		final AtomicReference<Object> descriptorCapture = new AtomicReference<>();
 
-		StreamingRuntimeContext context = new StreamingRuntimeContext(
-				createDescriptorCapturingMockOp(descriptorCapture, config),
-				createMockEnvironment(),
-				Collections.<String, Accumulator<?, ?>>emptyMap());
-
+		StreamingRuntimeContext context = createRuntimeContext(descriptorCapture, config);
 		ValueStateDescriptor<TaskInfo> descr = new ValueStateDescriptor<>("name", TaskInfo.class);
 		context.getState(descr);
 
@@ -110,10 +113,7 @@ public void testReducingStateInstantiation() throws Exception {
 
 		final AtomicReference<Object> descriptorCapture = new AtomicReference<>();
 
-		StreamingRuntimeContext context = new StreamingRuntimeContext(
-				createDescriptorCapturingMockOp(descriptorCapture, config),
-				createMockEnvironment(),
-				Collections.<String, Accumulator<?, ?>>emptyMap());
+		StreamingRuntimeContext context = createRuntimeContext(descriptorCapture, config);
 
 		@SuppressWarnings("unchecked")
 		ReduceFunction<TaskInfo> reducer = (ReduceFunction<TaskInfo>) mock(ReduceFunction.class);
@@ -133,16 +133,12 @@ public void testReducingStateInstantiation() throws Exception {
 
 	@Test
 	public void testAggregatingStateInstantiation() throws Exception {
-
 		final ExecutionConfig config = new ExecutionConfig();
 		config.registerKryoType(Path.class);
 
 		final AtomicReference<Object> descriptorCapture = new AtomicReference<>();
 
-		StreamingRuntimeContext context = new StreamingRuntimeContext(
-				createDescriptorCapturingMockOp(descriptorCapture, config),
-				createMockEnvironment(),
-				Collections.<String, Accumulator<?, ?>>emptyMap());
+		StreamingRuntimeContext context = createRuntimeContext(descriptorCapture, config);
 
 		@SuppressWarnings("unchecked")
 		AggregateFunction<String, TaskInfo, String> aggregate = (AggregateFunction<String, TaskInfo, String>) mock(AggregateFunction.class);
@@ -168,10 +164,7 @@ public void testFoldingStateInstantiation() throws Exception {
 
 		final AtomicReference<Object> descriptorCapture = new AtomicReference<>();
 
-		StreamingRuntimeContext context = new StreamingRuntimeContext(
-				createDescriptorCapturingMockOp(descriptorCapture, config),
-				createMockEnvironment(),
-				Collections.<String, Accumulator<?, ?>>emptyMap());
+		StreamingRuntimeContext context = createRuntimeContext(descriptorCapture, config);
 
 		@SuppressWarnings("unchecked")
 		FoldFunction<String, TaskInfo> folder = (FoldFunction<String, TaskInfo>) mock(FoldFunction.class);
@@ -197,10 +190,7 @@ public void testListStateInstantiation() throws Exception {
 
 		final AtomicReference<Object> descriptorCapture = new AtomicReference<>();
 
-		StreamingRuntimeContext context = new StreamingRuntimeContext(
-				createDescriptorCapturingMockOp(descriptorCapture, config),
-				createMockEnvironment(),
-				Collections.<String, Accumulator<?, ?>>emptyMap());
+		StreamingRuntimeContext context = createRuntimeContext(descriptorCapture, config);
 
 		ListStateDescriptor<TaskInfo> descr = new ListStateDescriptor<>("name", TaskInfo.class);
 		context.getListState(descr);
@@ -218,11 +208,7 @@ public void testListStateInstantiation() throws Exception {
 
 	@Test
 	public void testListStateReturnsEmptyListByDefault() throws Exception {
-
-		StreamingRuntimeContext context = new StreamingRuntimeContext(
-				createListPlainMockOp(),
-				createMockEnvironment(),
-				Collections.<String, Accumulator<?, ?>>emptyMap());
+		StreamingRuntimeContext context = createRuntimeContext();
 
 		ListStateDescriptor<String> descr = new ListStateDescriptor<>("name", String.class);
 		ListState<String> state = context.getListState(descr);
@@ -240,10 +226,7 @@ public void testMapStateInstantiation() throws Exception {
 
 		final AtomicReference<Object> descriptorCapture = new AtomicReference<>();
 
-		StreamingRuntimeContext context = new StreamingRuntimeContext(
-				createDescriptorCapturingMockOp(descriptorCapture, config),
-				createMockEnvironment(),
-				Collections.<String, Accumulator<?, ?>>emptyMap());
+		StreamingRuntimeContext context = createRuntimeContext(descriptorCapture, config);
 
 		MapStateDescriptor<String, TaskInfo> descr =
 				new MapStateDescriptor<>("name", String.class, TaskInfo.class);
@@ -261,10 +244,7 @@ public void testMapStateInstantiation() throws Exception {
 	@Test
 	public void testMapStateReturnsEmptyMapByDefault() throws Exception {
 
-		StreamingRuntimeContext context = new StreamingRuntimeContext(
-				createMapPlainMockOp(),
-				createMockEnvironment(),
-				Collections.<String, Accumulator<?, ?>>emptyMap());
+		StreamingRuntimeContext context = createMapOperatorRuntimeContext();
 
 		MapStateDescriptor<Integer, String> descr = new MapStateDescriptor<>("name", Integer.class, String.class);
 		MapState<Integer, String> state = context.getMapState(descr);
@@ -278,18 +258,71 @@ public void testMapStateReturnsEmptyMapByDefault() throws Exception {
 	//
 	// ------------------------------------------------------------------------
 
+	private StreamingRuntimeContext createMapOperatorRuntimeContext() throws Exception {
+		AbstractStreamOperator<?> mapPlainMockOp = createMapPlainMockOp();
+		return createRuntimeContext(mapPlainMockOp);
+	}
+
+	private StreamingRuntimeContext createRuntimeContext() throws Exception {
+		return new StreamingRuntimeContext(
+			createListPlainMockOp(),
+			MockEnvironment.builder()
+				.build(),
+			Collections.emptyMap());
+	}
+
+	private StreamingRuntimeContext createRuntimeContext(
+			AtomicReference<Object> descriptorCapture,
+			ExecutionConfig config) throws Exception {
+		return createDescriptorCapturingMockOp(
+			descriptorCapture,
+			config,
+			MockEnvironment.builder()
+				.setExecutionConfig(config)
+				.build()).getRuntimeContext();
+	}
+
+	private StreamingRuntimeContext createRuntimeContext(AbstractStreamOperator<?> operator) {
+		return new StreamingRuntimeContext(
+			MockEnvironment.builder()
+				.build(),
+			Collections.emptyMap(),
+			operator.getMetricGroup(),
+			operator.getOperatorID(),
+			operator.getProcessingTimeService(),
+			operator.getKeyedStateStore());
+	}
+
 	@SuppressWarnings("unchecked")
 	private static AbstractStreamOperator<?> createDescriptorCapturingMockOp(
-			final AtomicReference<Object> ref, final ExecutionConfig config) throws Exception {
+			final AtomicReference<Object> ref,
+			final ExecutionConfig config,
+			Environment environment) throws Exception {
 
-		AbstractStreamOperator<?> operatorMock = mock(AbstractStreamOperator.class);
+		AbstractStreamOperator<?> operator = new AbstractStreamOperator<Object>() {
+			@Override
+			public void setup(
+				StreamTask<?, ?> containingTask,
+				StreamConfig config,
+				Output<StreamRecord<Object>> output) {
+				super.setup(containingTask, config, output);
+			}
+		};
+		StreamConfig streamConfig = new StreamConfig(new Configuration());
+		streamConfig.setOperatorID(new OperatorID());
+		operator.setup(
+			new MockStreamTaskBuilder(environment).setExecutionConfig(config).build(),
+			streamConfig,
+			new CollectorOutput<>(new ArrayList<>()));
+
+		StreamTaskStateInitializer streamTaskStateManager = new StreamTaskStateInitializerImpl(
+			environment,
+			new MemoryStateBackend());
 
 		KeyedStateBackend keyedStateBackend = mock(KeyedStateBackend.class);
 
 		DefaultKeyedStateStore keyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, config);
 
-		when(operatorMock.getExecutionConfig()).thenReturn(config);
-
 		doAnswer(new Answer<Object>() {
 
 			@Override
@@ -299,10 +332,10 @@ public Object answer(InvocationOnMock invocationOnMock) throws Throwable {
 			}
 		}).when(keyedStateBackend).getPartitionedState(Matchers.any(), any(TypeSerializer.class), any(StateDescriptor.class));
 
-		when(operatorMock.getKeyedStateStore()).thenReturn(keyedStateStore);
-		when(operatorMock.getOperatorID()).thenReturn(new OperatorID());
+		operator.initializeState(streamTaskStateManager);
+		operator.getRuntimeContext().setKeyedStateStore(keyedStateStore);
 
-		return operatorMock;
+		return operator;
 	}
 
 	@SuppressWarnings("unchecked")
@@ -384,12 +417,7 @@ public MapState<Integer, String> answer(InvocationOnMock invocationOnMock) throw
 
 		when(operatorMock.getKeyedStateStore()).thenReturn(keyedStateStore);
 		when(operatorMock.getOperatorID()).thenReturn(new OperatorID());
+		when(operatorMock.getProcessingTimeService()).thenReturn(new TestProcessingTimeService());
 		return operatorMock;
 	}
-
-	private static Environment createMockEnvironment() {
-		return MockEnvironment.builder()
-			.setTaskName("test task")
-			.build();
-	}
 }
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/MailboxOperatorTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/MailboxOperatorTest.java
index 850b6981bfe54..753ff8e42990e 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/MailboxOperatorTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/MailboxOperatorTest.java
@@ -20,20 +20,18 @@
 import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
 import org.apache.flink.api.common.typeutils.base.IntSerializer;
 import org.apache.flink.runtime.jobgraph.OperatorID;
-import org.apache.flink.streaming.api.graph.StreamConfig;
 import org.apache.flink.streaming.api.operators.AbstractStreamOperator;
 import org.apache.flink.streaming.api.operators.AbstractStreamOperatorFactory;
 import org.apache.flink.streaming.api.operators.ChainingStrategy;
 import org.apache.flink.streaming.api.operators.MailboxExecutor;
 import org.apache.flink.streaming.api.operators.OneInputStreamOperator;
 import org.apache.flink.streaming.api.operators.OneInputStreamOperatorFactory;
-import org.apache.flink.streaming.api.operators.Output;
 import org.apache.flink.streaming.api.operators.StreamOperator;
+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;
 import org.apache.flink.streaming.api.operators.YieldingOperatorFactory;
 import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
 import org.apache.flink.streaming.runtime.tasks.OneInputStreamTask;
 import org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTestHarness;
-import org.apache.flink.streaming.runtime.tasks.StreamTask;
 import org.apache.flink.util.TestLogger;
 import org.apache.flink.util.function.RunnableWithException;
 
@@ -105,12 +103,10 @@ public void setMailboxExecutor(MailboxExecutor mailboxExecutor) {
 
 		@Override
 		public <Operator extends StreamOperator<Integer>> Operator createStreamOperator(
-				StreamTask<?, ?> containingTask,
-				StreamConfig config,
-				Output<StreamRecord<Integer>> output) {
+				StreamOperatorParameters<Integer> parameters) {
 			ReplicatingMailOperator operator = new ReplicatingMailOperator(maxProcessingElements, mailboxExecutor);
 			operator.setProcessingTimeService(processingTimeService);
-			operator.setup(containingTask, config, output);
+			operator.setup(parameters.getContainingTask(), parameters.getStreamConfig(), parameters.getOutput());
 			return (Operator) operator;
 		}
 
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/StreamTaskOperatorTimerTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/StreamTaskOperatorTimerTest.java
index 1d05ee7e08292..bb3662cef93d3 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/StreamTaskOperatorTimerTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/StreamTaskOperatorTimerTest.java
@@ -21,21 +21,19 @@
 import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
 import org.apache.flink.api.common.typeutils.base.StringSerializer;
 import org.apache.flink.runtime.jobgraph.OperatorID;
-import org.apache.flink.streaming.api.graph.StreamConfig;
 import org.apache.flink.streaming.api.operators.AbstractStreamOperator;
 import org.apache.flink.streaming.api.operators.AbstractStreamOperatorFactory;
 import org.apache.flink.streaming.api.operators.ChainingStrategy;
 import org.apache.flink.streaming.api.operators.MailboxExecutor;
 import org.apache.flink.streaming.api.operators.OneInputStreamOperator;
 import org.apache.flink.streaming.api.operators.OneInputStreamOperatorFactory;
-import org.apache.flink.streaming.api.operators.Output;
 import org.apache.flink.streaming.api.operators.StreamOperator;
+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;
 import org.apache.flink.streaming.api.operators.YieldingOperatorFactory;
 import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
 import org.apache.flink.streaming.runtime.tasks.OneInputStreamTask;
 import org.apache.flink.streaming.runtime.tasks.OneInputStreamTaskTestHarness;
 import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;
-import org.apache.flink.streaming.runtime.tasks.StreamTask;
 import org.apache.flink.util.TestLogger;
 
 import org.junit.Test;
@@ -91,12 +89,10 @@ public void setMailboxExecutor(MailboxExecutor mailboxExecutor) {
 
 		@Override
 		public <Operator extends StreamOperator<String>> Operator createStreamOperator(
-				StreamTask<?, ?> containingTask,
-				StreamConfig config,
-				Output<StreamRecord<String>> output) {
-			TestOperator operator = new TestOperator(config.getChainIndex(), mailboxExecutor);
+			StreamOperatorParameters<String> parameters) {
+			TestOperator operator = new TestOperator(parameters.getStreamConfig().getChainIndex(), mailboxExecutor);
 			operator.setProcessingTimeService(processingTimeService);
-			operator.setup(containingTask, config, output);
+			operator.setup(parameters.getContainingTask(), parameters.getStreamConfig(), parameters.getOutput());
 			return (Operator) operator;
 		}
 
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/MultipleInputStreamTaskTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/MultipleInputStreamTaskTest.java
index fc0144b732bc7..88c4f9a66a88c 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/MultipleInputStreamTaskTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/MultipleInputStreamTaskTest.java
@@ -30,9 +30,12 @@
 import org.apache.flink.runtime.metrics.groups.TaskMetricGroup;
 import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;
 import org.apache.flink.streaming.api.functions.co.CoMapFunction;
-import org.apache.flink.streaming.api.operators.AbstractStreamOperator;
+import org.apache.flink.streaming.api.operators.AbstractStreamOperatorFactory;
+import org.apache.flink.streaming.api.operators.AbstractStreamOperatorV2;
 import org.apache.flink.streaming.api.operators.Input;
 import org.apache.flink.streaming.api.operators.MultipleInputStreamOperator;
+import org.apache.flink.streaming.api.operators.StreamOperator;
+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;
 import org.apache.flink.streaming.api.operators.co.CoStreamMap;
 import org.apache.flink.streaming.runtime.io.InputStatus;
 import org.apache.flink.streaming.runtime.io.StreamMultipleInputProcessor;
@@ -68,7 +71,7 @@ public void testOpenCloseAndTimestamps() throws Exception {
 				.addInput(BasicTypeInfo.STRING_TYPE_INFO)
 				.addInput(BasicTypeInfo.INT_TYPE_INFO)
 				.addInput(BasicTypeInfo.DOUBLE_TYPE_INFO)
-				.setupOutputForSingletonOperatorChain(new MapToStringMultipleInputOperator())
+				.setupOutputForSingletonOperatorChain(new MapToStringMultipleInputOperatorFactory())
 				.build()) {
 
 			long initialTime = 0L;
@@ -98,7 +101,7 @@ public void testCheckpointBarriers() throws Exception {
 				.addInput(BasicTypeInfo.STRING_TYPE_INFO, 2)
 				.addInput(BasicTypeInfo.INT_TYPE_INFO, 2)
 				.addInput(BasicTypeInfo.DOUBLE_TYPE_INFO, 2)
-				.setupOutputForSingletonOperatorChain(new MapToStringMultipleInputOperator())
+				.setupOutputForSingletonOperatorChain(new MapToStringMultipleInputOperatorFactory())
 				.build()) {
 			ArrayDeque<Object> expectedOutput = new ArrayDeque<>();
 			long initialTime = 0L;
@@ -148,7 +151,7 @@ public void testOvertakingCheckpointBarriers() throws Exception {
 				.addInput(BasicTypeInfo.STRING_TYPE_INFO, 2)
 				.addInput(BasicTypeInfo.INT_TYPE_INFO, 2)
 				.addInput(BasicTypeInfo.DOUBLE_TYPE_INFO, 2)
-				.setupOutputForSingletonOperatorChain(new MapToStringMultipleInputOperator())
+				.setupOutputForSingletonOperatorChain(new MapToStringMultipleInputOperatorFactory())
 				.build()) {
 			ArrayDeque<Object> expectedOutput = new ArrayDeque<>();
 			long initialTime = 0L;
@@ -217,7 +220,7 @@ public OperatorMetricGroup getOrAddOperator(OperatorID operatorID, String name)
 				.addInput(BasicTypeInfo.STRING_TYPE_INFO)
 				.addInput(BasicTypeInfo.STRING_TYPE_INFO)
 				.addInput(BasicTypeInfo.STRING_TYPE_INFO)
-				.setupOperatorChain(new DuplicatingOperator())
+				.setupOperatorChain(new DuplicatingOperatorFactory())
 				.chain(new OneInputStreamTaskTest.DuplicatingOperator(), BasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()))
 				.chain(new OneInputStreamTaskTest.DuplicatingOperator(), BasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()))
 				.finish()
@@ -246,9 +249,13 @@ public OperatorMetricGroup getOrAddOperator(OperatorID operatorID, String name)
 		}
 	}
 
-	static class DuplicatingOperator extends AbstractStreamOperator<String>
+	static class DuplicatingOperator extends AbstractStreamOperatorV2<String>
 		implements MultipleInputStreamOperator<String> {
 
+		public DuplicatingOperator(StreamOperatorParameters<String> parameters) {
+			super(parameters, 3);
+		}
+
 		@Override
 		public List<Input> getInputs() {
 			return Arrays.asList(new DuplicatingInput(), new DuplicatingInput(), new DuplicatingInput());
@@ -270,7 +277,7 @@ public void testClosingAllOperatorsOnChainProperly() throws Exception {
 				.addInput(BasicTypeInfo.STRING_TYPE_INFO)
 				.addInput(BasicTypeInfo.STRING_TYPE_INFO)
 				.addInput(BasicTypeInfo.STRING_TYPE_INFO)
-				.setupOperatorChain(new TestBoundedMultipleInputOperator("Operator0"))
+				.setupOperatorChain(new TestBoundedMultipleInputOperatorFactory())
 				.chain(new TestBoundedOneInputStreamOperator("Operator1"), BasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()))
 				.finish()
 				.build();
@@ -317,7 +324,7 @@ public void testInputFairness() throws Exception {
 					.addInput(BasicTypeInfo.STRING_TYPE_INFO)
 					.addInput(BasicTypeInfo.STRING_TYPE_INFO)
 					.addInput(BasicTypeInfo.STRING_TYPE_INFO)
-					.setupOutputForSingletonOperatorChain(new MapToStringMultipleInputOperator())
+					.setupOutputForSingletonOperatorChain(new MapToStringMultipleInputOperatorFactory())
 					.build()) {
 			ArrayDeque<Object> expectedOutput = new ArrayDeque<>();
 
@@ -352,12 +359,16 @@ public void testInputFairness() throws Exception {
 	// This must only be used in one test, otherwise the static fields will be changed
 	// by several tests concurrently
 	private static class MapToStringMultipleInputOperator
-			extends AbstractStreamOperator<String> implements MultipleInputStreamOperator<String> {
+			extends AbstractStreamOperatorV2<String> implements MultipleInputStreamOperator<String> {
 		private static final long serialVersionUID = 1L;
 
 		private boolean openCalled;
 		private boolean closeCalled;
 
+		public MapToStringMultipleInputOperator(StreamOperatorParameters<String> parameters) {
+			super(parameters, 3);
+		}
+
 		@Override
 		public void open() throws Exception {
 			super.open();
@@ -418,5 +429,41 @@ public String map2(Integer value) {
 			return value.toString();
 		}
 	}
+
+	private static class TestBoundedMultipleInputOperatorFactory extends AbstractStreamOperatorFactory<String> {
+		@Override
+		public <T extends StreamOperator<String>> T createStreamOperator(StreamOperatorParameters<String> parameters) {
+			return (T) new TestBoundedMultipleInputOperator("Operator0", parameters);
+		}
+
+		@Override
+		public Class<? extends StreamOperator<String>> getStreamOperatorClass(ClassLoader classLoader) {
+			return TestBoundedMultipleInputOperator.class;
+		}
+	}
+
+	private static class DuplicatingOperatorFactory extends AbstractStreamOperatorFactory<String> {
+		@Override
+		public <T extends StreamOperator<String>> T createStreamOperator(StreamOperatorParameters<String> parameters) {
+			return (T) new DuplicatingOperator(parameters);
+		}
+
+		@Override
+		public Class<? extends StreamOperator<String>> getStreamOperatorClass(ClassLoader classLoader) {
+			return DuplicatingOperator.class;
+		}
+	}
+
+	private static class MapToStringMultipleInputOperatorFactory extends AbstractStreamOperatorFactory<String> {
+		@Override
+		public <T extends StreamOperator<String>> T createStreamOperator(StreamOperatorParameters<String> parameters) {
+			return (T) new MapToStringMultipleInputOperator(parameters);
+		}
+
+		@Override
+		public Class<? extends StreamOperator<String>> getStreamOperatorClass(ClassLoader classLoader) {
+			return MapToStringMultipleInputOperator.class;
+		}
+	}
 }
 
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/StreamTaskTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/StreamTaskTest.java
index 1628e4c055d7b..6f56a7fb79efd 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/StreamTaskTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/StreamTaskTest.java
@@ -90,6 +90,7 @@
 import org.apache.flink.streaming.api.operators.Output;
 import org.apache.flink.streaming.api.operators.StreamMap;
 import org.apache.flink.streaming.api.operators.StreamOperator;
+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;
 import org.apache.flink.streaming.api.operators.StreamOperatorStateContext;
 import org.apache.flink.streaming.api.operators.StreamSource;
 import org.apache.flink.streaming.api.operators.StreamTaskStateInitializer;
@@ -1703,10 +1704,7 @@ Throwable getLastDeclinedCheckpointCause() {
 
 	private static class UnusedOperatorFactory extends AbstractStreamOperatorFactory<String> {
 		@Override
-		public <T extends StreamOperator<String>> T createStreamOperator(
-				StreamTask<?, ?> containingTask,
-				StreamConfig config,
-				Output<StreamRecord<String>> output) {
+		public <T extends StreamOperator<String>> T createStreamOperator(StreamOperatorParameters<String> parameters) {
 			throw new UnsupportedOperationException("This shouldn't be called");
 		}
 
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/util/AbstractStreamOperatorTestHarness.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/util/AbstractStreamOperatorTestHarness.java
index 7d0cd510e5d96..13624e69cb386 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/util/AbstractStreamOperatorTestHarness.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/util/AbstractStreamOperatorTestHarness.java
@@ -495,7 +495,7 @@ public void initializeState(
 			}
 		}
 
-		operator.initializeState();
+		operator.initializeState(mockTask.createStreamTaskStateInitializer());
 		initializeCalled = true;
 	}
 
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/util/TestBoundedMultipleInputOperator.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/util/TestBoundedMultipleInputOperator.java
index 89d242a315e95..e6ebe84a8be1d 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/util/TestBoundedMultipleInputOperator.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/util/TestBoundedMultipleInputOperator.java
@@ -18,10 +18,11 @@
 
 package org.apache.flink.streaming.util;
 
-import org.apache.flink.streaming.api.operators.AbstractStreamOperator;
+import org.apache.flink.streaming.api.operators.AbstractStreamOperatorV2;
 import org.apache.flink.streaming.api.operators.BoundedMultiInput;
 import org.apache.flink.streaming.api.operators.Input;
 import org.apache.flink.streaming.api.operators.MultipleInputStreamOperator;
+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;
 import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
 
 import java.util.Arrays;
@@ -30,14 +31,15 @@
 /**
  * A test operator class implementing {@link BoundedMultiInput}.
  */
-public class TestBoundedMultipleInputOperator extends AbstractStreamOperator<String>
+public class TestBoundedMultipleInputOperator extends AbstractStreamOperatorV2<String>
 	implements MultipleInputStreamOperator<String>, BoundedMultiInput {
 
 	private static final long serialVersionUID = 1L;
 
 	private final String name;
 
-	public TestBoundedMultipleInputOperator(String name) {
+	public TestBoundedMultipleInputOperator(String name, StreamOperatorParameters<String> parameters) {
+		super(parameters, 3);
 		this.name = name;
 	}
 
diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/runtime/operators/KeyedCoProcessOperatorWithWatermarkDelay.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/runtime/operators/KeyedCoProcessOperatorWithWatermarkDelay.scala
index 72aec4824961b..3aaa7d22a0fc8 100644
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/runtime/operators/KeyedCoProcessOperatorWithWatermarkDelay.scala
+++ b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/runtime/operators/KeyedCoProcessOperatorWithWatermarkDelay.scala
@@ -50,7 +50,8 @@ class KeyedCoProcessOperatorWithWatermarkDelay[KEY, IN1, IN2, OUT](
 
   @throws[Exception]
   override def processWatermark(mark: Watermark) {
-    if (timeServiceManager != null) timeServiceManager.advanceWatermark(mark)
+    val timeServiceManager = getTimeServiceManager
+    if (timeServiceManager.isPresent) timeServiceManager.get().advanceWatermark(mark)
 
     emitter(mark)
   }
diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/runtime/operators/KeyedProcessOperatorWithWatermarkDelay.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/runtime/operators/KeyedProcessOperatorWithWatermarkDelay.scala
index f63bdb5acd663..a47638ae30825 100644
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/runtime/operators/KeyedProcessOperatorWithWatermarkDelay.scala
+++ b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/runtime/operators/KeyedProcessOperatorWithWatermarkDelay.scala
@@ -51,7 +51,8 @@ class KeyedProcessOperatorWithWatermarkDelay[KEY, IN, OUT](
 
   @throws[Exception]
   override def processWatermark(mark: Watermark) {
-    if (timeServiceManager != null) timeServiceManager.advanceWatermark(mark)
+    val timeServiceManager = getTimeServiceManager
+    if (timeServiceManager.isPresent) timeServiceManager.get().advanceWatermark(mark)
 
     emitter(mark)
   }
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/CodeGenOperatorFactory.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/CodeGenOperatorFactory.java
index 7eb8cf1f8db30..1648f6e5f0894 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/CodeGenOperatorFactory.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/CodeGenOperatorFactory.java
@@ -18,12 +18,9 @@
 
 package org.apache.flink.table.runtime.operators;
 
-import org.apache.flink.streaming.api.graph.StreamConfig;
 import org.apache.flink.streaming.api.operators.AbstractStreamOperatorFactory;
-import org.apache.flink.streaming.api.operators.Output;
 import org.apache.flink.streaming.api.operators.StreamOperator;
-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
-import org.apache.flink.streaming.runtime.tasks.StreamTask;
+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;
 import org.apache.flink.table.runtime.generated.GeneratedClass;
 
 /**
@@ -39,10 +36,14 @@ public CodeGenOperatorFactory(GeneratedClass<? extends StreamOperator<OUT>> gene
 
 	@SuppressWarnings("unchecked")
 	@Override
-	public <T extends StreamOperator<OUT>> T createStreamOperator(StreamTask<?, ?> containingTask,
-			StreamConfig config, Output<StreamRecord<OUT>> output) {
-		return (T) generatedClass.newInstance(containingTask.getUserCodeClassLoader(),
-				generatedClass.getReferences(), containingTask, config, output, processingTimeService);
+	public <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorParameters<OUT> parameters) {
+		return (T) generatedClass.newInstance(
+			parameters.getContainingTask().getUserCodeClassLoader(),
+			generatedClass.getReferences(),
+			parameters.getContainingTask(),
+			parameters.getStreamConfig(),
+			parameters.getOutput(),
+			processingTimeService);
 	}
 
 	@Override
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/KeyedCoProcessOperatorWithWatermarkDelay.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/KeyedCoProcessOperatorWithWatermarkDelay.java
index 73e20052f8397..fb2ce5035bcb5 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/KeyedCoProcessOperatorWithWatermarkDelay.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/KeyedCoProcessOperatorWithWatermarkDelay.java
@@ -19,11 +19,13 @@
 package org.apache.flink.table.runtime.operators.join;
 
 import org.apache.flink.streaming.api.functions.co.KeyedCoProcessFunction;
+import org.apache.flink.streaming.api.operators.InternalTimeServiceManager;
 import org.apache.flink.streaming.api.operators.co.KeyedCoProcessOperator;
 import org.apache.flink.streaming.api.watermark.Watermark;
 import org.apache.flink.util.Preconditions;
 
 import java.io.Serializable;
+import java.util.Optional;
 import java.util.function.Consumer;
 
 /**
@@ -51,10 +53,10 @@ public KeyedCoProcessOperatorWithWatermarkDelay(KeyedCoProcessFunction<K, IN1, I
 
 	@Override
 	public void processWatermark(Watermark mark) throws Exception {
-		if (timeServiceManager != null) {
-			timeServiceManager.advanceWatermark(mark);
+		Optional<InternalTimeServiceManager<?>> timeServiceManager = getTimeServiceManager();
+		if (timeServiceManager.isPresent()) {
+			timeServiceManager.get().advanceWatermark(mark);
 		}
 		emitter.accept(mark);
 	}
-
 }
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/wmassigners/WatermarkAssignerOperatorFactory.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/wmassigners/WatermarkAssignerOperatorFactory.java
index 75f4b796d0645..e3dbe86a2841a 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/wmassigners/WatermarkAssignerOperatorFactory.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/wmassigners/WatermarkAssignerOperatorFactory.java
@@ -18,12 +18,10 @@
 
 package org.apache.flink.table.runtime.operators.wmassigners;
 
-import org.apache.flink.streaming.api.graph.StreamConfig;
 import org.apache.flink.streaming.api.operators.AbstractStreamOperatorFactory;
 import org.apache.flink.streaming.api.operators.OneInputStreamOperatorFactory;
-import org.apache.flink.streaming.api.operators.Output;
 import org.apache.flink.streaming.api.operators.StreamOperator;
-import org.apache.flink.streaming.runtime.tasks.StreamTask;
+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;
 import org.apache.flink.table.dataformat.BaseRow;
 import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;
 import org.apache.flink.table.runtime.generated.WatermarkGenerator;
@@ -53,14 +51,18 @@ public WatermarkAssignerOperatorFactory(
 
 	@SuppressWarnings("unchecked")
 	@Override
-	public StreamOperator createStreamOperator(StreamTask containingTask, StreamConfig config, Output output) {
-		WatermarkGenerator watermarkGenerator = generatedWatermarkGenerator.newInstance(containingTask.getUserCodeClassLoader());
+	public StreamOperator createStreamOperator(StreamOperatorParameters initializer) {
+		WatermarkGenerator watermarkGenerator = generatedWatermarkGenerator.newInstance(
+			initializer.getContainingTask().getUserCodeClassLoader());
 		WatermarkAssignerOperator operator = new WatermarkAssignerOperator(
 			rowtimeFieldIndex,
 			watermarkGenerator,
 			idleTimeout,
 			processingTimeService);
-		operator.setup(containingTask, config, output);
+		operator.setup(
+			initializer.getContainingTask(),
+			initializer.getStreamConfig(),
+			initializer.getOutput());
 		return operator;
 	}
 
diff --git a/flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/MultipleInputITCase.java b/flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/MultipleInputITCase.java
index f3356598a893e..32b64249acb4d 100644
--- a/flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/MultipleInputITCase.java
+++ b/flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/MultipleInputITCase.java
@@ -21,17 +21,14 @@
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.datastream.MultipleConnectedStreams;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
-import org.apache.flink.streaming.api.graph.StreamConfig;
-import org.apache.flink.streaming.api.operators.AbstractStreamOperator;
-import org.apache.flink.streaming.api.operators.ChainingStrategy;
+import org.apache.flink.streaming.api.operators.AbstractStreamOperatorFactory;
+import org.apache.flink.streaming.api.operators.AbstractStreamOperatorV2;
 import org.apache.flink.streaming.api.operators.Input;
 import org.apache.flink.streaming.api.operators.MultipleInputStreamOperator;
-import org.apache.flink.streaming.api.operators.Output;
 import org.apache.flink.streaming.api.operators.StreamOperator;
-import org.apache.flink.streaming.api.operators.StreamOperatorFactory;
+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;
 import org.apache.flink.streaming.api.transformations.MultipleInputTransformation;
 import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
-import org.apache.flink.streaming.runtime.tasks.StreamTask;
 import org.apache.flink.test.streaming.runtime.util.TestListResultSink;
 import org.apache.flink.test.util.AbstractTestBase;
 
@@ -86,13 +83,14 @@ public void test() throws Exception {
 
 	/**
 	 * 3 input operator that sums all of it inputs.
-	 * TODO: provide non {@link SetupableStreamOperator} variant of {@link AbstractStreamOperator}?
-	 * TODO: provide non {@link AbstractStreamOperator} seems to pre-override processWatermark1/2 and other
-	 * methods that are not defined there?
 	 */
-	public static class SumAllInputOperator extends AbstractStreamOperator<Long> implements MultipleInputStreamOperator<Long> {
+	public static class SumAllInputOperator extends AbstractStreamOperatorV2<Long> implements MultipleInputStreamOperator<Long> {
 		private long sum;
 
+		public SumAllInputOperator(StreamOperatorParameters<Long> parameters) {
+			super(parameters, 3);
+		}
+
 		@Override
 		public List<Input> getInputs() {
 			return Arrays.asList(
@@ -116,32 +114,15 @@ public void processElement(StreamRecord<T> element) throws Exception {
 	/**
 	 * Factory for {@link SumAllInputOperator}.
 	 */
-	public static class SumAllInputOperatorFactory implements StreamOperatorFactory<Long> {
-		private ChainingStrategy chainingStrategy;
-
-		@Override
-		public <T extends StreamOperator<Long>> T createStreamOperator(
-				StreamTask<?, ?> containingTask,
-				StreamConfig config,
-				Output<StreamRecord<Long>> output) {
-			SumAllInputOperator sumAllInputOperator = new SumAllInputOperator();
-			sumAllInputOperator.setup(containingTask, config, output);
-			return (T) sumAllInputOperator;
-		}
-
-		@Override
-		public void setChainingStrategy(ChainingStrategy chainingStrategy) {
-			this.chainingStrategy = chainingStrategy;
-		}
-
+	public static class SumAllInputOperatorFactory extends AbstractStreamOperatorFactory<Long> {
 		@Override
-		public ChainingStrategy getChainingStrategy() {
-			return chainingStrategy;
+		public <T extends StreamOperator<Long>> T createStreamOperator(StreamOperatorParameters<Long> parameters) {
+			return (T) new SumAllInputOperator(parameters);
 		}
 
 		@Override
 		public Class<? extends StreamOperator> getStreamOperatorClass(ClassLoader classLoader) {
-			throw new UnsupportedOperationException();
+			return SumAllInputOperator.class;
 		}
 	}
 }
diff --git a/flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/StreamTaskSelectiveReadingITCase.java b/flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/StreamTaskSelectiveReadingITCase.java
index 28840d9633abf..7fa49f8ae2f47 100644
--- a/flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/StreamTaskSelectiveReadingITCase.java
+++ b/flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/StreamTaskSelectiveReadingITCase.java
@@ -25,7 +25,6 @@
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;
 import org.apache.flink.streaming.api.operators.ChainingStrategy;
-import org.apache.flink.streaming.api.operators.TwoInputStreamOperator;
 import org.apache.flink.streaming.util.TestSequentialReadingStreamOperator;
 import org.apache.flink.test.streaming.runtime.util.TestListResultSink;
 
@@ -60,7 +59,7 @@ public void testSequentialReading() throws Exception {
 			.setParallelism(2);
 		TestListResultSink<String> resultSink = new TestListResultSink<>();
 
-		TwoInputStreamOperator<String, Integer, String> twoInputStreamOperator = new TestSequentialReadingStreamOperator("Operator0");
+		TestSequentialReadingStreamOperator twoInputStreamOperator = new TestSequentialReadingStreamOperator("Operator0");
 		twoInputStreamOperator.setChainingStrategy(ChainingStrategy.NEVER);
 
 		source0.connect(source1)
