diff --git a/docs/dev/stream/state/schema_evolution.md b/docs/dev/stream/state/schema_evolution.md
index fd0a73c3e1dc0..9699dbec30ef7 100644
--- a/docs/dev/stream/state/schema_evolution.md
+++ b/docs/dev/stream/state/schema_evolution.md
@@ -78,11 +78,25 @@ Further details about the migration process is out of the scope of this document
 
 ## Supported data types for schema evolution
 
-Currently, schema evolution is supported only for Avro. Therefore, if you care about schema evolution for
-state, it is currently recommended to always use Avro for state data types.
+Currently, schema evolution is supported only for POJO and Avro types. Therefore, if you care about schema evolution for
+state, it is currently recommended to always use either Pojo or Avro for state data types.
 
-There are plans to extend the support for more composite types, such as POJOs; for more details,
-please refer to [FLINK-10897](https://issues.apache.org/jira/browse/FLINK-10897).
+There are plans to extend the support for more composite types; for more details,
+please refer to [FLINK-10896](https://issues.apache.org/jira/browse/FLINK-10896).
+
+### POJO types
+
+Flink supports evolving schema of [POJO types]({{ site.baseurl }}/dev/types_serialization.html#rules-for-pojo-types), 
+based on the following set of rules:
+
+ 1. Fields can be removed. Once removed, the previous value for the removed field will be dropped in future checkpoints and savepoints.
+ 2. New fields can be added. The new field will be initialized to the default value for its type, as
+    [defined by Java](https://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html).
+ 3. Declared fields types cannot change.
+ 4. Class name of the POJO type cannot change, including the namespace of the class.
+
+Note that the schema of POJO type state is only evolvable when restoring from a savepoint taken with Flink versions
+newer than 1.8.0. When restoring from savepoints of older versions, the schema cannot be changed.
 
 ### Avro types
 
diff --git a/flink-core/src/main/java/org/apache/flink/api/common/typeutils/CompositeTypeSerializerSnapshot.java b/flink-core/src/main/java/org/apache/flink/api/common/typeutils/CompositeTypeSerializerSnapshot.java
index d14a80eab447b..8da7948c78427 100644
--- a/flink-core/src/main/java/org/apache/flink/api/common/typeutils/CompositeTypeSerializerSnapshot.java
+++ b/flink-core/src/main/java/org/apache/flink/api/common/typeutils/CompositeTypeSerializerSnapshot.java
@@ -26,7 +26,6 @@
 import org.apache.flink.api.java.typeutils.runtime.EitherSerializer;
 import org.apache.flink.core.memory.DataInputView;
 import org.apache.flink.core.memory.DataOutputView;
-import org.apache.flink.util.Preconditions;
 
 import java.io.IOException;
 
@@ -304,57 +303,15 @@ private TypeSerializerSchemaCompatibility<T> constructFinalSchemaCompatibilityRe
 			TypeSerializer<?>[] newNestedSerializers,
 			TypeSerializerSnapshot<?>[] nestedSerializerSnapshots) {
 
-		Preconditions.checkArgument(newNestedSerializers.length == nestedSerializerSnapshots.length,
-			"Different number of new serializers and existing serializer snapshots.");
-
-		TypeSerializer<?>[] reconfiguredNestedSerializers = new TypeSerializer[newNestedSerializers.length];
-
-		// check nested serializers for compatibility
-		boolean nestedSerializerRequiresMigration = false;
-		boolean hasReconfiguredNestedSerializers = false;
-		for (int i = 0; i < nestedSerializerSnapshots.length; i++) {
-			TypeSerializerSchemaCompatibility<?> compatibility =
-				resolveCompatibility(newNestedSerializers[i], nestedSerializerSnapshots[i]);
-
-			// if any one of the new nested serializers is incompatible, we can just short circuit the result
-			if (compatibility.isIncompatible()) {
-				return TypeSerializerSchemaCompatibility.incompatible();
-			}
-
-			if (compatibility.isCompatibleAfterMigration()) {
-				nestedSerializerRequiresMigration = true;
-			} else if (compatibility.isCompatibleWithReconfiguredSerializer()) {
-				hasReconfiguredNestedSerializers = true;
-				reconfiguredNestedSerializers[i] = compatibility.getReconfiguredSerializer();
-			} else if (compatibility.isCompatibleAsIs()) {
-				reconfiguredNestedSerializers[i] = newNestedSerializers[i];
-			} else {
-				throw new IllegalStateException("Undefined compatibility type.");
-			}
-		}
-
-		if (nestedSerializerRequiresMigration) {
-			return TypeSerializerSchemaCompatibility.compatibleAfterMigration();
-		}
+		CompositeTypeSerializerUtil.IntermediateCompatibilityResult<T> intermediateResult =
+			CompositeTypeSerializerUtil.constructIntermediateCompatibilityResult(newNestedSerializers, nestedSerializerSnapshots);
 
-		if (hasReconfiguredNestedSerializers) {
+		if (intermediateResult.isCompatibleWithReconfiguredSerializer()) {
 			@SuppressWarnings("unchecked")
-			TypeSerializer<T> reconfiguredCompositeSerializer = createOuterSerializerWithNestedSerializers(reconfiguredNestedSerializers);
+			TypeSerializer<T> reconfiguredCompositeSerializer = createOuterSerializerWithNestedSerializers(intermediateResult.getNestedSerializers());
 			return TypeSerializerSchemaCompatibility.compatibleWithReconfiguredSerializer(reconfiguredCompositeSerializer);
 		}
 
-		// ends up here if everything is compatible as is
-		return TypeSerializerSchemaCompatibility.compatibleAsIs();
-	}
-
-	@SuppressWarnings("unchecked")
-	private static <E> TypeSerializerSchemaCompatibility<E> resolveCompatibility(
-		TypeSerializer<?> serializer,
-		TypeSerializerSnapshot<?> snapshot) {
-
-		TypeSerializer<E> typedSerializer = (TypeSerializer<E>) serializer;
-		TypeSerializerSnapshot<E> typedSnapshot = (TypeSerializerSnapshot<E>) snapshot;
-
-		return typedSnapshot.resolveSchemaCompatibility(typedSerializer);
+		return intermediateResult.getFinalResult();
 	}
 }
diff --git a/flink-core/src/main/java/org/apache/flink/api/common/typeutils/CompositeTypeSerializerUtil.java b/flink-core/src/main/java/org/apache/flink/api/common/typeutils/CompositeTypeSerializerUtil.java
index f98bc7239d3ed..8e1a65a97544b 100644
--- a/flink-core/src/main/java/org/apache/flink/api/common/typeutils/CompositeTypeSerializerUtil.java
+++ b/flink-core/src/main/java/org/apache/flink/api/common/typeutils/CompositeTypeSerializerUtil.java
@@ -19,8 +19,11 @@
 package org.apache.flink.api.common.typeutils;
 
 import org.apache.flink.annotation.Internal;
+import org.apache.flink.util.Preconditions;
 
 import static org.apache.flink.util.Preconditions.checkArgument;
+import static org.apache.flink.util.Preconditions.checkNotNull;
+import static org.apache.flink.util.Preconditions.checkState;
 
 /**
  * Utilities for the {@link CompositeTypeSerializerSnapshot}.
@@ -62,4 +65,147 @@ public static void setNestedSerializersSnapshots(
 		NestedSerializersSnapshotDelegate delegate = new NestedSerializersSnapshotDelegate(nestedSnapshots);
 		compositeSnapshot.setNestedSerializersSnapshotDelegate(delegate);
 	}
+
+	/**
+	 * Constructs an {@link IntermediateCompatibilityResult} with the given array of nested serializers and their
+	 * corresponding serializer snapshots.
+	 *
+	 * <p>This result is considered "intermediate", because the actual final result is not yet built if it isn't
+	 * defined. This is the case if the final result is supposed to be
+	 * {@link TypeSerializerSchemaCompatibility#compatibleWithReconfiguredSerializer(TypeSerializer)}, where
+	 * construction of the reconfigured serializer instance should be done by the caller.
+	 *
+	 * <p>For other cases, i.e. {@link TypeSerializerSchemaCompatibility#compatibleAsIs()},
+	 * {@link TypeSerializerSchemaCompatibility#compatibleAfterMigration()}, and
+	 * {@link TypeSerializerSchemaCompatibility#incompatible()}, these results are considered final.
+	 *
+	 * @param newNestedSerializers the new nested serializers to check for compatibility.
+	 * @param nestedSerializerSnapshots the associated nested serializers' snapshots.
+	 *
+	 * @return the intermediate compatibility result of the new nested serializers.
+	 */
+	public static <T> IntermediateCompatibilityResult<T> constructIntermediateCompatibilityResult(
+		TypeSerializer<?>[] newNestedSerializers,
+		TypeSerializerSnapshot<?>[] nestedSerializerSnapshots) {
+
+		Preconditions.checkArgument(newNestedSerializers.length == nestedSerializerSnapshots.length,
+			"Different number of new serializers and existing serializer snapshots.");
+
+		TypeSerializer<?>[] nestedSerializers = new TypeSerializer[newNestedSerializers.length];
+
+		// check nested serializers for compatibility
+		boolean nestedSerializerRequiresMigration = false;
+		boolean hasReconfiguredNestedSerializers = false;
+		for (int i = 0; i < nestedSerializerSnapshots.length; i++) {
+			TypeSerializerSchemaCompatibility<?> compatibility =
+				resolveCompatibility(newNestedSerializers[i], nestedSerializerSnapshots[i]);
+
+			// if any one of the new nested serializers is incompatible, we can just short circuit the result
+			if (compatibility.isIncompatible()) {
+				return IntermediateCompatibilityResult.definedIncompatibleResult();
+			}
+
+			if (compatibility.isCompatibleAfterMigration()) {
+				nestedSerializerRequiresMigration = true;
+			} else if (compatibility.isCompatibleWithReconfiguredSerializer()) {
+				hasReconfiguredNestedSerializers = true;
+				nestedSerializers[i] = compatibility.getReconfiguredSerializer();
+			} else if (compatibility.isCompatibleAsIs()) {
+				nestedSerializers[i] = newNestedSerializers[i];
+			} else {
+				throw new IllegalStateException("Undefined compatibility type.");
+			}
+		}
+
+		if (nestedSerializerRequiresMigration) {
+			return IntermediateCompatibilityResult.definedCompatibleAfterMigrationResult();
+		}
+
+		if (hasReconfiguredNestedSerializers) {
+			return IntermediateCompatibilityResult.undefinedReconfigureResult(nestedSerializers);
+		}
+
+		// ends up here if everything is compatible as is
+		return IntermediateCompatibilityResult.definedCompatibleAsIsResult(nestedSerializers);
+	}
+
+	public static class IntermediateCompatibilityResult<T> {
+
+		private final TypeSerializerSchemaCompatibility.Type compatibilityType;
+		private final TypeSerializer<?>[] nestedSerializers;
+
+		static <T> IntermediateCompatibilityResult<T> definedCompatibleAsIsResult(TypeSerializer<?>[] originalSerializers) {
+			return new IntermediateCompatibilityResult<>(TypeSerializerSchemaCompatibility.Type.COMPATIBLE_AS_IS, originalSerializers);
+		}
+
+		static <T> IntermediateCompatibilityResult<T> definedIncompatibleResult() {
+			return new IntermediateCompatibilityResult<>(TypeSerializerSchemaCompatibility.Type.INCOMPATIBLE, null);
+		}
+
+		static <T> IntermediateCompatibilityResult<T> definedCompatibleAfterMigrationResult() {
+			return new IntermediateCompatibilityResult<>(TypeSerializerSchemaCompatibility.Type.COMPATIBLE_AFTER_MIGRATION, null);
+		}
+
+		static <T> IntermediateCompatibilityResult<T> undefinedReconfigureResult(TypeSerializer<?>[] reconfiguredNestedSerializers) {
+			return new IntermediateCompatibilityResult<>(TypeSerializerSchemaCompatibility.Type.COMPATIBLE_WITH_RECONFIGURED_SERIALIZER, reconfiguredNestedSerializers);
+		}
+
+		private IntermediateCompatibilityResult(
+				TypeSerializerSchemaCompatibility.Type compatibilityType,
+				TypeSerializer<?>[] nestedSerializers) {
+			this.compatibilityType = checkNotNull(compatibilityType);
+			this.nestedSerializers = nestedSerializers;
+		}
+
+		public boolean isCompatibleWithReconfiguredSerializer() {
+			return compatibilityType == TypeSerializerSchemaCompatibility.Type.COMPATIBLE_WITH_RECONFIGURED_SERIALIZER;
+		}
+
+		public boolean isCompatibleAsIs() {
+			return compatibilityType == TypeSerializerSchemaCompatibility.Type.COMPATIBLE_AS_IS;
+		}
+
+		public boolean isCompatibleAfterMigration() {
+			return compatibilityType == TypeSerializerSchemaCompatibility.Type.COMPATIBLE_AFTER_MIGRATION;
+		}
+
+		public boolean isIncompatible() {
+			return compatibilityType == TypeSerializerSchemaCompatibility.Type.INCOMPATIBLE;
+		}
+
+		public TypeSerializerSchemaCompatibility<T> getFinalResult() {
+			checkState(
+				compatibilityType != TypeSerializerSchemaCompatibility.Type.COMPATIBLE_WITH_RECONFIGURED_SERIALIZER,
+				"unable to build final result if intermediate compatibility type is COMPATIBLE_WITH_RECONFIGURED_SERIALIZER.");
+			switch (compatibilityType) {
+				case COMPATIBLE_AS_IS:
+					return TypeSerializerSchemaCompatibility.compatibleAsIs();
+				case COMPATIBLE_AFTER_MIGRATION:
+					return TypeSerializerSchemaCompatibility.compatibleAfterMigration();
+				case INCOMPATIBLE:
+					return TypeSerializerSchemaCompatibility.incompatible();
+				default:
+					throw new IllegalStateException("unrecognized compatibility type.");
+			}
+		}
+
+		public TypeSerializer<?>[] getNestedSerializers() {
+			checkState(
+				compatibilityType == TypeSerializerSchemaCompatibility.Type.COMPATIBLE_AS_IS
+					|| compatibilityType == TypeSerializerSchemaCompatibility.Type.COMPATIBLE_WITH_RECONFIGURED_SERIALIZER,
+				"only intermediate compatibility types COMPATIBLE_AS_IS and COMPATIBLE_WITH_RECONFIGURED_SERIALIZER have nested serializers.");
+			return nestedSerializers;
+		}
+	}
+
+	@SuppressWarnings("unchecked")
+	private static <E> TypeSerializerSchemaCompatibility<E> resolveCompatibility(
+		TypeSerializer<?> serializer,
+		TypeSerializerSnapshot<?> snapshot) {
+
+		TypeSerializer<E> typedSerializer = (TypeSerializer<E>) serializer;
+		TypeSerializerSnapshot<E> typedSnapshot = (TypeSerializerSnapshot<E>) snapshot;
+
+		return typedSnapshot.resolveSchemaCompatibility(typedSerializer);
+	}
 }
diff --git a/flink-core/src/main/java/org/apache/flink/api/common/typeutils/TypeSerializerUtils.java b/flink-core/src/main/java/org/apache/flink/api/common/typeutils/TypeSerializerUtils.java
index 355edd4c9485c..c1672317e0a2b 100644
--- a/flink-core/src/main/java/org/apache/flink/api/common/typeutils/TypeSerializerUtils.java
+++ b/flink-core/src/main/java/org/apache/flink/api/common/typeutils/TypeSerializerUtils.java
@@ -26,7 +26,7 @@
 public final class TypeSerializerUtils {
 
 	/**
-	 * Takes config snapshots of the given serializers. In case where the config snapshots
+	 * Takes snapshots of the given serializers. In case where the snapshots
 	 * are still extending the old {@code TypeSerializerConfigSnapshot} class, the snapshots
 	 * are set up properly (with their originating serializer) such that the backwards
 	 * compatible code paths work.
@@ -35,10 +35,20 @@ public static TypeSerializerSnapshot<?>[] snapshotBackwardsCompatible(
 			TypeSerializer<?>... originatingSerializers) {
 
 		return Arrays.stream(originatingSerializers)
-				.map((s) -> configureForBackwardsCompatibility(s.snapshotConfiguration(), s))
+				.map(TypeSerializerUtils::snapshotBackwardsCompatible)
 				.toArray(TypeSerializerSnapshot[]::new);
 	}
 
+	/**
+	 * Takes a snapshot of the given serializer. In case where the snapshot
+	 * is still extending the old {@code TypeSerializerConfigSnapshot} class, the snapshot
+	 * is set up properly (with its originating serializer) such that the backwards
+	 * compatible code paths work.
+	 */
+	public static TypeSerializerSnapshot<?> snapshotBackwardsCompatible(TypeSerializer<?> originatingSerializer) {
+		return configureForBackwardsCompatibility(originatingSerializer.snapshotConfiguration(), originatingSerializer);
+	}
+
 	/**
 	 * Utility method to bind the serializer and serializer snapshot to a common
 	 * generic type variable.
diff --git a/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoFieldUtils.java b/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoFieldUtils.java
new file mode 100644
index 0000000000000..6d78919f648ab
--- /dev/null
+++ b/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoFieldUtils.java
@@ -0,0 +1,93 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.api.java.typeutils.runtime;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.core.memory.DataInputView;
+import org.apache.flink.core.memory.DataOutputView;
+import org.apache.flink.util.InstantiationUtil;
+
+import javax.annotation.Nullable;
+import java.io.IOException;
+import java.lang.reflect.Field;
+
+/**
+ * Utility class for reading, writing, and finding POJO fields.
+ */
+@Internal
+final class PojoFieldUtils {
+
+	/**
+	 * Writes a field to the given {@link DataOutputView}.
+	 *
+	 * <p>This write method avoids Java serialization, by writing only the classname of the field's declaring class
+	 * and the field name. The written field can be read using {@link #readField(DataInputView, ClassLoader)}.
+	 *
+	 * @param out the output view to write to.
+	 * @param field the field to write.
+	 */
+	static void writeField(DataOutputView out, Field field) throws IOException {
+		Class<?> declaringClass = field.getDeclaringClass();
+		out.writeUTF(declaringClass.getName());
+		out.writeUTF(field.getName());
+	}
+
+	/**
+	 * Reads a field from the given {@link DataInputView}.
+	 *
+	 * <p>This read methods avoids Java serialization, by reading the classname of the field's declaring class
+	 * and dynamically loading it. The field is also read by field name and obtained via reflection.
+	 *
+	 * @param in the input view to read from.
+	 * @param userCodeClassLoader the user classloader.
+	 *
+	 * @return the read field.
+	 */
+	static Field readField(DataInputView in, ClassLoader userCodeClassLoader) throws IOException {
+		Class<?> declaringClass = InstantiationUtil.resolveClassByName(in, userCodeClassLoader);
+		String fieldName = in.readUTF();
+		return getField(fieldName, declaringClass);
+	}
+
+	/**
+	 * Finds a field by name from its declaring class. This also searches for the
+	 * field in super classes.
+	 *
+	 * @param fieldName the name of the field to find.
+	 * @param declaringClass the declaring class of the field.
+	 *
+	 * @return the field.
+	 */
+	@Nullable
+	static Field getField(String fieldName, Class<?> declaringClass) {
+		Class<?> clazz = declaringClass;
+
+		while (clazz != null) {
+			try {
+				Field field = clazz.getDeclaredField(fieldName);
+				field.setAccessible(true);
+				return field;
+			} catch (NoSuchFieldException e) {
+				clazz = clazz.getSuperclass();
+			}
+		}
+
+		return null;
+	}
+}
diff --git a/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java b/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java
index 882f7bd21057e..611dabe41aafa 100644
--- a/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java
+++ b/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java
@@ -19,17 +19,15 @@
 package org.apache.flink.api.java.typeutils.runtime;
 
 import org.apache.flink.annotation.Internal;
-import org.apache.flink.annotation.VisibleForTesting;
 import org.apache.flink.api.common.ExecutionConfig;
-import org.apache.flink.api.common.typeutils.CompatibilityResult;
-import org.apache.flink.api.common.typeutils.CompatibilityUtil;
 import org.apache.flink.api.common.typeutils.GenericTypeSerializerConfigSnapshot;
+import org.apache.flink.api.common.typeutils.LegacySerializerSnapshotTransformer;
 import org.apache.flink.api.common.typeutils.TypeSerializer;
 import org.apache.flink.api.common.typeutils.TypeSerializerConfigSnapshot;
+import org.apache.flink.api.common.typeutils.TypeSerializerSchemaCompatibility;
 import org.apache.flink.api.common.typeutils.TypeSerializerSerializationUtil;
 import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;
 import org.apache.flink.api.common.typeutils.TypeSerializerSnapshotSerializationUtil;
-import org.apache.flink.api.common.typeutils.UnloadableDummyTypeSerializer;
 import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.api.java.typeutils.TypeExtractor;
 import org.apache.flink.core.memory.ByteArrayInputStreamWithPos;
@@ -53,6 +51,7 @@
 import java.util.Objects;
 
 import static org.apache.flink.util.Preconditions.checkNotNull;
+import static org.apache.flink.util.Preconditions.checkState;
 
 @Internal
 public final class PojoSerializer<T> extends TypeSerializer<T> {
@@ -78,43 +77,35 @@
 	 * <p>The fields are kept as a separate transient member, with their serialization
 	 * handled with the {@link #readObject(ObjectInputStream)} and {@link #writeObject(ObjectOutputStream)}
 	 * methods.
-	 *
-	 * <p>These may be reconfigured in {@link #ensureCompatibility(TypeSerializerConfigSnapshot)}.
 	 */
 	private transient Field[] fields;
-	private TypeSerializer<Object>[] fieldSerializers;
+	private final TypeSerializer<Object>[] fieldSerializers;
 	private final int numFields;
 
 	/**
 	 * Registered subclasses and their serializers.
 	 * Each subclass to their registered class tag is maintained as a separate map ordered by the class tag.
-	 *
-	 * <p>These may be reconfigured in {@link #ensureCompatibility(TypeSerializerConfigSnapshot)}.
 	 */
-	private LinkedHashMap<Class<?>, Integer> registeredClasses;
-	private TypeSerializer<?>[] registeredSerializers;
+	private final LinkedHashMap<Class<?>, Integer> registeredClasses;
+	private final TypeSerializer<?>[] registeredSerializers;
 
 	/**
 	 * Cache of non-registered subclasses to their serializers, created on-the-fly.
-	 *
-	 * <p>This cache is persisted and will be repopulated with reconfigured serializers
-	 * in {@link #ensureCompatibility(TypeSerializerConfigSnapshot)}.
 	 */
-	private transient HashMap<Class<?>, TypeSerializer<?>> subclassSerializerCache;
+	private transient Map<Class<?>, TypeSerializer<?>> subclassSerializerCache;
 
 	// --------------------------------------------------------------------------------------------
 
 	/**
 	 * Configuration of the current execution.
-	 *
-	 * <p>Nested serializers created using this will have the most up-to-date configuration,
-	 * and can be resolved for backwards compatibility with previous configuration
-	 * snapshots in {@link #ensureCompatibility(TypeSerializerConfigSnapshot)}.
 	 */
 	private final ExecutionConfig executionConfig;
 
 	private transient ClassLoader cl;
 
+	/**
+	 * Constructor to create a new {@link PojoSerializer}.
+	 */
 	@SuppressWarnings("unchecked")
 	public PojoSerializer(
 			Class<T> clazz,
@@ -144,13 +135,18 @@ public PojoSerializer(
 		this.subclassSerializerCache = new HashMap<>();
 	}
 
-	public PojoSerializer(
+	/**
+	 * Constructor to create a restore serializer or a reconfigured serializer
+	 * from a {@link PojoSerializerSnapshot}.
+	 */
+	PojoSerializer(
 			Class<T> clazz,
 			Field[] fields,
 			TypeSerializer<Object>[] fieldSerializers,
 			LinkedHashMap<Class<?>, Integer> registeredClasses,
 			TypeSerializer<?>[] registeredSerializers,
-			HashMap<Class<?>, TypeSerializer<?>> subclassSerializerCache) {
+			Map<Class<?>, TypeSerializer<?>> subclassSerializerCache,
+			ExecutionConfig executionConfig) {
 
 		this.clazz = checkNotNull(clazz);
 		this.fields = checkNotNull(fields);
@@ -159,8 +155,7 @@ public PojoSerializer(
 		this.registeredClasses = checkNotNull(registeredClasses);
 		this.registeredSerializers = checkNotNull(registeredSerializers);
 		this.subclassSerializerCache = checkNotNull(subclassSerializerCache);
-
-		this.executionConfig = null;
+		this.executionConfig = checkNotNull(executionConfig);
 	}
 	
 	@Override
@@ -580,8 +575,8 @@ public boolean equals(Object obj) {
 	// --------------------------------------------------------------------------------------------
 
 	@Override
-	public PojoSerializerConfigSnapshot<T> snapshotConfiguration() {
-		return buildConfigSnapshot(
+	public PojoSerializerSnapshot<T> snapshotConfiguration() {
+		return buildSnapshot(
 				clazz,
 				registeredClasses,
 				registeredSerializers,
@@ -590,162 +585,11 @@ public PojoSerializerConfigSnapshot<T> snapshotConfiguration() {
 				subclassSerializerCache);
 	}
 
-	@SuppressWarnings("unchecked")
-	@Override
-	public CompatibilityResult<T> ensureCompatibility(TypeSerializerConfigSnapshot<?> configSnapshot) {
-		if (configSnapshot instanceof PojoSerializerConfigSnapshot) {
-			final PojoSerializerConfigSnapshot<T> config = (PojoSerializerConfigSnapshot<T>) configSnapshot;
-
-			boolean requiresMigration = false;
-
-			if (clazz.equals(config.getTypeClass())) {
-				if (this.numFields == config.getFieldToSerializerConfigSnapshot().size()) {
-
-					CompatibilityResult<?> compatResult;
-
-					// ----------- check field order and compatibility of field serializers -----------
-
-					// reordered fields and their serializers;
-					// this won't be applied to this serializer until all compatibility checks have been completed
-					final Field[] reorderedFields = new Field[this.numFields];
-					final TypeSerializer<Object>[] reorderedFieldSerializers =
-						(TypeSerializer<Object>[]) new TypeSerializer<?>[this.numFields];
-
-					int i = 0;
-					for (Map.Entry<String, Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> fieldToConfigSnapshotEntry
-							: config.getFieldToSerializerConfigSnapshot().entrySet()) {
-
-						int fieldIndex = findField(fieldToConfigSnapshotEntry.getKey());
-						if (fieldIndex != -1) {
-							reorderedFields[i] = fields[fieldIndex];
-
-							compatResult = CompatibilityUtil.resolveCompatibilityResult(
-								fieldToConfigSnapshotEntry.getValue().f0,
-								UnloadableDummyTypeSerializer.class,
-								fieldToConfigSnapshotEntry.getValue().f1,
-								fieldSerializers[fieldIndex]);
-
-							if (compatResult.isRequiresMigration()) {
-								requiresMigration = true;
-
-								if (compatResult.getConvertDeserializer() != null) {
-									reorderedFieldSerializers[i] = (TypeSerializer<Object>) compatResult.getConvertDeserializer();
-								} else {
-									return CompatibilityResult.requiresMigration();
-								}
-							} else {
-								reorderedFieldSerializers[i] = fieldSerializers[fieldIndex];
-							}
-						} else {
-							return CompatibilityResult.requiresMigration();
-						}
-
-						i++;
-					}
-
-					// ---- check subclass registration order and compatibility of registered serializers ----
-
-					// reordered subclass registrations and their serializers;
-					// this won't be applied to this serializer until all compatibility checks have been completed
-					final LinkedHashMap<Class<?>, Integer> reorderedRegisteredSubclassesToClasstags;
-					final TypeSerializer<?>[] reorderedRegisteredSubclassSerializers;
-
-					final LinkedHashMap<Class<?>, Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> previousRegistrations =
-						config.getRegisteredSubclassesToSerializerConfigSnapshots();
-
-					// the reconfigured list of registered subclasses will be the previous registered
-					// subclasses in the original order with new subclasses appended at the end
-					LinkedHashSet<Class<?>> reorderedRegisteredSubclasses = new LinkedHashSet<>();
-					reorderedRegisteredSubclasses.addAll(previousRegistrations.keySet());
-					reorderedRegisteredSubclasses.addAll(
-						getRegisteredSubclassesFromExecutionConfig(clazz, executionConfig));
-
-					// re-establish the registered class tags and serializers
-					reorderedRegisteredSubclassesToClasstags = createRegisteredSubclassTags(reorderedRegisteredSubclasses);
-					reorderedRegisteredSubclassSerializers = createRegisteredSubclassSerializers(
-						reorderedRegisteredSubclasses, executionConfig);
-
-					i = 0;
-					for (Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>> previousRegisteredSerializerConfig : previousRegistrations.values()) {
-						// check compatibility of subclass serializer
-						compatResult = CompatibilityUtil.resolveCompatibilityResult(
-								previousRegisteredSerializerConfig.f0,
-								UnloadableDummyTypeSerializer.class,
-								previousRegisteredSerializerConfig.f1,
-								reorderedRegisteredSubclassSerializers[i]);
-
-						if (compatResult.isRequiresMigration()) {
-							requiresMigration = true;
-
-							if (compatResult.getConvertDeserializer() == null) {
-								return CompatibilityResult.requiresMigration();
-							}
-						}
-
-						i++;
-					}
-
-					// ------------------ ensure compatibility of non-registered subclass serializers ------------------
-
-					// the rebuilt cache for non-registered subclass serializers;
-					// this won't be applied to this serializer until all compatibility checks have been completed
-					HashMap<Class<?>, TypeSerializer<?>> rebuiltCache = new HashMap<>();
-
-					for (Map.Entry<Class<?>, Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> previousCachedEntry
-							: config.getNonRegisteredSubclassesToSerializerConfigSnapshots().entrySet()) {
-
-						TypeSerializer<?> cachedSerializer = createSubclassSerializer(previousCachedEntry.getKey());
-
-						// check compatibility of cached subclass serializer
-						compatResult = CompatibilityUtil.resolveCompatibilityResult(
-								previousCachedEntry.getValue().f0,
-								UnloadableDummyTypeSerializer.class,
-								previousCachedEntry.getValue().f1,
-								cachedSerializer);
-
-						if (compatResult.isRequiresMigration()) {
-							requiresMigration = true;
-
-							if (compatResult.getConvertDeserializer() != null) {
-								rebuiltCache.put(previousCachedEntry.getKey(), cachedSerializer);
-							} else {
-								return CompatibilityResult.requiresMigration();
-							}
-						} else {
-							rebuiltCache.put(previousCachedEntry.getKey(), cachedSerializer);
-						}
-					}
-
-					// completed compatibility checks; up to this point, we can just reconfigure
-					// the serializer so that it is compatible and migration is not required
-
-					if (!requiresMigration) {
-						this.fields = reorderedFields;
-						this.fieldSerializers = reorderedFieldSerializers;
-
-						this.registeredClasses = reorderedRegisteredSubclassesToClasstags;
-						this.registeredSerializers = reorderedRegisteredSubclassSerializers;
-
-						this.subclassSerializerCache = rebuiltCache;
-
-						return CompatibilityResult.compatible();
-					} else {
-						return CompatibilityResult.requiresMigration(
-							new PojoSerializer<>(
-								clazz,
-								reorderedFields,
-								reorderedFieldSerializers,
-								reorderedRegisteredSubclassesToClasstags,
-								reorderedRegisteredSubclassSerializers,
-								rebuiltCache));
-					}
-				}
-			}
-		}
-
-		return CompatibilityResult.requiresMigration();
-	}
-
+	/**
+	 * @deprecated This snapshot class is no longer being used.
+	 *             It has been fully replaced by {@link PojoSerializerSnapshot}.
+	 */
+	@Deprecated
 	public static final class PojoSerializerConfigSnapshot<T> extends GenericTypeSerializerConfigSnapshot<T> {
 
 		private static final int VERSION = 1;
@@ -814,6 +658,56 @@ public PojoSerializerConfigSnapshot(
 			this.ignoreTypeSerializerSerialization = ignoreTypeSerializerSerialization;
 		}
 
+		/**
+		 * This legacy snapshot delegates compatibility checks to the {@link PojoSerializerSnapshot}.
+		 */
+		@Override
+		public TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(TypeSerializer<T> newSerializer) {
+			LinkedHashMap<String, TypeSerializerSnapshot<?>> legacyFieldSerializerSnapshots =
+				preprocessLegacySerializerSnapshotTuples(fieldToSerializerConfigSnapshot);
+
+			LinkedHashMap<Field, TypeSerializerSnapshot<?>> fieldSerializerSnapshots = new LinkedHashMap<>(legacyFieldSerializerSnapshots.size());
+			legacyFieldSerializerSnapshots.forEach((fieldName, fieldSerializerSnapshot) -> {
+				Field field = PojoFieldUtils.getField(fieldName, getTypeClass());
+				checkState(
+					field != null,
+					"Detected a removed field [%s] from POJO [%s] while restoring from state snapshotted before Flink 1.8.0; POJO schema evolution is only available with state snapshotted after Flink 1.8.0.",
+					fieldName,
+					getTypeClass().getName());
+				fieldSerializerSnapshots.put(field, fieldSerializerSnapshot);
+			});
+
+			PojoSerializerSnapshot<T> newSnapshot = new PojoSerializerSnapshot<>(
+					getTypeClass(),
+					fieldSerializerSnapshots,
+					preprocessLegacySerializerSnapshotTuples(registeredSubclassesToSerializerConfigSnapshots),
+					preprocessLegacySerializerSnapshotTuples(nonRegisteredSubclassesToSerializerConfigSnapshots));
+
+			return newSnapshot.resolveSchemaCompatibility(newSerializer);
+		}
+
+		@SuppressWarnings("unchecked")
+		private static <K> LinkedHashMap<K, TypeSerializerSnapshot<?>> preprocessLegacySerializerSnapshotTuples(Map<K, Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> originalMap) {
+			LinkedHashMap<K, TypeSerializerSnapshot<?>> converted = new LinkedHashMap<>(originalMap.size());
+
+			originalMap.forEach((key, serializerSnapshotTuple) -> {
+				TypeSerializer<?> serializer = serializerSnapshotTuple.f0;
+				TypeSerializerSnapshot<?> snapshot = serializerSnapshotTuple.f1;
+
+				if (snapshot instanceof TypeSerializerConfigSnapshot) {
+					((TypeSerializerConfigSnapshot) snapshot).setPriorSerializer(serializer);
+				}
+
+				if (serializer instanceof LegacySerializerSnapshotTransformer) {
+					snapshot = ((LegacySerializerSnapshotTransformer) serializer).transformLegacySerializerSnapshot(snapshot);
+				}
+
+				converted.put(key, snapshot);
+			});
+
+			return converted;
+		}
+
 		@Override
 		public void write(DataOutputView out) throws IOException {
 			super.write(out);
@@ -1053,6 +947,52 @@ private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundE
 		subclassSerializerCache = new HashMap<Class<?>, TypeSerializer<?>>();
 	}
 
+	// --------------------------------------------------------------------------------------------
+	// Configuration access
+	// --------------------------------------------------------------------------------------------
+
+	Class<T> getPojoClass() {
+		return clazz;
+	}
+
+	Field[] getFields() {
+		return fields;
+	}
+
+	TypeSerializer<?>[] getFieldSerializers() {
+		return fieldSerializers;
+	}
+
+	TypeSerializer<?> getFieldSerializer(Field targetField) {
+		int fieldIndex = findField(targetField.getName());
+		if (fieldIndex == -1) {
+			return null;
+		}
+		return fieldSerializers[fieldIndex];
+	}
+
+	ExecutionConfig getExecutionConfig() {
+		return executionConfig;
+	}
+
+	LinkedHashMap<Class<?>, Integer> getRegisteredClasses() {
+		return registeredClasses;
+	}
+
+	TypeSerializer<?>[] getRegisteredSerializers() {
+		return registeredSerializers;
+	}
+
+	LinkedHashMap<Class<?>, TypeSerializer<?>> getBundledSubclassSerializerRegistry() {
+		final LinkedHashMap<Class<?>, TypeSerializer<?>> result = new LinkedHashMap<>(registeredClasses.size());
+		registeredClasses.forEach((registeredClass, id) -> result.put(registeredClass, registeredSerializers[id]));
+		return result;
+	}
+
+	Map<Class<?>, TypeSerializer<?>> getSubclassSerializerCache() {
+		return subclassSerializerCache;
+	}
+
 	// --------------------------------------------------------------------------------------------
 	// Utilities
 	// --------------------------------------------------------------------------------------------
@@ -1166,76 +1106,30 @@ private void copyBaseFieldOrder(PojoSerializer<?> baseSerializer) {
 	/**
 	 * Build and return a snapshot of the serializer's parameters and currently cached serializers.
 	 */
-	private static <T> PojoSerializerConfigSnapshot<T> buildConfigSnapshot(
+	private static <T> PojoSerializerSnapshot<T> buildSnapshot(
 			Class<T> pojoType,
 			LinkedHashMap<Class<?>, Integer> registeredSubclassesToTags,
 			TypeSerializer<?>[] registeredSubclassSerializers,
 			Field[] fields,
 			TypeSerializer<?>[] fieldSerializers,
-			HashMap<Class<?>, TypeSerializer<?>> nonRegisteredSubclassSerializerCache) {
+			Map<Class<?>, TypeSerializer<?>> nonRegisteredSubclassSerializerCache) {
 
-		final LinkedHashMap<String, Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> fieldToSerializerConfigSnapshots =
-			new LinkedHashMap<>(fields.length);
+		final LinkedHashMap<Field, TypeSerializer<?>> fieldToSerializers = new LinkedHashMap<>(fields.length);
 
 		for (int i = 0; i < fields.length; i++) {
-			fieldToSerializerConfigSnapshots.put(
-				fields[i].getName(),
-				new Tuple2<>(fieldSerializers[i], fieldSerializers[i].snapshotConfiguration()));
+			fieldToSerializers.put(fields[i], fieldSerializers[i]);
 		}
 
-		final LinkedHashMap<Class<?>, Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> registeredSubclassesToSerializerConfigSnapshots =
-				new LinkedHashMap<>(registeredSubclassesToTags.size());
+		final LinkedHashMap<Class<?>, TypeSerializer<?>> subclassRegistry = new LinkedHashMap<>(registeredSubclassesToTags.size());
 
 		for (Map.Entry<Class<?>, Integer> entry : registeredSubclassesToTags.entrySet()) {
-			registeredSubclassesToSerializerConfigSnapshots.put(
-					entry.getKey(),
-					new Tuple2<>(
-						registeredSubclassSerializers[entry.getValue()],
-						registeredSubclassSerializers[entry.getValue()].snapshotConfiguration()));
+			subclassRegistry.put(entry.getKey(), registeredSubclassSerializers[entry.getValue()]);
 		}
 
-		final HashMap<Class<?>, Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> nonRegisteredSubclassesToSerializerConfigSnapshots =
-				new LinkedHashMap<>(nonRegisteredSubclassSerializerCache.size());
-
-		for (Map.Entry<Class<?>, TypeSerializer<?>> entry : nonRegisteredSubclassSerializerCache.entrySet()) {
-			nonRegisteredSubclassesToSerializerConfigSnapshots.put(
-				entry.getKey(),
-				new Tuple2<>(entry.getValue(), entry.getValue().snapshotConfiguration()));
-		}
-
-		return new PojoSerializerConfigSnapshot<>(
+		return new PojoSerializerSnapshot<>(
 				pojoType,
-				fieldToSerializerConfigSnapshots,
-				registeredSubclassesToSerializerConfigSnapshots,
-				nonRegisteredSubclassesToSerializerConfigSnapshots);
-	}
-
-	// --------------------------------------------------------------------------------------------
-	// Test utilities
-	// --------------------------------------------------------------------------------------------
-
-	@VisibleForTesting
-	Field[] getFields() {
-		return fields;
-	}
-
-	@VisibleForTesting
-	TypeSerializer<?>[] getFieldSerializers() {
-		return fieldSerializers;
-	}
-
-	@VisibleForTesting
-	LinkedHashMap<Class<?>, Integer> getRegisteredClasses() {
-		return registeredClasses;
-	}
-
-	@VisibleForTesting
-	TypeSerializer<?>[] getRegisteredSerializers() {
-		return registeredSerializers;
-	}
-
-	@VisibleForTesting
-	HashMap<Class<?>, TypeSerializer<?>> getSubclassSerializerCache() {
-		return subclassSerializerCache;
+				fieldToSerializers,
+				subclassRegistry,
+				nonRegisteredSubclassSerializerCache);
 	}
 }
diff --git a/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerSnapshot.java b/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerSnapshot.java
new file mode 100644
index 0000000000000..6a64be8d48cd3
--- /dev/null
+++ b/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerSnapshot.java
@@ -0,0 +1,493 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.api.java.typeutils.runtime;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.annotation.VisibleForTesting;
+import org.apache.flink.api.common.ExecutionConfig;
+import org.apache.flink.api.common.typeutils.CompositeTypeSerializerUtil;
+import org.apache.flink.api.common.typeutils.TypeSerializer;
+import org.apache.flink.api.common.typeutils.TypeSerializerSchemaCompatibility;
+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;
+import org.apache.flink.api.java.tuple.Tuple2;
+import org.apache.flink.core.memory.DataInputView;
+import org.apache.flink.core.memory.DataOutputView;
+import org.apache.flink.util.LinkedOptionalMap;
+
+import java.io.IOException;
+import java.lang.reflect.Field;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.LinkedHashMap;
+import java.util.Map;
+import java.util.Set;
+
+import static org.apache.flink.util.Preconditions.checkArgument;
+import static org.apache.flink.util.Preconditions.checkNotNull;
+import static org.apache.flink.util.Preconditions.checkState;
+
+/**
+ * Snapshot class for the {@link PojoSerializer}.
+ */
+@Internal
+public class PojoSerializerSnapshot<T> implements TypeSerializerSnapshot<T> {
+
+	/**
+	 * We start from version {@code 2}. {@code 1} is retained for {@link PojoSerializer.PojoSerializerConfigSnapshot}.
+	 */
+	private static final int VERSION = 2;
+
+	/**
+	 * Contains the actual content for the serializer snapshot.
+	 */
+	private PojoSerializerSnapshotData<T> snapshotData;
+
+	/**
+	 * Constructor for reading the snapshot.
+	 */
+	public PojoSerializerSnapshot() {}
+
+	/**
+	 * Constructor for writing the snapshot.
+	 *
+	 * @param pojoClass the Pojo type class.
+	 * @param fieldSerializers map of fields to their corresponding serializers.
+	 * @param registeredSubclassSerializers map of registered subclasses to their corresponding serializers.
+	 * @param nonRegisteredSubclassSerializers map of non-registered subclasses to their corresponding serializers.
+	 */
+	PojoSerializerSnapshot(
+			Class<T> pojoClass,
+			LinkedHashMap<Field, TypeSerializer<?>> fieldSerializers,
+			LinkedHashMap<Class<?>, TypeSerializer<?>> registeredSubclassSerializers,
+			Map<Class<?>, TypeSerializer<?>> nonRegisteredSubclassSerializers) {
+
+		this.snapshotData = PojoSerializerSnapshotData.createFrom(
+			pojoClass,
+			fieldSerializers,
+			registeredSubclassSerializers,
+			nonRegisteredSubclassSerializers);
+	}
+
+	/**
+	 * Constructor for backwards compatibilty paths with the {@link PojoSerializer.PojoSerializerConfigSnapshot}.
+	 * This is used in {@link PojoSerializer.PojoSerializerConfigSnapshot#resolveSchemaCompatibility(TypeSerializer)}
+	 * to delegate the compatibility check to this snapshot class.
+	 *
+	 * @param pojoClass the Pojo type class.
+	 * @param existingFieldSerializerSnapshots the map of field serializer snapshots in the legacy snapshot.
+	 * @param existingRegisteredSubclassSerializerSnapshots the map of registered subclass serializer snapshots in the legacy snapshot.
+	 * @param existingNonRegisteredSubclassSerializerSnapshots the map of non-registered subclass serializer snapshots in the legacy snapshot.
+	 */
+	PojoSerializerSnapshot(
+			Class<T> pojoClass,
+			LinkedHashMap<Field, TypeSerializerSnapshot<?>> existingFieldSerializerSnapshots,
+			LinkedHashMap<Class<?>, TypeSerializerSnapshot<?>> existingRegisteredSubclassSerializerSnapshots,
+			LinkedHashMap<Class<?>, TypeSerializerSnapshot<?>> existingNonRegisteredSubclassSerializerSnapshots) {
+
+		this.snapshotData = PojoSerializerSnapshotData.createFrom(
+			pojoClass,
+			existingFieldSerializerSnapshots,
+			existingRegisteredSubclassSerializerSnapshots,
+			existingNonRegisteredSubclassSerializerSnapshots);
+	}
+
+	@VisibleForTesting
+	PojoSerializerSnapshot(PojoSerializerSnapshotData<T> snapshotData) {
+		this.snapshotData = checkNotNull(snapshotData);
+	}
+
+	@Override
+	public int getCurrentVersion() {
+		return VERSION;
+	}
+
+	@Override
+	public void writeSnapshot(DataOutputView out) throws IOException {
+		snapshotData.writeSnapshotData(out);
+	}
+
+	@Override
+	public void readSnapshot(int readVersion, DataInputView in, ClassLoader userCodeClassLoader) throws IOException {
+		checkArgument(readVersion == 2, "unrecognized read version %d", readVersion);
+		snapshotData = PojoSerializerSnapshotData.createFrom(in, userCodeClassLoader);
+	}
+
+	@Override
+	@SuppressWarnings("unchecked")
+	public TypeSerializer<T> restoreSerializer() {
+		final int numFields = snapshotData.getFieldSerializerSnapshots().size();
+
+		final ArrayList<Field> restoredFields = new ArrayList<>(numFields);
+		final ArrayList<TypeSerializer<?>> restoredFieldSerializers = new ArrayList<>(numFields);
+		snapshotData.getFieldSerializerSnapshots().forEach((fieldName, field, fieldSerializerSnapshot) -> {
+			restoredFields.add(field);
+			checkState(fieldSerializerSnapshot != null, "field serializer snapshots should be present.");
+			restoredFieldSerializers.add(fieldSerializerSnapshot.restoreSerializer());
+		});
+
+		final LinkedHashMap<Class<?>, TypeSerializer<?>> registeredSubclassSerializers = restoreSerializers(
+			snapshotData.getRegisteredSubclassSerializerSnapshots().unwrapOptionals());
+		final Tuple2<LinkedHashMap<Class<?>, Integer>, TypeSerializer<Object>[]> decomposedSubclassSerializerRegistry =
+			decomposeSubclassSerializerRegistry(registeredSubclassSerializers);
+
+		final LinkedHashMap<Class<?>, TypeSerializer<?>> nonRegisteredSubclassSerializers = restoreSerializers(
+			snapshotData.getNonRegisteredSubclassSerializerSnapshots().unwrapOptionals());
+
+		return new PojoSerializer<>(
+			snapshotData.getPojoClass(),
+			restoredFields.toArray(new Field[numFields]),
+			restoredFieldSerializers.toArray(new TypeSerializer[numFields]),
+			decomposedSubclassSerializerRegistry.f0,
+			decomposedSubclassSerializerRegistry.f1,
+			nonRegisteredSubclassSerializers,
+			new ExecutionConfig());
+	}
+
+	@Override
+	public TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(TypeSerializer<T> newSerializer) {
+		if (newSerializer.getClass() != PojoSerializer.class) {
+			return TypeSerializerSchemaCompatibility.incompatible();
+		}
+
+		final PojoSerializer<T> newPojoSerializer = (PojoSerializer<T>) newSerializer;
+
+		final Class<T> previousPojoClass = snapshotData.getPojoClass();
+		final LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> fieldSerializerSnapshots = snapshotData.getFieldSerializerSnapshots();
+		final LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> registeredSubclassSerializerSnapshots = snapshotData.getRegisteredSubclassSerializerSnapshots();
+		final LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> nonRegisteredSubclassSerializerSnapshots = snapshotData.getNonRegisteredSubclassSerializerSnapshots();
+
+		if (previousPojoClass != newPojoSerializer.getPojoClass()) {
+			return TypeSerializerSchemaCompatibility.incompatible();
+		}
+
+		if (registeredSubclassSerializerSnapshots.hasAbsentKeysOrValues()) {
+			return TypeSerializerSchemaCompatibility.incompatible();
+		}
+
+		if (nonRegisteredSubclassSerializerSnapshots.hasAbsentKeysOrValues()) {
+			return TypeSerializerSchemaCompatibility.incompatible();
+		}
+
+		final CompositeTypeSerializerUtil.IntermediateCompatibilityResult<T> preExistingFieldSerializersCompatibility =
+			getCompatibilityOfPreExistingFields(newPojoSerializer, fieldSerializerSnapshots);
+
+		if (preExistingFieldSerializersCompatibility.isIncompatible()) {
+			return TypeSerializerSchemaCompatibility.incompatible();
+		}
+
+		final CompositeTypeSerializerUtil.IntermediateCompatibilityResult<T> preExistingRegistrationsCompatibility =
+			getCompatibilityOfPreExistingRegisteredSubclasses(newPojoSerializer, registeredSubclassSerializerSnapshots);
+
+		if (preExistingRegistrationsCompatibility.isIncompatible()) {
+			return TypeSerializerSchemaCompatibility.incompatible();
+		}
+
+		if (newPojoSerializerIsCompatibleAfterMigration(
+				newPojoSerializer,
+				preExistingFieldSerializersCompatibility,
+				preExistingRegistrationsCompatibility,
+				fieldSerializerSnapshots)) {
+
+			return TypeSerializerSchemaCompatibility.compatibleAfterMigration();
+		}
+
+		if (newPojoSerializerIsCompatibleWithReconfiguredSerializer(
+				newPojoSerializer,
+				preExistingFieldSerializersCompatibility,
+				preExistingRegistrationsCompatibility,
+				registeredSubclassSerializerSnapshots,
+				nonRegisteredSubclassSerializerSnapshots)) {
+
+			return TypeSerializerSchemaCompatibility.compatibleWithReconfiguredSerializer(
+				constructReconfiguredPojoSerializer(
+					newPojoSerializer,
+					preExistingFieldSerializersCompatibility,
+					registeredSubclassSerializerSnapshots,
+					preExistingRegistrationsCompatibility,
+					nonRegisteredSubclassSerializerSnapshots));
+		}
+
+		return TypeSerializerSchemaCompatibility.compatibleAsIs();
+	}
+
+	// ---------------------------------------------------------------------------------------------
+	//  Utility methods
+	// ---------------------------------------------------------------------------------------------
+
+	/**
+	 * Transforms a {@link LinkedHashMap} with {@link TypeSerializerSnapshot}s as
+	 * the value to {@link TypeSerializer} as the value by restoring the snapshot.
+	 */
+	private static <K> LinkedHashMap<K, TypeSerializer<?>> restoreSerializers(LinkedHashMap<K, TypeSerializerSnapshot<?>> snapshotsMap) {
+		final LinkedHashMap<K, TypeSerializer<?>> restoredSerializersMap = new LinkedHashMap<>(snapshotsMap.size());
+		snapshotsMap.forEach((key, snapshot) -> restoredSerializersMap.put(key, snapshot.restoreSerializer()));
+		return restoredSerializersMap;
+	}
+
+	/**
+	 * Transforms the subclass serializer registry structure, {@code LinkedHashMap<Class<?>, TypeSerializer<?>>}
+	 * to 2 separate structures: a map containing with registered classes as key and their corresponding ids (order
+	 * in the original map) as value, as well as a separate array of the corresponding subclass serializers.
+	 */
+	@SuppressWarnings("unchecked")
+	private static Tuple2<LinkedHashMap<Class<?>, Integer>, TypeSerializer<Object>[]> decomposeSubclassSerializerRegistry(
+		LinkedHashMap<Class<?>, TypeSerializer<?>> subclassSerializerRegistry) {
+
+		final LinkedHashMap<Class<?>, Integer> subclassIds = new LinkedHashMap<>(subclassSerializerRegistry.size());
+		final TypeSerializer[] subclassSerializers = new TypeSerializer[subclassSerializerRegistry.size()];
+
+		subclassSerializerRegistry.forEach((registeredSubclassClass, serializer) -> {
+			int id = subclassIds.size();
+			subclassIds.put(registeredSubclassClass, id);
+			subclassSerializers[id] = serializer;
+		});
+
+		return Tuple2.of(subclassIds, subclassSerializers);
+	}
+
+	/**
+	 * Finds which Pojo fields exists both in the new {@link PojoSerializer} as well as in the previous one
+	 * (represented by this snapshot), and returns an {@link CompositeTypeSerializerUtil.IntermediateCompatibilityResult}
+	 * of the serializers of those preexisting fields.
+	 */
+	private static <T> CompositeTypeSerializerUtil.IntermediateCompatibilityResult<T> getCompatibilityOfPreExistingFields(
+			PojoSerializer<T> newPojoSerializer,
+			LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> fieldSerializerSnapshots) {
+
+		// the present entries dictates the preexisting fields, because removed fields would be
+		// represented as absent keys in the optional map.
+		final Set<LinkedOptionalMap.KeyValue<Field, TypeSerializerSnapshot<?>>> presentFieldSnapshots =
+			fieldSerializerSnapshots.getPresentEntries();
+
+		final ArrayList<TypeSerializerSnapshot<?>> associatedFieldSerializerSnapshots = new ArrayList<>(presentFieldSnapshots.size());
+		final ArrayList<TypeSerializer<?>> associatedNewFieldSerializers = new ArrayList<>(presentFieldSnapshots.size());
+
+		final Map<Field, TypeSerializer<?>> newFieldSerializersIndex = buildNewFieldSerializersIndex(newPojoSerializer);
+		for (LinkedOptionalMap.KeyValue<Field, TypeSerializerSnapshot<?>> presentFieldEntry : presentFieldSnapshots) {
+			TypeSerializer<?> associatedNewFieldSerializer = newFieldSerializersIndex.get(presentFieldEntry.getKey());
+			checkState(
+				associatedNewFieldSerializer != null,
+				"a present field should have its associated new field serializer available.");
+
+			associatedFieldSerializerSnapshots.add(presentFieldEntry.getValue());
+			associatedNewFieldSerializers.add(associatedNewFieldSerializer);
+		}
+
+		return CompositeTypeSerializerUtil.constructIntermediateCompatibilityResult(
+			associatedNewFieldSerializers.toArray(new TypeSerializer<?>[associatedNewFieldSerializers.size()]),
+			associatedFieldSerializerSnapshots.toArray(new TypeSerializerSnapshot<?>[associatedFieldSerializerSnapshots.size()]));
+	}
+
+	/**
+	 * Builds an index of fields to their corresponding serializers for the
+	 * new {@link PojoSerializer} for faster field serializer lookups.
+	 */
+	private static <T> Map<Field, TypeSerializer<?>> buildNewFieldSerializersIndex(PojoSerializer<T> newPojoSerializer) {
+		final Field[] newFields = newPojoSerializer.getFields();
+		final TypeSerializer<?>[] newFieldSerializers = newPojoSerializer.getFieldSerializers();
+
+		checkState(newFields.length == newFieldSerializers.length);
+
+		int numFields = newFields.length;
+		final Map<Field, TypeSerializer<?>> index = new HashMap<>(numFields);
+		for (int i = 0; i < numFields; i++) {
+			index.put(newFields[i], newFieldSerializers[i]);
+		}
+
+		return index;
+	}
+
+	/**
+	 * Finds which registered subclasses exists both in the new {@link PojoSerializer} as well as in the previous one
+	 * (represented by this snapshot), and returns an {@link CompositeTypeSerializerUtil.IntermediateCompatibilityResult}
+	 * of the serializers of this preexisting registered subclasses.
+	 */
+	private static <T> CompositeTypeSerializerUtil.IntermediateCompatibilityResult<T> getCompatibilityOfPreExistingRegisteredSubclasses(
+			PojoSerializer<T> newPojoSerializer,
+			LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> registeredSubclassSerializerSnapshots) {
+
+		final LinkedHashMap<Class<?>, TypeSerializerSnapshot<?>> unwrappedSerializerSnapshots = registeredSubclassSerializerSnapshots.unwrapOptionals();
+
+		final ArrayList<TypeSerializerSnapshot<?>> associatedSubclassSerializerSnapshots = new ArrayList<>();
+		final ArrayList<TypeSerializer<?>> associatedNewSubclassSerializers = new ArrayList<>();
+
+		final LinkedHashMap<Class<?>, TypeSerializer<?>> newSubclassSerializerRegistry = newPojoSerializer.getBundledSubclassSerializerRegistry();
+
+		for (Map.Entry<Class<?>, TypeSerializerSnapshot<?>> entry : unwrappedSerializerSnapshots.entrySet()) {
+			TypeSerializer<?> newRegisteredSerializer = newSubclassSerializerRegistry.get(entry.getKey());
+			if (newRegisteredSerializer != null) {
+				associatedSubclassSerializerSnapshots.add(entry.getValue());
+				associatedNewSubclassSerializers.add(newRegisteredSerializer);
+			}
+		}
+
+		return CompositeTypeSerializerUtil.constructIntermediateCompatibilityResult(
+			associatedNewSubclassSerializers.toArray(new TypeSerializer<?>[associatedNewSubclassSerializers.size()]),
+			associatedSubclassSerializerSnapshots.toArray(new TypeSerializerSnapshot<?>[associatedSubclassSerializerSnapshots.size()]));
+	}
+
+	/**
+	 * Checks if the new {@link PojoSerializer} is compatible after migration.
+	 */
+	private static <T> boolean newPojoSerializerIsCompatibleAfterMigration(
+			PojoSerializer<T> newPojoSerializer,
+			CompositeTypeSerializerUtil.IntermediateCompatibilityResult<T> fieldSerializerCompatibility,
+			CompositeTypeSerializerUtil.IntermediateCompatibilityResult<T> preExistingRegistrationsCompatibility,
+			LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> fieldSerializerSnapshots) {
+		return newPojoHasNewOrRemovedFields(fieldSerializerSnapshots, newPojoSerializer)
+			|| fieldSerializerCompatibility.isCompatibleAfterMigration()
+			|| preExistingRegistrationsCompatibility.isCompatibleAfterMigration();
+	}
+
+	/**
+	 * Checks if the new {@link PojoSerializer} is compatible with a reconfigured instance.
+	 */
+	private static <T> boolean newPojoSerializerIsCompatibleWithReconfiguredSerializer(
+			PojoSerializer<T> newPojoSerializer,
+			CompositeTypeSerializerUtil.IntermediateCompatibilityResult<T> fieldSerializerCompatibility,
+			CompositeTypeSerializerUtil.IntermediateCompatibilityResult<T> preExistingRegistrationsCompatibility,
+			LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> registeredSubclassSerializerSnapshots,
+			LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> nonRegisteredSubclassSerializerSnapshots) {
+		return newPojoHasDifferentSubclassRegistrationOrder(registeredSubclassSerializerSnapshots, newPojoSerializer)
+			|| previousSerializerHasNonRegisteredSubclasses(nonRegisteredSubclassSerializerSnapshots)
+			|| fieldSerializerCompatibility.isCompatibleWithReconfiguredSerializer()
+			|| preExistingRegistrationsCompatibility.isCompatibleWithReconfiguredSerializer();
+	}
+
+	/**
+	 * Checks whether the new {@link PojoSerializer} has new or removed fields compared to the previous one.
+	 */
+	private static boolean newPojoHasNewOrRemovedFields(
+			LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> fieldSerializerSnapshots,
+			PojoSerializer<?> newPojoSerializer) {
+		int numRemovedFields = fieldSerializerSnapshots.absentKeysOrValues().size();
+		int numPreexistingFields = fieldSerializerSnapshots.size() - numRemovedFields;
+
+		boolean hasRemovedFields = numRemovedFields > 0;
+		boolean hasNewFields = newPojoSerializer.getFields().length - numPreexistingFields > 0;
+		return hasRemovedFields || hasNewFields;
+	}
+
+	/**
+	 * Checks whether the new {@link PojoSerializer} has a different subclass registration order
+	 * compared to the previous one.
+	 */
+	private static boolean newPojoHasDifferentSubclassRegistrationOrder(
+			LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> registeredSubclassSerializerSnapshots,
+			PojoSerializer<?> newPojoSerializer) {
+		Set<Class<?>> previousRegistrationOrder = registeredSubclassSerializerSnapshots.unwrapOptionals().keySet();
+		Set<Class<?>> newRegistrationOrder = newPojoSerializer.getRegisteredClasses().keySet();
+		return !isPreviousRegistrationPrefixOfNewRegistration(previousRegistrationOrder, newRegistrationOrder);
+	}
+
+	private static boolean isPreviousRegistrationPrefixOfNewRegistration(
+		Set<Class<?>> previousRegistrationOrder,
+		Set<Class<?>> newRegistrationOrder) {
+		Iterator<Class<?>> newRegistrationItr = newRegistrationOrder.iterator();
+
+		for (Class<?> previousRegisteredClass : previousRegistrationOrder) {
+			if (!newRegistrationItr.hasNext()) {
+				return false;
+			}
+			Class<?> newRegisteredClass = newRegistrationItr.next();
+			if (!previousRegisteredClass.equals(newRegisteredClass)) {
+				return false;
+			}
+		}
+		return true;
+	}
+
+	/**
+	 * Checks whether the previous serializer, represented by this snapshot, has
+	 * non-registered subclasses.
+	 */
+	private static boolean previousSerializerHasNonRegisteredSubclasses(
+			LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> nonRegisteredSubclassSerializerSnapshots) {
+		return nonRegisteredSubclassSerializerSnapshots.size() > 0;
+	}
+
+	/**
+	 * Creates a reconfigured version of the {@link PojoSerializer}.
+	 *
+	 * @param originalNewPojoSerializer the original new {@link PojoSerializer} to create a reconfigured version of.
+	 * @param fieldSerializerCompatibility compatibility of preexisting fields' serializers.
+	 * @param registeredSerializerSnapshots snapshot of previous registered subclasses' serializers.
+	 * @param preExistingRegistrationsCompatibility compatibility of preexisting subclasses' serializers.
+	 * @param nonRegisteredSubclassSerializerSnapshots snapshot of previous non-registered subclasses' serializers.
+	 *
+	 * @return a reconfigured version of the original new {@link PojoSerializer}.
+	 */
+	private static <T> PojoSerializer<T> constructReconfiguredPojoSerializer(
+			PojoSerializer<T> originalNewPojoSerializer,
+			CompositeTypeSerializerUtil.IntermediateCompatibilityResult<T> fieldSerializerCompatibility,
+			LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> registeredSerializerSnapshots,
+			CompositeTypeSerializerUtil.IntermediateCompatibilityResult<T> preExistingRegistrationsCompatibility,
+			LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> nonRegisteredSubclassSerializerSnapshots) {
+
+		@SuppressWarnings("unchecked")
+		final TypeSerializer<Object>[] reconfiguredFieldSerializers = constructReconfiguredFieldSerializers(fieldSerializerCompatibility);
+
+		Tuple2<LinkedHashMap<Class<?>, Integer>, TypeSerializer<Object>[]> reconfiguredSubclassRegistry = constructReconfiguredSubclassRegistry(
+			originalNewPojoSerializer.getBundledSubclassSerializerRegistry(),
+			registeredSerializerSnapshots,
+			preExistingRegistrationsCompatibility);
+
+		return new PojoSerializer<>(
+			originalNewPojoSerializer.getPojoClass(),
+			originalNewPojoSerializer.getFields(),
+			reconfiguredFieldSerializers,
+			reconfiguredSubclassRegistry.f0,
+			reconfiguredSubclassRegistry.f1,
+			restoreSerializers(nonRegisteredSubclassSerializerSnapshots.unwrapOptionals()),
+			originalNewPojoSerializer.getExecutionConfig());
+	}
+
+	private static TypeSerializer[] constructReconfiguredFieldSerializers(
+			CompositeTypeSerializerUtil.IntermediateCompatibilityResult<?> fieldSerializerCompatibility) {
+		checkArgument(!fieldSerializerCompatibility.isIncompatible() && !fieldSerializerCompatibility.isCompatibleAfterMigration());
+		return fieldSerializerCompatibility.getNestedSerializers();
+	}
+
+	private static Tuple2<LinkedHashMap<Class<?>, Integer>, TypeSerializer<Object>[]> constructReconfiguredSubclassRegistry(
+			LinkedHashMap<Class<?>, TypeSerializer<?>> newSubclassRegistrations,
+			LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> registeredSerializerSnapshots,
+			CompositeTypeSerializerUtil.IntermediateCompatibilityResult<?> preExistingRegistrationsCompatibility) {
+
+		checkArgument(!preExistingRegistrationsCompatibility.isIncompatible() && !preExistingRegistrationsCompatibility.isCompatibleAfterMigration());
+
+		LinkedHashMap<Class<?>, TypeSerializer<?>> reconfiguredSubclassSerializerRegistry =
+			restoreSerializers(registeredSerializerSnapshots.unwrapOptionals());
+
+		Iterator<TypeSerializer<?>> serializersForPreexistingRegistrations =
+			Arrays.asList(preExistingRegistrationsCompatibility.getNestedSerializers()).iterator();
+
+		for (Map.Entry<Class<?>, TypeSerializer<?>> registration : newSubclassRegistrations.entrySet()) {
+			// new registrations should simply be appended to the subclass serializer registry with their new serializers;
+			// preexisting registrations should use the compatibility-checked serializer
+			TypeSerializer<?> newRegistration = (reconfiguredSubclassSerializerRegistry.containsKey(registration.getKey()))
+				? serializersForPreexistingRegistrations.next()
+				: registration.getValue();
+			reconfiguredSubclassSerializerRegistry.put(registration.getKey(), newRegistration);
+		}
+
+		return decomposeSubclassSerializerRegistry(reconfiguredSubclassSerializerRegistry);
+	}
+}
diff --git a/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerSnapshotData.java b/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerSnapshotData.java
new file mode 100644
index 0000000000000..1bd8253bb365a
--- /dev/null
+++ b/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerSnapshotData.java
@@ -0,0 +1,323 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.api.java.typeutils.runtime;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.annotation.VisibleForTesting;
+import org.apache.flink.api.common.typeutils.TypeSerializer;
+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;
+import org.apache.flink.api.common.typeutils.TypeSerializerUtils;
+import org.apache.flink.core.memory.DataInputView;
+import org.apache.flink.core.memory.DataOutputView;
+import org.apache.flink.util.InstantiationUtil;
+import org.apache.flink.util.LinkedOptionalMap;
+import org.apache.flink.util.function.BiConsumerWithException;
+import org.apache.flink.util.function.BiFunctionWithException;
+import org.apache.flink.util.function.FunctionWithException;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.IOException;
+import java.lang.reflect.Field;
+import java.util.HashMap;
+import java.util.LinkedHashMap;
+import java.util.Map;
+
+import static org.apache.flink.util.LinkedOptionalMap.optionalMapOf;
+import static org.apache.flink.util.Preconditions.checkNotNull;
+
+/**
+ * This class holds the snapshot content for the {@link PojoSerializer}.
+ *
+ * <h2>Serialization Format</hr>
+ *
+ * <p>The serialization format defined by this class is as follows:
+ *
+ * <pre>{@code
+ * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ * |                                            POJO class name                                          |
+ * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ * |      number of fields      |                (field name, field serializer snapshot)                 |
+ * |                            |                                pairs                                   |
+ * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ * |         number of          |       (registered subclass name, subclass serializer snapshot)         |
+ * |   registered subclasses    |                                pairs                                   |
+ * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ * |         number of          |     (non-registered subclass name, subclass serializer snapshot)       |
+ * | non-registered subclasses  |                                pairs                                   |
+ * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ * }</pre>
+ */
+@Internal
+final class PojoSerializerSnapshotData<T> {
+
+	private static final Logger LOG = LoggerFactory.getLogger(PojoSerializerSnapshotData.class);
+
+	// ---------------------------------------------------------------------------------------------
+	//  Factory methods
+	// ---------------------------------------------------------------------------------------------
+
+	/**
+	 * Creates a {@link PojoSerializerSnapshotData} from configuration of a {@link PojoSerializer}.
+	 *
+	 * <p>This factory method is meant to be used in regular write paths, i.e. when taking a snapshot
+	 * of the {@link PojoSerializer}. All POJO fields, registered subclass classes, and non-registered
+	 * subclass classes are all present.
+	 */
+	static <T> PojoSerializerSnapshotData<T> createFrom(
+			Class<T> pojoClass,
+			LinkedHashMap<Field, TypeSerializer<?>> fieldSerializers,
+			LinkedHashMap<Class<?>, TypeSerializer<?>> registeredSubclassSerializers,
+			Map<Class<?>, TypeSerializer<?>> nonRegisteredSubclassSerializers) {
+
+		LinkedHashMap<Field, TypeSerializerSnapshot<?>> fieldSerializerSnapshots = new LinkedHashMap<>(fieldSerializers.size());
+		fieldSerializers.forEach((k, v) -> fieldSerializerSnapshots.put(k, TypeSerializerUtils.snapshotBackwardsCompatible(v)));
+
+		LinkedHashMap<Class<?>, TypeSerializerSnapshot<?>> registeredSubclassSerializerSnapshots = new LinkedHashMap<>(registeredSubclassSerializers.size());
+		registeredSubclassSerializers.forEach((k, v) -> registeredSubclassSerializerSnapshots.put(k, TypeSerializerUtils.snapshotBackwardsCompatible(v)));
+
+		Map<Class<?>, TypeSerializerSnapshot<?>> nonRegisteredSubclassSerializerSnapshots = new HashMap<>(nonRegisteredSubclassSerializers.size());
+		nonRegisteredSubclassSerializers.forEach((k, v) -> nonRegisteredSubclassSerializerSnapshots.put(k, TypeSerializerUtils.snapshotBackwardsCompatible(v)));
+
+		return new PojoSerializerSnapshotData<>(
+			pojoClass,
+			optionalMapOf(fieldSerializerSnapshots, Field::getName),
+			optionalMapOf(registeredSubclassSerializerSnapshots, Class::getName),
+			optionalMapOf(nonRegisteredSubclassSerializerSnapshots, Class::getName));
+	}
+
+	/**
+	 * Creates a {@link PojoSerializerSnapshotData} from serialized data stream.
+	 *
+	 * <p>This factory method is meant to be used in regular read paths, i.e. when reading back a snapshot
+	 * of the {@link PojoSerializer}. POJO fields, registered subclass classes, and non-registered subclass
+	 * classes may no longer be present anymore.
+	 */
+	static <T> PojoSerializerSnapshotData<T> createFrom(DataInputView in, ClassLoader userCodeClassLoader) throws IOException {
+		return PojoSerializerSnapshotData.readSnapshotData(in, userCodeClassLoader);
+	}
+
+	/**
+	 * Creates a {@link PojoSerializerSnapshotData} from existing snapshotted configuration of a {@link PojoSerializer}.
+	 *
+	 * <p>This factory method is meant to be used for backwards compatible read paths.
+	 */
+	static <T> PojoSerializerSnapshotData<T> createFrom(
+		Class<T> pojoClass,
+		LinkedHashMap<Field, TypeSerializerSnapshot<?>> existingFieldSerializerSnapshots,
+		LinkedHashMap<Class<?>, TypeSerializerSnapshot<?>> existingRegisteredSubclassSerializerSnapshots,
+		LinkedHashMap<Class<?>, TypeSerializerSnapshot<?>> existingNonRegisteredSubclassSerializerSnapshots) {
+
+		return new PojoSerializerSnapshotData<>(
+			pojoClass,
+			optionalMapOf(existingFieldSerializerSnapshots, Field::getName),
+			optionalMapOf(existingRegisteredSubclassSerializerSnapshots, Class::getName),
+			optionalMapOf(existingNonRegisteredSubclassSerializerSnapshots, Class::getName));
+	}
+
+	@VisibleForTesting
+	static <T> PojoSerializerSnapshotData<T> createFrom(
+		Class<T> pojoClass,
+		LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> optionalFieldSerializerSnapshots,
+		LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> optionalRegisteredSubclassSerializerSnapshots,
+		LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> optionalNonRegisteredSubclassSerializerSnapshots) {
+
+		return new PojoSerializerSnapshotData<>(
+			pojoClass,
+			optionalFieldSerializerSnapshots,
+			optionalRegisteredSubclassSerializerSnapshots,
+			optionalNonRegisteredSubclassSerializerSnapshots);
+	}
+
+	private Class<T> pojoClass;
+	private LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> fieldSerializerSnapshots;
+	private LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> registeredSubclassSerializerSnapshots;
+	private LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> nonRegisteredSubclassSerializerSnapshots;
+
+	private PojoSerializerSnapshotData(
+			Class<T> typeClass,
+			LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> fieldSerializerSnapshots,
+			LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> registeredSubclassSerializerSnapshots,
+			LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> nonRegisteredSubclassSerializerSnapshots) {
+
+		this.pojoClass = checkNotNull(typeClass);
+		this.fieldSerializerSnapshots = checkNotNull(fieldSerializerSnapshots);
+		this.registeredSubclassSerializerSnapshots = checkNotNull(registeredSubclassSerializerSnapshots);
+		this.nonRegisteredSubclassSerializerSnapshots = checkNotNull(nonRegisteredSubclassSerializerSnapshots);
+	}
+
+	// ---------------------------------------------------------------------------------------------
+	//  Snapshot data read / write methods
+	// ---------------------------------------------------------------------------------------------
+
+	void writeSnapshotData(DataOutputView out) throws IOException {
+		out.writeUTF(pojoClass.getName());
+		writeOptionalMap(out, fieldSerializerSnapshots, PojoFieldUtils::writeField, TypeSerializerSnapshot::writeVersionedSnapshot);
+		writeOptionalMap(out, registeredSubclassSerializerSnapshots, NoOpWriter.noopWriter(), TypeSerializerSnapshot::writeVersionedSnapshot);
+		writeOptionalMap(out, nonRegisteredSubclassSerializerSnapshots, NoOpWriter.noopWriter(), TypeSerializerSnapshot::writeVersionedSnapshot);
+	}
+
+	private static <T> PojoSerializerSnapshotData<T> readSnapshotData(DataInputView in, ClassLoader userCodeClassLoader) throws IOException {
+		Class<T> pojoClass = InstantiationUtil.resolveClassByName(in, userCodeClassLoader);
+
+		LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> fieldSerializerSnapshots = readOptionalMap(
+			in,
+			fieldReader(userCodeClassLoader),
+			snapshotReader(userCodeClassLoader));
+		LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> registeredSubclassSerializerSnapshots = readOptionalMap(
+			in,
+			classReader(userCodeClassLoader),
+			snapshotReader(userCodeClassLoader));
+		LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> nonRegisteredSubclassSerializerSnapshots = readOptionalMap(
+			in,
+			classReader(userCodeClassLoader),
+			snapshotReader(userCodeClassLoader));
+
+		return new PojoSerializerSnapshotData<>(pojoClass, fieldSerializerSnapshots, registeredSubclassSerializerSnapshots, nonRegisteredSubclassSerializerSnapshots);
+	}
+
+	// ---------------------------------------------------------------------------------------------
+	//  Snapshot data accessors
+	// ---------------------------------------------------------------------------------------------
+
+	Class<T> getPojoClass() {
+		return pojoClass;
+	}
+
+	LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> getFieldSerializerSnapshots() {
+		return fieldSerializerSnapshots;
+	}
+
+	LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> getRegisteredSubclassSerializerSnapshots() {
+		return registeredSubclassSerializerSnapshots;
+	}
+
+	LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> getNonRegisteredSubclassSerializerSnapshots() {
+		return nonRegisteredSubclassSerializerSnapshots;
+	}
+
+	// ---------------------------------------------------------------------------------------------
+	//  Utilities
+	// ---------------------------------------------------------------------------------------------
+
+	private static <K, V> void writeOptionalMap(
+		DataOutputView out,
+		LinkedOptionalMap<K, V> map,
+		BiConsumerWithException<DataOutputView, K, IOException> keyWriter,
+		BiConsumerWithException<DataOutputView, V, IOException> valueWriter) throws IOException {
+
+		out.writeInt(map.size());
+		map.forEach(((keyName, key, value) -> {
+			out.writeUTF(keyName);
+			if (key == null) {
+				out.writeBoolean(false);
+				}
+			else {
+				out.writeBoolean(true);
+				keyWriter.accept(out, key);
+				}
+			if (value == null) {
+				out.writeBoolean(false);
+				}
+			else {
+				out.writeBoolean(true);
+				valueWriter.accept(out, value);
+				}
+			}
+		));
+	}
+
+	private static <K, V> LinkedOptionalMap<K, V> readOptionalMap(
+		DataInputView in,
+		BiFunctionWithException<DataInputView, String, K, IOException> keyReader,
+		FunctionWithException<DataInputView, V, IOException> valueReader) throws IOException {
+
+		long mapSize = in.readInt();
+
+		LinkedOptionalMap<K, V> map = new LinkedOptionalMap<>();
+		for (int i = 0; i < mapSize; i++) {
+			String keyName = in.readUTF();
+			final K key;
+			if (in.readBoolean()) {
+				key = keyReader.apply(in, keyName);
+			}
+			else {
+				key = null;
+			}
+			final V value;
+			if (in.readBoolean()) {
+				value = valueReader.apply(in);
+			}
+			else {
+				value = null;
+			}
+			map.put(keyName, key, value);
+		}
+		return map;
+	}
+
+	private enum NoOpWriter implements BiConsumerWithException<DataOutputView, Object, IOException> {
+		INSTANCE;
+
+		@Override
+		public void accept(DataOutputView dataOutputView, Object o) throws IOException {}
+
+		@SuppressWarnings("unchecked")
+		static <K> BiConsumerWithException<DataOutputView, K, IOException> noopWriter() {
+			return (BiConsumerWithException<DataOutputView, K, IOException>) INSTANCE;
+		}
+	}
+
+	private static BiFunctionWithException<DataInputView, String, Field, IOException> fieldReader(ClassLoader cl) {
+		return (input, fieldName) -> {
+			try {
+				return PojoFieldUtils.readField(input, cl);
+			}
+			catch (Throwable t) {
+				LOG.warn(String.format("Exception while reading field %s", fieldName), t);
+				return null;
+			}
+		};
+	}
+
+	private static FunctionWithException<DataInputView, TypeSerializerSnapshot<?>, IOException> snapshotReader(ClassLoader cl) {
+		return input -> {
+			try {
+				return TypeSerializerSnapshot.readVersionedSnapshot(input, cl);
+			}
+			catch (Throwable t) {
+				LOG.warn("Exception while reading serializer snapshot.", t);
+				return null;
+			}
+		};
+	}
+
+	private static BiFunctionWithException<DataInputView, String, Class<?>, IOException> classReader(ClassLoader cl) {
+		return (input, className) -> {
+			try {
+				// input is ignored because we don't write the actual class as value.
+				return Class.forName(className, false, cl);
+			} catch (Throwable t) {
+				LOG.warn(String.format("Exception while reading class %s", className), t);
+				return null;
+			}
+		};
+	}
+}
diff --git a/flink-core/src/main/java/org/apache/flink/util/LinkedOptionalMap.java b/flink-core/src/main/java/org/apache/flink/util/LinkedOptionalMap.java
new file mode 100644
index 0000000000000..fbcf5b33e5c11
--- /dev/null
+++ b/flink-core/src/main/java/org/apache/flink/util/LinkedOptionalMap.java
@@ -0,0 +1,300 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.util;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.annotation.VisibleForTesting;
+
+import javax.annotation.Nonnull;
+import javax.annotation.Nullable;
+
+import java.util.Iterator;
+import java.util.LinkedHashMap;
+import java.util.LinkedHashSet;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Optional;
+import java.util.Set;
+import java.util.function.Function;
+import java.util.stream.Collectors;
+
+import static org.apache.flink.util.Preconditions.checkNotNull;
+
+/**
+ * A LinkedOptionalMap is an order preserving map (like {@link LinkedHashMap}) where keys have a unique string name, but are
+ * optionally present, and the values are optional.
+ */
+@Internal
+public final class LinkedOptionalMap<K, V> {
+
+	// --------------------------------------------------------------------------------------------------------
+	// Factory
+	// --------------------------------------------------------------------------------------------------------
+
+	/**
+	 * Creates an {@code LinkedOptionalMap} from the provided map.
+	 *
+	 * <p>This method is the equivalent of {@link Optional#of(Object)} but for maps. To support more than one {@code NULL}
+	 * key, an optional map requires a unique string name to be associated with each key (provided by keyNameGetter)
+	 *
+	 * @param sourceMap     a source map to wrap as an optional map.
+	 * @param keyNameGetter function that assigns a unique name to the keys of the source map.
+	 * @param <K>           key type
+	 * @param <V>           value type
+	 * @return an {@code LinkedOptionalMap} with optional named keys, and optional values.
+	 */
+	public static <K, V> LinkedOptionalMap<K, V> optionalMapOf(Map<K, V> sourceMap, Function<K, String> keyNameGetter) {
+
+		LinkedHashMap<String, KeyValue<K, V>> underlyingMap = new LinkedHashMap<>(sourceMap.size());
+
+		sourceMap.forEach((k, v) -> {
+			String keyName = keyNameGetter.apply(k);
+			underlyingMap.put(keyName, new KeyValue<>(k, v));
+		});
+
+		return new LinkedOptionalMap<>(underlyingMap);
+	}
+
+	/**
+	 * Tries to merges the keys and the values of @right into @left.
+	 */
+	public static <K, V> MergeResult<K, V> mergeRightIntoLeft(LinkedOptionalMap<K, V> left, LinkedOptionalMap<K, V> right) {
+		LinkedOptionalMap<K, V> merged = new LinkedOptionalMap<>(left);
+		merged.putAll(right);
+
+		return new MergeResult<>(merged, isLeftPrefixOfRight(left, right));
+	}
+
+	// --------------------------------------------------------------------------------------------------------
+	// Constructor
+	// --------------------------------------------------------------------------------------------------------
+
+	private final LinkedHashMap<String, KeyValue<K, V>> underlyingMap;
+
+	public LinkedOptionalMap() {
+		this(new LinkedHashMap<>());
+	}
+
+	@SuppressWarnings("CopyConstructorMissesField")
+	LinkedOptionalMap(LinkedOptionalMap<K, V> linkedOptionalMap) {
+		this(new LinkedHashMap<>(linkedOptionalMap.underlyingMap));
+	}
+
+	private LinkedOptionalMap(LinkedHashMap<String, KeyValue<K, V>> underlyingMap) {
+		this.underlyingMap = checkNotNull(underlyingMap);
+	}
+
+	// --------------------------------------------------------------------------------------------------------
+	// API
+	// --------------------------------------------------------------------------------------------------------
+
+	public int size() {
+		return underlyingMap.size();
+	}
+
+	public void put(String keyName, @Nullable K key, @Nullable V value) {
+		checkNotNull(keyName);
+
+		underlyingMap.compute(keyName, (unused, kv) ->
+			(kv == null) ? new KeyValue<>(key, value) : kv.merge(key, value));
+	}
+
+	void putAll(LinkedOptionalMap<K, V> right) {
+		for (Entry<String, KeyValue<K, V>> entry : right.underlyingMap.entrySet()) {
+			KeyValue<K, V> kv = entry.getValue();
+			this.put(entry.getKey(), kv.key, kv.value);
+		}
+	}
+
+	/**
+	 * returns the key names of any keys or values that are absent.
+	 */
+	public Set<String> absentKeysOrValues() {
+		return underlyingMap.entrySet()
+			.stream()
+			.filter(LinkedOptionalMap::keyOrValueIsAbsent)
+			.map(Entry::getKey)
+			.collect(Collectors.toCollection(LinkedHashSet::new));
+	}
+
+	/**
+	 * Checks whether there are entries with absent keys or values.
+	 */
+	public boolean hasAbsentKeysOrValues() {
+		for (Entry<String, KeyValue<K, V>> entry : underlyingMap.entrySet()) {
+			if (keyOrValueIsAbsent(entry)) {
+				return true;
+			}
+		}
+		return false;
+	}
+
+	/**
+	 * A {@link java.util.function.Consumer} that throws exceptions.
+	 */
+	@FunctionalInterface
+	public interface ConsumerWithException<K, V, E extends Throwable> {
+		void accept(@Nonnull String keyName, @Nullable K key , @Nullable V value) throws E;
+	}
+
+	public <E extends Throwable> void forEach(ConsumerWithException<K, V, E> consumer) throws E {
+		for (Entry<String, KeyValue<K, V>> entry : underlyingMap.entrySet()) {
+			KeyValue<K, V> kv = entry.getValue();
+			consumer.accept(entry.getKey(), kv.key, kv.value);
+		}
+	}
+
+	public Set<KeyValue<K, V>> getPresentEntries() {
+		return underlyingMap.entrySet()
+			.stream()
+			.filter(entry -> !LinkedOptionalMap.keyOrValueIsAbsent(entry))
+			.map(Entry::getValue)
+			.collect(Collectors.toCollection(LinkedHashSet::new));
+	}
+
+	/**
+	 * assuming all the entries of this map are present (keys and values) this method would return
+	 * a map with these key and values, striped from their Optional wrappers.
+	 * NOTE: please note that if any of the key or values are absent this method would throw an {@link IllegalStateException}.
+	 */
+	public LinkedHashMap<K, V> unwrapOptionals() {
+		final LinkedHashMap<K, V> unwrapped = new LinkedHashMap<>(underlyingMap.size());
+
+		for (Entry<String, KeyValue<K, V>> entry : underlyingMap.entrySet()) {
+			String namedKey = entry.getKey();
+			KeyValue<K, V> kv = entry.getValue();
+			if (kv.key == null) {
+				throw new IllegalStateException("Missing key '" + namedKey + "'");
+			}
+			if (kv.value == null) {
+				throw new IllegalStateException("Missing value for the key '" + namedKey + "'");
+			}
+			unwrapped.put(kv.key, kv.value);
+		}
+		return unwrapped;
+	}
+
+	/**
+	 * returns the key names added to this map.
+	 */
+	public Set<String> keyNames() {
+		return underlyingMap.keySet();
+	}
+
+	// --------------------------------------------------------------------------------------------------------
+	// Static Utility Methods
+	// --------------------------------------------------------------------------------------------------------
+
+	private static <K, V> boolean keyOrValueIsAbsent(Entry<String, KeyValue<K, V>> entry) {
+		KeyValue<K, V> kv = entry.getValue();
+		return kv.key == null || kv.value == null;
+	}
+
+	@VisibleForTesting static <K, V> boolean isLeftPrefixOfRight(LinkedOptionalMap<K, V> left, LinkedOptionalMap<K, V> right) {
+		Iterator<String> rightKeys = right.keyNames().iterator();
+
+		for (String leftKey : left.keyNames()) {
+			if (!rightKeys.hasNext()) {
+				return false;
+			}
+			String rightKey = rightKeys.next();
+			if (!leftKey.equals(rightKey)) {
+				return false;
+			}
+		}
+		return true;
+	}
+
+	// --------------------------------------------------------------------------------------------------------
+	// Inner Classes
+	// --------------------------------------------------------------------------------------------------------
+
+	/**
+	 * Key-value pairs stored by the underlying map.
+	 *
+	 * @param <K> key type.
+	 * @param <V> value type.
+	 */
+	public static final class KeyValue<K, V> {
+		K key;
+		V value;
+
+		KeyValue(K key, V value) {
+			this.key = key;
+			this.value = value;
+		}
+
+		public K getKey() {
+			return key;
+		}
+
+		public V getValue() {
+			return value;
+		}
+
+		KeyValue<K, V> merge(K key, V value) {
+			this.key = firstNonNull(key, this.key);
+			this.value = firstNonNull(value, this.value);
+			return this;
+		}
+
+		private static <T> T firstNonNull(T first, T second) {
+			if (first != null) {
+				return first;
+			}
+			return second;
+		}
+	}
+
+	// --------------------------------------------------------------------------------------------------------
+	// Merge
+	// --------------------------------------------------------------------------------------------------------
+
+	static final class MergeResult<K, V> {
+		private final LinkedOptionalMap<K, V> merged;
+		private final Set<String> missingKeys;
+		private final boolean isOrderedSubset;
+
+		MergeResult(LinkedOptionalMap<K, V> merged, boolean isOrderedSubset) {
+			this.merged = merged;
+			this.missingKeys = merged.absentKeysOrValues();
+			this.isOrderedSubset = isOrderedSubset;
+		}
+
+		boolean hasMissingKeys() {
+			return !missingKeys.isEmpty();
+		}
+
+		Set<String> missingKeys() {
+			return missingKeys;
+		}
+
+		LinkedHashMap<K, V> getMerged() {
+			return merged.unwrapOptionals();
+		}
+
+		/**
+		 * returns {@code true} if keyNames present at @left, appearing in prefix order at @right.
+		 */
+		boolean isOrderedSubset() {
+			return isOrderedSubset;
+		}
+	}
+
+}
diff --git a/flink-core/src/test/java/org/apache/flink/api/common/typeutils/CompositeTypeSerializerUtilTest.java b/flink-core/src/test/java/org/apache/flink/api/common/typeutils/CompositeTypeSerializerUtilTest.java
new file mode 100644
index 0000000000000..1ae4b73a73ee8
--- /dev/null
+++ b/flink-core/src/test/java/org/apache/flink/api/common/typeutils/CompositeTypeSerializerUtilTest.java
@@ -0,0 +1,149 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.api.common.typeutils;
+
+import org.apache.flink.api.common.typeutils.CompositeTypeSerializerUtil.IntermediateCompatibilityResult;
+import org.apache.flink.testutils.migration.SchemaCompatibilityTestingSerializer;
+import org.junit.Test;
+
+import static org.junit.Assert.assertArrayEquals;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+
+/**
+ * Tests for the {@link CompositeTypeSerializerUtil}.
+ */
+public class CompositeTypeSerializerUtilTest {
+
+	// ------------------------------------------------------------------------------------------------
+	//  Tests for CompositeTypeSerializerUtil#constructIntermediateCompatibilityResult
+	// ------------------------------------------------------------------------------------------------
+
+	@Test
+	public void testCompatibleAsIsIntermediateCompatibilityResult() {
+		final TypeSerializerSnapshot<?>[] testSerializerSnapshots = new TypeSerializerSnapshot<?>[] {
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+		};
+
+		final TypeSerializer<?>[] testNewSerializers = new TypeSerializer<?>[] {
+			new SchemaCompatibilityTestingSerializer.InitialSerializer(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer(),
+		};
+
+		IntermediateCompatibilityResult<?> intermediateCompatibilityResult =
+			CompositeTypeSerializerUtil.constructIntermediateCompatibilityResult(testNewSerializers, testSerializerSnapshots);
+
+		assertTrue(intermediateCompatibilityResult.isCompatibleAsIs());
+		assertTrue(intermediateCompatibilityResult.getFinalResult().isCompatibleAsIs());
+		assertArrayEquals(testNewSerializers, intermediateCompatibilityResult.getNestedSerializers());
+	}
+
+	@Test
+	public void testCompatibleWithReconfiguredSerializerIntermediateCompatibilityResult() {
+		final TypeSerializerSnapshot<?>[] testSerializerSnapshots = new TypeSerializerSnapshot<?>[] {
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+		};
+
+		final TypeSerializer<?>[] testNewSerializers = new TypeSerializer<?>[] {
+			new SchemaCompatibilityTestingSerializer.InitialSerializer(),
+			new SchemaCompatibilityTestingSerializer.ReconfigurationRequiringSerializer<>(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer()
+		};
+
+		IntermediateCompatibilityResult<?> intermediateCompatibilityResult =
+			CompositeTypeSerializerUtil.constructIntermediateCompatibilityResult(testNewSerializers, testSerializerSnapshots);
+
+		assertTrue(intermediateCompatibilityResult.isCompatibleWithReconfiguredSerializer());
+		assertThatExceptionIsThrown(intermediateCompatibilityResult::getFinalResult);
+
+		final TypeSerializer<?>[] expectedReconfiguredNestedSerializers = new TypeSerializer<?>[] {
+			new SchemaCompatibilityTestingSerializer.InitialSerializer(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer()
+		};
+		assertArrayEquals(expectedReconfiguredNestedSerializers, intermediateCompatibilityResult.getNestedSerializers());
+	}
+
+	@Test
+	public void testCompatibleAfterMigrationIntermediateCompatibilityResult() {
+		final TypeSerializerSnapshot<?>[] testSerializerSnapshots = new TypeSerializerSnapshot<?>[] {
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+		};
+
+		final TypeSerializer<?>[] testNewSerializers = new TypeSerializer<?>[] {
+			new SchemaCompatibilityTestingSerializer.InitialSerializer(),
+			new SchemaCompatibilityTestingSerializer.ReconfigurationRequiringSerializer<>(),
+			new SchemaCompatibilityTestingSerializer.UpgradedSchemaSerializer<>(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer()
+		};
+
+		IntermediateCompatibilityResult<?> intermediateCompatibilityResult =
+			CompositeTypeSerializerUtil.constructIntermediateCompatibilityResult(testNewSerializers, testSerializerSnapshots);
+
+		assertTrue(intermediateCompatibilityResult.isCompatibleAfterMigration());
+		assertTrue(intermediateCompatibilityResult.getFinalResult().isCompatibleAfterMigration());
+		assertThatExceptionIsThrown(intermediateCompatibilityResult::getNestedSerializers);
+	}
+
+	@Test
+	public void testIncompatibleIntermediateCompatibilityResult() {
+		final TypeSerializerSnapshot<?>[] testSerializerSnapshots = new TypeSerializerSnapshot<?>[] {
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+			new SchemaCompatibilityTestingSerializer.InitialSerializer().snapshotConfiguration(),
+		};
+
+		final TypeSerializer<?>[] testNewSerializers = new TypeSerializer<?>[] {
+			new SchemaCompatibilityTestingSerializer.InitialSerializer(),
+			new SchemaCompatibilityTestingSerializer.IncompatibleSerializer<>(),
+			new SchemaCompatibilityTestingSerializer.ReconfigurationRequiringSerializer<>(),
+			new SchemaCompatibilityTestingSerializer.UpgradedSchemaSerializer()
+		};
+
+		IntermediateCompatibilityResult<?> intermediateCompatibilityResult =
+			CompositeTypeSerializerUtil.constructIntermediateCompatibilityResult(testNewSerializers, testSerializerSnapshots);
+
+		assertTrue(intermediateCompatibilityResult.isIncompatible());
+		assertTrue(intermediateCompatibilityResult.getFinalResult().isIncompatible());
+		assertThatExceptionIsThrown(intermediateCompatibilityResult::getNestedSerializers);
+	}
+
+	private void assertThatExceptionIsThrown(Runnable runnable) {
+		try {
+			runnable.run();
+			fail("exception should have been thrown.");
+		} catch (Exception e) {
+			// expected
+		}
+	}
+}
diff --git a/flink-core/src/test/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerSnapshotMigrationTest.java b/flink-core/src/test/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerSnapshotMigrationTest.java
new file mode 100644
index 0000000000000..5fb68857b1744
--- /dev/null
+++ b/flink-core/src/test/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerSnapshotMigrationTest.java
@@ -0,0 +1,78 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.api.java.typeutils.runtime;
+
+import org.apache.flink.api.common.ExecutionConfig;
+import org.apache.flink.api.common.typeutils.TypeSerializer;
+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshotMigrationTestBase;
+import org.apache.flink.api.java.typeutils.TypeExtractor;
+import org.apache.flink.testutils.migration.MigrationVersion;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
+
+import java.util.Collection;
+
+import static org.junit.Assert.assertTrue;
+
+/**
+ * Migration tests for the {@link PojoSerializerSnapshot}.
+ */
+@RunWith(Parameterized.class)
+public class PojoSerializerSnapshotMigrationTest extends TypeSerializerSnapshotMigrationTestBase<PojoSerializerSnapshotMigrationTest.TestPojo> {
+
+	public static class TestPojo {
+		public int id;
+		public String name;
+		public int age;
+
+		public TestPojo() {}
+
+		public TestPojo(int id, String name, int age) {
+			this.id = id;
+			this.name = name;
+			this.age = age;
+		}
+	}
+
+	public PojoSerializerSnapshotMigrationTest(
+		TestSpecification<TestPojo> testSpecification) {
+		super(testSpecification);
+	}
+
+	@SuppressWarnings("unchecked")
+	@Parameterized.Parameters(name = "Test Specification = {0}")
+	public static Collection<TestSpecification<?>> testSpecifications() {
+
+		final TestSpecifications testSpecifications = new TestSpecifications(MigrationVersion.v1_6, MigrationVersion.v1_7);
+
+		testSpecifications.add(
+			"pojo-serializer",
+			PojoSerializer.class,
+			PojoSerializerSnapshot.class,
+			PojoSerializerSnapshotMigrationTest::testPojoSerializerSupplier);
+
+		return testSpecifications.get();
+	}
+
+	private static TypeSerializer<TestPojo> testPojoSerializerSupplier() {
+		TypeSerializer<TestPojo> serializer = TypeExtractor.createTypeInfo(TestPojo.class).createSerializer(new ExecutionConfig());
+		assertTrue(serializer instanceof PojoSerializer);
+		return serializer;
+	}
+}
diff --git a/flink-core/src/test/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerSnapshotTest.java b/flink-core/src/test/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerSnapshotTest.java
new file mode 100644
index 0000000000000..15fa4d9fbfa00
--- /dev/null
+++ b/flink-core/src/test/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerSnapshotTest.java
@@ -0,0 +1,387 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.api.java.typeutils.runtime;
+
+import org.apache.flink.api.common.ExecutionConfig;
+import org.apache.flink.api.common.typeutils.TypeSerializer;
+import org.apache.flink.api.common.typeutils.TypeSerializerSchemaCompatibility;
+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;
+import org.apache.flink.api.common.typeutils.base.DoubleSerializer;
+import org.apache.flink.api.common.typeutils.base.IntSerializer;
+import org.apache.flink.api.common.typeutils.base.StringSerializer;
+import org.apache.flink.testutils.migration.SchemaCompatibilityTestingSerializer;
+import org.apache.flink.util.LinkedOptionalMap;
+
+import org.junit.Test;
+
+import java.lang.reflect.Field;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import static org.junit.Assert.assertArrayEquals;
+import static org.junit.Assert.assertTrue;
+
+/**
+ * Tests for the {@link PojoSerializerSnapshot}.
+ */
+public class PojoSerializerSnapshotTest {
+
+	public static class TestPojo {
+		public int id;
+		public String name;
+		public double height;
+
+		public TestPojo() {}
+
+		public TestPojo(int id, String name, double height) {
+			this.id = id;
+			this.name = name;
+			this.height = height;
+		}
+	}
+
+	private static class TestPojoField {
+		String name;
+		Field field;
+		TypeSerializer<?> serializer;
+		TypeSerializerSnapshot<?> serializerSnapshot;
+
+		TestPojoField(String name, TypeSerializer<?> serializer) throws Exception {
+			this.name = name;
+			this.field = TestPojo.class.getDeclaredField(name);
+			this.serializer = serializer;
+			this.serializerSnapshot = serializer.snapshotConfiguration();
+		}
+
+		TestPojoField(String name, Field field, TypeSerializerSnapshot<?> serializerSnapshot) {
+			this.name = name;
+			this.field = field;
+			this.serializerSnapshot = serializerSnapshot;
+		}
+
+		TestPojoField shallowCopy() {
+			return new TestPojoField(name, field, serializerSnapshot);
+		}
+	}
+
+	private final static Map<String, Field> FIELDS = new HashMap<>(3);
+	static {
+		try {
+			FIELDS.put("id", TestPojo.class.getDeclaredField("id"));
+			FIELDS.put("name", TestPojo.class.getDeclaredField("name"));
+			FIELDS.put("height", TestPojo.class.getDeclaredField("height"));
+		} catch (Exception e) {
+			throw new RuntimeException(e);
+		}
+	}
+
+	private static TestPojoField ID_FIELD;
+	private static TestPojoField NAME_FIELD;
+	private static TestPojoField HEIGHT_FIELD;
+	static {
+		try {
+			ID_FIELD = new TestPojoField("id", IntSerializer.INSTANCE);
+			NAME_FIELD = new TestPojoField("name", StringSerializer.INSTANCE);
+			HEIGHT_FIELD = new TestPojoField("height", DoubleSerializer.INSTANCE);
+		} catch (Exception e) {
+			throw new RuntimeException(e);
+		}
+	}
+	// ------------------------------------------------------------------------------------------------
+	//  Tests for PojoSerializerSnapshot#restoreSerializer
+	// ------------------------------------------------------------------------------------------------
+
+	@Test
+	public void testRestoreSerializerWithSameFields() {
+		final PojoSerializerSnapshot<TestPojo> testSnapshot = buildTestSnapshot(Arrays.asList(
+			ID_FIELD,
+			NAME_FIELD,
+			HEIGHT_FIELD
+		));
+
+		final TypeSerializer<TestPojo> restoredSerializer = testSnapshot.restoreSerializer();
+		assertTrue(restoredSerializer.getClass() == PojoSerializer.class);
+		final PojoSerializer<TestPojo> restoredPojoSerializer = (PojoSerializer<TestPojo>) restoredSerializer;
+
+		final Field[] restoredFields = restoredPojoSerializer.getFields();
+		assertArrayEquals(
+			new Field[] { ID_FIELD.field, NAME_FIELD.field, HEIGHT_FIELD.field },
+			restoredFields);
+
+		final TypeSerializer<?>[] restoredFieldSerializers = restoredPojoSerializer.getFieldSerializers();
+		assertArrayEquals(
+			new TypeSerializer[] { IntSerializer.INSTANCE, StringSerializer.INSTANCE, DoubleSerializer.INSTANCE },
+			restoredFieldSerializers);
+	}
+
+	@Test
+	public void testRestoreSerializerWithRemovedFields() {
+		final PojoSerializerSnapshot<TestPojo> testSnapshot = buildTestSnapshot(Arrays.asList(
+			mockRemovedField(ID_FIELD),
+			NAME_FIELD,
+			mockRemovedField(HEIGHT_FIELD)
+		));
+
+		final TypeSerializer<TestPojo> restoredSerializer = testSnapshot.restoreSerializer();
+		assertTrue(restoredSerializer.getClass() == PojoSerializer.class);
+		final PojoSerializer<TestPojo> restoredPojoSerializer = (PojoSerializer<TestPojo>) restoredSerializer;
+
+		final Field[] restoredFields = restoredPojoSerializer.getFields();
+		assertArrayEquals(
+			new Field[] { null, NAME_FIELD.field, null },
+			restoredFields);
+
+		final TypeSerializer<?>[] restoredFieldSerializers = restoredPojoSerializer.getFieldSerializers();
+		assertArrayEquals(
+			new TypeSerializer[] { IntSerializer.INSTANCE, StringSerializer.INSTANCE, DoubleSerializer.INSTANCE },
+			restoredFieldSerializers);
+	}
+
+	@Test
+	public void testRestoreSerializerWithNewFields() {
+		final PojoSerializerSnapshot<TestPojo> testSnapshot = buildTestSnapshot(Collections.singletonList(HEIGHT_FIELD));
+
+		final TypeSerializer<TestPojo> restoredSerializer = testSnapshot.restoreSerializer();
+		assertTrue(restoredSerializer.getClass() == PojoSerializer.class);
+		final PojoSerializer<TestPojo> restoredPojoSerializer = (PojoSerializer<TestPojo>) restoredSerializer;
+
+		final Field[] restoredFields = restoredPojoSerializer.getFields();
+		assertArrayEquals(
+			new Field[] { HEIGHT_FIELD.field },
+			restoredFields);
+
+		final TypeSerializer<?>[] restoredFieldSerializers = restoredPojoSerializer.getFieldSerializers();
+		assertArrayEquals(
+			new TypeSerializer[] { DoubleSerializer.INSTANCE },
+			restoredFieldSerializers);
+	}
+
+	// ------------------------------------------------------------------------------------------------
+	//  Tests for PojoSerializerSnapshot#resolveSchemaCompatibility
+	// ------------------------------------------------------------------------------------------------
+
+	@Test
+	public void testResolveSchemaCompatibilityWithSameFields() {
+		final PojoSerializerSnapshot<TestPojo> testSnapshot = buildTestSnapshot(Arrays.asList(
+			ID_FIELD,
+			NAME_FIELD,
+			HEIGHT_FIELD
+		));
+
+		final PojoSerializer<TestPojo> newPojoSerializer = buildTestNewPojoSerializer(Arrays.asList(
+			ID_FIELD,
+			NAME_FIELD,
+			HEIGHT_FIELD
+		));
+
+		final TypeSerializerSchemaCompatibility<TestPojo> resultCompatibility =
+			testSnapshot.resolveSchemaCompatibility(newPojoSerializer);
+
+		assertTrue(resultCompatibility.isCompatibleAsIs());
+	}
+
+	@Test
+	public void testResolveSchemaCompatibilityWithRemovedFields() {
+		final PojoSerializerSnapshot<TestPojo> testSnapshot = buildTestSnapshot(Arrays.asList(
+			mockRemovedField(ID_FIELD),
+			NAME_FIELD,
+			mockRemovedField(HEIGHT_FIELD)
+		));
+
+		final PojoSerializer<TestPojo> newPojoSerializer = buildTestNewPojoSerializer(Collections.singletonList(NAME_FIELD));
+
+		final TypeSerializerSchemaCompatibility<TestPojo> resultCompatibility =
+			testSnapshot.resolveSchemaCompatibility(newPojoSerializer);
+
+		assertTrue(resultCompatibility.isCompatibleAfterMigration());
+	}
+
+	@Test
+	public void testResolveSchemaCompatibilityWithNewFields() {
+		final PojoSerializerSnapshot<TestPojo> testSnapshot = buildTestSnapshot(Collections.singletonList(HEIGHT_FIELD));
+
+		final PojoSerializer<TestPojo> newPojoSerializer = buildTestNewPojoSerializer(Arrays.asList(
+			ID_FIELD,
+			NAME_FIELD,
+			HEIGHT_FIELD
+		));
+
+		final TypeSerializerSchemaCompatibility<TestPojo> resultCompatibility =
+			testSnapshot.resolveSchemaCompatibility(newPojoSerializer);
+
+		assertTrue(resultCompatibility.isCompatibleAfterMigration());
+	}
+
+	@Test
+	public void testResolveSchemaCompatibilityWithNewAndRemovedFields() {
+		final PojoSerializerSnapshot<TestPojo> testSnapshot = buildTestSnapshot(
+			Collections.singletonList(mockRemovedField(ID_FIELD)));
+
+		final PojoSerializer<TestPojo> newPojoSerializer = buildTestNewPojoSerializer(Arrays.asList(
+			NAME_FIELD,
+			HEIGHT_FIELD
+		));
+
+		final TypeSerializerSchemaCompatibility<TestPojo> resultCompatibility =
+			testSnapshot.resolveSchemaCompatibility(newPojoSerializer);
+
+		assertTrue(resultCompatibility.isCompatibleAfterMigration());
+	}
+
+	@Test
+	public void testResolveSchemaCompatibilityWithIncompatibleFieldSerializers() {
+		final PojoSerializerSnapshot<TestPojo> testSnapshot = buildTestSnapshot(Arrays.asList(
+			ID_FIELD,
+			mockFieldSerializerSnapshot(
+				NAME_FIELD,
+				new SchemaCompatibilityTestingSerializer.InitialSerializer<>().snapshotConfiguration()),
+			HEIGHT_FIELD
+		));
+
+		final PojoSerializer<TestPojo> newPojoSerializer = buildTestNewPojoSerializer(Arrays.asList(
+			ID_FIELD,
+			mockFieldSerializer(NAME_FIELD, new SchemaCompatibilityTestingSerializer.IncompatibleSerializer<>()),
+			HEIGHT_FIELD
+		));
+
+		final TypeSerializerSchemaCompatibility<TestPojo> resultCompatibility =
+			testSnapshot.resolveSchemaCompatibility(newPojoSerializer);
+
+		assertTrue(resultCompatibility.isIncompatible());
+	}
+
+	@Test
+	public void testResolveSchemaCompatibilityWithCompatibleAfterMigrationFieldSerializers() {
+		final PojoSerializerSnapshot<TestPojo> testSnapshot = buildTestSnapshot(Arrays.asList(
+			ID_FIELD,
+			NAME_FIELD,
+			mockFieldSerializerSnapshot(
+				HEIGHT_FIELD,
+				new SchemaCompatibilityTestingSerializer.InitialSerializer<>().snapshotConfiguration())
+		));
+
+		final PojoSerializer<TestPojo> newPojoSerializer = buildTestNewPojoSerializer(Arrays.asList(
+			ID_FIELD,
+			NAME_FIELD,
+			mockFieldSerializer(HEIGHT_FIELD, new SchemaCompatibilityTestingSerializer.UpgradedSchemaSerializer<>())
+		));
+
+		final TypeSerializerSchemaCompatibility<TestPojo> resultCompatibility =
+			testSnapshot.resolveSchemaCompatibility(newPojoSerializer);
+
+		assertTrue(resultCompatibility.isCompatibleAfterMigration());
+	}
+
+	@Test
+	public void testResolveSchemaCompatibilityWithCompatibleWithReconfigurationFieldSerializers() {
+		final PojoSerializerSnapshot<TestPojo> testSnapshot = buildTestSnapshot(Arrays.asList(
+			mockFieldSerializerSnapshot(
+				ID_FIELD,
+				new SchemaCompatibilityTestingSerializer.InitialSerializer<>().snapshotConfiguration()),
+			NAME_FIELD,
+			HEIGHT_FIELD
+		));
+
+		final PojoSerializer<TestPojo> newPojoSerializer = buildTestNewPojoSerializer(Arrays.asList(
+			mockFieldSerializer(ID_FIELD, new SchemaCompatibilityTestingSerializer.ReconfigurationRequiringSerializer<>()),
+			NAME_FIELD,
+			HEIGHT_FIELD
+		));
+
+		final TypeSerializerSchemaCompatibility<TestPojo> resultCompatibility =
+			testSnapshot.resolveSchemaCompatibility(newPojoSerializer);
+
+		assertTrue(resultCompatibility.isCompatibleWithReconfiguredSerializer());
+
+		final TypeSerializer<TestPojo> reconfiguredSerializer = resultCompatibility.getReconfiguredSerializer();
+		assertTrue(reconfiguredSerializer.getClass() == PojoSerializer.class);
+		final PojoSerializer<TestPojo> reconfiguredPojoSerializer = (PojoSerializer<TestPojo>) reconfiguredSerializer;
+
+		final TypeSerializer<?>[] reconfiguredFieldSerializers = reconfiguredPojoSerializer.getFieldSerializers();
+		assertArrayEquals(
+			new TypeSerializer[] {
+				new SchemaCompatibilityTestingSerializer.InitialSerializer(),
+				StringSerializer.INSTANCE,
+				DoubleSerializer.INSTANCE },
+			reconfiguredFieldSerializers);
+	}
+
+	// ------------------------------------------------------------------------------------------------
+	//  Test utilities
+	// ------------------------------------------------------------------------------------------------
+
+	private static PojoSerializerSnapshot<TestPojo> buildTestSnapshot(List<TestPojoField> fieldsToContainInSnapshot) {
+
+		LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> testFieldSerializerSnapshots = new LinkedOptionalMap<>();
+		fieldsToContainInSnapshot.forEach(
+			testPojoField ->
+				testFieldSerializerSnapshots.put(
+					testPojoField.name,
+					testPojoField.field,
+					testPojoField.serializerSnapshot)
+		);
+
+		return new PojoSerializerSnapshot<>(
+			PojoSerializerSnapshotData.createFrom(
+				TestPojo.class,
+				testFieldSerializerSnapshots,
+				new LinkedOptionalMap<>(),
+				new LinkedOptionalMap<>())
+		);
+	}
+
+	private static PojoSerializer<TestPojo> buildTestNewPojoSerializer(List<TestPojoField> fieldsForNewPojo) {
+		int numFields = fieldsForNewPojo.size();
+
+		final ArrayList<Field> fields = new ArrayList<>(numFields);
+		final ArrayList<TypeSerializer<?>> fieldSerializers = new ArrayList<>(numFields);
+		fieldsForNewPojo.forEach(fieldForNewPojo -> {
+			fields.add(fieldForNewPojo.field);
+			fieldSerializers.add(fieldForNewPojo.serializer);
+		});
+
+		return new PojoSerializer<>(
+			TestPojo.class,
+			fieldSerializers.toArray(new TypeSerializer[numFields]),
+			fields.toArray(new Field[numFields]),
+			new ExecutionConfig());
+	}
+
+	private static TestPojoField mockRemovedField(TestPojoField original) {
+		TestPojoField copy = original.shallowCopy();
+		copy.field = null;
+		return copy;
+	}
+
+	private static TestPojoField mockFieldSerializer(TestPojoField original, TypeSerializer<?> mockSerializer) {
+		TestPojoField copy = original.shallowCopy();
+		copy.serializer = mockSerializer;
+		return copy;
+	}
+
+	private static TestPojoField mockFieldSerializerSnapshot(TestPojoField original, TypeSerializerSnapshot<?> mockSnapshot) {
+		TestPojoField copy = original.shallowCopy();
+		copy.serializerSnapshot = mockSnapshot;
+		return copy;
+	}
+}
diff --git a/flink-core/src/test/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerTest.java b/flink-core/src/test/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerTest.java
index ef66403c2a727..a45508d73b3d0 100644
--- a/flink-core/src/test/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerTest.java
+++ b/flink-core/src/test/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializerTest.java
@@ -29,9 +29,7 @@
 import org.apache.flink.api.common.typeutils.TypeSerializerSchemaCompatibility;
 import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;
 import org.apache.flink.api.common.typeutils.TypeSerializerSnapshotSerializationUtil;
-import org.apache.flink.api.common.typeutils.UnloadableDummyTypeSerializer;
 import org.apache.flink.api.java.tuple.Tuple1;
-import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.api.java.tuple.Tuple3;
 import org.apache.flink.api.java.typeutils.PojoTypeInfo;
 import org.apache.flink.api.java.typeutils.TupleTypeInfo;
@@ -43,13 +41,9 @@
 
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
-import java.lang.reflect.Field;
 import java.util.ArrayList;
 import java.util.Date;
-import java.util.HashMap;
-import java.util.LinkedHashMap;
 import java.util.List;
-import java.util.Map;
 import java.util.Objects;
 import java.util.Random;
 
@@ -347,12 +341,14 @@ public void testReconfigureDifferentSubclassRegistrationOrder() throws Exception
 		@SuppressWarnings("unchecked")
 		TypeSerializerSchemaCompatibility<TestUserClass> compatResult =
 			pojoSerializerConfigSnapshot.resolveSchemaCompatibility(pojoSerializer);
-		assertTrue(compatResult.isCompatibleAsIs());
+		assertTrue(compatResult.isCompatibleWithReconfiguredSerializer());
+		assertTrue(compatResult.getReconfiguredSerializer() instanceof PojoSerializer);
 
 		// reconfigure - check reconfiguration result and that registration ids remains the same
 		//assertEquals(ReconfigureResult.COMPATIBLE, pojoSerializer.reconfigure(pojoSerializerConfigSnapshot));
-		assertEquals(subClassATag, pojoSerializer.getRegisteredClasses().get(SubTestUserClassA.class).intValue());
-		assertEquals(subClassBTag, pojoSerializer.getRegisteredClasses().get(SubTestUserClassB.class).intValue());
+		PojoSerializer<TestUserClass> reconfiguredPojoSerializer = (PojoSerializer<TestUserClass>) compatResult.getReconfiguredSerializer();
+		assertEquals(subClassATag, reconfiguredPojoSerializer.getRegisteredClasses().get(SubTestUserClassA.class).intValue());
+		assertEquals(subClassBTag, reconfiguredPojoSerializer.getRegisteredClasses().get(SubTestUserClassB.class).intValue());
 	}
 
 	/**
@@ -394,10 +390,13 @@ public void testReconfigureRepopulateNonregisteredSubclassSerializerCache() thro
 		@SuppressWarnings("unchecked")
 		TypeSerializerSchemaCompatibility<TestUserClass> compatResult =
 			pojoSerializerConfigSnapshot.resolveSchemaCompatibility(pojoSerializer);
-		assertTrue(compatResult.isCompatibleAsIs());
-		assertEquals(2, pojoSerializer.getSubclassSerializerCache().size());
-		assertTrue(pojoSerializer.getSubclassSerializerCache().containsKey(SubTestUserClassA.class));
-		assertTrue(pojoSerializer.getSubclassSerializerCache().containsKey(SubTestUserClassB.class));
+		assertTrue(compatResult.isCompatibleWithReconfiguredSerializer());
+		assertTrue(compatResult.getReconfiguredSerializer() instanceof PojoSerializer);
+
+		PojoSerializer<TestUserClass> reconfiguredPojoSerializer = (PojoSerializer<TestUserClass>) compatResult.getReconfiguredSerializer();
+		assertEquals(2, reconfiguredPojoSerializer.getSubclassSerializerCache().size());
+		assertTrue(reconfiguredPojoSerializer.getSubclassSerializerCache().containsKey(SubTestUserClassA.class));
+		assertTrue(reconfiguredPojoSerializer.getSubclassSerializerCache().containsKey(SubTestUserClassB.class));
 	}
 
 	/**
@@ -459,127 +458,15 @@ public void testReconfigureWithPreviouslyNonregisteredSubclasses() throws Except
 		@SuppressWarnings("unchecked")
 		TypeSerializerSchemaCompatibility<TestUserClass> compatResult =
 			pojoSerializerConfigSnapshot.resolveSchemaCompatibility(pojoSerializer);
-		assertTrue(compatResult.isCompatibleAsIs());
-		assertEquals(2, pojoSerializer.getSubclassSerializerCache().size());
-		assertTrue(pojoSerializer.getSubclassSerializerCache().containsKey(SubTestUserClassA.class));
-		assertTrue(pojoSerializer.getSubclassSerializerCache().containsKey(SubTestUserClassB.class));
-		assertEquals(2, pojoSerializer.getRegisteredClasses().size());
-		assertTrue(pojoSerializer.getRegisteredClasses().containsKey(SubTestUserClassA.class));
-		assertTrue(pojoSerializer.getRegisteredClasses().containsKey(SubTestUserClassB.class));
-	}
-
-	/**
-	 * Verifies that reconfiguration reorders the fields of the new Pojo serializer to remain the same.
-	 */
-	@Test
-	public void testReconfigureWithDifferentFieldOrder() throws Exception {
-		Field[] mockOriginalFieldOrder = {
-			TestUserClass.class.getField("dumm4"),
-			TestUserClass.class.getField("dumm3"),
-			TestUserClass.class.getField("nestedClass"),
-			TestUserClass.class.getField("dumm1"),
-			TestUserClass.class.getField("dumm2"),
-			TestUserClass.class.getField("dumm5"),
-		};
-
-		// creating this serializer just for generating config snapshots of the field serializers
-		PojoSerializer<TestUserClass> ser = (PojoSerializer<TestUserClass>) type.createSerializer(new ExecutionConfig());
-
-		LinkedHashMap<String, Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> mockOriginalFieldToSerializerConfigSnapshot =
-			new LinkedHashMap<>(mockOriginalFieldOrder.length);
-		mockOriginalFieldToSerializerConfigSnapshot.put(
-			mockOriginalFieldOrder[0].getName(),
-			new Tuple2<>(
-				ser.getFieldSerializers()[3],
-				ser.getFieldSerializers()[3].snapshotConfiguration()));
-		mockOriginalFieldToSerializerConfigSnapshot.put(
-			mockOriginalFieldOrder[1].getName(),
-			new Tuple2<>(
-				ser.getFieldSerializers()[2],
-				ser.getFieldSerializers()[2].snapshotConfiguration()));
-		mockOriginalFieldToSerializerConfigSnapshot.put(
-			mockOriginalFieldOrder[2].getName(),
-			new Tuple2<>(
-				ser.getFieldSerializers()[5],
-				ser.getFieldSerializers()[5].snapshotConfiguration()));
-		mockOriginalFieldToSerializerConfigSnapshot.put(
-			mockOriginalFieldOrder[3].getName(),
-			new Tuple2<>(
-				ser.getFieldSerializers()[0],
-				ser.getFieldSerializers()[0].snapshotConfiguration()));
-		mockOriginalFieldToSerializerConfigSnapshot.put(
-			mockOriginalFieldOrder[4].getName(),
-			new Tuple2<>(
-				ser.getFieldSerializers()[1],
-				ser.getFieldSerializers()[1].snapshotConfiguration()));
-		mockOriginalFieldToSerializerConfigSnapshot.put(
-			mockOriginalFieldOrder[5].getName(),
-			new Tuple2<>(
-				ser.getFieldSerializers()[4],
-				ser.getFieldSerializers()[4].snapshotConfiguration()));
-
-		PojoSerializer<TestUserClass> pojoSerializer = (PojoSerializer<TestUserClass>) type.createSerializer(new ExecutionConfig());
-
-		assertEquals(TestUserClass.class.getField("dumm1"), pojoSerializer.getFields()[0]);
-		assertEquals(TestUserClass.class.getField("dumm2"), pojoSerializer.getFields()[1]);
-		assertEquals(TestUserClass.class.getField("dumm3"), pojoSerializer.getFields()[2]);
-		assertEquals(TestUserClass.class.getField("dumm4"), pojoSerializer.getFields()[3]);
-		assertEquals(TestUserClass.class.getField("dumm5"), pojoSerializer.getFields()[4]);
-		assertEquals(TestUserClass.class.getField("nestedClass"), pojoSerializer.getFields()[5]);
-
-		PojoSerializer.PojoSerializerConfigSnapshot<TestUserClass> mockPreviousConfigSnapshot =
-			new PojoSerializer.PojoSerializerConfigSnapshot<>(
-				TestUserClass.class,
-				mockOriginalFieldToSerializerConfigSnapshot, // this mocks the previous field order
-				new LinkedHashMap<>(), // empty; irrelevant for this test
-				new HashMap<>()); // empty; irrelevant for this test
-
-		// reconfigure - check reconfiguration result and that fields are reordered to the previous order
-		TypeSerializerSchemaCompatibility<TestUserClass> compatResult =
-			mockPreviousConfigSnapshot.resolveSchemaCompatibility(pojoSerializer);
-		assertTrue(compatResult.isCompatibleAsIs());
-		int i = 0;
-		for (Field field : mockOriginalFieldOrder) {
-			assertEquals(field, pojoSerializer.getFields()[i]);
-			i++;
-		}
-	}
-
-	private static void verifyPojoSerializerConfigSnapshotWithSerializerSerializationFailure(
-			PojoSerializer.PojoSerializerConfigSnapshot<?> original,
-			PojoSerializer.PojoSerializerConfigSnapshot<?> deserializedConfig) {
-
-		LinkedHashMap<String, Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> originalFieldSerializersAndConfs =
-				original.getFieldToSerializerConfigSnapshot();
-		for (Map.Entry<String, Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> entry
-				: deserializedConfig.getFieldToSerializerConfigSnapshot().entrySet()) {
-
-			Assert.assertTrue(entry.getValue().f0 instanceof UnloadableDummyTypeSerializer);
-
-			if (entry.getValue().f1 instanceof PojoSerializer.PojoSerializerConfigSnapshot) {
-				verifyPojoSerializerConfigSnapshotWithSerializerSerializationFailure(
-					(PojoSerializer.PojoSerializerConfigSnapshot<?>) originalFieldSerializersAndConfs.get(entry.getKey()).f1,
-					(PojoSerializer.PojoSerializerConfigSnapshot<?>) entry.getValue().f1);
-			} else {
-				Assert.assertEquals(originalFieldSerializersAndConfs.get(entry.getKey()).f1, entry.getValue().f1);
-			}
-		}
-
-		LinkedHashMap<Class<?>, Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> originalRegistrations =
-				original.getRegisteredSubclassesToSerializerConfigSnapshots();
-
-		for (Map.Entry<Class<?>, Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> entry
-				: deserializedConfig.getRegisteredSubclassesToSerializerConfigSnapshots().entrySet()) {
-
-			Assert.assertTrue(entry.getValue().f0 instanceof UnloadableDummyTypeSerializer);
-
-			if (entry.getValue().f1 instanceof PojoSerializer.PojoSerializerConfigSnapshot) {
-				verifyPojoSerializerConfigSnapshotWithSerializerSerializationFailure(
-					(PojoSerializer.PojoSerializerConfigSnapshot<?>) originalRegistrations.get(entry.getKey()).f1,
-					(PojoSerializer.PojoSerializerConfigSnapshot<?>) entry.getValue().f1);
-			} else {
-				Assert.assertEquals(originalRegistrations.get(entry.getKey()).f1, entry.getValue().f1);
-			}
-		}
+		assertTrue(compatResult.isCompatibleWithReconfiguredSerializer());
+		assertTrue(compatResult.getReconfiguredSerializer() instanceof PojoSerializer);
+
+		PojoSerializer<TestUserClass> reconfiguredPojoSerializer = (PojoSerializer<TestUserClass>) compatResult.getReconfiguredSerializer();
+		assertEquals(2, reconfiguredPojoSerializer.getSubclassSerializerCache().size());
+		assertTrue(reconfiguredPojoSerializer.getSubclassSerializerCache().containsKey(SubTestUserClassA.class));
+		assertTrue(reconfiguredPojoSerializer.getSubclassSerializerCache().containsKey(SubTestUserClassB.class));
+		assertEquals(2, reconfiguredPojoSerializer.getRegisteredClasses().size());
+		assertTrue(reconfiguredPojoSerializer.getRegisteredClasses().containsKey(SubTestUserClassA.class));
+		assertTrue(reconfiguredPojoSerializer.getRegisteredClasses().containsKey(SubTestUserClassB.class));
 	}
 }
diff --git a/flink-core/src/test/java/org/apache/flink/testutils/migration/SchemaCompatibilityTestingSerializer.java b/flink-core/src/test/java/org/apache/flink/testutils/migration/SchemaCompatibilityTestingSerializer.java
new file mode 100644
index 0000000000000..253eed752cd68
--- /dev/null
+++ b/flink-core/src/test/java/org/apache/flink/testutils/migration/SchemaCompatibilityTestingSerializer.java
@@ -0,0 +1,296 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.testutils.migration;
+
+import org.apache.flink.api.common.typeutils.TypeSerializer;
+import org.apache.flink.api.common.typeutils.TypeSerializerSchemaCompatibility;
+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;
+import org.apache.flink.core.memory.DataInputView;
+import org.apache.flink.core.memory.DataOutputView;
+
+import java.io.IOException;
+
+/**
+ * The {@link SchemaCompatibilityTestingSerializer} is a mock serializer that can be used
+ * for schema compatibility and serializer upgrade related tests.
+ *
+ * <p>To use this, tests should always first instantiate an {@link InitialSerializer} serializer
+ * instance and then take a snapshot of it. Next, depending on what the new serializer is provided
+ * to the taken snapshot, tests can expect the following compatibility results:
+ * <ul>
+ *     <li>{@link InitialSerializer} as the new serializer: the compatibility result will be
+ *         {@link TypeSerializerSchemaCompatibility#compatibleAsIs()}.</li>
+ *     <li>{@link UpgradedSchemaSerializer} as the new serializer: the compatibility result will be
+ *         {@link TypeSerializerSchemaCompatibility#compatibleAfterMigration()}.</li>
+ *     <li>{@link ReconfigurationRequiringSerializer} as the new serializer: the compatibility result
+ *         will be {@link TypeSerializerSchemaCompatibility#compatibleWithReconfiguredSerializer(TypeSerializer)},
+ *         with a new instance of the {@link InitialSerializer} as the wrapped reconfigured serializer.</li>
+ *     <li>{@link IncompatibleSerializer} as the new serializer: the compatibility result will be
+ *         {@link TypeSerializerSchemaCompatibility#incompatible()}.</li>
+ * </ul>
+ */
+public abstract class SchemaCompatibilityTestingSerializer<T> extends TypeSerializer<T> {
+
+	private static final long serialVersionUID = 1L;
+
+	// ------------------------------------------------------------------------------------------------
+	//  Irrelevant serializer methods
+	// ------------------------------------------------------------------------------------------------
+
+	@Override
+	public TypeSerializer<T> duplicate() {
+		throw new UnsupportedOperationException(
+			"this is a SchemaCompatibilityTestingSerializer; should have only been used for snapshotting / compatibility test purposes.");
+	}
+
+	@Override
+	public void serialize(T record, DataOutputView target) throws IOException {
+		throw new UnsupportedOperationException(
+			"this is a SchemaCompatibilityTestingSerializer; should have only been used for snapshotting / compatibility test purposes.");
+
+	}
+
+	@Override
+	public T deserialize(T reuse, DataInputView source) throws IOException {
+		throw new UnsupportedOperationException(
+			"this is a SchemaCompatibilityTestingSerializer; should have only been used for snapshotting / compatibility test purposes.");
+
+	}
+
+	@Override
+	public T deserialize(DataInputView source) throws IOException {
+		throw new UnsupportedOperationException(
+			"this is a SchemaCompatibilityTestingSerializer; should have only been used for snapshotting / compatibility test purposes.");
+
+	}
+
+	@Override
+	public void copy(DataInputView source, DataOutputView target) throws IOException {
+		throw new UnsupportedOperationException(
+			"this is a SchemaCompatibilityTestingSerializer; should have only been used for snapshotting / compatibility test purposes.");
+
+	}
+
+	@Override
+	public T copy(T from) {
+		throw new UnsupportedOperationException(
+			"this is a SchemaCompatibilityTestingSerializer; should have only been used for snapshotting / compatibility test purposes.");
+
+	}
+
+	@Override
+	public T copy(T from, T reuse) {
+		throw new UnsupportedOperationException(
+			"this is a SchemaCompatibilityTestingSerializer; should have only been used for snapshotting / compatibility test purposes.");
+
+	}
+
+	@Override
+	public T createInstance() {
+		throw new UnsupportedOperationException(
+			"this is a SchemaCompatibilityTestingSerializer; should have only been used for snapshotting / compatibility test purposes.");
+
+	}
+
+	@Override
+	public boolean isImmutableType() {
+		throw new UnsupportedOperationException(
+			"this is a SchemaCompatibilityTestingSerializer; should have only been used for snapshotting / compatibility test purposes.");
+
+	}
+
+	@Override
+	public int getLength() {
+		throw new UnsupportedOperationException(
+			"this is a SchemaCompatibilityTestingSerializer; should have only been used for snapshotting / compatibility test purposes.");
+
+	}
+
+	// ------------------------------------------------------------------------------------------------
+	//  Test serializer variants
+	// ------------------------------------------------------------------------------------------------
+
+	public static class InitialSerializer<T> extends SchemaCompatibilityTestingSerializer<T> {
+
+		private static final long serialVersionUID = 1L;
+
+		@Override
+		public TypeSerializerSnapshot<T> snapshotConfiguration() {
+			return new InitialSerializerSnapshot();
+		}
+
+		@Override
+		public boolean equals(Object obj) {
+			return obj != null && obj.getClass() == InitialSerializer.class;
+		}
+
+		@Override
+		public int hashCode() {
+			return getClass().hashCode();
+		}
+	}
+
+	public static class UpgradedSchemaSerializer<T> extends SchemaCompatibilityTestingSerializer<T> {
+
+		private static final long serialVersionUID = 1L;
+
+		@Override
+		public TypeSerializerSnapshot<T> snapshotConfiguration() {
+			return new UpgradedSchemaSerializerSnapshot();
+		}
+
+		@Override
+		public boolean equals(Object obj) {
+			return obj != null && obj.getClass() == UpgradedSchemaSerializer.class;
+		}
+
+		@Override
+		public int hashCode() {
+			return getClass().hashCode();
+		}
+	}
+
+	public static class ReconfigurationRequiringSerializer<T> extends SchemaCompatibilityTestingSerializer<T> {
+
+		private static final long serialVersionUID = 1L;
+
+		@Override
+		public TypeSerializerSnapshot<T> snapshotConfiguration() {
+			throw new UnsupportedOperationException(
+				"this is a ReconfigurationRequiringSerializer; should not have been snapshotted.");
+		}
+
+		@Override
+		public boolean equals(Object obj) {
+			return obj != null && obj.getClass() == ReconfigurationRequiringSerializer.class;
+		}
+
+		@Override
+		public int hashCode() {
+			return getClass().hashCode();
+		}
+	}
+
+	public static class IncompatibleSerializer<T> extends SchemaCompatibilityTestingSerializer<T> {
+
+		private static final long serialVersionUID = 1L;
+
+		@Override
+		public TypeSerializerSnapshot<T> snapshotConfiguration() {
+			throw new UnsupportedOperationException(
+				"this is a IncompatibleSerializer; should not have been snapshotted.");
+		}
+
+		@Override
+		public boolean equals(Object obj) {
+			return obj != null && obj.getClass() == IncompatibleSerializer.class;
+		}
+
+		@Override
+		public int hashCode() {
+			return getClass().hashCode();
+		}
+	}
+
+	// ------------------------------------------------------------------------------------------------
+	//  Test serializer snapshots
+	// ------------------------------------------------------------------------------------------------
+
+	public class InitialSerializerSnapshot implements TypeSerializerSnapshot<T> {
+
+		@Override
+		public int getCurrentVersion() {
+			return 1;
+		}
+
+		@Override
+		public void writeSnapshot(DataOutputView out) throws IOException {}
+
+		@Override
+		public void readSnapshot(int readVersion, DataInputView in, ClassLoader userCodeClassLoader) throws IOException {}
+
+		@Override
+		public TypeSerializer<T> restoreSerializer() {
+			return new SchemaCompatibilityTestingSerializer.InitialSerializer<>();
+		}
+
+		@Override
+		public TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(TypeSerializer<T> newSerializer) {
+			if (newSerializer instanceof SchemaCompatibilityTestingSerializer.InitialSerializer) {
+				return TypeSerializerSchemaCompatibility.compatibleAsIs();
+			}
+
+			if (newSerializer instanceof SchemaCompatibilityTestingSerializer.UpgradedSchemaSerializer) {
+				return TypeSerializerSchemaCompatibility.compatibleAfterMigration();
+			}
+
+			if (newSerializer instanceof SchemaCompatibilityTestingSerializer.ReconfigurationRequiringSerializer) {
+				return TypeSerializerSchemaCompatibility.compatibleWithReconfiguredSerializer(new SchemaCompatibilityTestingSerializer.InitialSerializer<T>());
+			}
+
+			if (newSerializer instanceof SchemaCompatibilityTestingSerializer.IncompatibleSerializer) {
+				return TypeSerializerSchemaCompatibility.incompatible();
+			}
+
+			// reaches here if newSerializer isn't a SchemaCompatibilityTestingSerializer
+			return TypeSerializerSchemaCompatibility.incompatible();
+		}
+	}
+
+	public class UpgradedSchemaSerializerSnapshot implements TypeSerializerSnapshot<T> {
+
+		@Override
+		public int getCurrentVersion() {
+			return 1;
+		}
+
+		@Override
+		public void writeSnapshot(DataOutputView out) throws IOException {}
+
+		@Override
+		public void readSnapshot(int readVersion, DataInputView in, ClassLoader userCodeClassLoader) throws IOException {}
+
+		@Override
+		public TypeSerializer<T> restoreSerializer() {
+			return new SchemaCompatibilityTestingSerializer.UpgradedSchemaSerializer<>();
+		}
+
+		@Override
+		public TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(TypeSerializer<T> newSerializer) {
+			if (newSerializer instanceof SchemaCompatibilityTestingSerializer.InitialSerializer) {
+				return TypeSerializerSchemaCompatibility.incompatible();
+			}
+
+			if (newSerializer instanceof SchemaCompatibilityTestingSerializer.UpgradedSchemaSerializer) {
+				return TypeSerializerSchemaCompatibility.compatibleAsIs();
+			}
+
+			if (newSerializer instanceof SchemaCompatibilityTestingSerializer.ReconfigurationRequiringSerializer) {
+				return TypeSerializerSchemaCompatibility.compatibleWithReconfiguredSerializer(new SchemaCompatibilityTestingSerializer.UpgradedSchemaSerializer<T>());
+			}
+
+			if (newSerializer instanceof SchemaCompatibilityTestingSerializer.IncompatibleSerializer) {
+				return TypeSerializerSchemaCompatibility.incompatible();
+			}
+
+			// reaches here if newSerializer isn't a SchemaCompatibilityTestingSerializer
+			return TypeSerializerSchemaCompatibility.incompatible();
+		}
+	}
+}
diff --git a/flink-core/src/test/java/org/apache/flink/util/LinkedOptionalMapTest.java b/flink-core/src/test/java/org/apache/flink/util/LinkedOptionalMapTest.java
new file mode 100644
index 0000000000000..a12bf6cc1b738
--- /dev/null
+++ b/flink-core/src/test/java/org/apache/flink/util/LinkedOptionalMapTest.java
@@ -0,0 +1,214 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.util;
+
+import org.apache.flink.util.LinkedOptionalMap.MergeResult;
+
+import org.junit.Test;
+
+import java.util.LinkedHashMap;
+
+import static org.hamcrest.Matchers.contains;
+import static org.hamcrest.Matchers.empty;
+import static org.hamcrest.Matchers.hasItem;
+import static org.hamcrest.Matchers.hasItems;
+import static org.hamcrest.Matchers.is;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertThat;
+import static org.junit.Assert.assertTrue;
+
+/**
+ * Test {@link LinkedOptionalMap}.
+ */
+public class LinkedOptionalMapTest {
+
+	@Test
+	public void usageExample() {
+		LinkedOptionalMap<Class<?>, String> map = new LinkedOptionalMap<>();
+
+		map.put("java.lang.String", String.class, "a string class");
+		map.put("scala.Option", null, "a scala Option");
+		map.put("java.lang.Boolean", Boolean.class, null);
+
+		assertThat(map.keyNames(), hasItems("java.lang.String", "scala.Option"));
+		assertThat(map.absentKeysOrValues(), hasItems("scala.Option", "java.lang.Boolean"));
+	}
+
+	@Test
+	public void overridingKeyWithTheSameKeyName() {
+		LinkedOptionalMap<Class<?>, String> map = new LinkedOptionalMap<>();
+
+		map.put("java.lang.String", null, "a string class");
+		map.put("java.lang.String", String.class, "a string class");
+
+		assertThat(map.absentKeysOrValues(), is(empty()));
+	}
+
+	@Test
+	public void overridingKeysAndValuesWithTheSameKeyName() {
+		LinkedOptionalMap<Class<?>, String> map = new LinkedOptionalMap<>();
+
+		map.put("java.lang.String", null, null);
+		map.put("java.lang.String", String.class, "a string class");
+
+		assertThat(map.absentKeysOrValues(), is(empty()));
+	}
+
+	@Test
+	public void overridingAValueWithMissingKeyShouldBeConsideredAsAbsent() {
+		LinkedOptionalMap<Class<?>, String> map = new LinkedOptionalMap<>();
+
+		map.put("java.lang.String", null, null);
+		map.put("java.lang.String", null, "a string class");
+
+		assertThat(map.absentKeysOrValues(), hasItem("java.lang.String"));
+	}
+
+	@Test
+	public void mergingMapsWithPresentEntriesLeavesNoAbsentKeyNames() {
+		LinkedOptionalMap<Class<?>, String> first = new LinkedOptionalMap<>();
+		first.put("b", null, null);
+		first.put("c", String.class, null);
+
+		LinkedOptionalMap<Class<?>, String> second = new LinkedOptionalMap<>();
+		second.put("a", String.class, "aaa");
+		second.put("b", String.class, "bbb");
+		second.put("c", Void.class, "ccc");
+		second.put("d", String.class, "ddd");
+
+		first.putAll(second);
+
+		assertThat(first.absentKeysOrValues(), is(empty()));
+	}
+
+	@Test
+	public void mergingMapsPreserversTheOrderOfTheOriginalMap() {
+		LinkedOptionalMap<Class<?>, String> first = new LinkedOptionalMap<>();
+		first.put("b", null, null);
+		first.put("c", String.class, null);
+
+		LinkedOptionalMap<Class<?>, String> second = new LinkedOptionalMap<>();
+		second.put("a", String.class, "aaa");
+		second.put("b", String.class, "bbb");
+		second.put("c", Void.class, "ccc");
+		second.put("d", String.class, "ddd");
+
+		first.putAll(second);
+
+		assertThat(first.keyNames(), contains("b", "c", "a", "d"));
+	}
+
+	@Test
+	public void mergingToEmpty() {
+		LinkedOptionalMap<Class<?>, String> first = new LinkedOptionalMap<>();
+
+		LinkedOptionalMap<Class<?>, String> second = new LinkedOptionalMap<>();
+		second.put("a", String.class, "aaa");
+		second.put("b", String.class, "bbb");
+		second.put("c", Void.class, "ccc");
+		second.put("d", String.class, "ddd");
+
+		first.putAll(second);
+
+		assertThat(first.keyNames(), contains("a", "b", "c", "d"));
+	}
+
+	@Test(expected = IllegalStateException.class)
+	public void unwrapOptionalsWithMissingValueThrows() {
+		LinkedOptionalMap<Class<?>, String> map = new LinkedOptionalMap<>();
+
+		map.put("a", String.class, null);
+
+		map.unwrapOptionals();
+	}
+
+	@Test(expected = IllegalStateException.class)
+	public void unwrapOptionalsWithMissingKeyThrows() {
+		LinkedOptionalMap<Class<?>, String> map = new LinkedOptionalMap<>();
+
+		map.put("a", null, "blabla");
+
+		map.unwrapOptionals();
+	}
+
+	@Test
+	public void unwrapOptionalsPreservesOrder() {
+		LinkedOptionalMap<Class<?>, String> map = new LinkedOptionalMap<>();
+
+		map.put("a", String.class, "aaa");
+		map.put("b", Boolean.class, "bbb");
+
+		LinkedHashMap<Class<?>, String> m = map.unwrapOptionals();
+
+		assertThat(m.keySet(), contains(String.class, Boolean.class));
+		assertThat(m.values(), contains("aaa", "bbb"));
+	}
+
+	@Test
+	public void testPrefix() {
+		LinkedOptionalMap<Class<?>, String> left = new LinkedOptionalMap<>();
+
+		left.put("a", String.class, "aaa");
+		left.put("b", String.class, "aaa");
+
+		LinkedOptionalMap<Class<?>, String> right = new LinkedOptionalMap<>(left);
+
+		right.put("c", Boolean.class, "bbb");
+
+		assertTrue(LinkedOptionalMap.isLeftPrefixOfRight(left, right));
+	}
+
+	@Test
+	public void testNonPrefix() {
+		LinkedOptionalMap<Class<?>, String> left = new LinkedOptionalMap<>();
+
+		left.put("a", String.class, "aaa");
+		left.put("c", String.class, "aaa");
+
+		LinkedOptionalMap<Class<?>, String> right = new LinkedOptionalMap<>();
+
+		right.put("b", Boolean.class, "bbb");
+		right.put("c", Boolean.class, "bbb");
+
+		assertFalse(LinkedOptionalMap.isLeftPrefixOfRight(left, right));
+	}
+
+	@Test
+	@SuppressWarnings("unchecked")
+	public void demoMergeResult() {
+		LinkedOptionalMap<Class<?>, String> left = new LinkedOptionalMap<>();
+		left.put("b", null, null);
+		left.put("c", String.class, null);
+
+		LinkedOptionalMap<Class<?>, String> right = new LinkedOptionalMap<>();
+		right.put("b", String.class, "bbb");
+		right.put("c", Void.class, "ccc");
+		right.put("a", Boolean.class, "aaa");
+		right.put("d", Long.class, "ddd");
+
+		MergeResult<Class<?>, String> result = LinkedOptionalMap.mergeRightIntoLeft(left, right);
+
+		assertThat(result.hasMissingKeys(), is(false));
+		assertThat(result.isOrderedSubset(), is(true));
+		assertThat(result.missingKeys(), is(empty()));
+
+		LinkedHashMap<Class<?>, String> merged = result.getMerged();
+		assertThat(merged.keySet(), contains(String.class, Void.class, Boolean.class, Long.class));
+	}
+}
diff --git a/flink-core/src/test/resources/flink-1.6-pojo-serializer-data b/flink-core/src/test/resources/flink-1.6-pojo-serializer-data
new file mode 100644
index 0000000000000..153528f97a073
Binary files /dev/null and b/flink-core/src/test/resources/flink-1.6-pojo-serializer-data differ
diff --git a/flink-core/src/test/resources/flink-1.6-pojo-serializer-snapshot b/flink-core/src/test/resources/flink-1.6-pojo-serializer-snapshot
new file mode 100644
index 0000000000000..4d53f6c7080ae
Binary files /dev/null and b/flink-core/src/test/resources/flink-1.6-pojo-serializer-snapshot differ
diff --git a/flink-core/src/test/resources/flink-1.7-pojo-serializer-data b/flink-core/src/test/resources/flink-1.7-pojo-serializer-data
new file mode 100644
index 0000000000000..153528f97a073
Binary files /dev/null and b/flink-core/src/test/resources/flink-1.7-pojo-serializer-data differ
diff --git a/flink-core/src/test/resources/flink-1.7-pojo-serializer-snapshot b/flink-core/src/test/resources/flink-1.7-pojo-serializer-snapshot
new file mode 100644
index 0000000000000..4f5c92894fcda
Binary files /dev/null and b/flink-core/src/test/resources/flink-1.7-pojo-serializer-snapshot differ
diff --git a/flink-tests/src/test/java/org/apache/flink/test/typeserializerupgrade/PojoSerializerUpgradeTest.java b/flink-tests/src/test/java/org/apache/flink/test/typeserializerupgrade/PojoSerializerUpgradeTest.java
index 3f6f09be7f4ea..a02741e738a98 100644
--- a/flink-tests/src/test/java/org/apache/flink/test/typeserializerupgrade/PojoSerializerUpgradeTest.java
+++ b/flink-tests/src/test/java/org/apache/flink/test/typeserializerupgrade/PojoSerializerUpgradeTest.java
@@ -23,8 +23,6 @@
 import org.apache.flink.api.common.functions.RichMapFunction;
 import org.apache.flink.api.common.state.ListState;
 import org.apache.flink.api.common.state.ListStateDescriptor;
-import org.apache.flink.api.common.state.MapState;
-import org.apache.flink.api.common.state.MapStateDescriptor;
 import org.apache.flink.api.common.state.ReducingState;
 import org.apache.flink.api.common.state.ReducingStateDescriptor;
 import org.apache.flink.api.common.state.ValueState;
@@ -225,74 +223,38 @@ public void testChangedFieldTypesWithOperatorState() throws Exception {
 	}
 
 	/**
-	 * Adding fields to a POJO as keyed state should require a state migration.
+	 * Adding fields to a POJO as keyed state should succeed.
 	 */
 	@Test
 	public void testAdditionalFieldWithKeyedState() throws Exception {
-		try {
-			testPojoSerializerUpgrade(SOURCE_A, SOURCE_D, true, true);
-			fail("Expected a state migration exception.");
-		} catch (Exception e) {
-			if (CommonTestUtils.containsCause(e, StateMigrationException.class)) {
-				// StateMigrationException expected
-			} else {
-				throw e;
-			}
-		}
+		testPojoSerializerUpgrade(SOURCE_A, SOURCE_D, true, true);
 	}
 
 	/**
-	 * Adding fields to a POJO as operator state should require a state migration.
+	 * Adding fields to a POJO as operator state should succeed.
 	 */
 	@Test
 	public void testAdditionalFieldWithOperatorState() throws Exception {
-		try {
-			testPojoSerializerUpgrade(SOURCE_A, SOURCE_D, true, false);
-			fail("Expected a state migration exception.");
-		} catch (Exception e) {
-			if (CommonTestUtils.containsCause(e, StateMigrationException.class)) {
-				// StateMigrationException expected
-			} else {
-				throw e;
-			}
-		}
+		testPojoSerializerUpgrade(SOURCE_A, SOURCE_D, true, false);
 	}
 
 	/**
-	 * Removing fields from a POJO as keyed state should require a state migration.
+	 * Removing fields from a POJO as keyed state should succeed.
 	 */
 	@Test
 	public void testMissingFieldWithKeyedState() throws Exception {
-		try {
-			testPojoSerializerUpgrade(SOURCE_A, SOURCE_E, false, true);
-			fail("Expected a state migration exception.");
-		} catch (Exception e) {
-			if (CommonTestUtils.containsCause(e, StateMigrationException.class)) {
-				// StateMigrationException expected
-			} else {
-				throw e;
-			}
-		}
+		testPojoSerializerUpgrade(SOURCE_A, SOURCE_E, false, true);
 	}
 
 	/**
-	 * Removing fields from a POJO as operator state should require a state migration.
+	 * Removing fields from a POJO as operator state should succeed.
 	 */
 	@Test
 	public void testMissingFieldWithOperatorState() throws Exception {
-		try {
-			testPojoSerializerUpgrade(SOURCE_A, SOURCE_E, false, false);
-			fail("Expected a state migration exception.");
-		} catch (Exception e) {
-			if (CommonTestUtils.containsCause(e, StateMigrationException.class)) {
-				// StateMigrationException expected
-			} else {
-				throw e;
-			}
-		}
+		testPojoSerializerUpgrade(SOURCE_A, SOURCE_E, false, false);
 	}
 
-	public void testPojoSerializerUpgrade(String classSourceA, String classSourceB, boolean hasBField, boolean isKeyedState) throws Exception {
+	private void testPojoSerializerUpgrade(String classSourceA, String classSourceB, boolean hasBField, boolean isKeyedState) throws Exception {
 		final Configuration taskConfiguration = new Configuration();
 		final ExecutionConfig executionConfig = new ExecutionConfig();
 		final KeySelector<Long, Long> keySelector = new IdentityKeySelector<>();
@@ -424,7 +386,6 @@ private static final class StatefulMapper extends RichMapFunction<Long, Long> im
 
 		// keyed states
 		private transient ValueState<Object> keyedValueState;
-		private transient MapState<Object, Object> keyedMapState;
 		private transient ListState<Object> keyedListState;
 		private transient ReducingState<Object> keyedReducingState;
 
@@ -436,7 +397,7 @@ private static final class StatefulMapper extends RichMapFunction<Long, Long> im
 		private transient Field fieldA;
 		private transient Field fieldB;
 
-		public StatefulMapper(boolean keyed, boolean verify, boolean hasBField) {
+		StatefulMapper(boolean keyed, boolean verify, boolean hasBField) {
 			this.keyed = keyed;
 			this.verify = verify;
 			this.hasBField = hasBField;
@@ -456,9 +417,6 @@ public Long map(Long value) throws Exception {
 				if (keyed) {
 					assertEquals(pojo, keyedValueState.value());
 
-					assertTrue(keyedMapState.contains(pojo));
-					assertEquals(pojo, keyedMapState.get(pojo));
-
 					Iterator<Object> listIterator = keyedListState.get().iterator();
 
 					boolean elementFound = false;
@@ -488,7 +446,6 @@ public Long map(Long value) throws Exception {
 			} else {
 				if (keyed) {
 					keyedValueState.update(pojo);
-					keyedMapState.put(pojo, pojo);
 					keyedListState.add(pojo);
 					keyedReducingState.add(pojo);
 				} else {
@@ -505,6 +462,7 @@ public void snapshotState(FunctionSnapshotContext context) throws Exception {
 
 		}
 
+		@SuppressWarnings("unchecked")
 		@Override
 		public void initializeState(FunctionInitializationContext context) throws Exception {
 			pojoClass = getRuntimeContext().getUserCodeClassLoader().loadClass(POJO_NAME);
@@ -520,8 +478,6 @@ public void initializeState(FunctionInitializationContext context) throws Except
 			if (keyed) {
 				keyedValueState = context.getKeyedStateStore().getState(
 					new ValueStateDescriptor<>("keyedValueState", (Class<Object>) pojoClass));
-				keyedMapState = context.getKeyedStateStore().getMapState(
-					new MapStateDescriptor<>("keyedMapState", (Class<Object>) pojoClass, (Class<Object>) pojoClass));
 				keyedListState = context.getKeyedStateStore().getListState(
 					new ListStateDescriptor<>("keyedListState", (Class<Object>) pojoClass));
 
