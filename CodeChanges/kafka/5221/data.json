{
  "url": "https://api.github.com/repos/apache/kafka/pulls/5221",
  "id": 194760216,
  "node_id": "MDExOlB1bGxSZXF1ZXN0MTk0NzYwMjE2",
  "html_url": "https://github.com/apache/kafka/pull/5221",
  "diff_url": "https://github.com/apache/kafka/pull/5221.diff",
  "patch_url": "https://github.com/apache/kafka/pull/5221.patch",
  "issue_url": "https://api.github.com/repos/apache/kafka/issues/5221",
  "number": 5221,
  "state": "closed",
  "locked": false,
  "title": "KAFKA-7019; Make reading metadata lock-free by maintaining an atomically-updated read snapshot",
  "user": {
    "login": "radai-rosenblatt",
    "id": 1042632,
    "node_id": "MDQ6VXNlcjEwNDI2MzI=",
    "avatar_url": "https://avatars.githubusercontent.com/u/1042632?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/radai-rosenblatt",
    "html_url": "https://github.com/radai-rosenblatt",
    "followers_url": "https://api.github.com/users/radai-rosenblatt/followers",
    "following_url": "https://api.github.com/users/radai-rosenblatt/following{/other_user}",
    "gists_url": "https://api.github.com/users/radai-rosenblatt/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/radai-rosenblatt/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/radai-rosenblatt/subscriptions",
    "organizations_url": "https://api.github.com/users/radai-rosenblatt/orgs",
    "repos_url": "https://api.github.com/users/radai-rosenblatt/repos",
    "events_url": "https://api.github.com/users/radai-rosenblatt/events{/privacy}",
    "received_events_url": "https://api.github.com/users/radai-rosenblatt/received_events",
    "type": "User",
    "site_admin": false
  },
  "body": "we've seen cases where under a constant metadata update load (automated partition rebalance) request handling threads can block for a significant amount of time on the metadata lock.\r\n\r\nthe reason is that for large enough clusters (~200,000 topic partitions) a read operation can actually take a long while to compose a response. under a constant stream of reads + writes we see situations where a reader is currently in, a writer is pending (blocked) and then a big pile-up of more readers that are blocked behind the pending writer.\r\n\r\nthis patch makes the read path lock-free. the metadata is now stored in a logically-immutable snapshot. all read operations grab a snapshot and serve data out of it. write paths create an entirely new snapshot and atomically assign it. writers are still under a lock, for mutual exclusion.\r\n\r\nhere's the benchmark code i used to measure the effects of this patch:\r\n```java\r\npublic class MetadataCacheBenchmark {\r\n    private volatile boolean running = true;\r\n\r\n    int numBrokers = 150;\r\n    int numTopics = 3500;\r\n    int maxPartitionsPerTopic = 100;\r\n    int replicationFactor = 2;\r\n    int numUpdaters = 1;\r\n    double updateRateLimit = 10.0; //qps\r\n    int numReaders = 5;\r\n    boolean partialUpdate = true;\r\n\r\n    private final ListenerName listener = new ListenerName(\"listener\");\r\n\r\n    private final AtomicLong updateCounter = new AtomicLong();\r\n    private final AtomicLong readCounter = new AtomicLong();\r\n\r\n    @Test\r\n    public void benchmarkAllTheThings() throws Exception {\r\n        //long seed = System.currentTimeMillis();\r\n        long seed = 666;\r\n        System.err.println(\"seed is \" + seed);\r\n        Random r = new Random(seed);\r\n\r\n        MetadataCache cache = new MetadataCache(666);\r\n        UpdateMetadataRequest fullRequest = buildRequest(r, -1);\r\n        UpdateMetadataRequest partialRequest = buildRequest(r, 1);\r\n\r\n        cache.updateCache(0, fullRequest); //initial data (useful in case there are no writers)\r\n\r\n        Set<String> allTopics = new HashSet<>();\r\n        for (int i = 0; i < numTopics; i++) {\r\n            allTopics.add(\"topic-\" + i);\r\n        }\r\n        scala.collection.mutable.Set<String> topicsScalaSet = JavaConverters.asScalaSetConverter(allTopics).asScala();\r\n\r\n        Thread.UncaughtExceptionHandler exceptionHandler = new Thread.UncaughtExceptionHandler() {\r\n            @Override\r\n            public void uncaughtException(Thread t, Throwable e) {\r\n                running = false;\r\n                System.err.println(\"thread \" + t + \" died\");\r\n                e.printStackTrace(System.err);\r\n                System.exit(1);\r\n            }\r\n        };\r\n        List<Thread> threads = new ArrayList<>();\r\n\r\n        for (int i = 0; i < numUpdaters; i++) {\r\n            UpdateMetadataRequest req = partialUpdate ? partialRequest : fullRequest;\r\n\r\n            Runnable updaterRunnable;\r\n            if (updateRateLimit > 0) {\r\n                updaterRunnable = new RateLimitedUpdateRunnable(updateRateLimit, cache, req);\r\n            } else {\r\n                updaterRunnable = new UpdateRunnable(cache, req);\r\n            }\r\n            Thread updaterThread = new Thread(updaterRunnable, \"updater-\" + i);\r\n            updaterThread.setDaemon(true);\r\n            updaterThread.setUncaughtExceptionHandler(exceptionHandler);\r\n            threads.add(updaterThread);\r\n        }\r\n\r\n        for (int i = 0; i < numReaders; i++) {\r\n            ReadRunnable readRunnable = new ReadRunnable(cache, topicsScalaSet);\r\n            Thread readerThread = new Thread(readRunnable, \"reader-\" + i);\r\n            readerThread.setDaemon(true);\r\n            readerThread.setUncaughtExceptionHandler(exceptionHandler);\r\n            threads.add(readerThread);\r\n        }\r\n\r\n        for (Thread t : threads) {\r\n            t.start();\r\n        }\r\n\r\n        long prevTime = System.currentTimeMillis();\r\n        long prevUpdates = 0;\r\n        long prevReads = 0;\r\n\r\n        long now;\r\n        long updates;\r\n        long reads;\r\n\r\n        long timeDiff;\r\n        long updateDiff;\r\n        long readDiff;\r\n\r\n        double updateQps;\r\n        double readQps;\r\n\r\n        while (running) {\r\n            Thread.sleep(TimeUnit.SECONDS.toMillis(30));\r\n            now = System.currentTimeMillis();\r\n            updates = updateCounter.longValue();\r\n            reads = readCounter.longValue();\r\n\r\n            timeDiff = now - prevTime;\r\n            updateDiff = updates - prevUpdates;\r\n            readDiff = reads - prevReads;\r\n\r\n            updateQps = ((double) updateDiff * 1000) / timeDiff;\r\n            readQps = ((double) readDiff * 1000) / timeDiff;\r\n\r\n            prevTime = now;\r\n            prevUpdates = updates;\r\n            prevReads = reads;\r\n\r\n            System.err.println(\"updates: \" + updateQps + \" / sec\");\r\n            System.err.println(\"reads: \" + readQps + \" / sec\");\r\n        }\r\n    }\r\n\r\n    private UpdateMetadataRequest buildRequest(Random random, int numTopicsOverride) {\r\n        int controllerEpoch = 0;\r\n        int totalPartitions = 0;\r\n        Set<UpdateMetadataRequest.Broker> liveBrokers = new HashSet<>();\r\n\r\n        for (int i = 0; i < numBrokers; i++) {\r\n            UpdateMetadataRequest.EndPoint endPoint =\r\n                new UpdateMetadataRequest.EndPoint(\"host-\" + i, 6666, SecurityProtocol.PLAINTEXT, listener);\r\n            UpdateMetadataRequest.Broker broker =\r\n                new UpdateMetadataRequest.Broker(i, Collections.singletonList(endPoint), \"rack-\" + i);\r\n            liveBrokers.add(broker);\r\n        }\r\n\r\n        Map<TopicPartition, UpdateMetadataRequest.PartitionState> partitions = new HashMap<>();\r\n\r\n        int topicCount = numTopicsOverride > 0 ? numTopicsOverride : numTopics;\r\n\r\n        for (int i = 0; i < topicCount; i++) {\r\n            String topicName = \"topic-\" + i;\r\n            int numPartitions = 1 + random.nextInt(maxPartitionsPerTopic);\r\n            for (int j = 0; j < numPartitions; j++) {\r\n                TopicPartition tp = new TopicPartition(topicName, j);\r\n                List<Integer> replicas = pick(replicationFactor, numBrokers, random);\r\n                UpdateMetadataRequest.PartitionState state =\r\n                    new UpdateMetadataRequest.PartitionState(controllerEpoch, replicas.get(0), 0, replicas, 0, replicas,\r\n                        Collections.<Integer>emptyList());\r\n                partitions.put(tp, state);\r\n            }\r\n            totalPartitions += numPartitions;\r\n        }\r\n\r\n        UpdateMetadataRequest.Builder builder =\r\n            new UpdateMetadataRequest.Builder((short) 4, 0, controllerEpoch, partitions, liveBrokers);\r\n\r\n        UpdateMetadataRequest request = builder.build((short) 4);\r\n        System.err.println(\"request has \" + totalPartitions + \" TPs total\");\r\n        return request;\r\n    }\r\n\r\n    private List<Integer> pick(int howMany, int from, Random random) {\r\n        List<Integer> result = new ArrayList<>(howMany);\r\n        while (result.size() < howMany) {\r\n            int chosen = random.nextInt(from); //exclusive\r\n            if (!result.contains(chosen)) {\r\n                result.add(chosen);\r\n            }\r\n        }\r\n        return result;\r\n    }\r\n\r\n    private class UpdateRunnable implements Runnable {\r\n        private final MetadataCache cache;\r\n        private final UpdateMetadataRequest request;\r\n        private int counter = 0;\r\n\r\n        public UpdateRunnable(MetadataCache cache, UpdateMetadataRequest request) {\r\n            this.cache = cache;\r\n            this.request = request;\r\n        }\r\n\r\n        @Override\r\n        public void run() {\r\n            while (running) {\r\n                cache.updateCache(counter++, request);\r\n                updateCounter.incrementAndGet();\r\n            }\r\n        }\r\n    }\r\n\r\n    private class RateLimitedUpdateRunnable implements Runnable {\r\n        private final MetadataCache cache;\r\n        private final UpdateMetadataRequest request;\r\n        private int counter = 0;\r\n\r\n        private final double targetQps;\r\n        private final int intervalMillis;\r\n\r\n        public RateLimitedUpdateRunnable(double targetQps, MetadataCache cache, UpdateMetadataRequest request) {\r\n            this.cache = cache;\r\n            this.request = request;\r\n            this.targetQps = targetQps;\r\n            this.intervalMillis = (int) (1000.0 / targetQps);\r\n        }\r\n\r\n        @Override\r\n        public void run() {\r\n            while (running) {\r\n                long start = System.currentTimeMillis();\r\n                cache.updateCache(counter++, request);\r\n                long end = System.currentTimeMillis();\r\n                updateCounter.incrementAndGet();\r\n                long took = end - start;\r\n                long remaining = intervalMillis - took;\r\n                if (remaining > 0) {\r\n                    try {\r\n                        Thread.sleep(remaining);\r\n                    } catch (Exception e) {\r\n                        e.printStackTrace(System.err);\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    private class ReadRunnable implements Runnable {\r\n        private final MetadataCache cache;\r\n        private final scala.collection.mutable.Set<String> topics;\r\n\r\n        public ReadRunnable(MetadataCache cache, scala.collection.mutable.Set<String> topics) {\r\n            this.cache = cache;\r\n            this.topics = topics;\r\n        }\r\n\r\n        @Override\r\n        public void run() {\r\n            while (running) {\r\n                cache.getTopicMetadata(topics, listener, false);\r\n                readCounter.incrementAndGet();\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nthe interesting/problematic scenario is a combination of writers and readers,",
  "created_at": "2018-06-14T02:01:01Z",
  "updated_at": "2019-03-07T22:07:09Z",
  "closed_at": "2018-08-14T22:36:06Z",
  "merged_at": null,
  "merge_commit_sha": "861ebf23955deba80ef2b0e4468fe09bb63719ff",
  "assignee": {
    "login": "lindong28",
    "id": 5873403,
    "node_id": "MDQ6VXNlcjU4NzM0MDM=",
    "avatar_url": "https://avatars.githubusercontent.com/u/5873403?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/lindong28",
    "html_url": "https://github.com/lindong28",
    "followers_url": "https://api.github.com/users/lindong28/followers",
    "following_url": "https://api.github.com/users/lindong28/following{/other_user}",
    "gists_url": "https://api.github.com/users/lindong28/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/lindong28/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/lindong28/subscriptions",
    "organizations_url": "https://api.github.com/users/lindong28/orgs",
    "repos_url": "https://api.github.com/users/lindong28/repos",
    "events_url": "https://api.github.com/users/lindong28/events{/privacy}",
    "received_events_url": "https://api.github.com/users/lindong28/received_events",
    "type": "User",
    "site_admin": false
  },
  "assignees": [
    {
      "login": "lindong28",
      "id": 5873403,
      "node_id": "MDQ6VXNlcjU4NzM0MDM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5873403?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lindong28",
      "html_url": "https://github.com/lindong28",
      "followers_url": "https://api.github.com/users/lindong28/followers",
      "following_url": "https://api.github.com/users/lindong28/following{/other_user}",
      "gists_url": "https://api.github.com/users/lindong28/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lindong28/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lindong28/subscriptions",
      "organizations_url": "https://api.github.com/users/lindong28/orgs",
      "repos_url": "https://api.github.com/users/lindong28/repos",
      "events_url": "https://api.github.com/users/lindong28/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lindong28/received_events",
      "type": "User",
      "site_admin": false
    }
  ],
  "requested_reviewers": [],
  "requested_teams": [],
  "labels": [
    {
      "id": 838330122,
      "node_id": "MDU6TGFiZWw4MzgzMzAxMjI=",
      "url": "https://api.github.com/repos/apache/kafka/labels/core",
      "name": "core",
      "color": "ed5a86",
      "default": false,
      "description": null
    },
    {
      "id": 970614414,
      "node_id": "MDU6TGFiZWw5NzA2MTQ0MTQ=",
      "url": "https://api.github.com/repos/apache/kafka/labels/performance",
      "name": "performance",
      "color": "c2e0c6",
      "default": false,
      "description": ""
    }
  ],
  "milestone": null,
  "draft": false,
  "commits_url": "https://api.github.com/repos/apache/kafka/pulls/5221/commits",
  "review_comments_url": "https://api.github.com/repos/apache/kafka/pulls/5221/comments",
  "review_comment_url": "https://api.github.com/repos/apache/kafka/pulls/comments{/number}",
  "comments_url": "https://api.github.com/repos/apache/kafka/issues/5221/comments",
  "statuses_url": "https://api.github.com/repos/apache/kafka/statuses/d7ab57ffa9d5db82f8e5a01763b98bc21e0d825d",
  "head": {
    "label": "radai-rosenblatt:metadata-adventures",
    "ref": "metadata-adventures",
    "sha": "d7ab57ffa9d5db82f8e5a01763b98bc21e0d825d",
    "user": {
      "login": "radai-rosenblatt",
      "id": 1042632,
      "node_id": "MDQ6VXNlcjEwNDI2MzI=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1042632?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/radai-rosenblatt",
      "html_url": "https://github.com/radai-rosenblatt",
      "followers_url": "https://api.github.com/users/radai-rosenblatt/followers",
      "following_url": "https://api.github.com/users/radai-rosenblatt/following{/other_user}",
      "gists_url": "https://api.github.com/users/radai-rosenblatt/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/radai-rosenblatt/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/radai-rosenblatt/subscriptions",
      "organizations_url": "https://api.github.com/users/radai-rosenblatt/orgs",
      "repos_url": "https://api.github.com/users/radai-rosenblatt/repos",
      "events_url": "https://api.github.com/users/radai-rosenblatt/events{/privacy}",
      "received_events_url": "https://api.github.com/users/radai-rosenblatt/received_events",
      "type": "User",
      "site_admin": false
    },
    "repo": {
      "id": 64683013,
      "node_id": "MDEwOlJlcG9zaXRvcnk2NDY4MzAxMw==",
      "name": "kafka",
      "full_name": "radai-rosenblatt/kafka",
      "private": false,
      "owner": {
        "login": "radai-rosenblatt",
        "id": 1042632,
        "node_id": "MDQ6VXNlcjEwNDI2MzI=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1042632?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/radai-rosenblatt",
        "html_url": "https://github.com/radai-rosenblatt",
        "followers_url": "https://api.github.com/users/radai-rosenblatt/followers",
        "following_url": "https://api.github.com/users/radai-rosenblatt/following{/other_user}",
        "gists_url": "https://api.github.com/users/radai-rosenblatt/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/radai-rosenblatt/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/radai-rosenblatt/subscriptions",
        "organizations_url": "https://api.github.com/users/radai-rosenblatt/orgs",
        "repos_url": "https://api.github.com/users/radai-rosenblatt/repos",
        "events_url": "https://api.github.com/users/radai-rosenblatt/events{/privacy}",
        "received_events_url": "https://api.github.com/users/radai-rosenblatt/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/radai-rosenblatt/kafka",
      "description": "Mirror of Apache Kafka",
      "fork": true,
      "url": "https://api.github.com/repos/radai-rosenblatt/kafka",
      "forks_url": "https://api.github.com/repos/radai-rosenblatt/kafka/forks",
      "keys_url": "https://api.github.com/repos/radai-rosenblatt/kafka/keys{/key_id}",
      "collaborators_url": "https://api.github.com/repos/radai-rosenblatt/kafka/collaborators{/collaborator}",
      "teams_url": "https://api.github.com/repos/radai-rosenblatt/kafka/teams",
      "hooks_url": "https://api.github.com/repos/radai-rosenblatt/kafka/hooks",
      "issue_events_url": "https://api.github.com/repos/radai-rosenblatt/kafka/issues/events{/number}",
      "events_url": "https://api.github.com/repos/radai-rosenblatt/kafka/events",
      "assignees_url": "https://api.github.com/repos/radai-rosenblatt/kafka/assignees{/user}",
      "branches_url": "https://api.github.com/repos/radai-rosenblatt/kafka/branches{/branch}",
      "tags_url": "https://api.github.com/repos/radai-rosenblatt/kafka/tags",
      "blobs_url": "https://api.github.com/repos/radai-rosenblatt/kafka/git/blobs{/sha}",
      "git_tags_url": "https://api.github.com/repos/radai-rosenblatt/kafka/git/tags{/sha}",
      "git_refs_url": "https://api.github.com/repos/radai-rosenblatt/kafka/git/refs{/sha}",
      "trees_url": "https://api.github.com/repos/radai-rosenblatt/kafka/git/trees{/sha}",
      "statuses_url": "https://api.github.com/repos/radai-rosenblatt/kafka/statuses/{sha}",
      "languages_url": "https://api.github.com/repos/radai-rosenblatt/kafka/languages",
      "stargazers_url": "https://api.github.com/repos/radai-rosenblatt/kafka/stargazers",
      "contributors_url": "https://api.github.com/repos/radai-rosenblatt/kafka/contributors",
      "subscribers_url": "https://api.github.com/repos/radai-rosenblatt/kafka/subscribers",
      "subscription_url": "https://api.github.com/repos/radai-rosenblatt/kafka/subscription",
      "commits_url": "https://api.github.com/repos/radai-rosenblatt/kafka/commits{/sha}",
      "git_commits_url": "https://api.github.com/repos/radai-rosenblatt/kafka/git/commits{/sha}",
      "comments_url": "https://api.github.com/repos/radai-rosenblatt/kafka/comments{/number}",
      "issue_comment_url": "https://api.github.com/repos/radai-rosenblatt/kafka/issues/comments{/number}",
      "contents_url": "https://api.github.com/repos/radai-rosenblatt/kafka/contents/{+path}",
      "compare_url": "https://api.github.com/repos/radai-rosenblatt/kafka/compare/{base}...{head}",
      "merges_url": "https://api.github.com/repos/radai-rosenblatt/kafka/merges",
      "archive_url": "https://api.github.com/repos/radai-rosenblatt/kafka/{archive_format}{/ref}",
      "downloads_url": "https://api.github.com/repos/radai-rosenblatt/kafka/downloads",
      "issues_url": "https://api.github.com/repos/radai-rosenblatt/kafka/issues{/number}",
      "pulls_url": "https://api.github.com/repos/radai-rosenblatt/kafka/pulls{/number}",
      "milestones_url": "https://api.github.com/repos/radai-rosenblatt/kafka/milestones{/number}",
      "notifications_url": "https://api.github.com/repos/radai-rosenblatt/kafka/notifications{?since,all,participating}",
      "labels_url": "https://api.github.com/repos/radai-rosenblatt/kafka/labels{/name}",
      "releases_url": "https://api.github.com/repos/radai-rosenblatt/kafka/releases{/id}",
      "deployments_url": "https://api.github.com/repos/radai-rosenblatt/kafka/deployments",
      "created_at": "2016-08-01T16:23:51Z",
      "updated_at": "2020-05-21T04:05:29Z",
      "pushed_at": "2021-05-27T19:21:04Z",
      "git_url": "git://github.com/radai-rosenblatt/kafka.git",
      "ssh_url": "git@github.com:radai-rosenblatt/kafka.git",
      "clone_url": "https://github.com/radai-rosenblatt/kafka.git",
      "svn_url": "https://github.com/radai-rosenblatt/kafka",
      "homepage": null,
      "size": 115677,
      "stargazers_count": 0,
      "watchers_count": 0,
      "language": "Java",
      "has_issues": false,
      "has_projects": true,
      "has_downloads": true,
      "has_wiki": false,
      "has_pages": false,
      "has_discussions": false,
      "forks_count": 0,
      "mirror_url": null,
      "archived": false,
      "disabled": false,
      "open_issues_count": 0,
      "license": {
        "key": "apache-2.0",
        "name": "Apache License 2.0",
        "spdx_id": "Apache-2.0",
        "url": "https://api.github.com/licenses/apache-2.0",
        "node_id": "MDc6TGljZW5zZTI="
      },
      "allow_forking": true,
      "is_template": false,
      "web_commit_signoff_required": false,
      "topics": [],
      "visibility": "public",
      "forks": 0,
      "open_issues": 0,
      "watchers": 0,
      "default_branch": "trunk"
    }
  },
  "base": {
    "label": "apache:trunk",
    "ref": "trunk",
    "sha": "0d73351852369b0f969e11236332c03e2d955ae7",
    "user": {
      "login": "apache",
      "id": 47359,
      "node_id": "MDEyOk9yZ2FuaXphdGlvbjQ3MzU5",
      "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/apache",
      "html_url": "https://github.com/apache",
      "followers_url": "https://api.github.com/users/apache/followers",
      "following_url": "https://api.github.com/users/apache/following{/other_user}",
      "gists_url": "https://api.github.com/users/apache/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/apache/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/apache/subscriptions",
      "organizations_url": "https://api.github.com/users/apache/orgs",
      "repos_url": "https://api.github.com/users/apache/repos",
      "events_url": "https://api.github.com/users/apache/events{/privacy}",
      "received_events_url": "https://api.github.com/users/apache/received_events",
      "type": "Organization",
      "site_admin": false
    },
    "repo": {
      "id": 2211243,
      "node_id": "MDEwOlJlcG9zaXRvcnkyMjExMjQz",
      "name": "kafka",
      "full_name": "apache/kafka",
      "private": false,
      "owner": {
        "login": "apache",
        "id": 47359,
        "node_id": "MDEyOk9yZ2FuaXphdGlvbjQ3MzU5",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/apache",
        "html_url": "https://github.com/apache",
        "followers_url": "https://api.github.com/users/apache/followers",
        "following_url": "https://api.github.com/users/apache/following{/other_user}",
        "gists_url": "https://api.github.com/users/apache/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/apache/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/apache/subscriptions",
        "organizations_url": "https://api.github.com/users/apache/orgs",
        "repos_url": "https://api.github.com/users/apache/repos",
        "events_url": "https://api.github.com/users/apache/events{/privacy}",
        "received_events_url": "https://api.github.com/users/apache/received_events",
        "type": "Organization",
        "site_admin": false
      },
      "html_url": "https://github.com/apache/kafka",
      "description": "Mirror of Apache Kafka",
      "fork": false,
      "url": "https://api.github.com/repos/apache/kafka",
      "forks_url": "https://api.github.com/repos/apache/kafka/forks",
      "keys_url": "https://api.github.com/repos/apache/kafka/keys{/key_id}",
      "collaborators_url": "https://api.github.com/repos/apache/kafka/collaborators{/collaborator}",
      "teams_url": "https://api.github.com/repos/apache/kafka/teams",
      "hooks_url": "https://api.github.com/repos/apache/kafka/hooks",
      "issue_events_url": "https://api.github.com/repos/apache/kafka/issues/events{/number}",
      "events_url": "https://api.github.com/repos/apache/kafka/events",
      "assignees_url": "https://api.github.com/repos/apache/kafka/assignees{/user}",
      "branches_url": "https://api.github.com/repos/apache/kafka/branches{/branch}",
      "tags_url": "https://api.github.com/repos/apache/kafka/tags",
      "blobs_url": "https://api.github.com/repos/apache/kafka/git/blobs{/sha}",
      "git_tags_url": "https://api.github.com/repos/apache/kafka/git/tags{/sha}",
      "git_refs_url": "https://api.github.com/repos/apache/kafka/git/refs{/sha}",
      "trees_url": "https://api.github.com/repos/apache/kafka/git/trees{/sha}",
      "statuses_url": "https://api.github.com/repos/apache/kafka/statuses/{sha}",
      "languages_url": "https://api.github.com/repos/apache/kafka/languages",
      "stargazers_url": "https://api.github.com/repos/apache/kafka/stargazers",
      "contributors_url": "https://api.github.com/repos/apache/kafka/contributors",
      "subscribers_url": "https://api.github.com/repos/apache/kafka/subscribers",
      "subscription_url": "https://api.github.com/repos/apache/kafka/subscription",
      "commits_url": "https://api.github.com/repos/apache/kafka/commits{/sha}",
      "git_commits_url": "https://api.github.com/repos/apache/kafka/git/commits{/sha}",
      "comments_url": "https://api.github.com/repos/apache/kafka/comments{/number}",
      "issue_comment_url": "https://api.github.com/repos/apache/kafka/issues/comments{/number}",
      "contents_url": "https://api.github.com/repos/apache/kafka/contents/{+path}",
      "compare_url": "https://api.github.com/repos/apache/kafka/compare/{base}...{head}",
      "merges_url": "https://api.github.com/repos/apache/kafka/merges",
      "archive_url": "https://api.github.com/repos/apache/kafka/{archive_format}{/ref}",
      "downloads_url": "https://api.github.com/repos/apache/kafka/downloads",
      "issues_url": "https://api.github.com/repos/apache/kafka/issues{/number}",
      "pulls_url": "https://api.github.com/repos/apache/kafka/pulls{/number}",
      "milestones_url": "https://api.github.com/repos/apache/kafka/milestones{/number}",
      "notifications_url": "https://api.github.com/repos/apache/kafka/notifications{?since,all,participating}",
      "labels_url": "https://api.github.com/repos/apache/kafka/labels{/name}",
      "releases_url": "https://api.github.com/repos/apache/kafka/releases{/id}",
      "deployments_url": "https://api.github.com/repos/apache/kafka/deployments",
      "created_at": "2011-08-15T18:06:16Z",
      "updated_at": "2022-12-26T18:52:43Z",
      "pushed_at": "2022-12-26T09:06:09Z",
      "git_url": "git://github.com/apache/kafka.git",
      "ssh_url": "git@github.com:apache/kafka.git",
      "clone_url": "https://github.com/apache/kafka.git",
      "svn_url": "https://github.com/apache/kafka",
      "homepage": null,
      "size": 150940,
      "stargazers_count": 23789,
      "watchers_count": 23789,
      "language": "Java",
      "has_issues": false,
      "has_projects": true,
      "has_downloads": true,
      "has_wiki": false,
      "has_pages": false,
      "has_discussions": false,
      "forks_count": 12170,
      "mirror_url": null,
      "archived": false,
      "disabled": false,
      "open_issues_count": 1012,
      "license": {
        "key": "apache-2.0",
        "name": "Apache License 2.0",
        "spdx_id": "Apache-2.0",
        "url": "https://api.github.com/licenses/apache-2.0",
        "node_id": "MDc6TGljZW5zZTI="
      },
      "allow_forking": true,
      "is_template": false,
      "web_commit_signoff_required": false,
      "topics": [
        "kafka",
        "scala"
      ],
      "visibility": "public",
      "forks": 12170,
      "open_issues": 1012,
      "watchers": 23789,
      "default_branch": "trunk"
    }
  },
  "_links": {
    "self": {
      "href": "https://api.github.com/repos/apache/kafka/pulls/5221"
    },
    "html": {
      "href": "https://github.com/apache/kafka/pull/5221"
    },
    "issue": {
      "href": "https://api.github.com/repos/apache/kafka/issues/5221"
    },
    "comments": {
      "href": "https://api.github.com/repos/apache/kafka/issues/5221/comments"
    },
    "review_comments": {
      "href": "https://api.github.com/repos/apache/kafka/pulls/5221/comments"
    },
    "review_comment": {
      "href": "https://api.github.com/repos/apache/kafka/pulls/comments{/number}"
    },
    "commits": {
      "href": "https://api.github.com/repos/apache/kafka/pulls/5221/commits"
    },
    "statuses": {
      "href": "https://api.github.com/repos/apache/kafka/statuses/d7ab57ffa9d5db82f8e5a01763b98bc21e0d825d"
    }
  },
  "author_association": "CONTRIBUTOR",
  "auto_merge": null,
  "active_lock_reason": null,
  "merged": false,
  "mergeable": null,
  "rebaseable": null,
  "mergeable_state": "unknown",
  "merged_by": null,
  "comments": 31,
  "review_comments": 19,
  "maintainer_can_modify": false,
  "commits": 8,
  "additions": 107,
  "deletions": 106,
  "changed_files": 5
}