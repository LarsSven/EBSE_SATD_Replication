diff --git a/core/src/main/java/org/apache/carbondata/core/constants/CarbonCommonConstants.java b/core/src/main/java/org/apache/carbondata/core/constants/CarbonCommonConstants.java
index 02e8388009c..e2257ea0a70 100644
--- a/core/src/main/java/org/apache/carbondata/core/constants/CarbonCommonConstants.java
+++ b/core/src/main/java/org/apache/carbondata/core/constants/CarbonCommonConstants.java
@@ -2424,7 +2424,8 @@ private CarbonCommonConstants() {
   /**
    * Load all indexes to carbon LRU cache
    */
-  public static final String CARBON_LOAD_ALL_INDEX_TO_CACHE = "carbon.load.all.indexes.to.cache";
+  public static final String CARBON_LOAD_ALL_INDEX_TO_CACHE =
+      "carbon.load.all.segment.indexes.to.cache";
 
   /**
    * Default value for loading cache is true
diff --git a/core/src/main/java/org/apache/carbondata/core/datamap/Segment.java b/core/src/main/java/org/apache/carbondata/core/datamap/Segment.java
index fa8ebec3fff..563060c4d2a 100644
--- a/core/src/main/java/org/apache/carbondata/core/datamap/Segment.java
+++ b/core/src/main/java/org/apache/carbondata/core/datamap/Segment.java
@@ -34,7 +34,7 @@
 import org.apache.carbondata.core.statusmanager.LoadMetadataDetails;
 import org.apache.carbondata.core.statusmanager.SegmentRefreshInfo;
 import org.apache.carbondata.core.statusmanager.SegmentStatusManager;
-import org.apache.carbondata.core.util.SegmentMinMax;
+import org.apache.carbondata.core.util.SegmentMetaDataInfo;
 import org.apache.carbondata.core.util.path.CarbonTablePath;
 
 import org.apache.hadoop.conf.Configuration;
@@ -89,7 +89,7 @@ public class Segment implements Serializable, Writable {
   /**
    * Segment level min and max values
    */
-  private List<SegmentMinMax> segmentMinMax;
+  private SegmentMetaDataInfo segmentMetaDataINfo;
 
   public Segment() {
 
@@ -383,11 +383,11 @@ public void readFields(DataInput in) throws IOException {
     this.indexSize = in.readLong();
   }
 
-  public List<SegmentMinMax> getSegmentMinMax() {
-    return segmentMinMax;
+  public SegmentMetaDataInfo getSegmentMetaDataINfo() {
+    return segmentMetaDataINfo;
   }
 
-  public void setSegmentMinMax(List<SegmentMinMax> segmentMinMax) {
-    this.segmentMinMax = segmentMinMax;
+  public void setSegmentMetaDataINfo(SegmentMetaDataInfo segmentMetaDataINfo) {
+    this.segmentMetaDataINfo = segmentMetaDataINfo;
   }
 }
diff --git a/core/src/main/java/org/apache/carbondata/core/datamap/TableDataMap.java b/core/src/main/java/org/apache/carbondata/core/datamap/TableDataMap.java
index df9486b9e4b..09c671a2539 100644
--- a/core/src/main/java/org/apache/carbondata/core/datamap/TableDataMap.java
+++ b/core/src/main/java/org/apache/carbondata/core/datamap/TableDataMap.java
@@ -120,7 +120,8 @@ public List<ExtendedBlocklet> prune(List<Segment> allsegments, final DataMapFilt
     final List<ExtendedBlocklet> blocklets = new ArrayList<>();
     List<Segment> segments = getCarbonSegments(allsegments);
     final Map<Segment, List<DataMap>> dataMaps;
-    if (table.isHivePartitionTable() && filter != null && !filter.isEmpty() && partitions != null) {
+    boolean isFilterPresent = filter != null && !filter.isEmpty();
+    if (table.isHivePartitionTable() && isFilterPresent && partitions != null) {
       dataMaps = dataMapFactory.getDataMaps(segments, partitions, filter);
     } else {
       dataMaps = dataMapFactory.getDataMaps(segments, filter);
@@ -135,7 +136,7 @@ public List<ExtendedBlocklet> prune(List<Segment> allsegments, final DataMapFilt
     int datamapsCount = 0;
     // In case if filter has matched partitions, then update the segments with datamap's
     // segment list, as getDataMaps will return segments that matches the partition.
-    if (null != partitions && !partitions.isEmpty() || (null != filter && !filter.isEmpty())) {
+    if (isFilterPresent) {
       segments = new ArrayList<>(dataMaps.keySet());
     }
     for (Segment segment : segments) {
diff --git a/core/src/main/java/org/apache/carbondata/core/indexstore/SegmentBlockIndexInfo.java b/core/src/main/java/org/apache/carbondata/core/indexstore/SegmentBlockIndexInfo.java
index 12706364bcf..2f7a07ffbe6 100644
--- a/core/src/main/java/org/apache/carbondata/core/indexstore/SegmentBlockIndexInfo.java
+++ b/core/src/main/java/org/apache/carbondata/core/indexstore/SegmentBlockIndexInfo.java
@@ -17,10 +17,9 @@
 
 package org.apache.carbondata.core.indexstore;
 
-import java.util.List;
 import java.util.Set;
 
-import org.apache.carbondata.core.util.SegmentMinMax;
+import org.apache.carbondata.core.util.SegmentMetaDataInfo;
 
 /**
  * Holds tableBlockUniqueIdentifiers and block level minMax values for the segment
@@ -33,23 +32,23 @@ public class SegmentBlockIndexInfo {
   private Set<TableBlockIndexUniqueIdentifier> tableBlockIndexUniqueIdentifiers;
 
   /**
-   * List of block level min and max values
+   * segment level min and max values
    */
-  private List<SegmentMinMax> segmentMinMax;
+  private SegmentMetaDataInfo segmentMetaDataInfo;
 
   public SegmentBlockIndexInfo(
       Set<TableBlockIndexUniqueIdentifier> tableBlockIndexUniqueIdentifiers,
-      List<SegmentMinMax> segmentMinMax) {
+      SegmentMetaDataInfo segmentMetaDataInfo) {
     this.tableBlockIndexUniqueIdentifiers = tableBlockIndexUniqueIdentifiers;
-    this.segmentMinMax = segmentMinMax;
+    this.segmentMetaDataInfo = segmentMetaDataInfo;
   }
 
   public Set<TableBlockIndexUniqueIdentifier> getTableBlockIndexUniqueIdentifiers() {
     return tableBlockIndexUniqueIdentifiers;
   }
 
-  public List<SegmentMinMax> getSegmentMinMax() {
-    return segmentMinMax;
+  public SegmentMetaDataInfo getSegmentMetaDataInfo() {
+    return segmentMetaDataInfo;
   }
 
 }
diff --git a/core/src/main/java/org/apache/carbondata/core/indexstore/blockletindex/BlockletDataMapFactory.java b/core/src/main/java/org/apache/carbondata/core/indexstore/blockletindex/BlockletDataMapFactory.java
index 82975abf067..658f33b290d 100644
--- a/core/src/main/java/org/apache/carbondata/core/indexstore/blockletindex/BlockletDataMapFactory.java
+++ b/core/src/main/java/org/apache/carbondata/core/indexstore/blockletindex/BlockletDataMapFactory.java
@@ -66,10 +66,10 @@
 import org.apache.carbondata.core.scan.filter.FilterUtil;
 import org.apache.carbondata.core.scan.filter.executer.FilterExecuter;
 import org.apache.carbondata.core.scan.filter.resolver.FilterResolverIntf;
+import org.apache.carbondata.core.util.BlockColumnMetaDataInfo;
 import org.apache.carbondata.core.util.BlockletDataMapUtil;
 import org.apache.carbondata.core.util.CarbonProperties;
-import org.apache.carbondata.core.util.SegmentBlockMinMaxInfo;
-import org.apache.carbondata.core.util.SegmentMinMax;
+import org.apache.carbondata.core.util.SegmentMetaDataInfo;
 import org.apache.carbondata.core.util.path.CarbonTablePath;
 import org.apache.carbondata.events.Event;
 
@@ -157,15 +157,15 @@ public Map<Segment, List<CoarseGrainDataMap>> getDataMaps(List<Segment> segments
         getTableBlockUniqueIdentifierWrappers(partitionsToPrune,
             tableBlockIndexUniqueIdentifierWrappers, identifiers);
       } else {
-        List<SegmentMinMax> segmentMinMaxList = segment.getSegmentMinMax();
-        boolean isLoadAllIndex = Boolean.parseBoolean(CarbonProperties.getInstance()
-            .getProperty(CarbonCommonConstants.CARBON_LOAD_ALL_INDEX_TO_CACHE,
-                CarbonCommonConstants.CARBON_LOAD_ALL_INDEX_TO_CACHE_DEFAULT));
-        if (!isLoadAllIndex && null != segmentMinMaxList && !segmentMinMaxList.isEmpty()
-            && null != filter && !filter.isEmpty() && null != filter.getExpression()
-            && null == FilterUtil.getImplicitFilterExpression(filter.getExpression())) {
-          getTableBlockIndexUniqueIdentifierUsingSegmentMinMax(segment, segmentMinMaxList, filter,
-              identifiers, tableBlockIndexUniqueIdentifierWrappers);
+        SegmentMetaDataInfo segmentMetaDataInfoList = segment.getSegmentMetaDataINfo();
+        //        boolean isLoadAllIndex = Boolean.parseBoolean(CarbonProperties.getInstance()
+        //            .getProperty(CarbonCommonConstants.CARBON_LOAD_ALL_INDEX_TO_CACHE,
+        //                CarbonCommonConstants.CARBON_LOAD_ALL_INDEX_TO_CACHE_DEFAULT));
+        if (null != segmentMetaDataInfoList && null != filter && !filter
+            .isEmpty() && null != filter.getExpression() && null == FilterUtil
+            .getImplicitFilterExpression(filter.getExpression())) {
+          getTableBlockIndexUniqueIdentifierUsingSegmentMinMax(segment, segmentMetaDataInfoList,
+              filter, identifiers, tableBlockIndexUniqueIdentifierWrappers);
         } else {
           for (TableBlockIndexUniqueIdentifier tableBlockIndexUniqueIdentifier : identifiers) {
             tableBlockIndexUniqueIdentifierWrappers.add(
@@ -221,87 +221,83 @@ private void getTableBlockUniqueIdentifierWrappers(List<PartitionSpec> partition
    * Using blockLevel minmax values, identify if segment has to be added for further pruning and to
    * load segment index info to cache
    * @param segment to be identified if needed for loading block datamaps
-   * @param segmentMinMaxList list of block level min max values
+   * @param segmentMetaDataINfo list of block level min max values
    * @param filter filter expression
    * @param identifiers tableBlockIndexUniqueIdentifiers
    * @param tableBlockIndexUniqueIdentifierWrappers to add tableBlockIndexUniqueIdentifiers
    */
   private void getTableBlockIndexUniqueIdentifierUsingSegmentMinMax(Segment segment,
-      List<SegmentMinMax> segmentMinMaxList, DataMapFilter filter,
+      SegmentMetaDataInfo segmentMetaDataINfo, DataMapFilter filter,
       Set<TableBlockIndexUniqueIdentifier> identifiers,
       List<TableBlockIndexUniqueIdentifierWrapper> tableBlockIndexUniqueIdentifierWrappers) {
     boolean isScanRequired = false;
-    for (SegmentMinMax segmentMinMax : segmentMinMaxList) {
-      Map<String, SegmentBlockMinMaxInfo> segmentBlockMinMaxInfoMap =
-          segmentMinMax.getSegmentBlockMinMaxInfo();
-      int length = segmentBlockMinMaxInfoMap.size();
-      // Add columnSchemas based on the columns present in segment
-      List<ColumnSchema> columnSchemas = new ArrayList<>();
-      byte[][] min = new byte[length][];
-      byte[][] max = new byte[length][];
-      boolean[] minMaxFlag = new boolean[length];
-      int i = 0;
-
-      // get current columnSchema list for the table
-      Map<String, ColumnSchema> tableColumnSchemas =
-          this.getCarbonTable().getTableInfo().getFactTable().getListOfColumns().stream()
-              .collect(Collectors.toMap(ColumnSchema::getColumnUniqueId, ColumnSchema::clone));
-
-      // fill min,max and columnSchema values
-      for (Map.Entry<String, SegmentBlockMinMaxInfo> segmentBlockMinMaxInfo :
-          segmentBlockMinMaxInfoMap.entrySet()) {
-        ColumnSchema columnSchema = tableColumnSchemas.get(segmentBlockMinMaxInfo.getKey());
-        if (null != columnSchema) {
-          // get segment sort column and column drift info
-          boolean isSortColumnInBlock = segmentBlockMinMaxInfo.getValue().isSortColumn();
-          boolean isColumnDriftInBlock = segmentBlockMinMaxInfo.getValue().isColumnDrift();
-          if (null != columnSchema.getColumnProperties()) {
-            // get current sort column and column drift info
-            String isSortColumn =
-                columnSchema.getColumnProperties().get(CarbonCommonConstants.SORT_COLUMNS);
-            String isColumnDrift =
-                columnSchema.getColumnProperties().get(CarbonCommonConstants.COLUMN_DRIFT);
-            if (null != isSortColumn) {
-              if (isSortColumn.equalsIgnoreCase("true") && !isSortColumnInBlock) {
-                modifyColumnSchemaForSortColumn(columnSchema, isColumnDriftInBlock, isColumnDrift);
-              } else if (isSortColumn.equalsIgnoreCase("false") && isSortColumnInBlock) {
-                // modify column schema, if current columnSchema is changed
-                columnSchema.setSortColumn(true);
-                if (!columnSchema.isDimensionColumn()) {
-                  columnSchema.setDimensionColumn(true);
-                  columnSchema.getColumnProperties()
-                      .put(CarbonCommonConstants.COLUMN_DRIFT, "true");
-                }
-                columnSchema.getColumnProperties().put(CarbonCommonConstants.SORT_COLUMNS, "true");
-              }
-            } else {
+    Map<String, BlockColumnMetaDataInfo> segmentBlockMinMaxInfoMap =
+        segmentMetaDataINfo.getSegmentMetaDataInfo();
+    int length = segmentBlockMinMaxInfoMap.size();
+    // Add columnSchemas based on the columns present in segment
+    List<ColumnSchema> columnSchemas = new ArrayList<>();
+    byte[][] min = new byte[length][];
+    byte[][] max = new byte[length][];
+    boolean[] minMaxFlag = new boolean[length];
+    int i = 0;
+
+    // get current columnSchema list for the table
+    Map<String, ColumnSchema> tableColumnSchemas =
+        this.getCarbonTable().getTableInfo().getFactTable().getListOfColumns().stream()
+            .collect(Collectors.toMap(ColumnSchema::getColumnUniqueId, ColumnSchema::clone));
+
+    // fill min,max and columnSchema values
+    for (Map.Entry<String, BlockColumnMetaDataInfo> segmentBlockMinMaxInfo :
+        segmentBlockMinMaxInfoMap.entrySet()) {
+      ColumnSchema columnSchema = tableColumnSchemas.get(segmentBlockMinMaxInfo.getKey());
+      if (null != columnSchema) {
+        // get segment sort column and column drift info
+        boolean isSortColumnInBlock = segmentBlockMinMaxInfo.getValue().isSortColumn();
+        boolean isColumnDriftInBlock = segmentBlockMinMaxInfo.getValue().isColumnDrift();
+        if (null != columnSchema.getColumnProperties()) {
+          // get current sort column and column drift info
+          String isSortColumn =
+              columnSchema.getColumnProperties().get(CarbonCommonConstants.SORT_COLUMNS);
+          String isColumnDrift =
+              columnSchema.getColumnProperties().get(CarbonCommonConstants.COLUMN_DRIFT);
+          if (null != isSortColumn) {
+            if (isSortColumn.equalsIgnoreCase("true") && !isSortColumnInBlock) {
               modifyColumnSchemaForSortColumn(columnSchema, isColumnDriftInBlock, isColumnDrift);
+            } else if (isSortColumn.equalsIgnoreCase("false") && isSortColumnInBlock) {
+              // modify column schema, if current columnSchema is changed
+              columnSchema.setSortColumn(true);
+              if (!columnSchema.isDimensionColumn()) {
+                columnSchema.setDimensionColumn(true);
+                columnSchema.getColumnProperties().put(CarbonCommonConstants.COLUMN_DRIFT, "true");
+              }
+              columnSchema.getColumnProperties().put(CarbonCommonConstants.SORT_COLUMNS, "true");
             }
+          } else {
+            modifyColumnSchemaForSortColumn(columnSchema, isColumnDriftInBlock, isColumnDrift);
           }
-          columnSchemas.add(columnSchema);
-          min[i] = segmentBlockMinMaxInfo.getValue().getBlockMinValue();
-          max[i] = segmentBlockMinMaxInfo.getValue().getBlockMaxValue();
-          minMaxFlag[i] = min[i].length != 0 && max[i].length != 0;
-          i++;
         }
+        columnSchemas.add(columnSchema);
+        min[i] = segmentBlockMinMaxInfo.getValue().getBlockMinValue();
+        max[i] = segmentBlockMinMaxInfo.getValue().getBlockMaxValue();
+        minMaxFlag[i] = min[i].length != 0 && max[i].length != 0;
+        i++;
       }
-      // get segmentProperties using created columnSchemas list
-      SegmentProperties segmentProperties = SegmentPropertiesAndSchemaHolder.getInstance()
-          .addSegmentProperties(this.getCarbonTable(), columnSchemas, segment.getSegmentNo())
-          .getSegmentProperties();
-
-      FilterResolverIntf resolver =
-          new DataMapFilter(segmentProperties, this.getCarbonTable(), filter.getExpression())
-              .getResolver();
-      // prepare filter executer using datmapFilter resolver
-      FilterExecuter filterExecuter =
-          FilterUtil.getFilterExecuterTree(resolver, segmentProperties, null, null, false);
-      // check if block has to be pruned based on segment minmax
-      BitSet scanRequired = filterExecuter.isScanRequired(max, min, minMaxFlag);
-      if (!scanRequired.isEmpty()) {
-        isScanRequired = true;
-        break;
-      }
+    }
+    // get segmentProperties using created columnSchemas list
+    SegmentProperties segmentProperties = SegmentPropertiesAndSchemaHolder.getInstance()
+        .addSegmentProperties(this.getCarbonTable(), columnSchemas, segment.getSegmentNo())
+        .getSegmentProperties();
+
+    FilterResolverIntf resolver =
+        new DataMapFilter(segmentProperties, this.getCarbonTable(), filter.getExpression())
+            .getResolver();
+    // prepare filter executer using datmapFilter resolver
+    FilterExecuter filterExecuter =
+        FilterUtil.getFilterExecuterTree(resolver, segmentProperties, null, null, false);
+    // check if block has to be pruned based on segment minmax
+    BitSet scanRequired = filterExecuter.isScanRequired(max, min, minMaxFlag);
+    if (!scanRequired.isEmpty()) {
+      isScanRequired = true;
     }
     if (isScanRequired) {
       for (TableBlockIndexUniqueIdentifier tableBlockIndexUniqueIdentifier : identifiers) {
@@ -349,7 +345,8 @@ public Set<TableBlockIndexUniqueIdentifier> getTableBlockIndexUniqueIdentifiers(
     SegmentBlockIndexInfo segmentBlockIndexInfo = segmentMap.get(segment.getSegmentNo());
     Set<TableBlockIndexUniqueIdentifier> tableBlockIndexUniqueIdentifiers = null;
     if (null != segmentBlockIndexInfo) {
-      segment.setSegmentMinMax(segmentMap.get(segment.getSegmentNo()).getSegmentMinMax());
+      segment
+          .setSegmentMetaDataINfo(segmentMap.get(segment.getSegmentNo()).getSegmentMetaDataInfo());
       return segmentBlockIndexInfo.getTableBlockIndexUniqueIdentifiers();
     } else {
       tableBlockIndexUniqueIdentifiers =
@@ -357,7 +354,7 @@ public Set<TableBlockIndexUniqueIdentifier> getTableBlockIndexUniqueIdentifiers(
       if (tableBlockIndexUniqueIdentifiers.size() > 0) {
         segmentMap.put(segment.getSegmentNo(),
             new SegmentBlockIndexInfo(tableBlockIndexUniqueIdentifiers,
-                segment.getSegmentMinMax()));
+                segment.getSegmentMetaDataINfo()));
       }
     }
     return tableBlockIndexUniqueIdentifiers;
@@ -569,7 +566,7 @@ private List<TableBlockIndexUniqueIdentifierWrapper> getTableBlockIndexUniqueIde
       }
       segmentMap.put(distributable.getSegment().getSegmentNo(),
           new SegmentBlockIndexInfo(tableBlockIndexUniqueIdentifiers,
-              distributable.getSegment().getSegmentMinMax()));
+              distributable.getSegment().getSegmentMetaDataINfo()));
     } else {
       for (TableBlockIndexUniqueIdentifier tableBlockIndexUniqueIdentifier :
           tableBlockIndexUniqueIdentifiers) {
diff --git a/core/src/main/java/org/apache/carbondata/core/metadata/SegmentFileStore.java b/core/src/main/java/org/apache/carbondata/core/metadata/SegmentFileStore.java
index aefab7be5af..8be5920db26 100644
--- a/core/src/main/java/org/apache/carbondata/core/metadata/SegmentFileStore.java
+++ b/core/src/main/java/org/apache/carbondata/core/metadata/SegmentFileStore.java
@@ -58,10 +58,12 @@
 import org.apache.carbondata.core.statusmanager.SegmentStatus;
 import org.apache.carbondata.core.statusmanager.SegmentStatusManager;
 import org.apache.carbondata.core.statusmanager.SegmentUpdateStatusManager;
+import org.apache.carbondata.core.util.BlockColumnMetaDataInfo;
 import org.apache.carbondata.core.util.CarbonUtil;
 import org.apache.carbondata.core.util.DataFileFooterConverter;
 import org.apache.carbondata.core.util.ObjectSerializationUtil;
-import org.apache.carbondata.core.util.SegmentMinMax;
+import org.apache.carbondata.core.util.SegmentMetaDataInfo;
+import org.apache.carbondata.core.util.SegmentMetaDataInfoStats;
 import org.apache.carbondata.core.util.path.CarbonTablePath;
 
 import com.google.gson.Gson;
@@ -182,12 +184,12 @@ public static String genSegmentFileName(String segmentId, String UUID) {
    * @param carbonTable CarbonTable
    * @param segmentId segment id
    * @param UUID      a UUID string used to construct the segment file name
-   * @param segmentMinMaxList list of block level min and max values for segment
+   * @param segmentMetaDataINfo list of block level min and max values for segment
    * @return segment file name
    */
   public static String writeSegmentFile(CarbonTable carbonTable, String segmentId, String UUID,
-      List<SegmentMinMax> segmentMinMaxList) throws IOException {
-    return writeSegmentFile(carbonTable, segmentId, UUID, null, segmentMinMaxList);
+      SegmentMetaDataInfo segmentMetaDataINfo) throws IOException {
+    return writeSegmentFile(carbonTable, segmentId, UUID, null, segmentMetaDataINfo);
   }
 
   public static String writeSegmentFile(CarbonTable carbonTable, String segmentId, String UUID)
@@ -204,8 +206,8 @@ public static String writeSegmentFile(CarbonTable carbonTable, String segmentId,
    * @return segment file name
    */
   public static String writeSegmentFile(CarbonTable carbonTable, String segmentId, String UUID,
-      String segPath, List<SegmentMinMax> segmentMinMaxList) throws IOException {
-    return writeSegmentFile(carbonTable, segmentId, UUID, null, segPath, segmentMinMaxList);
+      String segPath, SegmentMetaDataInfo segmentMetaDataInfo) throws IOException {
+    return writeSegmentFile(carbonTable, segmentId, UUID, null, segPath, segmentMetaDataInfo);
   }
 
   public static String writeSegmentFile(CarbonTable carbonTable, String segmentId, String UUID,
@@ -327,7 +329,7 @@ public static boolean writeSegmentFileForOthers(
    * @throws IOException
    */
   public static String writeSegmentFile(CarbonTable carbonTable, String segmentId, String UUID,
-      final String currentLoadTimeStamp, String absSegPath, List<SegmentMinMax> segmentMinMaxList)
+      final String currentLoadTimeStamp, String absSegPath, SegmentMetaDataInfo segmentMetaDataInfo)
       throws IOException {
     String tablePath = carbonTable.getTablePath();
     boolean supportFlatFolder = carbonTable.isSupportFlatFolder();
@@ -370,8 +372,8 @@ public boolean accept(CarbonFile file) {
       }
       segmentFile.addPath(segmentRelativePath, folderDetails);
       // set segmentMinMax to segmentFile
-      if (null != segmentMinMaxList && !segmentMinMaxList.isEmpty()) {
-        segmentFile.setSegmentMinMax(segmentMinMaxList);
+      if (null != segmentMetaDataInfo) {
+        segmentFile.setSegmentMetaDataInfo(segmentMetaDataInfo);
       }
       String segmentFileFolder = CarbonTablePath.getSegmentFilesLocation(tablePath);
       CarbonFile carbonFile = FileFactory.getCarbonFile(segmentFileFolder);
@@ -1241,9 +1243,9 @@ public static class SegmentFile implements Serializable {
     private Map<String, String> options;
 
     /**
-     * Segment minMax List
+     * Segment minMax
      */
-    private String segmentMinMax;
+    private String segmentMetaDataInfo;
 
     SegmentFile() {
       locationMap = new HashMap<>();
@@ -1262,11 +1264,35 @@ public SegmentFile merge(SegmentFile segmentFile) throws IOException {
             locationMap.put(entry.getKey(), entry.getValue());
           }
         }
-        if (segmentMinMax != null && !segmentFile.getSegmentMinMax().isEmpty()) {
-          List<SegmentMinMax> segmentMinMaxList = new ArrayList<>(
-              (List<SegmentMinMax>) ObjectSerializationUtil.convertStringToObject(segmentMinMax));
-          segmentMinMaxList.addAll(segmentFile.getSegmentMinMax());
-          segmentMinMax = ObjectSerializationUtil.convertObjectToString(segmentMinMaxList);
+        if (segmentMetaDataInfo != null) {
+          SegmentMetaDataInfo currentSegmentMetaDataInfo =
+              (SegmentMetaDataInfo) ObjectSerializationUtil
+                  .convertStringToObject(segmentMetaDataInfo);
+          if (null != segmentFile.getSegmentMetaDataInfo()) {
+            // get updated blockColumnMetaDataInfo based on comparing block min-max values
+            Map<String, BlockColumnMetaDataInfo> previousBlockColumnMetaDataInfo =
+                segmentFile.getSegmentMetaDataInfo().getSegmentMetaDataInfo();
+            for (Map.Entry<String, BlockColumnMetaDataInfo> entry : previousBlockColumnMetaDataInfo
+                .entrySet()) {
+              if (currentSegmentMetaDataInfo.getSegmentMetaDataInfo()
+                  .containsKey(entry.getKey())) {
+                BlockColumnMetaDataInfo currentBlockMinMaxInfo =
+                    currentSegmentMetaDataInfo.getSegmentMetaDataInfo().get(entry.getKey());
+                byte[] blockMaxValue = SegmentMetaDataInfoStats.getInstance()
+                    .compareAndUpdateMinMax(currentBlockMinMaxInfo.getBlockMaxValue(),
+                        entry.getValue().getBlockMaxValue(), false);
+                byte[] blockMinValue = SegmentMetaDataInfoStats.getInstance()
+                    .compareAndUpdateMinMax(currentBlockMinMaxInfo.getBlockMinValue(),
+                        entry.getValue().getBlockMinValue(), true);
+                currentSegmentMetaDataInfo.getSegmentMetaDataInfo().get(entry.getKey())
+                    .setBlockMaxValue(blockMaxValue);
+                currentSegmentMetaDataInfo.getSegmentMetaDataInfo().get(entry.getKey())
+                    .setBlockMinValue(blockMinValue);
+              }
+            }
+          }
+          segmentMetaDataInfo =
+              ObjectSerializationUtil.convertObjectToString(currentSegmentMetaDataInfo);
         }
       }
       if (locationMap == null) {
@@ -1294,22 +1320,19 @@ public void setOptions(Map<String, String> options) {
       this.options = options;
     }
 
-    public List<SegmentMinMax> getSegmentMinMax() {
-      List<SegmentMinMax> segmentMinMaxList = null;
+    public SegmentMetaDataInfo getSegmentMetaDataInfo() {
+      SegmentMetaDataInfo newSegmentMetaDataInfo = null;
       try {
-        segmentMinMaxList =
-            (List<SegmentMinMax>) ObjectSerializationUtil.convertStringToObject(segmentMinMax);
+        newSegmentMetaDataInfo = (SegmentMetaDataInfo) ObjectSerializationUtil
+            .convertStringToObject(segmentMetaDataInfo);
       } catch (IOException e) {
         LOGGER.error("Error while getting segment minmax");
       }
-      if (null == segmentMinMaxList) {
-        return new ArrayList<>();
-      }
-      return segmentMinMaxList;
+      return newSegmentMetaDataInfo;
     }
 
-    public void setSegmentMinMax(List<SegmentMinMax> segmentMinMax) throws IOException {
-      this.segmentMinMax = ObjectSerializationUtil.convertObjectToString(segmentMinMax);
+    public void setSegmentMetaDataInfo(SegmentMetaDataInfo segmentMetaDataINfo) throws IOException {
+      this.segmentMetaDataInfo = ObjectSerializationUtil.convertObjectToString(segmentMetaDataINfo);
     }
   }
 
diff --git a/core/src/main/java/org/apache/carbondata/core/readcommitter/TableStatusReadCommittedScope.java b/core/src/main/java/org/apache/carbondata/core/readcommitter/TableStatusReadCommittedScope.java
index 6b5342de294..93678305672 100644
--- a/core/src/main/java/org/apache/carbondata/core/readcommitter/TableStatusReadCommittedScope.java
+++ b/core/src/main/java/org/apache/carbondata/core/readcommitter/TableStatusReadCommittedScope.java
@@ -86,7 +86,7 @@ public Map<String, String> getCommittedIndexFile(Segment segment) throws IOExcep
       SegmentFileStore fileStore =
           new SegmentFileStore(identifier.getTablePath(), segment.getSegmentFileName());
       indexFiles = fileStore.getIndexOrMergeFiles();
-      segment.setSegmentMinMax(fileStore.getSegmentFile().getSegmentMinMax());
+      segment.setSegmentMetaDataINfo(fileStore.getSegmentFile().getSegmentMetaDataInfo());
     }
     return indexFiles;
   }
diff --git a/core/src/main/java/org/apache/carbondata/core/util/SegmentBlockMinMaxInfo.java b/core/src/main/java/org/apache/carbondata/core/util/BlockColumnMetaDataInfo.java
similarity index 83%
rename from core/src/main/java/org/apache/carbondata/core/util/SegmentBlockMinMaxInfo.java
rename to core/src/main/java/org/apache/carbondata/core/util/BlockColumnMetaDataInfo.java
index be794eae5f6..3b4b154f915 100644
--- a/core/src/main/java/org/apache/carbondata/core/util/SegmentBlockMinMaxInfo.java
+++ b/core/src/main/java/org/apache/carbondata/core/util/BlockColumnMetaDataInfo.java
@@ -22,18 +22,26 @@
 /**
  * Represent min, max and alter sort column properties for each column in a block
  */
-public class SegmentBlockMinMaxInfo implements Serializable {
+public class BlockColumnMetaDataInfo implements Serializable {
 
   /**
    * true if column is a sort column
    */
   private boolean isSortColumn;
 
+  public void setBlockMinValue(byte[] blockMinValue) {
+    this.blockMinValue = blockMinValue;
+  }
+
   /**
    * block level  min value for a column
    */
   private byte[] blockMinValue;
 
+  public void setBlockMaxValue(byte[] blockMaxValue) {
+    this.blockMaxValue = blockMaxValue;
+  }
+
   /**
    * block level max value for a column
    */
@@ -44,7 +52,7 @@ public class SegmentBlockMinMaxInfo implements Serializable {
    */
   private boolean isColumnDrift;
 
-  public SegmentBlockMinMaxInfo(boolean isSortColumn, byte[] blockMinValue, byte[] blockMaxValue,
+  public BlockColumnMetaDataInfo(boolean isSortColumn, byte[] blockMinValue, byte[] blockMaxValue,
       boolean isColumnDrift) {
     this.isSortColumn = isSortColumn;
     this.blockMinValue = blockMinValue;
diff --git a/core/src/main/java/org/apache/carbondata/core/util/SegmentMinMax.java b/core/src/main/java/org/apache/carbondata/core/util/SegmentMetaDataInfo.java
similarity index 67%
rename from core/src/main/java/org/apache/carbondata/core/util/SegmentMinMax.java
rename to core/src/main/java/org/apache/carbondata/core/util/SegmentMetaDataInfo.java
index 18d9446c7f9..64385e9eefe 100644
--- a/core/src/main/java/org/apache/carbondata/core/util/SegmentMinMax.java
+++ b/core/src/main/java/org/apache/carbondata/core/util/SegmentMetaDataInfo.java
@@ -23,18 +23,23 @@
 /**
  *  Represent SegmentBlockMinMaxInfo for each block in a segment
  */
-public class SegmentMinMax implements Serializable {
+public class SegmentMetaDataInfo implements Serializable {
 
   /**
    * Map of Column id's and it's block level min,max and isSortColumn values
    */
-  private Map<String, SegmentBlockMinMaxInfo> segmentBlockMinMaxInfo;
+  private Map<String, BlockColumnMetaDataInfo> segmentMetaDataInfo;
 
-  SegmentMinMax(Map<String, SegmentBlockMinMaxInfo> segmentBlockMinMaxInfo) {
-    this.segmentBlockMinMaxInfo = segmentBlockMinMaxInfo;
+  SegmentMetaDataInfo(Map<String, BlockColumnMetaDataInfo> segmentMetaDataInfo) {
+    this.segmentMetaDataInfo = segmentMetaDataInfo;
   }
 
-  public Map<String, SegmentBlockMinMaxInfo> getSegmentBlockMinMaxInfo() {
-    return segmentBlockMinMaxInfo;
+  public Map<String, BlockColumnMetaDataInfo> getSegmentMetaDataInfo() {
+    return segmentMetaDataInfo;
+  }
+
+  public void setSegmentMetaDataInfo(
+      Map<String, BlockColumnMetaDataInfo> segmentMetaDataInfo) {
+    this.segmentMetaDataInfo = segmentMetaDataInfo;
   }
 }
diff --git a/core/src/main/java/org/apache/carbondata/core/util/SegmentMetaDataInfoStats.java b/core/src/main/java/org/apache/carbondata/core/util/SegmentMetaDataInfoStats.java
new file mode 100644
index 00000000000..ddee2c6e032
--- /dev/null
+++ b/core/src/main/java/org/apache/carbondata/core/util/SegmentMetaDataInfoStats.java
@@ -0,0 +1,119 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.carbondata.core.util;
+
+import java.util.HashMap;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+
+/**
+ * Holds segment level meta data information such as min,max, sortColumn info for the
+ * corresponding table
+ */
+public class SegmentMetaDataInfoStats {
+
+  private SegmentMetaDataInfoStats() {
+    tableSegmentMetaDataInfo = new ConcurrentHashMap<>();
+  }
+
+  public static SegmentMetaDataInfoStats getInstance() {
+    if (null == segmentMetaDataInfoStats) {
+      segmentMetaDataInfoStats = new SegmentMetaDataInfoStats();
+      return segmentMetaDataInfoStats;
+    } else {
+      return segmentMetaDataInfoStats;
+    }
+  }
+
+  private Map<String, Map<String, SegmentMetaDataInfo>> tableSegmentMetaDataInfo;
+
+  private static SegmentMetaDataInfoStats segmentMetaDataInfoStats;
+
+  public Map<String, Map<String, SegmentMetaDataInfo>> getTableSegmentMetaDataInfo() {
+    return tableSegmentMetaDataInfo;
+  }
+
+  public synchronized void setBlockMetaDataInfo(String tableName, String segmentId,
+      Map<String, BlockColumnMetaDataInfo> currentBlockColumnMetaInfo) {
+    // check if tableName is present in segmentMinMaxMap
+    if (!this.tableSegmentMetaDataInfo.isEmpty() && null != this.tableSegmentMetaDataInfo
+        .get(tableName) && !this.tableSegmentMetaDataInfo.get(tableName).isEmpty()
+        && null != this.tableSegmentMetaDataInfo.get(tableName).get(segmentId)) {
+      Map<String, BlockColumnMetaDataInfo> previousBlockColumnMetaInfo =
+          this.tableSegmentMetaDataInfo.get(tableName).get(segmentId).getSegmentMetaDataInfo();
+      for (Map.Entry<String, BlockColumnMetaDataInfo> entry : previousBlockColumnMetaInfo
+          .entrySet()) {
+        if (currentBlockColumnMetaInfo.containsKey(entry.getKey())) {
+          BlockColumnMetaDataInfo currentBlockMinMaxInfo =
+              currentBlockColumnMetaInfo.get(entry.getKey());
+          byte[] blockMaxValue = compareAndUpdateMinMax(currentBlockMinMaxInfo.getBlockMaxValue(),
+              entry.getValue().getBlockMaxValue(), false);
+          byte[] blockMinValue = compareAndUpdateMinMax(currentBlockMinMaxInfo.getBlockMinValue(),
+              entry.getValue().getBlockMinValue(), true);
+          currentBlockColumnMetaInfo.get(entry.getKey()).setBlockMaxValue(blockMaxValue);
+          currentBlockColumnMetaInfo.get(entry.getKey()).setBlockMinValue(blockMinValue);
+        }
+      }
+      this.tableSegmentMetaDataInfo.get(tableName).get(segmentId)
+          .setSegmentMetaDataInfo(currentBlockColumnMetaInfo);
+    } else {
+      Map<String, SegmentMetaDataInfo> segmentMinMaxMap = new HashMap<>();
+      if (null != this.tableSegmentMetaDataInfo.get(tableName) && !this.tableSegmentMetaDataInfo
+          .get(tableName).isEmpty()) {
+        segmentMinMaxMap = this.tableSegmentMetaDataInfo.get(tableName);
+      }
+      segmentMinMaxMap.put(segmentId, new SegmentMetaDataInfo(currentBlockColumnMetaInfo));
+      this.tableSegmentMetaDataInfo.put(tableName, segmentMinMaxMap);
+    }
+  }
+
+  /**
+   * Clear the corresponding segmentId and tableName from the segmentMinMaxMap
+   */
+  public void clear(String tableName, String segmentId) {
+    if (null != tableSegmentMetaDataInfo.get(tableName)) {
+      if (null != tableSegmentMetaDataInfo.get(tableName).get(segmentId)) {
+        tableSegmentMetaDataInfo.get(tableName).remove(segmentId);
+      }
+      if (tableSegmentMetaDataInfo.get(tableName).isEmpty()) {
+        tableSegmentMetaDataInfo.remove(tableName);
+      }
+    }
+  }
+
+  /**
+   * This method will do min/max comparison of values and update if required
+   */
+  public synchronized byte[] compareAndUpdateMinMax(byte[] minMaxValueCompare1,
+      byte[] minMaxValueCompare2, boolean isMinValueComparison) {
+    // Compare and update min max values
+    byte[] updatedMinMaxValues = new byte[minMaxValueCompare1.length];
+    System.arraycopy(minMaxValueCompare1, 0, updatedMinMaxValues, 0, minMaxValueCompare1.length);
+    int compare =
+        ByteUtil.UnsafeComparer.INSTANCE.compareTo(minMaxValueCompare2, minMaxValueCompare1);
+    if (isMinValueComparison) {
+      if (compare < 0) {
+        updatedMinMaxValues = minMaxValueCompare2;
+      }
+    } else if (compare > 0) {
+      updatedMinMaxValues = minMaxValueCompare2;
+    }
+    return updatedMinMaxValues;
+  }
+
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/apache/carbondata/core/util/SegmentMinMaxStats.java b/core/src/main/java/org/apache/carbondata/core/util/SegmentMinMaxStats.java
deleted file mode 100644
index c8d4db1f391..00000000000
--- a/core/src/main/java/org/apache/carbondata/core/util/SegmentMinMaxStats.java
+++ /dev/null
@@ -1,96 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.carbondata.core.util;
-
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.concurrent.ConcurrentHashMap;
-
-/**
- * Holds list of block level min max of each segment for the corresponding table
- */
-public class SegmentMinMaxStats {
-
-  private SegmentMinMaxStats() {
-    tableSegmentMinMaxMap = new ConcurrentHashMap<>();
-  }
-
-  public static SegmentMinMaxStats getInstance() {
-    if (null == segmentMinMaxStats) {
-      segmentMinMaxStats = new SegmentMinMaxStats();
-      return segmentMinMaxStats;
-    } else {
-      return segmentMinMaxStats;
-    }
-  }
-
-  private Map<String, Map<String, List<SegmentMinMax>>> tableSegmentMinMaxMap;
-
-  private static SegmentMinMaxStats segmentMinMaxStats;
-
-  public Map<String, Map<String, List<SegmentMinMax>>> getTableSegmentMinMaxMap() {
-    return tableSegmentMinMaxMap;
-  }
-
-  public synchronized void setSegmentMinMaxList(String tableName, String segmentId,
-      Map<String, SegmentBlockMinMaxInfo> segmentBlockMinMaxInfo) {
-    // check if tableName is present in segmentMinMaxMap
-    if (!this.tableSegmentMinMaxMap.isEmpty() && null != this.tableSegmentMinMaxMap.get(tableName)
-        && !this.tableSegmentMinMaxMap.get(tableName).isEmpty()
-        && null != this.tableSegmentMinMaxMap.get(tableName).get(segmentId)) {
-      this.tableSegmentMinMaxMap.get(tableName).get(segmentId)
-          .add(new SegmentMinMax(segmentBlockMinMaxInfo));
-    } else {
-      addSegmentEntryToMap(tableName, segmentId, segmentBlockMinMaxInfo);
-    }
-  }
-
-  /**
-   * Add's a list of block level minMax info of a segment to the
-   * corresponding table name
-   */
-  private void addSegmentEntryToMap(String tableName, String segmentId,
-      Map<String, SegmentBlockMinMaxInfo> segmentBlockMinMaxInfo) {
-    Map<String, List<SegmentMinMax>> segmentMinMaxMap = new HashMap<>();
-    if (null != this.tableSegmentMinMaxMap.get(tableName) && !this.tableSegmentMinMaxMap
-        .get(tableName).isEmpty()) {
-      segmentMinMaxMap = this.tableSegmentMinMaxMap.get(tableName);
-    }
-    List<SegmentMinMax> blockMinMaxList = new ArrayList<>();
-    blockMinMaxList.add(new SegmentMinMax(segmentBlockMinMaxInfo));
-    segmentMinMaxMap.put(segmentId, blockMinMaxList);
-    this.tableSegmentMinMaxMap.put(tableName, segmentMinMaxMap);
-  }
-
-  /**
-   * Clear the corresponding segmentId and tableName from the segmentMinMaxMap
-   */
-  public void clear(String tableName, String segmentId) {
-    if (null != tableSegmentMinMaxMap.get(tableName)) {
-      if (null != tableSegmentMinMaxMap.get(tableName).get(segmentId)) {
-        tableSegmentMinMaxMap.get(tableName).remove(segmentId);
-      }
-      if (tableSegmentMinMaxMap.get(tableName).isEmpty()) {
-        tableSegmentMinMaxMap.remove(tableName);
-      }
-    }
-  }
-
-}
\ No newline at end of file
diff --git a/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/CarbonDataRDDFactory.scala b/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/CarbonDataRDDFactory.scala
index 4c179d8652e..83af1eb0e40 100644
--- a/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/CarbonDataRDDFactory.scala
+++ b/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/CarbonDataRDDFactory.scala
@@ -58,7 +58,7 @@ import org.apache.carbondata.core.metadata.{CarbonTableIdentifier, ColumnarForma
 import org.apache.carbondata.core.metadata.schema.table.CarbonTable
 import org.apache.carbondata.core.mutate.CarbonUpdateUtil
 import org.apache.carbondata.core.statusmanager.{LoadMetadataDetails, SegmentStatus, SegmentStatusManager}
-import org.apache.carbondata.core.util.{CarbonProperties, CarbonUtil, SegmentMinMax, SegmentMinMaxStats, ThreadLocalSessionInfo}
+import org.apache.carbondata.core.util.{CarbonProperties, CarbonUtil, SegmentMetaDataInfo, SegmentMetaDataInfoStats, ThreadLocalSessionInfo}
 import org.apache.carbondata.core.util.path.CarbonTablePath
 import org.apache.carbondata.events.{OperationContext, OperationListenerBus}
 import org.apache.carbondata.indexserver.{DistributedRDDUtils, IndexServer}
@@ -318,9 +318,9 @@ object CarbonDataRDDFactory {
     var status: Array[(String, (LoadMetadataDetails, ExecutionErrors))] = null
     var res: Array[List[(String, (LoadMetadataDetails, ExecutionErrors))]] = null
     // accumulator to collect segment minmax
-    val segmentMinMaxAccumulator = sqlContext
+    val segmentMetaDataAccumulator = sqlContext
       .sparkContext
-      .collectionAccumulator[Map[String, List[SegmentMinMax]]]
+      .collectionAccumulator[Map[String, SegmentMetaDataInfo]]
     // create new segment folder  in carbon store
     if (updateModel.isEmpty && carbonLoadModel.isCarbonTransactionalTable) {
       CarbonLoaderUtil.checkAndCreateCarbonDataLocation(carbonLoadModel.getSegmentId, carbonTable)
@@ -344,7 +344,7 @@ object CarbonDataRDDFactory {
             updateModel,
             carbonTable,
             hadoopConf,
-            segmentMinMaxAccumulator)
+            segmentMetaDataAccumulator)
           res.foreach { resultOfSeg =>
             resultOfSeg.foreach { resultOfBlock =>
               if (resultOfBlock._2._1.getSegmentStatus == SegmentStatus.LOAD_FAILURE) {
@@ -384,7 +384,7 @@ object CarbonDataRDDFactory {
                 None,
                 Some(convertedRdd),
                 carbonLoadModel,
-                segmentMinMaxAccumulator)
+                segmentMetaDataAccumulator)
             }
           } else {
             if (dataFrame.isEmpty && isSortTable &&
@@ -399,9 +399,13 @@ object CarbonDataRDDFactory {
                 carbonLoadModel,
                 hadoopConf)
             } else if (dataFrame.isDefined) {
-              loadDataFrame(sqlContext, dataFrame, None, carbonLoadModel, segmentMinMaxAccumulator)
+              loadDataFrame(sqlContext,
+                dataFrame,
+                None,
+                carbonLoadModel,
+                segmentMetaDataAccumulator)
             } else {
-              loadDataFile(sqlContext, carbonLoadModel, hadoopConf, segmentMinMaxAccumulator)
+              loadDataFile(sqlContext, carbonLoadModel, hadoopConf, segmentMetaDataAccumulator)
             }
           }
           val newStatusMap = scala.collection.mutable.Map.empty[String, SegmentStatus]
@@ -488,16 +492,16 @@ object CarbonDataRDDFactory {
             segmentDetails.add(new Segment(resultOfBlock._2._1.getLoadName))
           }
         }
-        var segmentMinMaxMap: Map[String, List[SegmentMinMax]] = Map()
-        if (!segmentMinMaxAccumulator.isZero) {
-          segmentMinMaxAccumulator.value.asScala.foreach(map => if (map.nonEmpty) {
-            segmentMinMaxMap = segmentMinMaxMap ++ map
+        var segmentMetaDataInfoMap = scala.collection.mutable.Map.empty[String, SegmentMetaDataInfo]
+        if (!segmentMetaDataAccumulator.isZero) {
+          segmentMetaDataAccumulator.value.asScala.foreach(map => if (map.nonEmpty) {
+            segmentMetaDataInfoMap = segmentMetaDataInfoMap ++ map
           })
         }
         val segmentFiles = updateSegmentFiles(carbonTable,
           segmentDetails,
           updateModel.get,
-          segmentMinMaxMap.mapValues(_.asJava).asJava)
+          segmentMetaDataInfoMap.asJava)
 
         // this means that the update doesnt have any records to update so no need to do table
         // status file updation.
@@ -570,9 +574,9 @@ object CarbonDataRDDFactory {
         }
 
       val segmentMinMax =
-        if (!segmentMinMaxAccumulator.isZero &&
-            segmentMinMaxAccumulator.value.get(0).contains(carbonLoadModel.getSegmentId)) {
-          segmentMinMaxAccumulator.value.get(0)(carbonLoadModel.getSegmentId).asJava
+        if (!segmentMetaDataAccumulator.isZero &&
+            segmentMetaDataAccumulator.value.get(0).contains(carbonLoadModel.getSegmentId)) {
+          segmentMetaDataAccumulator.value.get(0)(carbonLoadModel.getSegmentId)
         } else {
           null
         }
@@ -694,7 +698,7 @@ object CarbonDataRDDFactory {
       carbonTable: CarbonTable,
       segmentDetails: util.HashSet[Segment],
       updateModel: UpdateTableModel,
-      segmentMinMaxMap: util.Map[String, util.List[SegmentMinMax]]) = {
+      segmentMetaDataInfoMap: util.Map[String, SegmentMetaDataInfo]) = {
     val metadataDetails =
       SegmentStatusManager.readTableStatusFile(
         CarbonTablePath.getTableStatusFilePath(carbonTable.getTablePath))
@@ -704,7 +708,7 @@ object CarbonDataRDDFactory {
       val segmentFile = load.getSegmentFile
       var segmentFiles: Seq[CarbonFile] = Seq.empty[CarbonFile]
 
-      val value = segmentMinMaxMap.get(seg.getSegmentNo)
+      val value = segmentMetaDataInfoMap.get(seg.getSegmentNo)
       val file = SegmentFileStore.writeSegmentFile(
         carbonTable,
         seg.getSegmentNo,
@@ -750,7 +754,7 @@ object CarbonDataRDDFactory {
       updateModel: Option[UpdateTableModel],
       carbonTable: CarbonTable,
       hadoopConf: Configuration,
-      segmentMinMaxAccumulator: CollectionAccumulator[Map[String, List[SegmentMinMax]]]
+      blockMetaDataAccumulator: CollectionAccumulator[Map[String, SegmentMetaDataInfo]]
   ): Array[List[(String, (LoadMetadataDetails, ExecutionErrors))]] = {
     val segmentUpdateParallelism = CarbonProperties.getInstance().getParallelismForSegmentUpdate
 
@@ -805,7 +809,7 @@ object CarbonDataRDDFactory {
           segId.getSegmentNo,
           newTaskNo,
           partition,
-          segmentMinMaxAccumulator).toList).toIterator
+          blockMetaDataAccumulator).toList).toIterator
       }.collect()
     }
   }
@@ -819,7 +823,7 @@ object CarbonDataRDDFactory {
       key: String,
       taskNo: Long,
       iter: Iterator[Row],
-      segmentMinMaxAccumulator: CollectionAccumulator[Map[String, List[SegmentMinMax]]]
+      blockMetaDataAccumulator: CollectionAccumulator[Map[String, SegmentMetaDataInfo]]
   ): Iterator[(String, (LoadMetadataDetails, ExecutionErrors))] = {
     val rddResult = new updateResultImpl()
     val LOGGER = LogServiceFactory.getLogService(this.getClass.getName)
@@ -846,7 +850,7 @@ object CarbonDataRDDFactory {
           iter,
           carbonLoadModel,
           loadMetadataDetails,
-          segmentMinMaxAccumulator)
+          blockMetaDataAccumulator)
       } catch {
         case e: NoRetryException =>
           loadMetadataDetails
@@ -1030,7 +1034,7 @@ object CarbonDataRDDFactory {
       dataFrame: Option[DataFrame],
       scanResultRDD: Option[RDD[InternalRow]],
       carbonLoadModel: CarbonLoadModel,
-      segmentMinMaxAccumulator: CollectionAccumulator[Map[String, List[SegmentMinMax]]]
+      segmentMetaDataAccumulator: CollectionAccumulator[Map[String, SegmentMetaDataInfo]]
   ): Array[(String, (LoadMetadataDetails, ExecutionErrors))] = {
     try {
       val rdd = if (dataFrame.isDefined) {
@@ -1061,7 +1065,7 @@ object CarbonDataRDDFactory {
         new DataLoadResultImpl(),
         carbonLoadModel,
         newRdd,
-        segmentMinMaxAccumulator
+        segmentMetaDataAccumulator
       ).collect()
     } catch {
       case ex: Exception =>
@@ -1077,7 +1081,7 @@ object CarbonDataRDDFactory {
       sqlContext: SQLContext,
       carbonLoadModel: CarbonLoadModel,
       hadoopConf: Configuration,
-      segmentMinMaxAccumulator: CollectionAccumulator[Map[String, List[SegmentMinMax]]]
+      segmentMetaDataAccumulator: CollectionAccumulator[Map[String, SegmentMetaDataInfo]]
   ): Array[(String, (LoadMetadataDetails, ExecutionErrors))] = {
     /*
      * when data load handle by node partition
@@ -1173,23 +1177,23 @@ object CarbonDataRDDFactory {
       new DataLoadResultImpl(),
       carbonLoadModel,
       blocksGroupBy,
-      segmentMinMaxAccumulator
+      segmentMetaDataAccumulator
     ).collect()
   }
 
   /**
    * Fill segment level min max to accumulator based on tableName and segmentId
    */
-  def fillSegmentMinMaxToAccumulator(
+  def fillSegmentMetaDataInfoToAccumulator(
       tableName: String,
       segmentId: String,
-      segmentMinMaxAccumulator: CollectionAccumulator[Map[String, List[SegmentMinMax]]]): Unit = {
-    val tableSegmentMinMax = SegmentMinMaxStats.getInstance().getTableSegmentMinMaxMap
+      segmentMetaDataAccumulator: CollectionAccumulator[Map[String, SegmentMetaDataInfo]]): Unit = {
+    val tableSegmentMinMax = SegmentMetaDataInfoStats.getInstance().getTableSegmentMetaDataInfo
       .get(tableName)
     if (null != tableSegmentMinMax && null != tableSegmentMinMax.get(segmentId)) {
-      val segmentMinMaxList = tableSegmentMinMax.get(segmentId).asScala.toList
-      segmentMinMaxAccumulator.add(scala.Predef.Map(segmentId -> segmentMinMaxList))
-      SegmentMinMaxStats.getInstance().clear(tableName, segmentId)
+      segmentMetaDataAccumulator.add(scala.Predef
+        .Map(segmentId -> tableSegmentMinMax.get(segmentId)))
+      SegmentMetaDataInfoStats.getInstance().clear(tableName, segmentId)
     }
   }
 }
diff --git a/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/InsertTaskCompletionListener.scala b/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/InsertTaskCompletionListener.scala
index 546969c98cc..1c97d630116 100644
--- a/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/InsertTaskCompletionListener.scala
+++ b/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/InsertTaskCompletionListener.scala
@@ -17,29 +17,27 @@
 
 package org.apache.carbondata.spark.rdd
 
-import scala.collection.JavaConverters._
-
 import org.apache.spark.TaskContext
 import org.apache.spark.sql.carbondata.execution.datasources.tasklisteners.CarbonLoadTaskCompletionListener
 import org.apache.spark.sql.execution.command.ExecutionErrors
 import org.apache.spark.util.CollectionAccumulator
 
-import org.apache.carbondata.core.util.{DataTypeUtil, SegmentMinMax, SegmentMinMaxStats, ThreadLocalTaskInfo}
+import org.apache.carbondata.core.util.{DataTypeUtil, SegmentMetaDataInfo, SegmentMetaDataInfoStats, ThreadLocalTaskInfo}
 import org.apache.carbondata.processing.loading.{DataLoadExecutor, FailureCauses}
 import org.apache.carbondata.spark.util.CommonUtil
 
 class InsertTaskCompletionListener(dataLoadExecutor: DataLoadExecutor,
     executorErrors: ExecutionErrors,
-    segmentMinMaxAccumulator: CollectionAccumulator[Map[String, List[SegmentMinMax]]],
+    segmentMetaDataAccumulator: CollectionAccumulator[Map[String, SegmentMetaDataInfo]],
     tableName: String,
     segmentId: String)
   extends CarbonLoadTaskCompletionListener {
   override def onTaskCompletion(context: TaskContext): Unit = {
     try {
       // fill segment level minMax to accumulator
-      CarbonDataRDDFactory.fillSegmentMinMaxToAccumulator(tableName,
+      CarbonDataRDDFactory.fillSegmentMetaDataInfoToAccumulator(tableName,
         segmentId,
-        segmentMinMaxAccumulator)
+        segmentMetaDataAccumulator)
       dataLoadExecutor.close()
     }
     catch {
diff --git a/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/NewCarbonDataLoadRDD.scala b/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/NewCarbonDataLoadRDD.scala
index 24890a8e8ca..8d975b87683 100644
--- a/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/NewCarbonDataLoadRDD.scala
+++ b/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/NewCarbonDataLoadRDD.scala
@@ -40,7 +40,7 @@ import org.apache.carbondata.core.constants.CarbonCommonConstants
 import org.apache.carbondata.core.datastore.impl.FileFactory
 import org.apache.carbondata.core.metadata.datatype.DataTypes
 import org.apache.carbondata.core.statusmanager.{LoadMetadataDetails, SegmentStatus}
-import org.apache.carbondata.core.util.{CarbonProperties, CarbonTimeStatisticsFactory, DataTypeUtil, SegmentMinMax}
+import org.apache.carbondata.core.util.{CarbonProperties, CarbonTimeStatisticsFactory, DataTypeUtil, SegmentMetaDataInfo}
 import org.apache.carbondata.core.util.path.CarbonTablePath
 import org.apache.carbondata.processing.loading.{DataLoadExecutor, FailureCauses, TableProcessingOperations}
 import org.apache.carbondata.processing.loading.csvinput.{BlockDetails, CSVInputFormat, CSVRecordReaderIterator}
@@ -101,7 +101,7 @@ class NewCarbonDataLoadRDD[K, V](
     result: DataLoadResult[K, V],
     carbonLoadModel: CarbonLoadModel,
     blocksGroupBy: Array[(String, Array[BlockDetails])],
-    segmentMinMaxAccumulator: CollectionAccumulator[Map[String, List[SegmentMinMax]]])
+    segmentMetaDataAccumulator: CollectionAccumulator[Map[String, SegmentMetaDataInfo]])
   extends CarbonRDD[(K, V)](ss, Nil) {
 
   ss.sparkContext.setLocalProperty("spark.scheduler.pool", "DDL")
@@ -150,7 +150,7 @@ class NewCarbonDataLoadRDD[K, V](
           .addTaskCompletionListener {
             new InsertTaskCompletionListener(executor,
               executionErrors,
-              segmentMinMaxAccumulator,
+              segmentMetaDataAccumulator,
               model.getTableName,
               model.getSegment.getSegmentNo)
           }
@@ -255,7 +255,7 @@ class NewDataFrameLoaderRDD[K, V](
     result: DataLoadResult[K, V],
     carbonLoadModel: CarbonLoadModel,
     prev: DataLoadCoalescedRDD[_],
-    segmentMinMaxAccumulator: CollectionAccumulator[Map[String, List[SegmentMinMax]]]
+    segmentMetaDataAccumulator: CollectionAccumulator[Map[String, SegmentMetaDataInfo]]
     ) extends CarbonRDD[(K, V)](ss, prev) {
 
   override def internalCompute(theSplit: Partition, context: TaskContext): Iterator[(K, V)] = {
@@ -309,7 +309,7 @@ class NewDataFrameLoaderRDD[K, V](
         context
           .addTaskCompletionListener(new InsertTaskCompletionListener(executor,
             executionErrors,
-            segmentMinMaxAccumulator,
+            segmentMetaDataAccumulator,
             carbonLoadModel.getTableName,
             carbonLoadModel.getSegment.getSegmentNo))
         executor.execute(model, loader.storeLocation, recordReaders.toArray)
diff --git a/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/UpdateDataLoad.scala b/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/UpdateDataLoad.scala
index 926e8deff41..6ddc8e4bdd0 100644
--- a/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/UpdateDataLoad.scala
+++ b/integration/spark/src/main/scala/org/apache/carbondata/spark/rdd/UpdateDataLoad.scala
@@ -17,7 +17,6 @@
 
 package org.apache.carbondata.spark.rdd
 
-import scala.collection.JavaConverters._
 import scala.collection.mutable
 
 import org.apache.spark.TaskContext
@@ -27,7 +26,7 @@ import org.apache.spark.util.CollectionAccumulator
 import org.apache.carbondata.common.CarbonIterator
 import org.apache.carbondata.common.logging.LogServiceFactory
 import org.apache.carbondata.core.statusmanager.{LoadMetadataDetails, SegmentStatus}
-import org.apache.carbondata.core.util.{SegmentMinMax, SegmentMinMaxStats, ThreadLocalTaskInfo}
+import org.apache.carbondata.core.util.{SegmentMetaDataInfo, ThreadLocalTaskInfo}
 import org.apache.carbondata.processing.loading.{DataLoadExecutor, TableProcessingOperations}
 import org.apache.carbondata.processing.loading.model.CarbonLoadModel
 import org.apache.carbondata.spark.util.CommonUtil
@@ -43,7 +42,7 @@ object UpdateDataLoad {
       iter: Iterator[Row],
       carbonLoadModel: CarbonLoadModel,
       loadMetadataDetails: LoadMetadataDetails,
-      segmentMinMaxAccumulator: CollectionAccumulator[Map[String, List[SegmentMinMax]]]): Unit = {
+      segmentMetaDataAccumulator: CollectionAccumulator[Map[String, SegmentMetaDataInfo]]): Unit = {
     val LOGGER = LogServiceFactory.getLogService(this.getClass.getCanonicalName)
     try {
       val recordReaders = mutable.Buffer[CarbonIterator[Array[AnyRef]]]()
@@ -62,9 +61,9 @@ object UpdateDataLoad {
       val executor = new DataLoadExecutor
       TaskContext.get().addTaskCompletionListener { context =>
         // fill segment level minMax to accumulator
-      CarbonDataRDDFactory.fillSegmentMinMaxToAccumulator(carbonLoadModel.getTableName,
+      CarbonDataRDDFactory.fillSegmentMetaDataInfoToAccumulator(carbonLoadModel.getTableName,
           segId,
-          segmentMinMaxAccumulator)
+          segmentMetaDataAccumulator)
         executor.close()
         CommonUtil.clearUnsafeMemory(ThreadLocalTaskInfo.getCarbonTaskInfo.getTaskId)
       }
diff --git a/integration/spark/src/main/scala/org/apache/spark/sql/execution/command/management/CarbonInsertFromStageCommand.scala b/integration/spark/src/main/scala/org/apache/spark/sql/execution/command/management/CarbonInsertFromStageCommand.scala
index 4ffc53d03bc..0430e744b51 100644
--- a/integration/spark/src/main/scala/org/apache/spark/sql/execution/command/management/CarbonInsertFromStageCommand.scala
+++ b/integration/spark/src/main/scala/org/apache/spark/sql/execution/command/management/CarbonInsertFromStageCommand.scala
@@ -40,7 +40,7 @@ import org.apache.carbondata.core.locks.{CarbonLockFactory, CarbonLockUtil, ICar
 import org.apache.carbondata.core.metadata.{ColumnarFormatVersion, SegmentFileStore}
 import org.apache.carbondata.core.metadata.schema.table.CarbonTable
 import org.apache.carbondata.core.statusmanager.{SegmentStatus, SegmentStatusManager, StageInput}
-import org.apache.carbondata.core.util.SegmentMinMax
+import org.apache.carbondata.core.util.SegmentMetaDataInfo
 import org.apache.carbondata.core.util.path.CarbonTablePath
 import org.apache.carbondata.hadoop.CarbonInputSplit
 import org.apache.carbondata.processing.loading.FailureCauses
@@ -298,7 +298,7 @@ case class CarbonInsertFromStageCommand(
           Option(dataFrame),
           None,
           loadModel,
-          spark.sqlContext.sparkContext.collectionAccumulator[Map[String, List[SegmentMinMax]]])
+          spark.sqlContext.sparkContext.collectionAccumulator[Map[String, SegmentMetaDataInfo]])
       }
       LOGGER.info(s"finish data loading, time taken ${System.currentTimeMillis() - start}ms")
 
diff --git a/processing/src/main/java/org/apache/carbondata/processing/store/writer/AbstractFactDataWriter.java b/processing/src/main/java/org/apache/carbondata/processing/store/writer/AbstractFactDataWriter.java
index f78913d30c8..37ed07b1ce6 100644
--- a/processing/src/main/java/org/apache/carbondata/processing/store/writer/AbstractFactDataWriter.java
+++ b/processing/src/main/java/org/apache/carbondata/processing/store/writer/AbstractFactDataWriter.java
@@ -43,13 +43,13 @@
 import org.apache.carbondata.core.metadata.converter.ThriftWrapperSchemaConverterImpl;
 import org.apache.carbondata.core.metadata.index.BlockIndexInfo;
 import org.apache.carbondata.core.metadata.schema.table.column.ColumnSchema;
+import org.apache.carbondata.core.util.BlockColumnMetaDataInfo;
 import org.apache.carbondata.core.util.CarbonMetadataUtil;
 import org.apache.carbondata.core.util.CarbonProperties;
 import org.apache.carbondata.core.util.CarbonThreadFactory;
 import org.apache.carbondata.core.util.CarbonUtil;
 import org.apache.carbondata.core.util.OutputFilesInfoHolder;
-import org.apache.carbondata.core.util.SegmentBlockMinMaxInfo;
-import org.apache.carbondata.core.util.SegmentMinMaxStats;
+import org.apache.carbondata.core.util.SegmentMetaDataInfoStats;
 import org.apache.carbondata.core.util.path.CarbonTablePath;
 import org.apache.carbondata.core.writer.CarbonIndexFileWriter;
 import org.apache.carbondata.format.BlockIndex;
@@ -396,7 +396,7 @@ protected void writeIndexFile() throws IOException, CarbonDataWriterException {
     // get all block minmax and add to segmentMinMaxMap
     if (null != model.getSegmentId()) {
       for (BlockIndexInfo blockIndex : blockIndexInfoList) {
-        Map<String, SegmentBlockMinMaxInfo> segmentBlockMinMaxInfo = new LinkedHashMap<>();
+        Map<String, BlockColumnMetaDataInfo> blockLevelMetaDataInfoMap = new LinkedHashMap<>();
         byte[][] min = blockIndex.getBlockletIndex().getMinMaxIndex().getMinValues();
         byte[][] max = blockIndex.getBlockletIndex().getMinMaxIndex().getMaxValues();
         for (int i = 0; i < thriftColumnSchemaList.size(); i++) {
@@ -411,12 +411,12 @@ protected void writeIndexFile() throws IOException, CarbonDataWriterException {
               isColumnDrift = true;
             }
           }
-          segmentBlockMinMaxInfo.put(columnSchema.column_id,
-              new SegmentBlockMinMaxInfo(isSortColumn, min[i], max[i], isColumnDrift));
+          blockLevelMetaDataInfoMap.put(columnSchema.column_id,
+              new BlockColumnMetaDataInfo(isSortColumn, min[i], max[i], isColumnDrift));
         }
-        SegmentMinMaxStats.getInstance()
-            .setSegmentMinMaxList(model.getTableName(), model.getSegmentId(),
-                segmentBlockMinMaxInfo);
+        SegmentMetaDataInfoStats.getInstance()
+            .setBlockMetaDataInfo(model.getTableName(), model.getSegmentId(),
+                blockLevelMetaDataInfoMap);
       }
     }
     String indexFileName;
