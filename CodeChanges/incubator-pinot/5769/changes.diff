diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyApplication.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyApplication.java
index 439b0575eb6..0435848c9e6 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyApplication.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyApplication.java
@@ -118,9 +118,15 @@ public void start() throws Exception {
         requestStatisticsLogger.start();
 
         if (config.isWorker()) {
-          taskDriver = new TaskDriver(config);
+          taskDriver = new TaskDriver(config, false);
           taskDriver.start();
         }
+
+        if (config.isOnlineWorker()) {
+          taskDriver = new TaskDriver(config, true);
+          taskDriver.start();
+        }
+
         if (config.isMonitor()) {
           monitorJobScheduler = new MonitorJobScheduler(config.getMonitorConfiguration());
           monitorJobScheduler.start();
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyConfiguration.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyConfiguration.java
index 9203b1fb04e..c46dea7ef47 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyConfiguration.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyConfiguration.java
@@ -40,6 +40,7 @@ public class ThirdEyeAnomalyConfiguration extends ThirdEyeConfiguration {
   private boolean pinotProxy = false;
   private boolean scheduler = false;
   private boolean worker = false;
+  private boolean onlineWorker = false;
   private boolean detectionPipeline = false;
   private boolean detectionAlert = false;
   private boolean dataAvailabilityEventListener = false;
@@ -147,6 +148,14 @@ public void setWorker(boolean worker) {
     this.worker = worker;
   }
 
+  public boolean isOnlineWorker() {
+    return onlineWorker;
+  }
+
+  public void setOnlineWorker(boolean onlineWorker) {
+    this.onlineWorker = onlineWorker;
+  }
+
   public boolean isMonitor() {
     return monitor;
   }
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskConstants.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskConstants.java
index 95ed5e18fe2..d3539dacdca 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskConstants.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskConstants.java
@@ -26,7 +26,8 @@ public enum TaskType {
     DETECTION,                 // tasks to detect anomalies
     DETECTION_ALERT,           // tasks to send alerts to customers regarding anomalies
     YAML_DETECTION_ONBOARD,    // tasks to onboard new YAML configured detection
-    MONITOR                    // tasks to clean up expired/invalid execution history
+    MONITOR,                   // tasks to clean up expired/invalid execution history
+    DETECTION_ONLINE           // tasks to online detection anomalies
   }
 
   public enum TaskStatus {
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskDriver.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskDriver.java
index eb4cbe28595..bbeb8b9edb7 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskDriver.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskDriver.java
@@ -65,23 +65,26 @@ public class TaskDriver {
   private long workerId;
   private final Set<TaskStatus> allowedOldTaskStatus = new HashSet<>();
   private TaskDriverConfiguration driverConfiguration;
+  private boolean isOnline;
 
   private volatile boolean shutdown = false;
 
-  public TaskDriver(ThirdEyeAnomalyConfiguration thirdEyeAnomalyConfiguration) {
+  public TaskDriver(ThirdEyeAnomalyConfiguration thirdEyeAnomalyConfiguration, boolean isOnline) {
     driverConfiguration = thirdEyeAnomalyConfiguration.getTaskDriverConfiguration();
     workerId = thirdEyeAnomalyConfiguration.getId();
     taskDAO = DAO_REGISTRY.getTaskDAO();
+    String threadNamePrefix = isOnline ? "online-" : "";
     taskExecutorService = Executors.newFixedThreadPool(
             driverConfiguration.getMaxParallelTasks(),
-            new ThreadFactoryBuilder().setNameFormat("task-executor-%d").build());
+            new ThreadFactoryBuilder().setNameFormat(threadNamePrefix + "task-executor-%d").build());
     taskWatcherExecutorService = Executors.newFixedThreadPool(
             driverConfiguration.getMaxParallelTasks(),
-            new ThreadFactoryBuilder().setNameFormat("task-watcher-%d").setDaemon(true).build());
+            new ThreadFactoryBuilder().setNameFormat(threadNamePrefix + "task-watcher-%d").setDaemon(true).build());
     taskContext = new TaskContext();
     taskContext.setThirdEyeAnomalyConfiguration(thirdEyeAnomalyConfiguration);
     allowedOldTaskStatus.add(TaskStatus.FAILED);
     allowedOldTaskStatus.add(TaskStatus.WAITING);
+    this.isOnline = isOnline;
   }
 
   public void start() throws Exception {
@@ -106,6 +109,9 @@ public void start() throws Exception {
 
             if (anomalyTaskSpec != null) { // a task has acquired and we must finish executing it before termination
               long tStart = System.nanoTime();
+              if (TaskDriver.this.isOnline) {
+                ThirdeyeMetricsUtil.onlineTaskCounter.inc();
+              }
               ThirdeyeMetricsUtil.taskCounter.inc();
 
               try {
@@ -152,6 +158,9 @@ public List<TaskResult> call() throws Exception {
                 long elapsedTime = System.nanoTime() - tStart;
                 LOG.info("Task {} took {} nano seconds", anomalyTaskSpec.getId(), elapsedTime);
                 MDC.clear();
+                if (TaskDriver.this.isOnline) {
+                  ThirdeyeMetricsUtil.onlineTaskDurationCounter.inc(elapsedTime);
+                }
                 ThirdeyeMetricsUtil.taskDurationCounter.inc(elapsedTime);
               }
             }
@@ -183,8 +192,11 @@ private TaskDTO acquireTask() {
       try {
         // randomize fetching head and tail to reduce synchronized patterns across threads (and hosts)
         boolean orderAscending = System.currentTimeMillis() % 2 == 0;
+
+        // find by task type to separate online task from a normal task
+        TaskType type = this.isOnline ? TaskType.DETECTION_ONLINE : TaskType.DETECTION;
         anomalyTasks = taskDAO
-            .findByStatusOrderByCreateTime(TaskStatus.WAITING, driverConfiguration.getTaskFetchSizeCap(),
+            .findByStatusAndTypeOrderByCreateTime(TaskStatus.WAITING, type, driverConfiguration.getTaskFetchSizeCap(),
                 orderAscending);
       } catch (Exception e) {
         hasFetchError = true;
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskInfoFactory.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskInfoFactory.java
index df7063df277..4cc3b1c4058 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskInfoFactory.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskInfoFactory.java
@@ -57,8 +57,11 @@ public static TaskInfo getTaskInfoFromTaskType(TaskType taskType, String taskInf
         case MONITOR:
           taskInfo = OBJECT_MAPPER.readValue(taskInfoString, MonitorTaskInfo.class);
           break;
+        case DETECTION_ONLINE:
+          taskInfo = OBJECT_MAPPER.readValue(taskInfoString, DetectionPipelineTaskInfo.class);
+          break;
         default:
-          LOG.error("TaskType must be one of DATA_QUALITY, DETECTION, DETECTION_ALERT, YAML_DETECTION_ONBOARD, MONITOR");
+          LOG.error("TaskType must be one of DATA_QUALITY, DETECTION, DETECTION_ALERT, YAML_DETECTION_ONBOARD, MONITOR, DETECTION_ONLINE");
           break;
       }
     } catch (Exception e) {
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskRunnerFactory.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskRunnerFactory.java
index f46b1c00c70..c3c1cb0ee12 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskRunnerFactory.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskRunnerFactory.java
@@ -49,6 +49,9 @@ public static TaskRunner getTaskRunnerFromTaskType(TaskType taskType) {
       case MONITOR:
         taskRunner = new MonitorTaskRunner();
         break;
+      case DETECTION_ONLINE:
+        taskRunner = new DetectionPipelineTaskRunner();
+        break;
       default:
     }
     return taskRunner;
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/utils/ThirdeyeMetricsUtil.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/utils/ThirdeyeMetricsUtil.java
index cffdd26abf3..0cddf4d6cbc 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/utils/ThirdeyeMetricsUtil.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/utils/ThirdeyeMetricsUtil.java
@@ -197,6 +197,12 @@ public Integer value() {
   public static final Counter jiraAlertsNumCommentsCounter =
       metricsRegistry.newCounter(ThirdeyeMetricsUtil.class, "jiraAlertsNumCommentsCounter");
 
+  public static final Counter onlineTaskCounter =
+          metricsRegistry.newCounter(ThirdeyeMetricsUtil.class, "onlineTaskCounter");
+
+  public static final Counter onlineTaskDurationCounter =
+          metricsRegistry.newCounter(ThirdeyeMetricsUtil.class, "onlineTaskDurationCounter");
+
   public static MetricsRegistry getMetricsRegistry() {
     return metricsRegistry;
   }
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java
new file mode 100644
index 00000000000..104ce41c77f
--- /dev/null
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java
@@ -0,0 +1,746 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.apache.pinot.thirdeye.api.detection;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.node.ArrayNode;
+import com.fasterxml.jackson.databind.node.ObjectNode;
+import com.fasterxml.jackson.databind.node.TextNode;
+import com.google.common.base.Preconditions;
+import com.google.inject.Inject;
+import io.dropwizard.auth.Auth;
+import io.swagger.annotations.Api;
+import io.swagger.annotations.ApiOperation;
+import io.swagger.annotations.ApiParam;
+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;
+import org.apache.pinot.thirdeye.api.Constants;
+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;
+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;
+import org.apache.pinot.thirdeye.common.metric.MetricType;
+import org.apache.pinot.thirdeye.constant.MetricAggFunction;
+import org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies.AnomalySearchFilter;
+import org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies.AnomalySearcher;
+import org.apache.pinot.thirdeye.datalayer.bao.*;
+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;
+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;
+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;
+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;
+import org.apache.pinot.thirdeye.datalayer.util.Predicate;
+import org.apache.pinot.thirdeye.datasource.DAORegistry;
+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;
+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;
+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;
+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;
+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;
+import org.apache.pinot.thirdeye.detection.*;
+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;
+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;
+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;
+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;
+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;
+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.yaml.snakeyaml.Yaml;
+import javax.ws.rs.*;
+import javax.ws.rs.core.MediaType;
+import javax.ws.rs.core.Response;
+import javax.ws.rs.core.UriBuilder;
+import java.util.*;
+import java.util.concurrent.TimeUnit;
+
+@Path("/anomaly-detection")
+@Api(tags = { Constants.DETECTION_TAG })
+public class AnomalyDetectionResource {
+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);
+
+  /* -------- Request/Response field -------- */
+  private static final String DATA_FIELD = "data";
+  private static final String COLUMNS_FIELD = "columns";
+  private static final String ROWS_FIELD = "rows";
+  private static final String DEFAULT_METRIC_COLUMN = "metric";
+  private static final String DEFAULT_TIME_COLUMN = "date";
+  private static final String DATASET_FIELD = "datasetConfiguration";
+  private static final String METRIC_FIELD = "metricConfiguration";
+  private static final String DETECTION_FIELD = "detectionConfiguration";
+  private static final String ANOMALIES_FIELD = "anomalies";
+
+  /* -------- Others -------- */
+  private static final String ONLINE_DATASOURCE = "OnlineThirdEyeDataSource";
+  private static final String DEFAULT_DETECTION_NAME = "online_detection";
+  private static final String DEFAULT_DATASET_NAME = "online_dataset";
+  private static final String DEFAULT_METRIC_NAME = "online_metric";
+  private static final String TEMPLATE_DETECTION_PATH = "detection-config-template.yml";
+  private static final long POLLING_SLEEP_TIME = 5L;
+  private static final long POLLING_TIMEOUT = 60 * 10L;
+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;
+  private static final int ANOMALIES_LIMIT = 500;
+
+  private final DetectionConfigManager detectionConfigDAO;
+  private final DataProvider provider;
+  private final MetricConfigManager metricConfigDAO;
+  private final DatasetConfigManager datasetConfigDAO;
+  private final EventManager eventDAO;
+  private final MergedAnomalyResultManager anomalyDAO;
+  private final EvaluationManager evaluationDAO;
+  private final TaskManager taskDAO;
+  private final DetectionPipelineLoader loader;
+  private final DetectionConfigValidator detectionValidator;
+  private final AnomalySearcher anomalySearcher;
+  private final ObjectMapper objectMapper;
+  private final Yaml yaml;
+
+  @Inject
+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {
+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();
+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();
+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();
+    this.eventDAO = DAORegistry.getInstance().getEventDAO();
+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();
+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();
+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();
+    this.objectMapper = new ObjectMapper();
+
+    TimeSeriesLoader timeseriesLoader =
+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,
+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),
+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());
+
+    AggregationLoader aggregationLoader =
+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,
+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),
+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());
+
+    this.loader = new DetectionPipelineLoader();
+
+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,
+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,
+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());
+    this.detectionValidator = new DetectionConfigValidator(this.provider);
+    this.anomalySearcher = new AnomalySearcher();
+    this.yaml = new Yaml();
+  }
+
+  /**
+   * Run an online anomaly detection service synchronously. It will run anomaly detection using
+   * default configs for detection, metric, dataset
+   *
+   * @param start     detection window start time
+   * @param end       detection window end time
+   * @param payload   payload in request including online data
+   * @param principal user who sent this request. It's used to separate different config names
+   * @return a message containing the detected anomalies and the detection config used
+   */
+  @POST
+  @Path("/")
+  @Produces(MediaType.APPLICATION_JSON)
+  @Consumes(MediaType.APPLICATION_JSON)
+  @ApiOperation("Request an anomaly detection online task")
+  public Response onlineApi(
+          @QueryParam("start") long start,
+          @QueryParam("end") long end,
+          @ApiParam("jsonPayload") String payload,
+          @Auth ThirdEyePrincipal principal) {
+    DatasetConfigDTO datasetConfigDTO = null;
+    MetricConfigDTO metricConfigDTO = null;
+    DetectionConfigDTO detectionConfigDTO;
+    TaskDTO taskDTO;
+    Map<String, Object> anomalies;
+    Response.Status responseStatus;
+    Map<String, String> responseMessage = new HashMap<>();
+    ObjectMapper objectMapper = new ObjectMapper();
+    // Suffix format: _<user_name>_<uuid>
+    String nameSuffix = "_" + principal.getName() + "_" + UUID.randomUUID().toString();
+
+    try {
+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {
+        responseStatus = Response.Status.BAD_REQUEST;
+        responseMessage.put("message", "Payload too large");
+        return Response.status(responseStatus).entity(responseMessage).build();
+      }
+
+      JsonNode payloadNode = objectMapper.readTree(payload);
+
+      if (!validateOnlineRequestPayload(payloadNode)) {
+        responseStatus = Response.Status.BAD_REQUEST;
+        responseMessage.put("message", "Invalid request payload");
+        return Response.status(responseStatus).entity(responseMessage).build();
+      }
+
+      // Preprocess: remove existing entities generated by the previous interrupted request
+      cleanExistingOnlineTask(nameSuffix);
+
+      // Create & save dataset
+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);
+
+      // Create & save metric along with online data
+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix, datasetConfigDTO);
+
+      // Create & save detection
+      detectionConfigDTO =
+          generateDetectionConfig(payloadNode, nameSuffix, datasetConfigDTO, metricConfigDTO, start,
+              end);
+
+      // Create & save task
+      taskDTO = generateTaskConfig(detectionConfigDTO, start, end, nameSuffix);
+
+      // Polling task status
+      TaskDTO polledTaskDTO = pollingTask(taskDTO.getId());
+
+      // Task failure
+      if (polledTaskDTO.getStatus() != TaskConstants.TaskStatus.COMPLETED) {
+        LOG.warn("Task is not completed after polling: " + polledTaskDTO);
+
+        responseStatus = Response.Status.INTERNAL_SERVER_ERROR;
+
+        switch (polledTaskDTO.getStatus()) {
+        case FAILED:
+          responseStatus = Response.Status.INTERNAL_SERVER_ERROR;
+          responseMessage.put("message", "Failed to execute anomaly detection task.");
+          break;
+        case TIMEOUT:
+          responseStatus = Response.Status.REQUEST_TIMEOUT;
+          responseMessage.put("message", "Anomaly detection task timeout.");
+        default:
+          LOG.error("Error task status after polling: " + polledTaskDTO.getStatus());
+          responseMessage.put("message", "unknown task status.");
+          break;
+        }
+
+        responseMessage.put("more-info", "Error = " + polledTaskDTO.getMessage());
+
+        // Send response
+        return Response.status(responseStatus).entity(responseMessage).build();
+      }
+
+      // Task success
+      // Retrieve task result
+      anomalies = getAnomalies(start, end, metricConfigDTO.getName(), datasetConfigDTO.getName());
+
+      // Build success response
+      JsonNode anomalyNode = objectMapper.convertValue(anomalies, JsonNode.class);
+      JsonNode detectionConfigNode =
+          objectMapper.convertValue(detectionConfigDTO.getYaml(), JsonNode.class);
+      ObjectNode responseNode = objectMapper.createObjectNode();
+      responseNode.set(ANOMALIES_FIELD, anomalyNode);
+      responseNode.set(DETECTION_FIELD, detectionConfigNode);
+
+      responseStatus = Response.Status.OK;
+      return Response.status(responseStatus).entity(objectMapper.writeValueAsString(responseNode))
+          .build();
+    } catch (JsonProcessingException e) {
+      LOG.error("Error: {}", e.getMessage());
+      responseStatus = Response.Status.BAD_REQUEST;
+      responseMessage.put("message", "Invalid request payload");
+      processException(e, responseMessage);
+      return Response.status(responseStatus).entity(responseMessage).build();
+    } catch (Exception e) {
+      LOG.error("Error: {}", e.getMessage());
+      responseStatus = Response.Status.INTERNAL_SERVER_ERROR;
+      responseMessage.put("message", "Failed executing anomaly detection service.");
+      processException(e, responseMessage);
+      return Response.status(responseStatus).entity(responseMessage).build();
+    } finally {
+      // Online service is stateless
+      cleanStates(metricConfigDTO, datasetConfigDTO);
+    }
+  }
+
+  void cleanExistingOnlineTask(String nameSuffix) {
+    String metricName = DEFAULT_METRIC_NAME + nameSuffix;
+    int metricCnt = metricConfigDAO.deleteByPredicate(
+        Predicate.EQ("name", metricName));
+    LOG.info("Deleted existing {} metrics", metricCnt);
+
+    String datasetName = DEFAULT_DATASET_NAME + nameSuffix;
+    int datasetCnt = datasetConfigDAO.deleteByPredicate(
+        Predicate.EQ("dataset", datasetName));
+    LOG.info("Deleted existing {} datasets", datasetCnt);
+
+    String taskName = TaskConstants.TaskType.DETECTION.name() + nameSuffix;
+    int taskCnt = taskDAO.deleteByPredicate(Predicate.EQ("name", taskName));
+    LOG.info("Deleted existing {} task", taskCnt);
+
+    int anomalyCnt = anomalyDAO.deleteByPredicate(
+        Predicate.EQ("metric", metricName));
+    LOG.info("Deleted existing {} anomalies with metric: {}", anomalyCnt, metricName);
+
+    anomalyCnt = anomalyDAO.deleteByPredicate(
+        Predicate.EQ("collection", datasetName));
+    LOG.info("Deleted existing {} anomalies with dataset: {}", anomalyCnt, datasetName);
+  }
+
+  boolean validateOnlineRequestPayload(JsonNode payloadNode) {
+    if (!payloadNode.has(DATA_FIELD))
+      return false;
+
+    JsonNode dataNode = payloadNode.get(DATA_FIELD);
+    if (!dataNode.has(COLUMNS_FIELD) || !dataNode.has(ROWS_FIELD))
+      return false;
+
+    JsonNode columnsNode = dataNode.get(COLUMNS_FIELD);
+    if (!columnsNode.isArray()) return false;
+
+    return true;
+  }
+
+  DatasetConfigDTO generateDatasetConfig(JsonNode payloadNode, String suffix) {
+    DatasetConfigDTO datasetConfigDTO = new DatasetConfigDTO();
+
+    // Default configuration
+    datasetConfigDTO.setDataset(DEFAULT_DATASET_NAME + suffix);
+    datasetConfigDTO.setDimensions(Collections.unmodifiableList(new ArrayList<>()));
+    datasetConfigDTO.setTimeColumn(DEFAULT_TIME_COLUMN);
+    datasetConfigDTO.setTimeDuration(1);
+    datasetConfigDTO.setTimeUnit(TimeUnit.DAYS);
+    datasetConfigDTO.setTimeFormat("SIMPLE_DATE_FORMAT:yyyyMMdd");
+    datasetConfigDTO.setTimezone("US/Pacific");
+    datasetConfigDTO.setDataSource(ONLINE_DATASOURCE);
+
+    // Customized configuration
+    if (payloadNode.has(DATASET_FIELD)) {
+
+      Map<String, Object> datasetYaml =
+          ConfigUtils.getMap(yaml.load(payloadNode.get(DATASET_FIELD).textValue()));
+
+      if (datasetYaml.containsKey("timeColumn")) {
+        datasetConfigDTO.setTimeColumn((String) datasetYaml.get("timeColumn"));
+      }
+      if (datasetYaml.containsKey("timeUnit")) {
+        datasetConfigDTO
+            .setTimeUnit(TimeUnit.valueOf((String) datasetYaml.get("timeUnit")));
+      }
+      if (datasetYaml.containsKey("timeDuration")) {
+        datasetConfigDTO.setTimeDuration((Integer) datasetYaml.get("timeDuration"));
+      }
+      if (datasetYaml.containsKey("timeFormat")) {
+        datasetConfigDTO.setTimeFormat((String) datasetYaml.get("timeFormat"));
+      }
+      if (datasetYaml.containsKey("timezone")) {
+        datasetConfigDTO.setTimezone((String) datasetYaml.get("timezone"));
+      }
+    }
+
+    datasetConfigDAO.save(datasetConfigDTO);
+    LOG.info("Created dataset with config {}", datasetConfigDTO);
+
+    return datasetConfigDTO;
+  }
+
+  MetricConfigDTO generateMetricConfig(JsonNode payloadNode, String suffix,
+        DatasetConfigDTO datasetConfigDTO)
+      throws JsonProcessingException {
+    MetricConfigDTO metricConfigDTO = new MetricConfigDTO();
+    JsonNode dataNode = payloadNode.get(DATA_FIELD);
+
+    // Default configuration
+    metricConfigDTO.setName(DEFAULT_METRIC_NAME + suffix);
+    metricConfigDTO.setDataset(DEFAULT_DATASET_NAME + suffix);
+    metricConfigDTO.setAlias(ThirdEyeUtils
+        .constructMetricAlias(DEFAULT_DATASET_NAME + suffix,
+            DEFAULT_METRIC_NAME + suffix));
+    metricConfigDTO.setDatatype(MetricType.DOUBLE);
+    metricConfigDTO.setDefaultAggFunction(MetricAggFunction.SUM);
+    metricConfigDTO.setActive(true);
+
+    // Customized configuration
+    if (payloadNode.has(METRIC_FIELD)) {
+      Map<String, Object> metricYaml =
+          ConfigUtils.getMap(yaml.load(payloadNode.get(METRIC_FIELD).textValue()));
+
+      // Append suffix to metric name
+      if (metricYaml.containsKey("metricColumn")) {
+        metricConfigDTO.setName(metricYaml.get("metricColumn") + suffix);
+      }
+
+      if (metricYaml.containsKey("datatype")) {
+        metricConfigDTO
+            .setDatatype(MetricType.valueOf((String) metricYaml.get("datatype")));
+      }
+    }
+
+    // Check if time & metric columns exist in adhoc data
+    ArrayNode columnsNode = dataNode.withArray(COLUMNS_FIELD);
+    int[] colIndices = findTimeAndMetricColumns(columnsNode,
+        datasetConfigDTO.getTimeColumn(),
+        metricConfigDTO.getName().replace(suffix, ""));
+    int timeColIdx = colIndices[0];
+    int metricColIdx = colIndices[1];
+
+    Preconditions.checkArgument(metricColIdx>=0 && timeColIdx>=0,
+        String.format("metric: %s or time: %s not found in adhoc data.",
+            metricConfigDTO.getName().replace(suffix, ""),
+            datasetConfigDTO.getTimeColumn()));
+
+    // Append suffix to metric column name to keep consistency with configs
+    columnsNode.set(metricColIdx, new TextNode(metricConfigDTO.getName()));
+
+    // TODO: should store online data into a new table
+    metricConfigDTO.setOnlineData(this.objectMapper.writeValueAsString(dataNode));
+
+    metricConfigDAO.save(metricConfigDTO);
+    LOG.info("Created metric with config {}", metricConfigDTO);
+
+    return metricConfigDTO;
+  }
+
+  DetectionConfigDTO generateDetectionConfig(JsonNode payloadNode, String suffix,
+      DatasetConfigDTO datasetConfigDTO, MetricConfigDTO metricConfigDTO, long start, long end) {
+    DetectionConfigDTO detectionConfigDTO;
+    Map<String, Object> detectionYaml;
+    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();
+
+    if (payloadNode.has(DETECTION_FIELD)) {
+      // Customized configuration: retrieve config from user request
+      detectionYaml = ConfigUtils.getMap(yaml.load(payloadNode.get(DETECTION_FIELD).textValue()));
+    } else {
+      // Default configuration: retrieve the template from disk
+      detectionYaml =
+          ConfigUtils.getMap(yaml.load(classLoader.getResourceAsStream(TEMPLATE_DETECTION_PATH)));
+    }
+
+    // Do not support customized detection name as it is not a common use case
+    detectionYaml.put("detectionName", DEFAULT_DETECTION_NAME + suffix);
+    detectionYaml.put("dataset", datasetConfigDTO.getName());
+    detectionYaml.put("metric", metricConfigDTO.getName());
+
+    detectionConfigDTO =
+        new DetectionConfigTranslator(this.yaml.dump(detectionYaml), this.provider).translate();
+    detectionConfigDTO.setCron("0 0 0 1 1 ? 2200"); // Never scheduled
+
+    // Tune the detection config - Passes the raw yaml params & injects tuned params
+    DetectionConfigTuner detectionTuner = new DetectionConfigTuner(detectionConfigDTO, provider);
+    detectionConfigDTO = detectionTuner.tune(start, end);
+
+    // Validate the detection config
+    detectionValidator.validateConfig(detectionConfigDTO);
+
+    // Online detection will not save detect config into DB
+
+    LOG.info("Created detection with config {}", detectionConfigDTO);
+
+    return detectionConfigDTO;
+  }
+
+  TaskDTO generateTaskConfig(DetectionConfigDTO detectionConfigDTO,
+        long start, long end, String nameSuffix)
+      throws JsonProcessingException {
+    TaskDTO taskDTO = new TaskDTO();
+    taskDTO.setJobName(
+        TaskConstants.TaskType.DETECTION_ONLINE.toString() + nameSuffix);
+    taskDTO.setStatus(TaskConstants.TaskStatus.WAITING);
+    taskDTO.setTaskType(TaskConstants.TaskType.DETECTION_ONLINE);
+    DetectionPipelineTaskInfo taskInfo =
+        new DetectionPipelineTaskInfo(-1L, start, end);
+    taskInfo.setOnline(true);
+
+    // Store the detection config into online task info
+    taskDAO.populateDetectionConfig(detectionConfigDTO, taskInfo);
+
+    String taskInfoJson = objectMapper.writeValueAsString(taskInfo);
+    taskDTO.setTaskInfo(taskInfoJson);
+
+    taskDAO.save(taskDTO);
+    LOG.info("Created task: {}", taskDTO);
+
+    return taskDTO;
+  }
+
+  private TaskDTO pollingTask(long taskId) {
+    long startTime = System.currentTimeMillis();
+    TaskDTO taskDTO;
+
+    // Add timeout mechanism in case anything external goes wrong
+    while (true) {
+      taskDTO = taskDAO.findById(taskId);
+
+      LOG.info("Polling task : " + taskDTO);
+
+      TaskConstants.TaskStatus taskStatus = taskDTO.getStatus();
+      if (!taskStatus.equals(TaskConstants.TaskStatus.WAITING) &&
+              !taskStatus.equals(TaskConstants.TaskStatus.RUNNING)) {
+        LOG.info("Polling finished ({}ms). Task status: {}",
+            System.currentTimeMillis() - startTime, taskStatus);
+        break;
+      }
+
+      try {
+        TimeUnit.SECONDS.sleep(POLLING_SLEEP_TIME);
+      } catch (InterruptedException e) {
+        LOG.warn("Interrupted during polling sleep");
+        break;
+      }
+
+      if ( (System.currentTimeMillis() - startTime) > TimeUnit.SECONDS.toMillis(POLLING_TIMEOUT)) {
+        LOG.warn("Polling timeout. Mark task as FAILED");
+        taskDTO.setStatus(TaskConstants.TaskStatus.FAILED);
+        break;
+      }
+    }
+
+    return taskDTO;
+  }
+
+  private Map<String, Object> getAnomalies(long start, long end, String metric, String dataset) {
+    AnomalySearchFilter searchFilter =
+        new AnomalySearchFilter(start, end, Collections.emptyList(), Collections.emptyList(), Collections.emptyList(),
+            Collections.singletonList(metric), Collections.singletonList(dataset), Collections.emptyList());
+
+    Map<String, Object> anomalies = this.anomalySearcher.search(searchFilter, ANOMALIES_LIMIT, 0);
+
+    LOG.info("Successfully returned " + anomalies.get("count") + " anomalies.");
+    return anomalies;
+  }
+
+  private void cleanStates(MetricConfigDTO metricConfigDTO, DatasetConfigDTO datasetConfigDTO) {
+    if (datasetConfigDTO != null) {
+      datasetConfigDAO.delete(datasetConfigDTO);
+      LOG.info("Deleted dataset: {}", datasetConfigDTO);
+
+      int anomalyCnt = anomalyDAO.deleteByPredicate(
+          Predicate.EQ("collection", datasetConfigDTO.getName()));
+      LOG.info("Deleted {} anomalies with dataset {}",
+          anomalyCnt, datasetConfigDTO.getName());
+    }
+
+    if (metricConfigDTO != null) {
+      metricConfigDAO.delete(metricConfigDTO);
+      LOG.info("Deleted metric: {}", metricConfigDTO);
+
+      int anomalyCnt = anomalyDAO.deleteByPredicate(
+          Predicate.EQ("metric", metricConfigDTO.getName()));
+      LOG.info("Deleted {} anomalies with metric {}",
+          anomalyCnt, metricConfigDTO.getName());
+    }
+  }
+
+  private int[] findTimeAndMetricColumns(JsonNode node, String timeColName, String metricColName) {
+    int metricColIdx = -1, timeColIdx = -1;
+    if (node.isArray()) {
+      for (int colIdx = 0; colIdx < node.size(); colIdx++) {
+        if (node.get(colIdx).textValue().equals(timeColName)) {
+          timeColIdx = colIdx;
+        }
+
+        if (node.get(colIdx).textValue().equals(metricColName)) {
+          metricColIdx = colIdx;
+        }
+      }
+    }
+    return new int[]{timeColIdx, metricColIdx};
+  }
+
+  /**
+   * Given a detection config name, run a anomaly detection task using this detection config
+   * asynchronously. It will return a task ID for query the task status later.
+   *
+   * @param start         detection window start time
+   * @param end           detection window end time
+   * @param detectionName the name of the detection config already existing in TE database
+   * @return a message containing the ID of the anomaly detection task and HATEOAS links
+   */
+  @POST
+  @Path("/tasks")
+  @Produces(MediaType.APPLICATION_JSON)
+  @Consumes(MediaType.TEXT_PLAIN)
+  @ApiOperation("Submit an anomaly detection task")
+  public Response taskSubmitApi(
+      @QueryParam("start") long start,
+      @QueryParam("end") long end,
+      @QueryParam("detectionName") String detectionName) {
+    long ts = System.currentTimeMillis();
+    Map<String, String> responseMessage = new HashMap<>();
+    try {
+      // Find detection by name
+      List<DetectionConfigDTO> detectionConfigDTOS =
+          detectionConfigDAO.findByPredicate(Predicate.EQ("name", detectionName));
+
+      // Precondition check
+      if (detectionConfigDTOS.isEmpty()) {
+        LOG.warn("Detection config not found: {}", detectionName);
+        responseMessage.put("message", "Detection config not found: " + detectionName);
+        return Response.status(Response.Status.NOT_FOUND).entity(responseMessage).build();
+      } else if (detectionConfigDTOS.size() > 1) {
+        LOG.error("Duplicate detection configs: {}", detectionConfigDTOS);
+        responseMessage.put("message", "Duplicate detection configs");
+        return Response.status(Response.Status.INTERNAL_SERVER_ERROR).entity(responseMessage)
+            .build();
+      }
+
+      DetectionConfigDTO detectionConfigDTO = detectionConfigDTOS.get(0);
+
+      LOG.info("Find detection config: {}", detectionConfigDTO);
+
+      // Create task
+      DetectionPipelineTaskInfo taskInfo =
+          new DetectionPipelineTaskInfo(detectionConfigDTO.getId(), start, end);
+      String taskInfoJson;
+      TaskDTO taskDTO;
+      long taskId;
+      try {
+        taskInfoJson = objectMapper.writeValueAsString(taskInfo);
+        taskDTO = TaskUtils
+            .buildTask(taskInfo.getConfigId(), taskInfoJson, TaskConstants.TaskType.DETECTION);
+        taskId = taskDAO.save(taskDTO);
+        LOG.info("Saved task: " + taskDTO + " into DB");
+        LOG.info("Create task successful, used {} milliseconds", System.currentTimeMillis() - ts);
+      } catch (JsonProcessingException e) {
+        LOG.error("Exception when converting DetectionPipelineTaskInfo {} to jsonString", taskInfo,
+            e);
+        responseMessage.put("message", "Error while creating detection task");
+        return Response.status(Response.Status.INTERNAL_SERVER_ERROR).entity(responseMessage)
+            .build();
+      }
+
+      // Build HATEOAS response
+      ObjectNode responseJson = buildResponseJson(
+          UriBuilder.fromResource(AnomalyDetectionResource.class)
+              .path(AnomalyDetectionResource.class, "taskSubmitApi")
+              .build().toString(), "POST");
+
+      Response.Status responseStatus = Response.Status.CREATED;
+
+      if (taskId < 0) {
+        responseStatus = Response.Status.BAD_REQUEST;
+        return Response.status(responseStatus).entity(responseJson).build();
+      }
+
+      responseJson.put("taskId", taskId);
+      addLink(responseJson, "taskStatus",
+          UriBuilder.fromResource(AnomalyDetectionResource.class)
+                .path(AnomalyDetectionResource.class, "taskStatusApi")
+                .resolveTemplate("taskId", taskId)
+                .build().toString(), "GET");
+
+      return Response.status(responseStatus).entity(responseJson).build();
+    } catch (IllegalArgumentException e) {
+      LOG.error("Error: {}", e.getMessage());
+      responseMessage.put("message", "Failed submitting anomaly detection task.");
+      processException(e, responseMessage);
+      return Response.status(Response.Status.BAD_REQUEST).entity(responseMessage).build();
+    } catch (Exception e) {
+      LOG.error("Error: {}", e.getMessage());
+      responseMessage.put("message", "Failed submitting anomaly detection task.");
+      processException(e, responseMessage);
+      return Response.serverError().entity(responseMessage).build();
+    }
+  }
+
+  private void processException(Throwable e, Map<String, String> responseMessage) {
+    StringBuilder sb = new StringBuilder();
+    // show more stack message to frontend for debugging
+    getErrorMessage(0, 5, e, sb);
+    responseMessage.put("more-info", "Error stack: " + sb.toString());
+  }
+
+  private void getErrorMessage(int curLevel, int totalLevel, Throwable e, StringBuilder sb) {
+    if (curLevel <= totalLevel && e != null) {
+      sb.append("==");
+      if (e.getMessage() != null) {
+        sb.append(e.getMessage());
+      }
+      getErrorMessage(curLevel + 1, totalLevel, e.getCause(), sb);
+    }
+  }
+
+  /**
+   * Given a anomaly detection task ID, return its current status.
+   *
+   * @param taskId the ID of the anomaly detection task to be queried
+   * @return a message containing the status of the task and HATEOAS links
+   */
+  @GET @Path("/task/{taskId}")
+  @Produces(MediaType.APPLICATION_JSON)
+  @Consumes(MediaType.TEXT_PLAIN)
+  @ApiOperation("Query a task status")
+  public Response taskStatusApi(@PathParam("taskId") long taskId) {
+    Map<String, String> responseMessage = new HashMap<>();
+
+    try {
+      // Find task
+      TaskDTO taskDTO = taskDAO.findById(taskId);
+
+      // Precondition check
+      LOG.info("Try to find task by ID: " + taskId);
+      if (taskDTO == null) {
+        LOG.warn("Task not found {}", taskId);
+        responseMessage.put("message", "Task not found: " + taskId);
+        return Response.status(Response.Status.NOT_FOUND).entity(responseMessage).build();
+      }
+
+      LOG.info("Found task" + taskDTO);
+
+      // Check task status
+      TaskConstants.TaskStatus taskStatus = taskDTO.getStatus();
+      Response.Status responseStatus;
+      if (taskStatus.equals(TaskConstants.TaskStatus.COMPLETED)) {
+        responseStatus = Response.Status.SEE_OTHER;
+      } else {
+        responseStatus = Response.Status.ACCEPTED;
+      }
+
+      // Build HATEOAS response
+      ObjectNode responseJson = buildResponseJson(
+          UriBuilder.fromResource(AnomalyDetectionResource.class)
+              .path(AnomalyDetectionResource.class, "taskStatusApi")
+              .resolveTemplate("taskId", taskId).build().toString(), "GET");
+
+      responseJson.put("status", taskStatus.name());
+
+      if (responseStatus.equals(Response.Status.SEE_OTHER)) {
+        addLink(responseJson, "anomalies", "/userdashboard/anomalies", "GET");
+      }
+
+      return Response.status(responseStatus).entity(responseJson).build();
+    } catch (Exception e) {
+      LOG.error("Error: {}", e.getMessage());
+      responseMessage.put("message", "Failed querying anomaly detection task.");
+      processException(e, responseMessage);
+      return Response.serverError().entity(responseMessage).build();
+    }
+  }
+
+  /* ----------- HATEOAS Utilities --------------- */
+  private ObjectNode buildResponseJson(String selfUri, String selfMethod) {
+    ObjectMapper mapper = new ObjectMapper();
+    ObjectNode rootNode = mapper.createObjectNode();
+
+    ObjectNode linksNode = mapper.createObjectNode();
+    ObjectNode selfNode = mapper.createObjectNode();
+
+    rootNode.set("_links", linksNode);
+    linksNode.set("self", selfNode);
+
+    selfNode.put("href", selfUri);
+    selfNode.put("method", selfMethod);
+
+    return rootNode;
+  }
+
+  private void addLink(ObjectNode rootNode, String rel, String href, String method) {
+    ObjectMapper mapper = new ObjectMapper();
+    ObjectNode linkNode = mapper.createObjectNode();
+    linkNode.put("href", href);
+    linkNode.put("method", method);
+    ((ObjectNode) rootNode.get("_links")).set(rel, linkNode);
+  }
+}
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/user/dashboard/UserDashboardResource.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/user/dashboard/UserDashboardResource.java
index e04cad6ea56..88eb2b20574 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/user/dashboard/UserDashboardResource.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/user/dashboard/UserDashboardResource.java
@@ -90,7 +90,7 @@ public UserDashboardResource(MergedAnomalyResultManager anomalyDAO,
     this.detectionAlertDAO = detectionAlertDAO;
   }
 
-  List<AnomalySummary> queryAnomalies(Long start, Long end, String application, String group, String metric,
+  public List<AnomalySummary> queryAnomalies(Long start, Long end, String application, String group, String metric,
       String dataset, List<MetricDatasetPair> metricDatasetPairs, boolean fetchTrueAnomaly, Integer limit) {
     if (limit == null) {
       LOG.warn("No upper limit specified while fetching anomalies. Defaulting to " + ANOMALIES_LIMIT_DEFAULT);
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/ThirdEyeDashboardApplication.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/ThirdEyeDashboardApplication.java
index 38fa5d2ab43..d32ccd6967e 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/ThirdEyeDashboardApplication.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/ThirdEyeDashboardApplication.java
@@ -39,6 +39,7 @@
 import javax.servlet.FilterRegistration;
 import org.apache.pinot.thirdeye.api.application.ApplicationResource;
 import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;
+import org.apache.pinot.thirdeye.api.detection.AnomalyDetectionResource;
 import org.apache.pinot.thirdeye.auth.ThirdEyeAuthFilter;
 import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;
 import org.apache.pinot.thirdeye.common.BaseThirdEyeApplication;
@@ -168,7 +169,8 @@ public void run(ThirdEyeDashboardConfiguration config, Environment env)
         RootCauseTemplateResource.class,
         RootCauseSessionResource.class,
         RootCauseMetricResource.class,
-        AnomalySearchResource.class
+        AnomalySearchResource.class,
+        AnomalyDetectionResource.class
     )
         .map(c -> injector.getInstance(c))
         .forEach(jersey::register);
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datalayer/bao/TaskManager.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datalayer/bao/TaskManager.java
index 7714cd9609c..75d85608db9 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datalayer/bao/TaskManager.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datalayer/bao/TaskManager.java
@@ -23,7 +23,9 @@
 
 import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;
 import org.apache.pinot.thirdeye.anomaly.task.TaskConstants.TaskStatus;
+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;
 import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;
+import org.apache.pinot.thirdeye.detection.DetectionPipelineTaskInfo;
 import java.util.Set;
 
 public interface TaskManager extends AbstractManager<TaskDTO>{
@@ -42,6 +44,8 @@ public interface TaskManager extends AbstractManager<TaskDTO>{
 
   List<TaskDTO> findByStatusOrderByCreateTime(TaskStatus status, int fetchSize, boolean asc);
 
+  List<TaskDTO> findByStatusAndTypeOrderByCreateTime(TaskStatus status, TaskConstants.TaskType type, int fetchSize, boolean asc);
+
   List<TaskDTO> findByStatusAndWorkerId(Long workerId, TaskStatus status);
 
   boolean updateStatusAndWorkerId(Long workerId, Long id, Set<TaskStatus> allowedOldStatus, int expectedVersion);
@@ -54,4 +58,8 @@ void updateStatusAndTaskEndTime(Long id, TaskStatus oldStatus, TaskStatus newSta
   int deleteRecordsOlderThanDaysWithStatus(int days, TaskStatus status);
 
   int countWaiting();
+
+  void populateDetectionConfig(DetectionConfigDTO detectionConfigDTO, DetectionPipelineTaskInfo taskInfo);
+
+  DetectionConfigDTO extractDetectionConfig(DetectionPipelineTaskInfo taskInfo);
 }
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datalayer/bao/jdbc/TaskManagerImpl.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datalayer/bao/jdbc/TaskManagerImpl.java
index 3c05c6c3e1d..2fce02b857c 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datalayer/bao/jdbc/TaskManagerImpl.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datalayer/bao/jdbc/TaskManagerImpl.java
@@ -32,6 +32,9 @@
 import java.util.Map;
 import java.util.Set;
 
+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;
+import org.apache.pinot.thirdeye.datalayer.pojo.DetectionConfigBean;
+import org.apache.pinot.thirdeye.detection.DetectionPipelineTaskInfo;
 import org.joda.time.DateTime;
 
 import com.google.inject.persist.Transactional;
@@ -52,6 +55,12 @@ public class TaskManagerImpl extends AbstractManagerImpl<TaskDTO> implements Tas
   private static final String FIND_BY_STATUS_ORDER_BY_CREATE_TIME_DESC =
       " WHERE status = :status order by startTime desc limit 10";
 
+  private static final String FIND_BY_STATUS_AND_TYPE_ORDER_BY_CREATE_TIME_ASC =
+          " WHERE status = :status and type = :type order by startTime asc limit 10";
+
+  private static final String FIND_BY_STATUS_AND_TYPE__ORDER_BY_CREATE_TIME_DESC =
+          " WHERE status = :status and type = :type order by startTime desc limit 10";
+
   private static final String FIND_BY_NAME_ORDER_BY_CREATE_TIME_ASC =
       " WHERE name = :name order by createTime asc limit ";
 
@@ -116,6 +125,22 @@ public List<TaskDTO> findByStatusOrderByCreateTime(TaskStatus status, int fetchS
     return result;
   }
 
+  @Override
+  public List<TaskDTO> findByStatusAndTypeOrderByCreateTime(TaskStatus status, TaskConstants.TaskType type, int fetchSize, boolean asc) {
+    Map<String, Object> parameterMap = new HashMap<>();
+    parameterMap.put("status", status.toString());
+    parameterMap.put("type", type.toString());
+    List<TaskBean> list;
+    String queryClause = (asc) ? FIND_BY_STATUS_AND_TYPE_ORDER_BY_CREATE_TIME_ASC
+            : FIND_BY_STATUS_AND_TYPE__ORDER_BY_CREATE_TIME_DESC;
+    list = genericPojoDao.executeParameterizedSQL(queryClause, parameterMap, TaskBean.class);
+    List<TaskDTO> result = new ArrayList<>();
+    for (TaskBean bean : list) {
+      result.add(MODEL_MAPPER.map(bean, TaskDTO.class));
+    }
+    return result;
+  }
+
   @Override
   public boolean updateStatusAndWorkerId(Long workerId, Long id, Set<TaskStatus> permittedOldStatus,
       int expectedVersion) {
@@ -226,4 +251,16 @@ public int countWaiting() {
       return -1;
     }
   }
+
+  @Override
+  public void populateDetectionConfig(DetectionConfigDTO detectionConfigDTO, DetectionPipelineTaskInfo taskInfo) {
+    DetectionConfigBean bean = convertDTO2Bean(detectionConfigDTO, DetectionConfigBean.class);
+    taskInfo.setDetectionConfigBean(bean);
+  }
+
+  @Override
+  public DetectionConfigDTO extractDetectionConfig(DetectionPipelineTaskInfo taskInfo) {
+    DetectionConfigBean detectionConfigBean = taskInfo.getDetectionConfigBean();
+    return MODEL_MAPPER.map(detectionConfigBean, DetectionConfigDTO.class);
+  }
 }
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datalayer/pojo/MetricConfigBean.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datalayer/pojo/MetricConfigBean.java
index 65e6db5f01b..8832969ded5 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datalayer/pojo/MetricConfigBean.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datalayer/pojo/MetricConfigBean.java
@@ -119,6 +119,16 @@ public enum DimensionAsMetricProperties {
 
   private boolean dimensionAsMetric = false;
 
+  private String onlineData = "";
+
+  public String getOnlineData() {
+    return onlineData;
+  }
+
+  public void setOnlineData(String onlineData) {
+    this.onlineData = onlineData;
+  }
+
   public String getName() {
     return name;
   }
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datasource/online/OnlineThirdEyeDataSource.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datasource/online/OnlineThirdEyeDataSource.java
new file mode 100644
index 00000000000..a6428aaf6fe
--- /dev/null
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datasource/online/OnlineThirdEyeDataSource.java
@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.apache.pinot.thirdeye.datasource.online;
+
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.node.ArrayNode;
+import com.google.common.collect.Multimap;
+import org.apache.pinot.thirdeye.common.time.TimeSpec;
+import org.apache.pinot.thirdeye.dataframe.DataFrame;
+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;
+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;
+import org.apache.pinot.thirdeye.datasource.*;
+import org.apache.pinot.thirdeye.datasource.pinot.resultset.*;
+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;
+import org.joda.time.DateTime;
+import org.joda.time.DateTimeZone;
+import org.joda.time.format.DateTimeFormat;
+import org.joda.time.format.DateTimeFormatter;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import java.util.Map;
+import java.util.HashMap;
+import java.util.List;
+import java.util.ArrayList;
+import java.util.LinkedHashMap;
+import java.util.Collection;
+
+public class OnlineThirdEyeDataSource implements ThirdEyeDataSource {
+  public static final String DATA_SOURCE_NAME = OnlineThirdEyeDataSource.class.getSimpleName();
+  static final Logger LOG = LoggerFactory.getLogger(OnlineThirdEyeDataSource.class);
+  private static final String ONLINE = "Online";
+
+  Map<String, DataFrame> dataSets;
+
+  /**
+   * Construct an online data source, which connects to internal database to retrieve data.
+   *
+   * @param properties the configuration providing the information to initialize online datasource.
+   */
+  public OnlineThirdEyeDataSource(Map<String, Object> properties) {
+    LOG.info("Initializing online datasource with prop: " + properties);
+  }
+
+  private static DateTime convertStringToDate(final String str, String tz, String dateFormat) {
+    DateTimeFormatter formatter = DateTimeFormat.forPattern(dateFormat);
+    formatter.withZone(DateTimeZone.forID(tz));
+    return formatter.parseDateTime(str);
+  }
+
+  @Override public String getName() {
+    return DATA_SOURCE_NAME;
+  }
+
+  @Override public ThirdEyeResponse execute(ThirdEyeRequest request) throws Exception {
+    // Currently only support single metric function (non-derived)
+    if (request.getMetricFunctions().size() != 1) {
+      throw new RuntimeException(
+          "Not supported size of metric functions: " + request.getMetricFunctions().size());
+    }
+
+    LinkedHashMap<MetricFunction, List<ThirdEyeResultSet>> metricFunctionToResultSetList =
+        new LinkedHashMap<>();
+
+    // Retrieve online data from database
+    // TODO: should retrieve online from a new table
+    MetricFunction metricFunction = request.getMetricFunctions().get(0);
+    MetricConfigDTO metricConfig = metricFunction.getMetricConfig();
+    String onlineData = metricConfig.getOnlineData();
+
+    String dataset = metricFunction.getDataset();
+    DatasetConfigDTO datasetConfig = ThirdEyeUtils.getDatasetConfigFromName(dataset);
+    TimeSpec dataTimeSpec = ThirdEyeUtils.getTimestampTimeSpecFromDatasetConfig(datasetConfig);
+
+    Multimap<String, String> decoratedFilterSet = request.getFilterSet();
+
+    List<String> columnNameWithDataType = new ArrayList<>();
+    columnNameWithDataType.add(datasetConfig.getTimeColumn() + ":STRING");
+    columnNameWithDataType.add(metricConfig.getName() + ":STRING");
+    DataFrame.Builder dfBuilder = DataFrame.builder(columnNameWithDataType);
+
+    // Find time/metric/filtering column indices
+    int totalColumnCount = 2; // Currently only support default settings: <date, online_metric>
+    String[] columnsOfTheRow;
+    ObjectMapper objectMapper = new ObjectMapper();
+    JsonNode rootNode = objectMapper.readTree(onlineData);
+    ArrayNode columnsNode = (ArrayNode) rootNode.path("columns");
+    ArrayNode rowsNode = (ArrayNode) rootNode.path("rows");
+
+    int timeColIdx = -1, metricColIdx = -1;
+    Map<String, Integer> colNameToFilterColIndices = new HashMap<>();
+    if (columnsNode.isArray()) {
+      int idx = 0;
+      for (JsonNode columnNode : columnsNode) {
+        String columnName = columnNode.textValue();
+        if (columnName.equals(datasetConfig.getTimeColumn()))
+          timeColIdx = idx;
+        else if (columnName.equals(metricConfig.getName()))
+          metricColIdx = idx;
+        if (decoratedFilterSet.keySet().contains(columnName))
+          colNameToFilterColIndices.put(columnName, idx);
+        idx++;
+      }
+    }
+
+    // Filter values in each row and build dataFrame
+    DateTime startTime = request.getStartTimeInclusive();
+    DateTime endTime = request.getEndTimeExclusive();
+
+    if (rowsNode.isArray()) {
+      for (JsonNode rowNode : rowsNode) {
+        if (rowNode.isArray()) {
+          // Filter by time range
+          String timeValString = rowNode.get(timeColIdx).textValue();
+          DateTime timeValDate = convertStringToDate(timeValString, datasetConfig.getTimezone(),
+              dataTimeSpec.getFormat());
+          if (timeValDate.isBefore(startTime) || timeValDate.isAfter(endTime))
+            continue;
+
+          // Filter by filtering set
+          boolean needFiltered = false;
+          for (String columnName : colNameToFilterColIndices.keySet()) {
+            int inspectIdx = colNameToFilterColIndices.get(columnName);
+            String inspectVal = rowNode.get(inspectIdx).textValue();
+            Collection<String> filterSet = decoratedFilterSet.get(columnName);
+            if (filterSet.contains(inspectVal)) {
+              needFiltered = true;
+              break;
+            }
+          }
+          if (needFiltered)
+            continue;
+
+          int idxInDF = 0;
+          columnsOfTheRow = new String[totalColumnCount];
+          columnsOfTheRow[idxInDF++] = rowNode.get(timeColIdx).textValue();
+          columnsOfTheRow[idxInDF] = rowNode.get(metricColIdx).textValue();
+          dfBuilder.append(columnsOfTheRow);
+        }
+      }
+    }
+    DataFrame dataFrame = dfBuilder.build();
+
+    // Create resultSetGroup
+    List<String> groupKeyColumnNames = new ArrayList<>();
+    groupKeyColumnNames.add(datasetConfig.getTimeColumn());
+    List<String> metricColumnNames = new ArrayList<>();
+    metricColumnNames.add(metricConfig.getName());
+    ThirdEyeResultSetMetaData thirdEyeResultSetMetaData =
+        new ThirdEyeResultSetMetaData(groupKeyColumnNames, metricColumnNames);
+
+    List<ThirdEyeResultSet> resultSets = new ArrayList<>();
+    resultSets.add(new ThirdEyeDataFrameResultSet(thirdEyeResultSetMetaData, dataFrame));
+    ThirdEyeResultSetGroup resultSetGroup = new ThirdEyeResultSetGroup(resultSets);
+    metricFunctionToResultSetList.put(metricFunction, resultSetGroup.getResultSets());
+
+    List<String[]> resultRows =
+        ThirdEyeResultSetUtils.parseResultSets(request, metricFunctionToResultSetList, ONLINE);
+
+    return new RelationalThirdEyeResponse(request, resultRows, dataTimeSpec);
+  }
+
+  @Override public List<String> getDatasets() throws Exception {
+    return new ArrayList<>(this.dataSets.keySet());
+  }
+
+  @Override public void clear() throws Exception {
+    throw new RuntimeException("Online service: not supported");
+  }
+
+  @Override public void close() throws Exception {
+    throw new RuntimeException("Online service: not supported");
+  }
+
+  @Override public long getMaxDataTime(String dataset) throws Exception {
+    throw new RuntimeException("Online service: not supported");
+  }
+
+  @Override public Map<String, List<String>> getDimensionFilters(String dataset) throws Exception {
+    throw new RuntimeException("Online service: not supported");
+  }
+}
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datasource/pinot/resultset/ThirdEyeResultSetUtils.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datasource/pinot/resultset/ThirdEyeResultSetUtils.java
index 9bd622de88b..12cb11708cb 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datasource/pinot/resultset/ThirdEyeResultSetUtils.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/datasource/pinot/resultset/ThirdEyeResultSetUtils.java
@@ -49,6 +49,7 @@ public class ThirdEyeResultSetUtils {
   private static final String MYSQL = "MySQL";
   private static final String H2 = "H2";
   private static final String PINOT = "Pinot";
+  private static final String ONLINE = "Online";
 
   public static List<String[]> parseResultSets(ThirdEyeRequest request,
       Map<MetricFunction, List<ThirdEyeResultSet>> metricFunctionToResultSetList,
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/DetectionPipelineTaskInfo.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/DetectionPipelineTaskInfo.java
index d8821e98cf4..183bcf0859f 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/DetectionPipelineTaskInfo.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/DetectionPipelineTaskInfo.java
@@ -20,12 +20,14 @@
 package org.apache.pinot.thirdeye.detection;
 
 import org.apache.pinot.thirdeye.anomaly.task.TaskInfo;
-
+import org.apache.pinot.thirdeye.datalayer.pojo.DetectionConfigBean;
 
 public class DetectionPipelineTaskInfo implements TaskInfo {
   long configId;
   long start;
   long end;
+  boolean online;
+  DetectionConfigBean detectionConfigBean;
 
   public DetectionPipelineTaskInfo(long configId, long start, long end) {
     this.configId = configId;
@@ -60,4 +62,20 @@ public long getEnd() {
   public void setEnd(long end) {
     this.end = end;
   }
+
+  public boolean isOnline() {
+    return online;
+  }
+
+  public void setOnline(boolean online) {
+    this.online = online;
+  }
+
+  public DetectionConfigBean getDetectionConfigBean() {
+    return detectionConfigBean;
+  }
+
+  public void setDetectionConfigBean(DetectionConfigBean detectionConfigBean) {
+    this.detectionConfigBean = detectionConfigBean;
+  }
 }
diff --git a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/DetectionPipelineTaskRunner.java b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/DetectionPipelineTaskRunner.java
index a61330261a7..86126c7d592 100644
--- a/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/DetectionPipelineTaskRunner.java
+++ b/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/DetectionPipelineTaskRunner.java
@@ -21,6 +21,7 @@
 
 import java.util.Collections;
 import java.util.List;
+import com.google.common.base.Preconditions;
 import org.apache.pinot.thirdeye.anomaly.task.TaskContext;
 import org.apache.pinot.thirdeye.anomaly.task.TaskInfo;
 import org.apache.pinot.thirdeye.anomaly.task.TaskResult;
@@ -32,6 +33,7 @@
 import org.apache.pinot.thirdeye.datalayer.bao.EventManager;
 import org.apache.pinot.thirdeye.datalayer.bao.MergedAnomalyResultManager;
 import org.apache.pinot.thirdeye.datalayer.bao.MetricConfigManager;
+import org.apache.pinot.thirdeye.datalayer.bao.TaskManager;
 import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;
 import org.apache.pinot.thirdeye.datalayer.dto.EvaluationDTO;
 import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;
@@ -54,10 +56,13 @@ public class DetectionPipelineTaskRunner implements TaskRunner {
   private final DetectionConfigManager detectionDAO;
   private final MergedAnomalyResultManager anomalyDAO;
   private final EvaluationManager evaluationDAO;
+  private final TaskManager taskDAO;
   private final DetectionPipelineLoader loader;
   private final DataProvider provider;
   private final ModelMaintenanceFlow maintenanceFlow;
 
+  private static final Long dummyDetectionId = 123456789L;
+
   /**
    * Default constructor for ThirdEye task execution framework.
    * Loads dependencies from DAORegitry and CacheRegistry
@@ -70,6 +75,7 @@ public DetectionPipelineTaskRunner() {
     this.detectionDAO = DAORegistry.getInstance().getDetectionConfigManager();
     this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();
     this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();
+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();
     MetricConfigManager metricDAO = DAORegistry.getInstance().getMetricConfigDAO();
     DatasetConfigManager datasetDAO = DAORegistry.getInstance().getDatasetConfigDAO();
     EventManager eventDAO = DAORegistry.getInstance().getEventDAO();
@@ -105,6 +111,7 @@ public DetectionPipelineTaskRunner(DetectionConfigManager detectionDAO, MergedAn
     this.evaluationDAO = evaluationDAO;
     this.loader = loader;
     this.provider = provider;
+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();
     this.maintenanceFlow = new ModelRetuneFlow(this.provider, DetectionRegistry.getInstance());
   }
 
@@ -114,10 +121,20 @@ public List<TaskResult> execute(TaskInfo taskInfo, TaskContext taskContext) thro
 
     try {
       DetectionPipelineTaskInfo info = (DetectionPipelineTaskInfo) taskInfo;
-
-      DetectionConfigDTO config = this.detectionDAO.findById(info.configId);
-      if (config == null) {
-        throw new IllegalArgumentException(String.format("Could not resolve config id %d", info.configId));
+      DetectionConfigDTO config;
+      if (info.isOnline()) {
+        config = taskDAO.extractDetectionConfig(info);
+        // Online detection is not saved into DB so it does not have an ID
+        // To prevent later on pipeline throws a false error for null ID, use a dummy id here
+        config.setId(dummyDetectionId);
+        Preconditions.checkNotNull(config,
+            "Could not find detection config for online task info: " + info);
+      } else {
+        config = this.detectionDAO.findById(info.configId);
+
+        if (config == null) {
+          throw new IllegalArgumentException(String.format("Could not resolve config id %d", info.configId));
+        }
       }
 
       LOG.info("Start detection for config {} between {} and {}", config.getId(), info.start, info.end);
diff --git a/thirdeye/thirdeye-pinot/src/main/resources/detection-config-template.yml b/thirdeye/thirdeye-pinot/src/main/resources/detection-config-template.yml
new file mode 100644
index 00000000000..4d61b33d7fd
--- /dev/null
+++ b/thirdeye/thirdeye-pinot/src/main/resources/detection-config-template.yml
@@ -0,0 +1,24 @@
+detectionName: 'template detection'
+description: 'This is the detection used by online service'
+
+metric: metric_to_monitor
+dataset: dataset_to_which_this_metric_belongs
+
+rules:
+- detection:
+  - name: detection_rule_1
+    type: PERCENTAGE_RULE
+    params:
+      offset: wo1w
+      percentageChange: 0.2
+  filter:
+  - name: filter_rule_1
+    type: PERCENTAGE_CHANGE_FILTER
+    params:
+      pattern: UP_OR_DOWN
+      threshold: 0.05
+  quality:
+  - name: data_sla_rule_1
+    type: DATA_SLA
+    params:
+      sla: 3_DAYS
diff --git a/thirdeye/thirdeye-pinot/src/test/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResourceTest.java b/thirdeye/thirdeye-pinot/src/test/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResourceTest.java
new file mode 100644
index 00000000000..cf764fa1210
--- /dev/null
+++ b/thirdeye/thirdeye-pinot/src/test/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResourceTest.java
@@ -0,0 +1,232 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.apache.pinot.thirdeye.api.detection;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import org.apache.commons.io.IOUtils;
+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;
+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;
+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;
+import org.apache.pinot.thirdeye.datalayer.bao.*;
+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;
+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;
+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;
+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;
+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;
+import org.apache.pinot.thirdeye.datasource.DAORegistry;
+import org.apache.pinot.thirdeye.detection.annotation.registry.DetectionRegistry;
+import org.apache.pinot.thirdeye.detection.components.PercentageChangeRuleAnomalyFilter;
+import org.apache.pinot.thirdeye.detection.components.PercentageChangeRuleDetector;
+import org.apache.pinot.thirdeye.detection.dataquality.components.DataSlaQualityChecker;
+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;
+import org.testng.Assert;
+import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeMethod;
+import org.testng.annotations.Test;
+import java.io.IOException;
+
+public class AnomalyDetectionResourceTest {
+  private static final String DEFAULT_DETECTION_NAME = "online_detection";
+  private static final String DEFAULT_DATASET_NAME = "online_dataset";
+  private static final String DEFAULT_METRIC_NAME = "online_metric";
+
+  private DAOTestBase testDAOProvider;
+  private AnomalyDetectionResource anomalyDetectionResource;
+  private DAORegistry daoRegistry;
+  private DetectionConfigManager detectionDAO;
+  private DatasetConfigManager datasetDAO;
+  private MetricConfigManager metricDAO;
+  private TaskManager taskDAO;
+  private MergedAnomalyResultManager anomalyDAO;
+  private ThirdEyePrincipal user;
+  private String suffix;
+  private ObjectMapper objectMapper;
+
+  @BeforeMethod
+  public void beforeClass() {
+    testDAOProvider = DAOTestBase.getInstance();
+    this.user = new ThirdEyePrincipal("test", "test");
+    this.daoRegistry = DAORegistry.getInstance();
+    this.detectionDAO = this.daoRegistry.getDetectionConfigManager();
+    this.datasetDAO = this.daoRegistry.getDatasetConfigDAO();
+    this.metricDAO = this.daoRegistry.getMetricConfigDAO();
+    this.taskDAO = this.daoRegistry.getTaskDAO();
+    anomalyDAO = this.daoRegistry.getMergedAnomalyResultDAO();
+    this.suffix = "_" + this.user.getName();
+    this.objectMapper = new ObjectMapper();
+    UserDashboardResource userDashboardResource = new UserDashboardResource(
+        this.daoRegistry.getMergedAnomalyResultDAO(), metricDAO, datasetDAO,
+        detectionDAO, this.daoRegistry.getDetectionAlertConfigManager());
+    this.anomalyDetectionResource = new AnomalyDetectionResource(userDashboardResource);
+
+    DetectionRegistry
+        .registerComponent(PercentageChangeRuleDetector.class.getName(), "PERCENTAGE_RULE");
+    DetectionRegistry.registerComponent(PercentageChangeRuleAnomalyFilter.class.getName(),
+        "PERCENTAGE_CHANGE_FILTER");
+    DetectionRegistry.registerComponent(DataSlaQualityChecker.class.getName(), "DATA_SLA");
+  }
+
+  @AfterMethod(alwaysRun = true)
+  void afterClass() {
+    testDAOProvider.cleanup();
+  }
+
+  // TODO: will add more testings
+
+  @Test
+  public void testCleanExistingOnlineTask() {
+    DatasetConfigDTO datasetConfigDTO = new DatasetConfigDTO();
+    datasetConfigDTO.setDataset(DEFAULT_DATASET_NAME + this.suffix);
+    this.datasetDAO.save(datasetConfigDTO);
+
+    MetricConfigDTO metricConfigDTO = new MetricConfigDTO();
+    metricConfigDTO.setName(DEFAULT_METRIC_NAME + this.suffix);
+    metricConfigDTO.setDataset(datasetConfigDTO.getDataset());
+    metricConfigDTO.setAlias(ThirdEyeUtils
+        .constructMetricAlias(datasetConfigDTO.getDataset(), metricConfigDTO.getName()));
+    this.metricDAO.save(metricConfigDTO);
+
+    DetectionConfigDTO detectionConfigDTO = new DetectionConfigDTO();
+    detectionConfigDTO.setName(DEFAULT_DETECTION_NAME + this.suffix);
+
+    TaskDTO taskDTO = new TaskDTO();
+    taskDTO.setJobName(TaskConstants.TaskType.DETECTION + this.suffix);
+    taskDTO.setStatus(TaskConstants.TaskStatus.FAILED);
+    taskDTO.setTaskType(TaskConstants.TaskType.DETECTION_ONLINE);
+    this.taskDAO.save(taskDTO);
+
+    MergedAnomalyResultDTO anomalyResultDTO = new MergedAnomalyResultDTO();
+    anomalyResultDTO.setMetric(metricConfigDTO.getName());
+    long anomalyId1 = anomalyDAO.save(anomalyResultDTO);
+
+    anomalyResultDTO.setCollection(datasetConfigDTO.getName());
+    anomalyResultDTO.setMetric(null);
+    anomalyResultDTO.setId(null);
+    long anomalyId2 = anomalyDAO.save(anomalyResultDTO);
+
+    this.anomalyDetectionResource.cleanExistingOnlineTask(this.suffix);
+
+    Assert.assertNull(this.datasetDAO.findById(datasetConfigDTO.getId()));
+    Assert.assertNull(this.metricDAO.findById(metricConfigDTO.getId()));
+    Assert.assertNull(this.taskDAO.findById(taskDTO.getId()));
+    Assert.assertNull(this.anomalyDAO.findById(anomalyId1));
+    Assert.assertNull(this.anomalyDAO.findById(anomalyId2));
+  }
+
+  @Test
+  public void testValidateOnlineRequestPayload() throws Exception {
+    String goodPayload = IOUtils.toString(this.getClass().getResourceAsStream("payload-good.json"));
+    boolean goodResult =
+        this.anomalyDetectionResource.validateOnlineRequestPayload(this.objectMapper.readTree(goodPayload));
+    Assert.assertTrue(goodResult);
+
+    String badPayload = IOUtils.toString(this.getClass().getResourceAsStream("payload-bad.json"));
+    boolean badResult =
+        this.anomalyDetectionResource.validateOnlineRequestPayload(this.objectMapper.readTree(badPayload));
+    Assert.assertFalse(badResult);
+  }
+
+  @Test
+  public void testGenerateDatasetConfig() throws Exception {
+    String payload = IOUtils.toString(this.getClass().getResourceAsStream("payload-good.json"));
+
+    DatasetConfigDTO datasetConfigDTO = this.anomalyDetectionResource
+        .generateDatasetConfig(this.objectMapper.readTree(payload), this.suffix);
+
+    // Do not support customized config names. Test this
+    Assert.assertEquals(datasetConfigDTO.getDataset(), DEFAULT_DATASET_NAME + this.suffix);
+  }
+
+  @Test
+  public void testGenerateMetricConfig() throws Exception {
+    String payload = IOUtils.toString(this.getClass().getResourceAsStream("payload-good.json"));
+    JsonNode node = this.objectMapper.readTree(payload);
+    DatasetConfigDTO datasetConfigDTO = this.anomalyDetectionResource
+        .generateDatasetConfig(node, this.suffix);
+    MetricConfigDTO metricConfigDTO = this.anomalyDetectionResource
+        .generateMetricConfig(node, this.suffix, datasetConfigDTO);
+
+    // Do not support customized config names. Test this
+    Assert.assertEquals(metricConfigDTO.getName(), DEFAULT_METRIC_NAME + this.suffix);
+    Assert.assertNotNull(metricConfigDTO.getOnlineData());
+
+    this.anomalyDetectionResource.cleanExistingOnlineTask(this.suffix);
+
+    // Test customized metric and time column names - good
+    payload = IOUtils.toString(this.getClass().getResourceAsStream("payload-good-custom.json"));
+    node = this.objectMapper.readTree(payload);
+    datasetConfigDTO = this.anomalyDetectionResource
+        .generateDatasetConfig(node, this.suffix);
+    try {
+      // pass
+      this.anomalyDetectionResource
+          .generateMetricConfig(node, this.suffix, datasetConfigDTO);
+    } catch (IllegalArgumentException e) {
+      Assert.fail("Unexpected exception: " + e);
+    }
+    this.anomalyDetectionResource.cleanExistingOnlineTask(this.suffix);
+
+    // Test customized metric and time column names - bad
+    payload = IOUtils.toString(this.getClass().getResourceAsStream("payload-bad-custom.json"));
+    node = this.objectMapper.readTree(payload);
+    datasetConfigDTO = this.anomalyDetectionResource
+        .generateDatasetConfig(node, this.suffix);
+    try {
+      this.anomalyDetectionResource
+          .generateMetricConfig(node, this.suffix, datasetConfigDTO);
+      Assert.fail("Inconsistent metric name should throw illegal arg exception");
+    } catch (IllegalArgumentException e) {
+      // pass
+    } catch (Exception e) {
+      Assert.fail("Unexpected exception: " + e);
+    }
+  }
+
+  @Test
+  public void testGenerateDetectionConfig() throws IOException {
+    String payload = IOUtils.toString(this.getClass().getResourceAsStream("payload-good.json"));
+    JsonNode payloadNode = this.objectMapper.readTree(payload);
+
+    DatasetConfigDTO datasetConfigDTO =
+        this.anomalyDetectionResource.generateDatasetConfig(payloadNode, this.suffix);
+    MetricConfigDTO metricConfigDTO =
+        this.anomalyDetectionResource.generateMetricConfig(payloadNode, this.suffix, datasetConfigDTO);
+
+    DetectionConfigDTO detectionConfigDTO = this.anomalyDetectionResource
+        .generateDetectionConfig(payloadNode, this.suffix, datasetConfigDTO, metricConfigDTO, 0, 0);
+
+    // Do not support customized config names. Test this
+    Assert.assertEquals(detectionConfigDTO.getName(), DEFAULT_DETECTION_NAME + this.suffix);
+  }
+
+  @Test
+  public void testGenerateTaskConfig() throws JsonProcessingException {
+    long dummyId = 123456L;
+    DetectionConfigDTO detectionConfigDTO = new DetectionConfigDTO();
+    detectionConfigDTO.setId(dummyId);
+    TaskDTO taskDTO = this.anomalyDetectionResource
+        .generateTaskConfig(detectionConfigDTO, 0, 0, this.suffix);
+
+    Assert.assertEquals(taskDTO.getTaskType(), TaskConstants.TaskType.DETECTION_ONLINE);
+    Assert.assertEquals(taskDTO.getStatus(), TaskConstants.TaskStatus.WAITING);
+  }
+}
diff --git a/thirdeye/thirdeye-pinot/src/test/resources/org/apache/pinot/thirdeye/api/detection/payload-bad-custom.json b/thirdeye/thirdeye-pinot/src/test/resources/org/apache/pinot/thirdeye/api/detection/payload-bad-custom.json
new file mode 100644
index 00000000000..819f30c26f6
--- /dev/null
+++ b/thirdeye/thirdeye-pinot/src/test/resources/org/apache/pinot/thirdeye/api/detection/payload-bad-custom.json
@@ -0,0 +1,4 @@
+{"detectionConfiguration": "detectionName: name_of_the_detection_test\ndescription: This is the detection used by online service\nrules:\n- detection:\n  - name: detection_rule_1\n    type: PERCENTAGE_RULE\n    params: {offset: wo1w, percentageChange: 0.2}\n  filter:\n  - name: filter_rule_1\n    type: PERCENTAGE_CHANGE_FILTER\n    params: {pattern: UP_OR_DOWN, threshold: 0.05}\n  quality:\n  - name: data_sla_rule_1\n    type: DATA_SLA\n    params: {sla: 3_DAYS}\nmetric: online_metric_admin\ndataset: online_dataset_admin\n",
+  "metricConfiguration": "datatype: INT\nmetricColumn: foo",
+  "datasetConfiguration": "timeColumn: time\ntimeUnit: DAYS\ntimeDuration: 1\ntimeFormat: SIMPLE_DATE_FORMAT:yyyyMMdd\ntimezone: US/Pacific",
+  "data":{"columns":["time","rate"],"rows":[["20200325","68"],["20200428","67"],["20200422","63"]]}}
diff --git a/thirdeye/thirdeye-pinot/src/test/resources/org/apache/pinot/thirdeye/api/detection/payload-bad.json b/thirdeye/thirdeye-pinot/src/test/resources/org/apache/pinot/thirdeye/api/detection/payload-bad.json
new file mode 100644
index 00000000000..d13ec7259be
--- /dev/null
+++ b/thirdeye/thirdeye-pinot/src/test/resources/org/apache/pinot/thirdeye/api/detection/payload-bad.json
@@ -0,0 +1,3 @@
+{"detectionConfiguration": "detectionName: name_of_the_detection_test\ndescription: This is the detection used by online service\nrules:\n- detection:\n  - name: detection_rule_1\n    type: PERCENTAGE_RULE\n    params: {offset: wo1w, percentageChange: 0.2}\n  filter:\n  - name: filter_rule_1\n    type: PERCENTAGE_CHANGE_FILTER\n    params: {pattern: UP_OR_DOWN, threshold: 0.05}\n  quality:\n  - name: data_sla_rule_1\n    type: DATA_SLA\n    params: {sla: 3_DAYS}\nmetric: online_metric_admin\ndataset: online_dataset_admin\n",
+  "metricConfiguration": "datatype: INT",
+  "datasetConfiguration": "timeColumn: date\ntimeUnit: DAYS\ntimeDuration: 1\ntimeFormat: SIMPLE_DATE_FORMAT:yyyyMMdd\ntimezone: US/Pacific"}
diff --git a/thirdeye/thirdeye-pinot/src/test/resources/org/apache/pinot/thirdeye/api/detection/payload-good-custom.json b/thirdeye/thirdeye-pinot/src/test/resources/org/apache/pinot/thirdeye/api/detection/payload-good-custom.json
new file mode 100644
index 00000000000..c73fa82ad84
--- /dev/null
+++ b/thirdeye/thirdeye-pinot/src/test/resources/org/apache/pinot/thirdeye/api/detection/payload-good-custom.json
@@ -0,0 +1,4 @@
+{"detectionConfiguration": "detectionName: name_of_the_detection_test\ndescription: This is the detection used by online service\nrules:\n- detection:\n  - name: detection_rule_1\n    type: PERCENTAGE_RULE\n    params: {offset: wo1w, percentageChange: 0.2}\n  filter:\n  - name: filter_rule_1\n    type: PERCENTAGE_CHANGE_FILTER\n    params: {pattern: UP_OR_DOWN, threshold: 0.05}\n  quality:\n  - name: data_sla_rule_1\n    type: DATA_SLA\n    params: {sla: 3_DAYS}\nmetric: online_metric_admin\ndataset: online_dataset_admin\n",
+  "metricConfiguration": "datatype: INT\nmetricColumn: rate",
+  "datasetConfiguration": "timeColumn: time\ntimeUnit: DAYS\ntimeDuration: 1\ntimeFormat: SIMPLE_DATE_FORMAT:yyyyMMdd\ntimezone: US/Pacific",
+  "data":{"columns":["time","rate"],"rows":[["20200325","68"],["20200428","67"],["20200422","63"]]}}
diff --git a/thirdeye/thirdeye-pinot/src/test/resources/org/apache/pinot/thirdeye/api/detection/payload-good.json b/thirdeye/thirdeye-pinot/src/test/resources/org/apache/pinot/thirdeye/api/detection/payload-good.json
new file mode 100644
index 00000000000..8bd51343a6f
--- /dev/null
+++ b/thirdeye/thirdeye-pinot/src/test/resources/org/apache/pinot/thirdeye/api/detection/payload-good.json
@@ -0,0 +1,4 @@
+{"detectionConfiguration": "detectionName: name_of_the_detection_test\ndescription: This is the detection used by online service\nrules:\n- detection:\n  - name: detection_rule_1\n    type: PERCENTAGE_RULE\n    params: {offset: wo1w, percentageChange: 0.2}\n  filter:\n  - name: filter_rule_1\n    type: PERCENTAGE_CHANGE_FILTER\n    params: {pattern: UP_OR_DOWN, threshold: 0.05}\n  quality:\n  - name: data_sla_rule_1\n    type: DATA_SLA\n    params: {sla: 3_DAYS}\nmetric: online_metric_admin\ndataset: online_dataset_admin\n",
+  "metricConfiguration": "datatype: INT",
+  "datasetConfiguration": "timeColumn: date\ntimeUnit: DAYS\ntimeDuration: 1\ntimeFormat: SIMPLE_DATE_FORMAT:yyyyMMdd\ntimezone: US/Pacific",
+  "data":{"columns":["date","online_metric"],"rows":[["20200325","68"],["20200428","67"],["20200422","63"]]}}
