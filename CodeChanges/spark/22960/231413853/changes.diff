diff --git a/sql/core/src/test/scala/org/apache/spark/sql/CsvFunctionsSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/CsvFunctionsSuite.scala
index f0fd1917b0f12..b97ac380def63 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/CsvFunctionsSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/CsvFunctionsSuite.scala
@@ -162,37 +162,6 @@ class CsvFunctionsSuite extends QueryTest with SharedSQLContext {
 
   test("Support to_csv in SQL") {
     val df1 = Seq(Tuple1(Tuple1(1))).toDF("a")
-    checkAnswer(
-      df1.selectExpr("to_csv(a)"),
-      Row("1") :: Nil)
-
-    val df2 = Seq(Tuple1(Tuple1(java.sql.Timestamp.valueOf("2015-08-26 18:00:00.0")))).toDF("a")
-    checkAnswer(
-      df2.selectExpr("to_csv(a, map('timestampFormat', 'dd/MM/yyyy HH:mm'))"),
-      Row("26/08/2015 18:00") :: Nil)
-
-    val errMsg = intercept[AnalysisException] {
-      df2.selectExpr("to_csv(a, map('a', 1))")
-    }
-    assert(errMsg.getMessage.startsWith(
-      "A type of keys and values in map() must be string, but got"))
-  }
-
-  test("Support from_csv in SQL") {
-    val df1 = Seq("1").toDS()
-    checkAnswer(
-      df1.selectExpr("from_csv(value, 'a INT')"),
-      Row(Row(1)) :: Nil)
-
-    val df2 = Seq("26/08/2015 18:00").toDS()
-    checkAnswer(
-      df2.selectExpr(
-        "from_csv(value, 'time Timestamp', map('timestampFormat', 'dd/MM/yyyy HH:mm'))"),
-      Row(Row(java.sql.Timestamp.valueOf("2015-08-26 18:00:00.0"))))
-
-    val errMsg = intercept[AnalysisException] {
-      df2.selectExpr("from_csv(value, 'time Timestamp', named_struct('a', 1))")
-    }
-    assert(errMsg.getMessage.startsWith("Must use a map() function for options"))
+    checkAnswer(df1.selectExpr("to_csv(a)"), Row("1") :: Nil)
   }
 }
