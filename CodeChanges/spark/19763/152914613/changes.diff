diff --git a/core/src/main/scala/org/apache/spark/MapOutputTracker.scala b/core/src/main/scala/org/apache/spark/MapOutputTracker.scala
index 63be9d4cfc42a..195fd4f818b36 100644
--- a/core/src/main/scala/org/apache/spark/MapOutputTracker.scala
+++ b/core/src/main/scala/org/apache/spark/MapOutputTracker.scala
@@ -514,7 +514,7 @@ private[spark] class MapOutputTrackerMaster(
         SHUFFLE_MAP_OUTPUT_PARALLEL_AGGREGATION_THRESHOLD)
       val parallelism = math.min(
         Runtime.getRuntime.availableProcessors(),
-        statuses.length * totalSizes.length / parallelAggThreshold + 1)
+        statuses.length.toLong * totalSizes.length / parallelAggThreshold + 1).toInt
       if (parallelism <= 1) {
         for (s <- statuses) {
           for (i <- 0 until totalSizes.length) {
@@ -522,8 +522,8 @@ private[spark] class MapOutputTrackerMaster(
           }
         }
       } else {
+        val threadPool = ThreadUtils.newDaemonFixedThreadPool(parallelism, "map-output-aggregate")
         try {
-          val threadPool = ThreadUtils.newDaemonFixedThreadPool(parallelism, "map-output-aggregate")
           implicit val executionContext = ExecutionContext.fromExecutor(threadPool)
           val mapStatusSubmitTasks = equallyDivide(totalSizes.length, parallelism).map {
             reduceIds => Future {
@@ -534,7 +534,7 @@ private[spark] class MapOutputTrackerMaster(
           }
           ThreadUtils.awaitResult(Future.sequence(mapStatusSubmitTasks), Duration.Inf)
         } finally {
-          threadpool.shutdown()
+          threadPool.shutdown()
         }
       }
       new MapOutputStatistics(dep.shuffleId, totalSizes)
diff --git a/core/src/main/scala/org/apache/spark/internal/config/package.scala b/core/src/main/scala/org/apache/spark/internal/config/package.scala
index 71888db83a606..67cc52283d49b 100644
--- a/core/src/main/scala/org/apache/spark/internal/config/package.scala
+++ b/core/src/main/scala/org/apache/spark/internal/config/package.scala
@@ -490,8 +490,10 @@ package object config {
     ConfigBuilder("spark.shuffle.mapOutput.parallelAggregationThreshold")
       .internal()
       .doc("Multi-thread is used when the number of mappers * shuffle partitions is greater than " +
-        "or equal to this threshold.")
+        "or equal to this threshold. Note that the actual parallelism is calculated by number of " +
+        "mappers * shuffle partitions / this threshold + 1, so this threshold should be positive.")
       .intConf
+      .checkValue(v => v > 0, "The threshold should be positive.")
       .createWithDefault(10000000)
 
 }
