diff --git a/core/src/main/scala/org/apache/spark/internal/config/package.scala b/core/src/main/scala/org/apache/spark/internal/config/package.scala
index 0ecda92f35dec..eaf6a787ce778 100644
--- a/core/src/main/scala/org/apache/spark/internal/config/package.scala
+++ b/core/src/main/scala/org/apache/spark/internal/config/package.scala
@@ -225,11 +225,11 @@ package object config {
     .createWithDefault(4 * 1024 * 1024)
 
   private[spark] val SECRET_REDACTION_PATTERN =
-    ConfigBuilder("spark.secret.redactionPattern")
-      .doc("Scala regex(case-sensitive) to decide which Spark configuration properties and " +
-        "environment variables in driver and executor environments contain sensitive information." +
-        " When this regex matches the property or environment variable name, its value is " +
-        "redacted from the environment UI and various logs like YARN and event logs")
+    ConfigBuilder("spark.redacton.regex")
+      .doc("Regex to decide which Spark configuration properties and environment variables in " +
+        "driver and executor environments contain sensitive information. When this regex matches " +
+        "a property , its value is redacted from the environment UI and various logs like YARN " +
+        "and event logs")
       .stringConf
-      .createWithDefault("secret|password|SECRET|PASSWORD")
+      .createWithDefault("(?i)secret|password")
 }
diff --git a/core/src/main/scala/org/apache/spark/util/Utils.scala b/core/src/main/scala/org/apache/spark/util/Utils.scala
index abf71dde777b2..76f3aa6f5852f 100644
--- a/core/src/main/scala/org/apache/spark/util/Utils.scala
+++ b/core/src/main/scala/org/apache/spark/util/Utils.scala
@@ -2557,6 +2557,7 @@ private[spark] object Utils extends Logging {
   }
 
   private[util] val REDACTION_REPLACEMENT_TEXT = "*********(redacted)"
+
   def redact(conf: SparkConf)(kv: (String, String)): (String, String) = {
     val redactionPattern = conf.get(SECRET_REDACTION_PATTERN).r
     if (redactionPattern.findFirstIn(kv._1).isDefined) {
diff --git a/core/src/test/scala/org/apache/spark/scheduler/EventLoggingListenerSuite.scala b/core/src/test/scala/org/apache/spark/scheduler/EventLoggingListenerSuite.scala
index 8664114bd0101..3331ba55c35f8 100644
--- a/core/src/test/scala/org/apache/spark/scheduler/EventLoggingListenerSuite.scala
+++ b/core/src/test/scala/org/apache/spark/scheduler/EventLoggingListenerSuite.scala
@@ -116,7 +116,7 @@ class EventLoggingListenerSuite extends SparkFunSuite with LocalSparkContext wit
     val regex = """"spark.executorEnv.HADOOP_CREDSTORE_PASSWORD":"([^"]*)"""".r
     val matches = regex.findAllIn(eventLog)
     assert(matches.nonEmpty)
-    matches.foreach(matched => assert(matched.equals(expected)))
+    matches.foreach{ matched => assert(matched.equals(expected)) }
   }
 
   test("Log overwriting") {
diff --git a/core/src/test/scala/org/apache/spark/util/UtilsSuite.scala b/core/src/test/scala/org/apache/spark/util/UtilsSuite.scala
index bb27d1f6b5db1..cc0d51eff1a62 100644
--- a/core/src/test/scala/org/apache/spark/util/UtilsSuite.scala
+++ b/core/src/test/scala/org/apache/spark/util/UtilsSuite.scala
@@ -977,15 +977,25 @@ class UtilsSuite extends SparkFunSuite with ResetSystemProperties with Logging {
 
   test("redact sensitive information") {
     val sparkConf = new SparkConf
-    sparkConf.set("spark.executorEnv.HADOOP_CREDSTORE_PASSWORD", "secret_password")
-    sparkConf.set("spark.my.password", "secret_password")
-    sparkConf.set("spark.my.secret", "secret_password")
+
+    // Set some secret keys
+    val secretKeys = Seq("" +
+      "spark.executorEnv.HADOOP_CREDSTORE_PASSWORD",
+      "spark.my.password",
+      "spark.my.sECreT")
+    secretKeys.foreach { key =>
+      sparkConf.set(key, "secret_password")
+    }
+    // Set a non-secret key
     sparkConf.set("spark.regular.property", "not_a_secret")
+
+    // Redact sensitive information
     val redactedConf = sparkConf.getAll.map(Utils.redact(sparkConf)).toMap
-    assert(redactedConf.get("spark.executorEnv.HADOOP_CREDSTORE_PASSWORD").get == Utils
-      .REDACTION_REPLACEMENT_TEXT)
-    assert(redactedConf.get("spark.my.password").get == Utils.REDACTION_REPLACEMENT_TEXT)
-    assert(redactedConf.get("spark.my.secret").get == Utils.REDACTION_REPLACEMENT_TEXT)
+
+    // Assert that secret information got redacted while the regular property remained the same
+    secretKeys.foreach { key =>
+      assert(redactedConf.get(key).get == Utils.REDACTION_REPLACEMENT_TEXT)
+    }
     assert(redactedConf.get("spark.regular.property").get == "not_a_secret")
   }
 }
diff --git a/docs/configuration.md b/docs/configuration.md
index 5e8bd41a7f7ba..aa201c6b6a7ea 100644
--- a/docs/configuration.md
+++ b/docs/configuration.md
@@ -357,13 +357,12 @@ Apart from these, the following properties are also available, and may be useful
   </td>
 </tr>
 <tr>
-  <td><code>spark.secret.redactionPattern</code></td>
-  <td>secret|password|SECRET|PASSWORD</td>
+  <td><code>spark.redaction.regex</code></td>
+  <td>(?i)secret|password</td>
   <td>
-    Scala regex(case-sensitive) to decide which Spark configuration properties and environment
-    variables in driver and executor environments contain sensitive information. When this
-    regex matches the property or environment variable name, its value is redacted from the
-    environment UI and various logs like YARN and event logs.
+    Regex to decide which Spark configuration properties and environment variables in driver and
+    executor environments contain sensitive information. When this regex matches a property, its
+    value is redacted from the environment UI and various logs like YARN and event logs.
   </td>
 </tr>
 <tr>
