{
  "url": "https://api.github.com/repos/apache/spark/pulls/3099",
  "id": 23879224,
  "node_id": "MDExOlB1bGxSZXF1ZXN0MjM4NzkyMjQ=",
  "html_url": "https://github.com/apache/spark/pull/3099",
  "diff_url": "https://github.com/apache/spark/pull/3099.diff",
  "patch_url": "https://github.com/apache/spark/pull/3099.patch",
  "issue_url": "https://api.github.com/repos/apache/spark/issues/3099",
  "number": 3099,
  "state": "closed",
  "locked": false,
  "title": "[SPARK-3530][MLLIB] pipeline and parameters with examples",
  "user": {
    "login": "mengxr",
    "id": 829644,
    "node_id": "MDQ6VXNlcjgyOTY0NA==",
    "avatar_url": "https://avatars.githubusercontent.com/u/829644?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/mengxr",
    "html_url": "https://github.com/mengxr",
    "followers_url": "https://api.github.com/users/mengxr/followers",
    "following_url": "https://api.github.com/users/mengxr/following{/other_user}",
    "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions",
    "organizations_url": "https://api.github.com/users/mengxr/orgs",
    "repos_url": "https://api.github.com/users/mengxr/repos",
    "events_url": "https://api.github.com/users/mengxr/events{/privacy}",
    "received_events_url": "https://api.github.com/users/mengxr/received_events",
    "type": "User",
    "site_admin": false
  },
  "body": "This PR adds package \"org.apache.spark.ml\" with pipeline and parameters, as discussed on the JIRA. This is a joint work of @jkbradley @etrain @shivaram and many others who helped on the design, also with help from  @marmbrus and @liancheng on the Spark SQL side. The design doc can be found at:\n\nhttps://docs.google.com/document/d/1rVwXRjWKfIb-7PI6b86ipytwbUH7irSNLF1_6dLmh8o/edit?usp=sharing\n\n**org.apache.spark.ml**\n\nThis is a new package with new set of ML APIs that address practical machine learning pipelines. (Sorry for taking so long!) It will be an alpha component, so this is definitely not something set in stone. The new set of APIs, inspired by the MLI project from AMPLab and scikit-learn, takes leverage on Spark SQL's schema support and execution plan optimization. It introduces the following components that help build a practical pipeline:\n1. Transformer, which transforms a dataset into another\n2. Estimator, which fits models to data, where models are transformers\n3. Evaluator, which evaluates model output and returns a scalar metric\n4. Pipeline, a simple pipeline that consists of transformers and estimators\n\nParameters could be supplied at fit/transform or embedded with components.\n1. Param: a strong-typed parameter key with self-contained doc\n2. ParamMap: a param -> value map\n3. Params: trait for components with parameters\n\nFor any component that implements `Params`, user can easily check the doc by calling `explainParams`:\n\n```\n> val lr = new LogisticRegression\n> lr.explainParams\nmaxIter: max number of iterations (default: 100)\nregParam: regularization constant (default: 0.1)\nlabelCol: label column name (default: label)\nfeaturesCol: features column name (default: features)\n```\n\nor user can check individual param:\n\n```\n> lr.maxIter\nmaxIter: max number of iterations (default: 100)\n```\n\n**Please start with the example code in test suites and under `org.apache.spark.examples.ml`, where I put several examples:**\n1. run a simple logistic regression job\n\n```\n    val lr = new LogisticRegression()\n      .setMaxIter(10)\n      .setRegParam(1.0)\n    val model = lr.fit(dataset)\n    model.transform(dataset, model.threshold -> 0.8) // overwrite threshold\n      .select('label, 'score, 'prediction).collect()\n      .foreach(println)\n```\n1. run logistic regression with cross-validation and grid search using areaUnderROC (default) as the metric\n\n```\n    val lr = new LogisticRegression\n    val lrParamMaps = new ParamGridBuilder()\n      .addGrid(lr.regParam, Array(0.1, 100.0))\n      .addGrid(lr.maxIter, Array(0, 5))\n      .build()\n    val eval = new BinaryClassificationEvaluator\n    val cv = new CrossValidator()\n      .setEstimator(lr)\n      .setEstimatorParamMaps(lrParamMaps)\n      .setEvaluator(eval)\n      .setNumFolds(3)\n    val bestModel = cv.fit(dataset)\n```\n1. run a pipeline that consists of a standard scaler and a logistic regression component\n\n```\n    val scaler = new StandardScaler()\n      .setInputCol(\"features\")\n      .setOutputCol(\"scaledFeatures\")\n    val lr = new LogisticRegression()\n      .setFeaturesCol(scaler.getOutputCol)\n    val pipeline = new Pipeline()\n      .setStages(Array(scaler, lr))\n    val model = pipeline.fit(dataset)\n    val predictions = model.transform(dataset)\n      .select('label, 'score, 'prediction)\n      .collect()\n      .foreach(println)\n```\n1. a simple text classification pipeline, which recognizes \"spark\":\n\n```\n    val training = sparkContext.parallelize(Seq(\n      LabeledDocument(0L, \"a b c d e spark\", 1.0),\n      LabeledDocument(1L, \"b d\", 0.0),\n      LabeledDocument(2L, \"spark f g h\", 1.0),\n      LabeledDocument(3L, \"hadoop mapreduce\", 0.0)))\n    val tokenizer = new Tokenizer()\n      .setInputCol(\"text\")\n      .setOutputCol(\"words\")\n    val hashingTF = new HashingTF()\n      .setInputCol(tokenizer.getOutputCol)\n      .setOutputCol(\"features\")\n    val lr = new LogisticRegression()\n      .setMaxIter(10)\n    val pipeline = new Pipeline()\n      .setStages(Array(tokenizer, hashingTF, lr))\n    val model = pipeline.fit(training)\n    val test = sparkContext.parallelize(Seq(\n      Document(4L, \"spark i j k\"),\n      Document(5L, \"l m\"),\n      Document(6L, \"mapreduce spark\"),\n      Document(7L, \"apache hadoop\")))\n    model.transform(test)\n      .select('id, 'text, 'prediction, 'score)\n      .collect()\n      .foreach(println)\n```\n\nJava examples are very similar. I put example code that creates a simple text classification pipeline in Scala and Java, where a simple tokenizer is defined as a transformer outside `org.apache.spark.ml`.\n\n**What are missing now and will be added soon:**\n1. ~~Runtime check of schemas. So before we touch the data, we will go through the schema and make sure column names and types match the input parameters.~~\n2. ~~Java examples.~~\n3. ~~Store training parameters in trained models.~~\n4. (later) Serialization and Python API.\n",
  "created_at": "2014-11-05T01:51:46Z",
  "updated_at": "2014-11-14T19:20:36Z",
  "closed_at": "2014-11-12T19:02:40Z",
  "merged_at": null,
  "merge_commit_sha": "350c8afeefadd8a6cfffc5efdef20f19d46fa926",
  "assignee": null,
  "assignees": [],
  "requested_reviewers": [],
  "requested_teams": [],
  "labels": [],
  "milestone": null,
  "draft": false,
  "commits_url": "https://api.github.com/repos/apache/spark/pulls/3099/commits",
  "review_comments_url": "https://api.github.com/repos/apache/spark/pulls/3099/comments",
  "review_comment_url": "https://api.github.com/repos/apache/spark/pulls/comments{/number}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/3099/comments",
  "statuses_url": "https://api.github.com/repos/apache/spark/statuses/2cc93fd7104b76a7cfb6428b3b3deade76e91590",
  "head": {
    "label": "mengxr:SPARK-3530",
    "ref": "SPARK-3530",
    "sha": "2cc93fd7104b76a7cfb6428b3b3deade76e91590",
    "user": {
      "login": "mengxr",
      "id": 829644,
      "node_id": "MDQ6VXNlcjgyOTY0NA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/829644?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mengxr",
      "html_url": "https://github.com/mengxr",
      "followers_url": "https://api.github.com/users/mengxr/followers",
      "following_url": "https://api.github.com/users/mengxr/following{/other_user}",
      "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions",
      "organizations_url": "https://api.github.com/users/mengxr/orgs",
      "repos_url": "https://api.github.com/users/mengxr/repos",
      "events_url": "https://api.github.com/users/mengxr/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mengxr/received_events",
      "type": "User",
      "site_admin": false
    },
    "repo": {
      "id": 17278743,
      "node_id": "MDEwOlJlcG9zaXRvcnkxNzI3ODc0Mw==",
      "name": "spark",
      "full_name": "mengxr/spark",
      "private": false,
      "owner": {
        "login": "mengxr",
        "id": 829644,
        "node_id": "MDQ6VXNlcjgyOTY0NA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/829644?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mengxr",
        "html_url": "https://github.com/mengxr",
        "followers_url": "https://api.github.com/users/mengxr/followers",
        "following_url": "https://api.github.com/users/mengxr/following{/other_user}",
        "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions",
        "organizations_url": "https://api.github.com/users/mengxr/orgs",
        "repos_url": "https://api.github.com/users/mengxr/repos",
        "events_url": "https://api.github.com/users/mengxr/events{/privacy}",
        "received_events_url": "https://api.github.com/users/mengxr/received_events",
        "type": "User",
        "site_admin": false
      },
      "html_url": "https://github.com/mengxr/spark",
      "description": "Mirror of Apache Spark",
      "fork": true,
      "url": "https://api.github.com/repos/mengxr/spark",
      "forks_url": "https://api.github.com/repos/mengxr/spark/forks",
      "keys_url": "https://api.github.com/repos/mengxr/spark/keys{/key_id}",
      "collaborators_url": "https://api.github.com/repos/mengxr/spark/collaborators{/collaborator}",
      "teams_url": "https://api.github.com/repos/mengxr/spark/teams",
      "hooks_url": "https://api.github.com/repos/mengxr/spark/hooks",
      "issue_events_url": "https://api.github.com/repos/mengxr/spark/issues/events{/number}",
      "events_url": "https://api.github.com/repos/mengxr/spark/events",
      "assignees_url": "https://api.github.com/repos/mengxr/spark/assignees{/user}",
      "branches_url": "https://api.github.com/repos/mengxr/spark/branches{/branch}",
      "tags_url": "https://api.github.com/repos/mengxr/spark/tags",
      "blobs_url": "https://api.github.com/repos/mengxr/spark/git/blobs{/sha}",
      "git_tags_url": "https://api.github.com/repos/mengxr/spark/git/tags{/sha}",
      "git_refs_url": "https://api.github.com/repos/mengxr/spark/git/refs{/sha}",
      "trees_url": "https://api.github.com/repos/mengxr/spark/git/trees{/sha}",
      "statuses_url": "https://api.github.com/repos/mengxr/spark/statuses/{sha}",
      "languages_url": "https://api.github.com/repos/mengxr/spark/languages",
      "stargazers_url": "https://api.github.com/repos/mengxr/spark/stargazers",
      "contributors_url": "https://api.github.com/repos/mengxr/spark/contributors",
      "subscribers_url": "https://api.github.com/repos/mengxr/spark/subscribers",
      "subscription_url": "https://api.github.com/repos/mengxr/spark/subscription",
      "commits_url": "https://api.github.com/repos/mengxr/spark/commits{/sha}",
      "git_commits_url": "https://api.github.com/repos/mengxr/spark/git/commits{/sha}",
      "comments_url": "https://api.github.com/repos/mengxr/spark/comments{/number}",
      "issue_comment_url": "https://api.github.com/repos/mengxr/spark/issues/comments{/number}",
      "contents_url": "https://api.github.com/repos/mengxr/spark/contents/{+path}",
      "compare_url": "https://api.github.com/repos/mengxr/spark/compare/{base}...{head}",
      "merges_url": "https://api.github.com/repos/mengxr/spark/merges",
      "archive_url": "https://api.github.com/repos/mengxr/spark/{archive_format}{/ref}",
      "downloads_url": "https://api.github.com/repos/mengxr/spark/downloads",
      "issues_url": "https://api.github.com/repos/mengxr/spark/issues{/number}",
      "pulls_url": "https://api.github.com/repos/mengxr/spark/pulls{/number}",
      "milestones_url": "https://api.github.com/repos/mengxr/spark/milestones{/number}",
      "notifications_url": "https://api.github.com/repos/mengxr/spark/notifications{?since,all,participating}",
      "labels_url": "https://api.github.com/repos/mengxr/spark/labels{/name}",
      "releases_url": "https://api.github.com/repos/mengxr/spark/releases{/id}",
      "deployments_url": "https://api.github.com/repos/mengxr/spark/deployments",
      "created_at": "2014-02-28T07:27:59Z",
      "updated_at": "2021-09-27T16:31:41Z",
      "pushed_at": "2021-09-27T16:30:46Z",
      "git_url": "git://github.com/mengxr/spark.git",
      "ssh_url": "git@github.com:mengxr/spark.git",
      "clone_url": "https://github.com/mengxr/spark.git",
      "svn_url": "https://github.com/mengxr/spark",
      "homepage": null,
      "size": 355912,
      "stargazers_count": 0,
      "watchers_count": 0,
      "language": "Scala",
      "has_issues": false,
      "has_projects": true,
      "has_downloads": true,
      "has_wiki": false,
      "has_pages": false,
      "has_discussions": false,
      "forks_count": 0,
      "mirror_url": null,
      "archived": false,
      "disabled": false,
      "open_issues_count": 0,
      "license": {
        "key": "apache-2.0",
        "name": "Apache License 2.0",
        "spdx_id": "Apache-2.0",
        "url": "https://api.github.com/licenses/apache-2.0",
        "node_id": "MDc6TGljZW5zZTI="
      },
      "allow_forking": true,
      "is_template": false,
      "web_commit_signoff_required": false,
      "topics": [],
      "visibility": "public",
      "forks": 0,
      "open_issues": 0,
      "watchers": 0,
      "default_branch": "master"
    }
  },
  "base": {
    "label": "apache:master",
    "ref": "master",
    "sha": "faeb41de215d3ac567ce72a43ab242ad433ca93e",
    "user": {
      "login": "apache",
      "id": 47359,
      "node_id": "MDEyOk9yZ2FuaXphdGlvbjQ3MzU5",
      "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/apache",
      "html_url": "https://github.com/apache",
      "followers_url": "https://api.github.com/users/apache/followers",
      "following_url": "https://api.github.com/users/apache/following{/other_user}",
      "gists_url": "https://api.github.com/users/apache/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/apache/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/apache/subscriptions",
      "organizations_url": "https://api.github.com/users/apache/orgs",
      "repos_url": "https://api.github.com/users/apache/repos",
      "events_url": "https://api.github.com/users/apache/events{/privacy}",
      "received_events_url": "https://api.github.com/users/apache/received_events",
      "type": "Organization",
      "site_admin": false
    },
    "repo": {
      "id": 17165658,
      "node_id": "MDEwOlJlcG9zaXRvcnkxNzE2NTY1OA==",
      "name": "spark",
      "full_name": "apache/spark",
      "private": false,
      "owner": {
        "login": "apache",
        "id": 47359,
        "node_id": "MDEyOk9yZ2FuaXphdGlvbjQ3MzU5",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/apache",
        "html_url": "https://github.com/apache",
        "followers_url": "https://api.github.com/users/apache/followers",
        "following_url": "https://api.github.com/users/apache/following{/other_user}",
        "gists_url": "https://api.github.com/users/apache/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/apache/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/apache/subscriptions",
        "organizations_url": "https://api.github.com/users/apache/orgs",
        "repos_url": "https://api.github.com/users/apache/repos",
        "events_url": "https://api.github.com/users/apache/events{/privacy}",
        "received_events_url": "https://api.github.com/users/apache/received_events",
        "type": "Organization",
        "site_admin": false
      },
      "html_url": "https://github.com/apache/spark",
      "description": "Apache Spark - A unified analytics engine for large-scale data processing",
      "fork": false,
      "url": "https://api.github.com/repos/apache/spark",
      "forks_url": "https://api.github.com/repos/apache/spark/forks",
      "keys_url": "https://api.github.com/repos/apache/spark/keys{/key_id}",
      "collaborators_url": "https://api.github.com/repos/apache/spark/collaborators{/collaborator}",
      "teams_url": "https://api.github.com/repos/apache/spark/teams",
      "hooks_url": "https://api.github.com/repos/apache/spark/hooks",
      "issue_events_url": "https://api.github.com/repos/apache/spark/issues/events{/number}",
      "events_url": "https://api.github.com/repos/apache/spark/events",
      "assignees_url": "https://api.github.com/repos/apache/spark/assignees{/user}",
      "branches_url": "https://api.github.com/repos/apache/spark/branches{/branch}",
      "tags_url": "https://api.github.com/repos/apache/spark/tags",
      "blobs_url": "https://api.github.com/repos/apache/spark/git/blobs{/sha}",
      "git_tags_url": "https://api.github.com/repos/apache/spark/git/tags{/sha}",
      "git_refs_url": "https://api.github.com/repos/apache/spark/git/refs{/sha}",
      "trees_url": "https://api.github.com/repos/apache/spark/git/trees{/sha}",
      "statuses_url": "https://api.github.com/repos/apache/spark/statuses/{sha}",
      "languages_url": "https://api.github.com/repos/apache/spark/languages",
      "stargazers_url": "https://api.github.com/repos/apache/spark/stargazers",
      "contributors_url": "https://api.github.com/repos/apache/spark/contributors",
      "subscribers_url": "https://api.github.com/repos/apache/spark/subscribers",
      "subscription_url": "https://api.github.com/repos/apache/spark/subscription",
      "commits_url": "https://api.github.com/repos/apache/spark/commits{/sha}",
      "git_commits_url": "https://api.github.com/repos/apache/spark/git/commits{/sha}",
      "comments_url": "https://api.github.com/repos/apache/spark/comments{/number}",
      "issue_comment_url": "https://api.github.com/repos/apache/spark/issues/comments{/number}",
      "contents_url": "https://api.github.com/repos/apache/spark/contents/{+path}",
      "compare_url": "https://api.github.com/repos/apache/spark/compare/{base}...{head}",
      "merges_url": "https://api.github.com/repos/apache/spark/merges",
      "archive_url": "https://api.github.com/repos/apache/spark/{archive_format}{/ref}",
      "downloads_url": "https://api.github.com/repos/apache/spark/downloads",
      "issues_url": "https://api.github.com/repos/apache/spark/issues{/number}",
      "pulls_url": "https://api.github.com/repos/apache/spark/pulls{/number}",
      "milestones_url": "https://api.github.com/repos/apache/spark/milestones{/number}",
      "notifications_url": "https://api.github.com/repos/apache/spark/notifications{?since,all,participating}",
      "labels_url": "https://api.github.com/repos/apache/spark/labels{/name}",
      "releases_url": "https://api.github.com/repos/apache/spark/releases{/id}",
      "deployments_url": "https://api.github.com/repos/apache/spark/deployments",
      "created_at": "2014-02-25T08:00:08Z",
      "updated_at": "2022-12-26T21:18:49Z",
      "pushed_at": "2022-12-26T23:10:31Z",
      "git_url": "git://github.com/apache/spark.git",
      "ssh_url": "git@github.com:apache/spark.git",
      "clone_url": "https://github.com/apache/spark.git",
      "svn_url": "https://github.com/apache/spark",
      "homepage": "https://spark.apache.org/",
      "size": 451536,
      "stargazers_count": 34617,
      "watchers_count": 34617,
      "language": "Scala",
      "has_issues": false,
      "has_projects": true,
      "has_downloads": true,
      "has_wiki": false,
      "has_pages": false,
      "has_discussions": false,
      "forks_count": 26430,
      "mirror_url": null,
      "archived": false,
      "disabled": false,
      "open_issues_count": 208,
      "license": {
        "key": "apache-2.0",
        "name": "Apache License 2.0",
        "spdx_id": "Apache-2.0",
        "url": "https://api.github.com/licenses/apache-2.0",
        "node_id": "MDc6TGljZW5zZTI="
      },
      "allow_forking": true,
      "is_template": false,
      "web_commit_signoff_required": false,
      "topics": [
        "big-data",
        "java",
        "jdbc",
        "python",
        "r",
        "scala",
        "spark",
        "sql"
      ],
      "visibility": "public",
      "forks": 26430,
      "open_issues": 208,
      "watchers": 34617,
      "default_branch": "master"
    }
  },
  "_links": {
    "self": {
      "href": "https://api.github.com/repos/apache/spark/pulls/3099"
    },
    "html": {
      "href": "https://github.com/apache/spark/pull/3099"
    },
    "issue": {
      "href": "https://api.github.com/repos/apache/spark/issues/3099"
    },
    "comments": {
      "href": "https://api.github.com/repos/apache/spark/issues/3099/comments"
    },
    "review_comments": {
      "href": "https://api.github.com/repos/apache/spark/pulls/3099/comments"
    },
    "review_comment": {
      "href": "https://api.github.com/repos/apache/spark/pulls/comments{/number}"
    },
    "commits": {
      "href": "https://api.github.com/repos/apache/spark/pulls/3099/commits"
    },
    "statuses": {
      "href": "https://api.github.com/repos/apache/spark/statuses/2cc93fd7104b76a7cfb6428b3b3deade76e91590"
    }
  },
  "author_association": "CONTRIBUTOR",
  "auto_merge": null,
  "active_lock_reason": null,
  "merged": false,
  "mergeable": false,
  "rebaseable": false,
  "mergeable_state": "dirty",
  "merged_by": null,
  "comments": 105,
  "review_comments": 128,
  "maintainer_can_modify": false,
  "commits": 55,
  "additions": 2425,
  "deletions": 16,
  "changed_files": 33
}