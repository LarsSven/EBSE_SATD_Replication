diff --git a/tests/api/common/experimental/test_trigger_dag.py b/tests/api/common/experimental/test_trigger_dag.py
index a77838f7e20e4..47afdfa58dc25 100644
--- a/tests/api/common/experimental/test_trigger_dag.py
+++ b/tests/api/common/experimental/test_trigger_dag.py
@@ -26,7 +26,7 @@
 from airflow.api.common.experimental.trigger_dag import _trigger_dag
 
 
-class TriggerDagTests(unittest.TestCase):
+class TestTriggerDag(unittest.TestCase):
 
     @mock.patch('airflow.models.DagRun')
     @mock.patch('airflow.models.DagBag')
diff --git a/tests/contrib/hooks/test_cassandra_hook.py b/tests/contrib/hooks/test_cassandra_hook.py
index dc3c1c1d5a817..6d9e823c4f9d4 100644
--- a/tests/contrib/hooks/test_cassandra_hook.py
+++ b/tests/contrib/hooks/test_cassandra_hook.py
@@ -29,7 +29,7 @@
 from tests.compat import mock, patch
 
 
-class CassandraHookTest(unittest.TestCase):
+class TestCassandraHook(unittest.TestCase):
     def setUp(self):
         db.merge_conn(
             Connection(
diff --git a/tests/contrib/hooks/test_databricks_hook.py b/tests/contrib/hooks/test_databricks_hook.py
index febd0cfdbf3db..fd2cd61acecbc 100644
--- a/tests/contrib/hooks/test_databricks_hook.py
+++ b/tests/contrib/hooks/test_databricks_hook.py
@@ -153,7 +153,7 @@ def setup_mock_requests(mock_requests,
             [side_effect] * error_count + [create_valid_response_mock(response_content)]
 
 
-class DatabricksHookTest(unittest.TestCase):
+class TestDatabricksHook(unittest.TestCase):
     """
     Tests for DatabricksHook.
     """
@@ -390,7 +390,7 @@ def test_terminate_cluster(self, mock_requests):
             timeout=self.hook.timeout_seconds)
 
 
-class DatabricksHookTokenTest(unittest.TestCase):
+class TestDatabricksHookToken(unittest.TestCase):
     """
     Tests for DatabricksHook when auth is done with token.
     """
@@ -424,7 +424,7 @@ def test_submit_run(self, mock_requests):
         self.assertEqual(kwargs['auth'].token, TOKEN)
 
 
-class RunStateTest(unittest.TestCase):
+class TestRunState(unittest.TestCase):
     def test_is_terminal_true(self):
         terminal_states = ['TERMINATED', 'SKIPPED', 'INTERNAL_ERROR']
         for state in terminal_states:
diff --git a/tests/contrib/hooks/test_gcp_api_base_hook.py b/tests/contrib/hooks/test_gcp_api_base_hook.py
index 6a65ecf3b0666..cf6db0a253abc 100644
--- a/tests/contrib/hooks/test_gcp_api_base_hook.py
+++ b/tests/contrib/hooks/test_gcp_api_base_hook.py
@@ -135,7 +135,7 @@ def test_restrict_positional_arguments(self):
 ENV_VALUE = "/tmp/a"
 
 
-class ProvideGcpCredentialFileTestCase(unittest.TestCase):
+class TestProvideGcpCredentialFile(unittest.TestCase):
     def setUp(self):
         with mock.patch(
             'airflow.contrib.hooks.gcp_api_base_hook.GoogleCloudBaseHook.__init__',
diff --git a/tests/contrib/hooks/test_gcp_dataproc_hook.py b/tests/contrib/hooks/test_gcp_dataproc_hook.py
index b4f29e44757bd..b24d5c9661d92 100644
--- a/tests/contrib/hooks/test_gcp_dataproc_hook.py
+++ b/tests/contrib/hooks/test_gcp_dataproc_hook.py
@@ -38,7 +38,7 @@ def mock_init(self, gcp_conn_id, delegate_to=None):  # pylint: disable=unused-ar
     pass
 
 
-class DataProcHookTest(unittest.TestCase):
+class TestDataProcHook(unittest.TestCase):
     def setUp(self):
         with mock.patch(BASE_STRING.format('GoogleCloudBaseHook.__init__'),
                         new=mock_init):
@@ -53,7 +53,7 @@ def test_submit(self, job_mock):
                                              job_error_states=mock.ANY, num_retries=mock.ANY)
 
 
-class DataProcJobTest(unittest.TestCase):
+class TestDataProcJob(unittest.TestCase):
     UUID = '12345678'
     JOB_TO_SUBMIT = {
         'job':
diff --git a/tests/contrib/hooks/test_qubole_check_hook.py b/tests/contrib/hooks/test_qubole_check_hook.py
index 150eb45852070..e6cd56b3f05dc 100644
--- a/tests/contrib/hooks/test_qubole_check_hook.py
+++ b/tests/contrib/hooks/test_qubole_check_hook.py
@@ -21,7 +21,7 @@
 from airflow.contrib.hooks.qubole_check_hook import parse_first_row
 
 
-class QuboleCheckHookTest(unittest.TestCase):
+class TestQuboleCheckHook(unittest.TestCase):
     def test_single_row_bool(self):
         query_result = ['true\ttrue']
         record_list = parse_first_row(query_result)
diff --git a/tests/contrib/hooks/test_sftp_hook.py b/tests/contrib/hooks/test_sftp_hook.py
index 9a2c380cc0505..4810ffd705ac8 100644
--- a/tests/contrib/hooks/test_sftp_hook.py
+++ b/tests/contrib/hooks/test_sftp_hook.py
@@ -34,7 +34,7 @@
 SFTP_CONNECTION_USER = "root"
 
 
-class SFTPHookTest(unittest.TestCase):
+class TestSFTPHook(unittest.TestCase):
 
     @provide_session
     def update_connection(self, login, session=None):
diff --git a/tests/contrib/hooks/test_ssh_hook.py b/tests/contrib/hooks/test_ssh_hook.py
index 2b14bbe1c72cf..15d1caa3d8d21 100644
--- a/tests/contrib/hooks/test_ssh_hook.py
+++ b/tests/contrib/hooks/test_ssh_hook.py
@@ -38,7 +38,7 @@
 """
 
 
-class SSHHookTest(unittest.TestCase):
+class TestSSHHook(unittest.TestCase):
     @mock.patch('airflow.contrib.hooks.ssh_hook.paramiko.SSHClient')
     def test_ssh_connection_with_password(self, ssh_mock):
         hook = SSHHook(remote_host='remote_host',
diff --git a/tests/contrib/operators/test_adls_list_operator.py b/tests/contrib/operators/test_adls_list_operator.py
index f668b55a5a80f..a020dc5ceab01 100644
--- a/tests/contrib/operators/test_adls_list_operator.py
+++ b/tests/contrib/operators/test_adls_list_operator.py
@@ -28,7 +28,7 @@
               "test/path/PARQUET.parquet", "test/path/PIC.png"]
 
 
-class AzureDataLakeStorageListOperatorTest(unittest.TestCase):
+class TestAzureDataLakeStorageListOperator(unittest.TestCase):
 
     @mock.patch('airflow.contrib.operators.adls_list_operator.AzureDataLakeHook')
     def test_execute(self, mock_hook):
diff --git a/tests/contrib/operators/test_adls_to_gcs_operator.py b/tests/contrib/operators/test_adls_to_gcs_operator.py
index 36d61eb798690..10a443fc3dc51 100644
--- a/tests/contrib/operators/test_adls_to_gcs_operator.py
+++ b/tests/contrib/operators/test_adls_to_gcs_operator.py
@@ -32,7 +32,7 @@
 GCS_CONN_ID = 'google_cloud_default'
 
 
-class AdlsToGoogleCloudStorageOperatorTest(unittest.TestCase):
+class TestAdlsToGoogleCloudStorageOperator(unittest.TestCase):
     def test_init(self):
         """Test AdlsToGoogleCloudStorageOperator instance is properly initialized."""
 
diff --git a/tests/contrib/operators/test_bigquery_operator.py b/tests/contrib/operators/test_bigquery_operator.py
index b935b292a4c7b..4af429d53abef 100644
--- a/tests/contrib/operators/test_bigquery_operator.py
+++ b/tests/contrib/operators/test_bigquery_operator.py
@@ -51,7 +51,7 @@
 TEST_DAG_ID = 'test-bigquery-operators'
 
 
-class BigQueryCreateEmptyTableOperatorTest(unittest.TestCase):
+class TestBigQueryCreateEmptyTableOperator(unittest.TestCase):
 
     @mock.patch('airflow.contrib.operators.bigquery_operator.BigQueryHook')
     def test_execute(self, mock_hook):
@@ -76,7 +76,7 @@ def test_execute(self, mock_hook):
             )
 
 
-class BigQueryCreateExternalTableOperatorTest(unittest.TestCase):
+class TestBigQueryCreateExternalTableOperator(unittest.TestCase):
 
     @mock.patch('airflow.contrib.operators.bigquery_operator.BigQueryHook')
     def test_execute(self, mock_hook):
@@ -117,7 +117,7 @@ def test_execute(self, mock_hook):
             )
 
 
-class BigQueryDeleteDatasetOperatorTest(unittest.TestCase):
+class TestBigQueryDeleteDatasetOperator(unittest.TestCase):
     @mock.patch('airflow.contrib.operators.bigquery_operator.BigQueryHook')
     def test_execute(self, mock_hook):
         operator = BigQueryDeleteDatasetOperator(
@@ -139,7 +139,7 @@ def test_execute(self, mock_hook):
             )
 
 
-class BigQueryCreateEmptyDatasetOperatorTest(unittest.TestCase):
+class TestBigQueryCreateEmptyDatasetOperator(unittest.TestCase):
     @mock.patch('airflow.contrib.operators.bigquery_operator.BigQueryHook')
     def test_execute(self, mock_hook):
         operator = BigQueryCreateEmptyDatasetOperator(
@@ -160,7 +160,7 @@ def test_execute(self, mock_hook):
             )
 
 
-class BigQueryGetDatasetOperatorTest(unittest.TestCase):
+class TestBigQueryGetDatasetOperator(unittest.TestCase):
     @mock.patch('airflow.contrib.operators.bigquery_operator.BigQueryHook')
     def test_execute(self, mock_hook):
         operator = BigQueryGetDatasetOperator(
@@ -180,7 +180,7 @@ def test_execute(self, mock_hook):
             )
 
 
-class BigQueryPatchDatasetOperatorTest(unittest.TestCase):
+class TestBigQueryPatchDatasetOperator(unittest.TestCase):
     @mock.patch('airflow.contrib.operators.bigquery_operator.BigQueryHook')
     def test_execute(self, mock_hook):
         dataset_resource = {"friendlyName": 'Test DS'}
@@ -203,7 +203,7 @@ def test_execute(self, mock_hook):
             )
 
 
-class BigQueryUpdateDatasetOperatorTest(unittest.TestCase):
+class TestBigQueryUpdateDatasetOperator(unittest.TestCase):
     @mock.patch('airflow.contrib.operators.bigquery_operator.BigQueryHook')
     def test_execute(self, mock_hook):
         dataset_resource = {"friendlyName": 'Test DS'}
@@ -226,7 +226,7 @@ def test_execute(self, mock_hook):
             )
 
 
-class BigQueryOperatorTest(unittest.TestCase):
+class TestBigQueryOperator(unittest.TestCase):
     def setUp(self):
         self.dagbag = models.DagBag(
             dag_folder='/dev/null', include_examples=True)
@@ -462,7 +462,7 @@ def test_bigquery_operator_extra_link(self, mock_hook):
         )
 
 
-class BigQueryGetDataOperatorTest(unittest.TestCase):
+class TestBigQueryGetDataOperator(unittest.TestCase):
 
     @mock.patch('airflow.contrib.operators.bigquery_get_data.BigQueryHook')
     def test_execute(self, mock_hook):
@@ -488,7 +488,7 @@ def test_execute(self, mock_hook):
             )
 
 
-class BigQueryTableDeleteOperatorTest(unittest.TestCase):
+class TestBigQueryTableDeleteOperator(unittest.TestCase):
     @mock.patch('airflow.contrib.operators.bigquery_table_delete_operator.BigQueryHook')
     def test_execute(self, mock_hook):
         ignore_if_missing = True
@@ -511,7 +511,7 @@ def test_execute(self, mock_hook):
             )
 
 
-class BigQueryToBigQueryOperatorTest(unittest.TestCase):
+class TestBigQueryToBigQueryOperator(unittest.TestCase):
     @mock.patch('airflow.contrib.operators.bigquery_to_bigquery.BigQueryHook')
     def test_execute(self, mock_hook):
         source_project_dataset_tables = '{}.{}'.format(
@@ -548,7 +548,7 @@ def test_execute(self, mock_hook):
             )
 
 
-class BigQueryToCloudStorageOperatorTest(unittest.TestCase):
+class TestBigQueryToCloudStorageOperator(unittest.TestCase):
     @mock.patch('airflow.contrib.operators.bigquery_to_gcs.BigQueryHook')
     def test_execute(self, mock_hook):
         source_project_dataset_table = '{}.{}'.format(
@@ -587,7 +587,7 @@ def test_execute(self, mock_hook):
             )
 
 
-class BigQueryToMySqlOperatorTest(unittest.TestCase):
+class TestBigQueryToMySqlOperator(unittest.TestCase):
     @mock.patch('airflow.contrib.operators.bigquery_to_mysql_operator.BigQueryHook')
     def test_execute_good_request_to_bq(self, mock_hook):
         destination_table = 'table'
diff --git a/tests/contrib/operators/test_cassandra_to_gcs_operator.py b/tests/contrib/operators/test_cassandra_to_gcs_operator.py
index 031c93380d7fa..31ef805153ff2 100644
--- a/tests/contrib/operators/test_cassandra_to_gcs_operator.py
+++ b/tests/contrib/operators/test_cassandra_to_gcs_operator.py
@@ -28,7 +28,7 @@
 TMP_FILE_NAME = "temp-file"
 
 
-class CassandraToGCSTest(unittest.TestCase):
+class TestCassandraToGCS(unittest.TestCase):
     @mock.patch("airflow.contrib.operators.cassandra_to_gcs.NamedTemporaryFile")
     @mock.patch(
         "airflow.contrib.operators.cassandra_to_gcs.GoogleCloudStorageHook.upload"
diff --git a/tests/contrib/operators/test_databricks_operator.py b/tests/contrib/operators/test_databricks_operator.py
index c30b7e0f0f65a..73fc002f783e6 100644
--- a/tests/contrib/operators/test_databricks_operator.py
+++ b/tests/contrib/operators/test_databricks_operator.py
@@ -68,7 +68,7 @@
 SPARK_SUBMIT_PARAMS = ["--class", "org.apache.spark.examples.SparkPi"]
 
 
-class DatabricksOperatorSharedFunctions(unittest.TestCase):
+class TestDatabricksOperatorSharedFunctions(unittest.TestCase):
     def test_deep_string_coerce(self):
         test_json = {
             'test_int': 1,
@@ -88,7 +88,7 @@ def test_deep_string_coerce(self):
         self.assertDictEqual(databricks_operator._deep_string_coerce(test_json), expected)
 
 
-class DatabricksSubmitRunOperatorTest(unittest.TestCase):
+class TestDatabricksSubmitRunOperator(unittest.TestCase):
     def test_init_with_named_parameters(self):
         """
         Test the initializer with the named parameters.
@@ -260,7 +260,7 @@ def test_on_kill(self, db_mock_class):
         db_mock.cancel_run.assert_called_once_with(RUN_ID)
 
 
-class DatabricksRunNowOperatorTest(unittest.TestCase):
+class TestDatabricksRunNowOperator(unittest.TestCase):
 
     def test_init_with_named_parameters(self):
         """
diff --git a/tests/contrib/operators/test_dataproc_operator.py b/tests/contrib/operators/test_dataproc_operator.py
index 3941e8cce8e55..6c49e76f04201 100644
--- a/tests/contrib/operators/test_dataproc_operator.py
+++ b/tests/contrib/operators/test_dataproc_operator.py
@@ -116,7 +116,7 @@ def _assert_dataproc_job_id(mock_hook, dataproc_task):
     assert dataproc_task.dataproc_job_id == DATAPROC_JOB_ID
 
 
-class DataprocClusterCreateOperatorTest(unittest.TestCase):
+class TestDataprocClusterCreateOperator(unittest.TestCase):
     # Unit test for the DataprocClusterCreateOperator
     def setUp(self):
         # instantiate two different test cases with different labels.
@@ -531,7 +531,7 @@ def create_cluster_with_invalid_internal_ip_only_setup():
                          "Set internal_ip_only to true only when you pass a subnetwork_uri.")
 
 
-class DataprocClusterScaleOperatorTest(unittest.TestCase):
+class TestDataprocClusterScaleOperator(unittest.TestCase):
     # Unit test for the DataprocClusterScaleOperator
     def setUp(self):
         # Setup service.projects().regions().clusters().patch()
@@ -594,7 +594,7 @@ def test_update_cluster(self):
             hook.wait.assert_called_once_with(self.operation)
 
 
-class DataprocClusterDeleteOperatorTest(unittest.TestCase):
+class TestDataprocClusterDeleteOperator(unittest.TestCase):
     # Unit test for the DataprocClusterDeleteOperator
     def setUp(self):
         # Setup service.projects().regions().clusters().delete()
@@ -643,7 +643,7 @@ def test_delete_cluster(self):
             hook.wait.assert_called_once_with(self.operation)
 
 
-class DataProcJobBaseOperatorTest(unittest.TestCase):
+class TestDataProcJobBaseOperator(unittest.TestCase):
 
     def setUp(self):
         self.dag = DAG(
@@ -682,7 +682,7 @@ def submit_side_effect(_1, _2, _3, _4):
             mock_hook.cancel.assert_called_once_with(mock.ANY, job_id, GCP_REGION)
 
 
-class DataProcHadoopOperatorTest(unittest.TestCase):
+class TestDataProcHadoopOperator(unittest.TestCase):
     # Unit test for the DataProcHadoopOperator
     @mock.patch(
         'airflow.contrib.hooks.gcp_dataproc_hook.DataProcHook.project_id',
@@ -731,7 +731,7 @@ def test_dataproc_job_id_is_set():
             _assert_dataproc_job_id(mock_hook, dataproc_task)
 
 
-class DataProcHiveOperatorTest(unittest.TestCase):
+class TestDataProcHiveOperator(unittest.TestCase):
     # Unit test for the DataProcHiveOperator
     @mock.patch(
         'airflow.contrib.hooks.gcp_dataproc_hook.DataProcHook.project_id',
@@ -780,7 +780,7 @@ def test_dataproc_job_id_is_set():
             _assert_dataproc_job_id(mock_hook, dataproc_task)
 
 
-class DataProcPigOperatorTest(unittest.TestCase):
+class TestDataProcPigOperator(unittest.TestCase):
     @mock.patch(
         'airflow.contrib.hooks.gcp_dataproc_hook.DataProcHook.project_id',
         new_callable=PropertyMock,
@@ -832,7 +832,7 @@ def test_dataproc_job_id_is_set():
             _assert_dataproc_job_id(mock_hook, dataproc_task)
 
 
-class DataProcPySparkOperatorTest(unittest.TestCase):
+class TestDataProcPySparkOperator(unittest.TestCase):
     # Unit test for the DataProcPySparkOperator
     @mock.patch(
         'airflow.contrib.hooks.gcp_dataproc_hook.DataProcHook.project_id',
@@ -884,7 +884,7 @@ def test_dataproc_job_id_is_set():
             _assert_dataproc_job_id(mock_hook, dataproc_task)
 
 
-class DataProcSparkOperatorTest(unittest.TestCase):
+class TestDataProcSparkOperator(unittest.TestCase):
     # Unit test for the DataProcSparkOperator
     @mock.patch(
         'airflow.contrib.hooks.gcp_dataproc_hook.DataProcHook.project_id',
@@ -934,7 +934,7 @@ def test_dataproc_job_id_is_set():
             _assert_dataproc_job_id(mock_hook, dataproc_task)
 
 
-class DataprocWorkflowTemplateInstantiateOperatorTest(unittest.TestCase):
+class TestDataprocWorkflowTemplateInstantiateOperator(unittest.TestCase):
     def setUp(self):
         # Setup service.projects().regions().workflowTemplates().instantiate().execute()
         self.operation = {'name': 'operation', 'done': True}
@@ -981,7 +981,7 @@ def test_workflow(self):
             hook.wait.assert_called_once_with(self.operation)
 
 
-class DataprocWorkflowTemplateInstantiateInlineOperatorTest(unittest.TestCase):
+class TestDataprocWorkflowTemplateInstantiateInlineOperator(unittest.TestCase):
     def setUp(self):
         # Setup service.projects().regions().workflowTemplates().instantiateInline()
         #              .execute()
diff --git a/tests/contrib/operators/test_dataproc_operator_system.py b/tests/contrib/operators/test_dataproc_operator_system.py
index ff71a66874737..a83e25131be8a 100644
--- a/tests/contrib/operators/test_dataproc_operator_system.py
+++ b/tests/contrib/operators/test_dataproc_operator_system.py
@@ -18,12 +18,12 @@
 # under the License.
 import unittest
 
-from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 from tests.contrib.utils.gcp_authenticator import GCP_DATAPROC_KEY
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_DATAPROC_KEY), SKIP_TEST_WARNING)
-class DataprocPigOperatorExampleDagsTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_DATAPROC_KEY), SKIP_TEST_WARNING)
+class DataprocPigOperatorExampleDagsTest(TestDagGcpSystem):
     def __init__(self, method_name="runTest"):
         super().__init__(
             method_name, dag_id="example_gcp_dataproc_pig_operator", gcp_key=GCP_DATAPROC_KEY
diff --git a/tests/contrib/operators/test_gcs_acl_operator.py b/tests/contrib/operators/test_gcs_acl_operator.py
index c6fb1f3f2febe..912953f257550 100644
--- a/tests/contrib/operators/test_gcs_acl_operator.py
+++ b/tests/contrib/operators/test_gcs_acl_operator.py
@@ -25,7 +25,7 @@
 from tests.compat import mock
 
 
-class GoogleCloudStorageAclTest(unittest.TestCase):
+class TestGoogleCloudStorageAcl(unittest.TestCase):
     @mock.patch('airflow.contrib.operators.gcs_acl_operator.GoogleCloudStorageHook')
     def test_bucket_create_acl(self, mock_hook):
         operator = GoogleCloudStorageBucketCreateAclEntryOperator(
diff --git a/tests/contrib/operators/test_gcs_acl_operator_system.py b/tests/contrib/operators/test_gcs_acl_operator_system.py
index 8ed566ee53571..e29984ee3e4a4 100644
--- a/tests/contrib/operators/test_gcs_acl_operator_system.py
+++ b/tests/contrib/operators/test_gcs_acl_operator_system.py
@@ -18,14 +18,12 @@
 # under the License.
 import unittest
 
-from tests.contrib.utils.base_gcp_system_test_case import \
-    SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 from tests.contrib.utils.gcp_authenticator import GCP_GCS_KEY
 
 
-@unittest.skipIf(
-    DagGcpSystemTestCase.skip_check(GCP_GCS_KEY), SKIP_TEST_WARNING)
-class CloudStorageExampleDagsSystemTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_GCS_KEY), SKIP_TEST_WARNING)
+class CloudStorageExampleDagsSystemTest(TestDagGcpSystem):
     def __init__(self, method_name='runTest'):
         super().__init__(
             method_name,
diff --git a/tests/contrib/operators/test_gcs_delete_operator.py b/tests/contrib/operators/test_gcs_delete_operator.py
index 443a08124877b..f931bcc9294fe 100644
--- a/tests/contrib/operators/test_gcs_delete_operator.py
+++ b/tests/contrib/operators/test_gcs_delete_operator.py
@@ -28,7 +28,7 @@
 MOCK_FILES = ["a", "ab", "abc"]
 
 
-class GoogleCloudStorageDeleteOperatorTest(unittest.TestCase):
+class TestGoogleCloudStorageDeleteOperator(unittest.TestCase):
     @mock.patch('airflow.contrib.operators.gcs_delete_operator.GoogleCloudStorageHook')
     def test_delete_objects(self, mock_hook):
         operator = GoogleCloudStorageDeleteOperator(task_id=TASK_ID,
diff --git a/tests/contrib/operators/test_gcs_download_operator.py b/tests/contrib/operators/test_gcs_download_operator.py
index 72fc4ac679bac..5256481d2629e 100644
--- a/tests/contrib/operators/test_gcs_download_operator.py
+++ b/tests/contrib/operators/test_gcs_download_operator.py
@@ -29,7 +29,7 @@
 LOCAL_FILE_PATH = '/home/airflow/gcp/test-object'
 
 
-class GoogleCloudStorageDownloadOperatorTest(unittest.TestCase):
+class TestGoogleCloudStorageDownloadOperator(unittest.TestCase):
 
     @mock.patch('airflow.contrib.operators.gcs_download_operator.GoogleCloudStorageHook')
     def test_execute(self, mock_hook):
diff --git a/tests/contrib/operators/test_gcs_list_operator.py b/tests/contrib/operators/test_gcs_list_operator.py
index 528f4a30b88c7..c12e28914a04b 100644
--- a/tests/contrib/operators/test_gcs_list_operator.py
+++ b/tests/contrib/operators/test_gcs_list_operator.py
@@ -29,7 +29,7 @@
 MOCK_FILES = ["TEST1.csv", "TEST2.csv", "TEST3.csv"]
 
 
-class GoogleCloudStorageListOperatorTest(unittest.TestCase):
+class TestGoogleCloudStorageListOperator(unittest.TestCase):
 
     @mock.patch('airflow.contrib.operators.gcs_list_operator.GoogleCloudStorageHook')
     def test_execute(self, mock_hook):
diff --git a/tests/contrib/operators/test_gcs_operator.py b/tests/contrib/operators/test_gcs_operator.py
index 67c86d62d6f6e..e9e99defd7a40 100644
--- a/tests/contrib/operators/test_gcs_operator.py
+++ b/tests/contrib/operators/test_gcs_operator.py
@@ -28,7 +28,7 @@
 TEST_PROJECT = 'test-project'
 
 
-class GoogleCloudStorageCreateBucketTest(unittest.TestCase):
+class TestGoogleCloudStorageCreateBucket(unittest.TestCase):
 
     @mock.patch('airflow.contrib.operators.gcs_operator.GoogleCloudStorageHook')
     def test_execute(self, mock_hook):
diff --git a/tests/contrib/operators/test_gcs_to_gcs_operator.py b/tests/contrib/operators/test_gcs_to_gcs_operator.py
index 4e6faf77de60a..6de26debaadf8 100644
--- a/tests/contrib/operators/test_gcs_to_gcs_operator.py
+++ b/tests/contrib/operators/test_gcs_to_gcs_operator.py
@@ -45,7 +45,7 @@
 MOD_TIME_1 = datetime(2016, 1, 1)
 
 
-class GoogleCloudStorageToCloudStorageOperatorTest(unittest.TestCase):
+class TestGoogleCloudStorageToCloudStorageOperator(unittest.TestCase):
     """
     Tests the three use-cases for the wildcard operator. These are
     no_prefix: *test_object
diff --git a/tests/contrib/operators/test_gcs_to_s3_operator.py b/tests/contrib/operators/test_gcs_to_s3_operator.py
index 8add0956b09fd..8758e509c3e1a 100644
--- a/tests/contrib/operators/test_gcs_to_s3_operator.py
+++ b/tests/contrib/operators/test_gcs_to_s3_operator.py
@@ -36,7 +36,7 @@
 MOCK_FILES = ["TEST1.csv", "TEST2.csv", "TEST3.csv"]
 
 
-class GoogleCloudStorageToS3OperatorTest(unittest.TestCase):
+class TestGoogleCloudStorageToS3Operator(unittest.TestCase):
 
     # Test1: incremental behaviour (just some files missing)
     @mock_s3
diff --git a/tests/contrib/operators/test_hipchat_operator.py b/tests/contrib/operators/test_hipchat_operator.py
index be0d1b35176b0..7851841730de8 100644
--- a/tests/contrib/operators/test_hipchat_operator.py
+++ b/tests/contrib/operators/test_hipchat_operator.py
@@ -26,7 +26,7 @@
 from tests.compat import mock
 
 
-class HipChatOperatorTest(unittest.TestCase):
+class TestHipChatOperator(unittest.TestCase):
     @unittest.skipIf(mock is None, 'mock package not present')
     @mock.patch('requests.request')
     def test_execute(self, request_mock):
diff --git a/tests/contrib/operators/test_hive_to_dynamodb_operator.py b/tests/contrib/operators/test_hive_to_dynamodb_operator.py
index cccb9690477fe..5b80d32110154 100644
--- a/tests/contrib/operators/test_hive_to_dynamodb_operator.py
+++ b/tests/contrib/operators/test_hive_to_dynamodb_operator.py
@@ -40,7 +40,7 @@
     mock_dynamodb2 = None
 
 
-class HiveToDynamoDBTransferOperatorTest(unittest.TestCase):
+class TestHiveToDynamoDBTransferOperator(unittest.TestCase):
 
     def setUp(self):
         args = {'owner': 'airflow', 'start_date': DEFAULT_DATE}
diff --git a/tests/contrib/operators/test_jenkins_operator.py b/tests/contrib/operators/test_jenkins_operator.py
index 634e25a49da6f..79963fa43adcb 100644
--- a/tests/contrib/operators/test_jenkins_operator.py
+++ b/tests/contrib/operators/test_jenkins_operator.py
@@ -29,7 +29,7 @@
 from tests.compat import mock
 
 
-class JenkinsOperatorTestCase(unittest.TestCase):
+class TestJenkinsOperator(unittest.TestCase):
     @unittest.skipIf(mock is None, 'mock package not present')
     def test_execute(self):
         jenkins_mock = mock.Mock(spec=jenkins.Jenkins, auth='secret')
diff --git a/tests/contrib/operators/test_mongo_to_s3_operator.py b/tests/contrib/operators/test_mongo_to_s3_operator.py
index a5f6b24231d5e..fd04f1222316e 100644
--- a/tests/contrib/operators/test_mongo_to_s3_operator.py
+++ b/tests/contrib/operators/test_mongo_to_s3_operator.py
@@ -39,7 +39,7 @@
 ]
 
 
-class MongoToS3OperatorTest(unittest.TestCase):
+class TestMongoToS3Operator(unittest.TestCase):
 
     def setUp(self):
         args = {
diff --git a/tests/contrib/operators/test_mssql_to_gcs_operator.py b/tests/contrib/operators/test_mssql_to_gcs_operator.py
index f7f980870d921..0b58945f104ee 100644
--- a/tests/contrib/operators/test_mssql_to_gcs_operator.py
+++ b/tests/contrib/operators/test_mssql_to_gcs_operator.py
@@ -51,7 +51,7 @@
 ]
 
 
-class MsSqlToGoogleCloudStorageOperatorTest(unittest.TestCase):
+class TestMsSqlToGoogleCloudStorageOperator(unittest.TestCase):
 
     def test_init(self):
         """Test MySqlToGoogleCloudStorageOperator instance is properly initialized."""
diff --git a/tests/contrib/operators/test_mysql_to_gcs_operator.py b/tests/contrib/operators/test_mysql_to_gcs_operator.py
index 9760fb5c74491..5d4824a34f5ce 100644
--- a/tests/contrib/operators/test_mysql_to_gcs_operator.py
+++ b/tests/contrib/operators/test_mysql_to_gcs_operator.py
@@ -68,7 +68,7 @@
 ]
 
 
-class MySqlToGoogleCloudStorageOperatorTest(unittest.TestCase):
+class TestMySqlToGoogleCloudStorageOperator(unittest.TestCase):
 
     def test_init(self):
         """Test MySqlToGoogleCloudStorageOperator instance is properly initialized."""
diff --git a/tests/contrib/operators/test_oracle_to_azure_data_lake_transfer.py b/tests/contrib/operators/test_oracle_to_azure_data_lake_transfer.py
index 7686afad21885..2844175ab2b77 100644
--- a/tests/contrib/operators/test_oracle_to_azure_data_lake_transfer.py
+++ b/tests/contrib/operators/test_oracle_to_azure_data_lake_transfer.py
@@ -1,127 +1,127 @@
-# -*- coding: utf-8 -*-
-#
-# Licensed to the Apache Software Foundation (ASF) under one
-# or more contributor license agreements.  See the NOTICE file
-# distributed with this work for additional information
-# regarding copyright ownership.  The ASF licenses this file
-# to you under the Apache License, Version 2.0 (the
-# "License"); you may not use this file except in compliance
-# with the License.  You may obtain a copy of the License at
-#
-#   http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing,
-# software distributed under the License is distributed on an
-# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-# KIND, either express or implied.  See the License for the
-# specific language governing permissions and limitations
-# under the License.
-
-import unittest
-from airflow.contrib.operators.oracle_to_azure_data_lake_transfer \
-    import OracleToAzureDataLakeTransfer
-from airflow.utils.file import TemporaryDirectory
-import unicodecsv as csv
-import os
-
-from tests.compat import mock, MagicMock
-
-
-class OracleToAzureDataLakeTransferTest(unittest.TestCase):
-
-    mock_module_path = 'airflow.contrib.operators.oracle_to_azure_data_lake_transfer'
-
-    def test_write_temp_file(self):
-        task_id = "some_test_id"
-        sql = "some_sql"
-        sql_params = {':p_data': "2018-01-01"}
-        oracle_conn_id = "oracle_conn_id"
-        filename = "some_filename"
-        azure_data_lake_conn_id = 'azure_data_lake_conn_id'
-        azure_data_lake_path = 'azure_data_lake_path'
-        delimiter = '|'
-        encoding = 'utf-8'
-        cursor_description = [
-            ('id', "<class 'cx_Oracle.NUMBER'>", 39, None, 38, 0, 0),
-            ('description', "<class 'cx_Oracle.STRING'>", 60, 240, None, None, 1)
-        ]
-        cursor_rows = [[1, 'description 1'], [2, 'description 2']]
-        mock_cursor = MagicMock()
-        mock_cursor.description = cursor_description
-        mock_cursor.__iter__.return_value = cursor_rows
-
-        op = OracleToAzureDataLakeTransfer(
-            task_id=task_id,
-            filename=filename,
-            oracle_conn_id=oracle_conn_id,
-            sql=sql,
-            sql_params=sql_params,
-            azure_data_lake_conn_id=azure_data_lake_conn_id,
-            azure_data_lake_path=azure_data_lake_path,
-            delimiter=delimiter,
-            encoding=encoding)
-
-        with TemporaryDirectory(prefix='airflow_oracle_to_azure_op_') as temp:
-            op._write_temp_file(mock_cursor, os.path.join(temp, filename))
-
-            assert os.path.exists(os.path.join(temp, filename)) == 1
-
-            with open(os.path.join(temp, filename), 'rb') as csvfile:
-                temp_file = csv.reader(csvfile, delimiter=delimiter, encoding=encoding)
-
-                rownum = 0
-                for row in temp_file:
-                    if rownum == 0:
-                        self.assertEqual(row[0], 'id')
-                        self.assertEqual(row[1], 'description')
-                    else:
-                        self.assertEqual(row[0], str(cursor_rows[rownum - 1][0]))
-                        self.assertEqual(row[1], cursor_rows[rownum - 1][1])
-                    rownum = rownum + 1
-
-    @mock.patch(mock_module_path + '.OracleHook',
-                autospec=True)
-    @mock.patch(mock_module_path + '.AzureDataLakeHook',
-                autospec=True)
-    def test_execute(self, mock_data_lake_hook, mock_oracle_hook):
-        task_id = "some_test_id"
-        sql = "some_sql"
-        sql_params = {':p_data': "2018-01-01"}
-        oracle_conn_id = "oracle_conn_id"
-        filename = "some_filename"
-        azure_data_lake_conn_id = 'azure_data_lake_conn_id'
-        azure_data_lake_path = 'azure_data_lake_path'
-        delimiter = '|'
-        encoding = 'latin-1'
-        cursor_description = [
-            ('id', "<class 'cx_Oracle.NUMBER'>", 39, None, 38, 0, 0),
-            ('description', "<class 'cx_Oracle.STRING'>", 60, 240, None, None, 1)
-        ]
-        cursor_rows = [[1, 'description 1'], [2, 'description 2']]
-        cursor_mock = MagicMock()
-        cursor_mock.description.return_value = cursor_description
-        cursor_mock.__iter__.return_value = cursor_rows
-        mock_oracle_conn = MagicMock()
-        mock_oracle_conn.cursor().return_value = cursor_mock
-        mock_oracle_hook.get_conn().return_value = mock_oracle_conn
-
-        op = OracleToAzureDataLakeTransfer(
-            task_id=task_id,
-            filename=filename,
-            oracle_conn_id=oracle_conn_id,
-            sql=sql,
-            sql_params=sql_params,
-            azure_data_lake_conn_id=azure_data_lake_conn_id,
-            azure_data_lake_path=azure_data_lake_path,
-            delimiter=delimiter,
-            encoding=encoding)
-
-        op.execute(None)
-
-        mock_oracle_hook.assert_called_once_with(oracle_conn_id=oracle_conn_id)
-        mock_data_lake_hook.assert_called_once_with(
-            azure_data_lake_conn_id=azure_data_lake_conn_id)
-
-
-if __name__ == '__main__':
-    unittest.main()
+# -*- coding: utf-8 -*-
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#   http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+
+import unittest
+from airflow.contrib.operators.oracle_to_azure_data_lake_transfer \
+    import OracleToAzureDataLakeTransfer
+from airflow.utils.file import TemporaryDirectory
+import unicodecsv as csv
+import os
+
+from tests.compat import mock, MagicMock
+
+
+class TestOracleToAzureDataLakeTransfer(unittest.TestCase):
+
+    mock_module_path = 'airflow.contrib.operators.oracle_to_azure_data_lake_transfer'
+
+    def test_write_temp_file(self):
+        task_id = "some_test_id"
+        sql = "some_sql"
+        sql_params = {':p_data': "2018-01-01"}
+        oracle_conn_id = "oracle_conn_id"
+        filename = "some_filename"
+        azure_data_lake_conn_id = 'azure_data_lake_conn_id'
+        azure_data_lake_path = 'azure_data_lake_path'
+        delimiter = '|'
+        encoding = 'utf-8'
+        cursor_description = [
+            ('id', "<class 'cx_Oracle.NUMBER'>", 39, None, 38, 0, 0),
+            ('description', "<class 'cx_Oracle.STRING'>", 60, 240, None, None, 1)
+        ]
+        cursor_rows = [[1, 'description 1'], [2, 'description 2']]
+        mock_cursor = MagicMock()
+        mock_cursor.description = cursor_description
+        mock_cursor.__iter__.return_value = cursor_rows
+
+        op = OracleToAzureDataLakeTransfer(
+            task_id=task_id,
+            filename=filename,
+            oracle_conn_id=oracle_conn_id,
+            sql=sql,
+            sql_params=sql_params,
+            azure_data_lake_conn_id=azure_data_lake_conn_id,
+            azure_data_lake_path=azure_data_lake_path,
+            delimiter=delimiter,
+            encoding=encoding)
+
+        with TemporaryDirectory(prefix='airflow_oracle_to_azure_op_') as temp:
+            op._write_temp_file(mock_cursor, os.path.join(temp, filename))
+
+            assert os.path.exists(os.path.join(temp, filename)) == 1
+
+            with open(os.path.join(temp, filename), 'rb') as csvfile:
+                temp_file = csv.reader(csvfile, delimiter=delimiter, encoding=encoding)
+
+                rownum = 0
+                for row in temp_file:
+                    if rownum == 0:
+                        self.assertEqual(row[0], 'id')
+                        self.assertEqual(row[1], 'description')
+                    else:
+                        self.assertEqual(row[0], str(cursor_rows[rownum - 1][0]))
+                        self.assertEqual(row[1], cursor_rows[rownum - 1][1])
+                    rownum = rownum + 1
+
+    @mock.patch(mock_module_path + '.OracleHook',
+                autospec=True)
+    @mock.patch(mock_module_path + '.AzureDataLakeHook',
+                autospec=True)
+    def test_execute(self, mock_data_lake_hook, mock_oracle_hook):
+        task_id = "some_test_id"
+        sql = "some_sql"
+        sql_params = {':p_data': "2018-01-01"}
+        oracle_conn_id = "oracle_conn_id"
+        filename = "some_filename"
+        azure_data_lake_conn_id = 'azure_data_lake_conn_id'
+        azure_data_lake_path = 'azure_data_lake_path'
+        delimiter = '|'
+        encoding = 'latin-1'
+        cursor_description = [
+            ('id', "<class 'cx_Oracle.NUMBER'>", 39, None, 38, 0, 0),
+            ('description', "<class 'cx_Oracle.STRING'>", 60, 240, None, None, 1)
+        ]
+        cursor_rows = [[1, 'description 1'], [2, 'description 2']]
+        cursor_mock = MagicMock()
+        cursor_mock.description.return_value = cursor_description
+        cursor_mock.__iter__.return_value = cursor_rows
+        mock_oracle_conn = MagicMock()
+        mock_oracle_conn.cursor().return_value = cursor_mock
+        mock_oracle_hook.get_conn().return_value = mock_oracle_conn
+
+        op = OracleToAzureDataLakeTransfer(
+            task_id=task_id,
+            filename=filename,
+            oracle_conn_id=oracle_conn_id,
+            sql=sql,
+            sql_params=sql_params,
+            azure_data_lake_conn_id=azure_data_lake_conn_id,
+            azure_data_lake_path=azure_data_lake_path,
+            delimiter=delimiter,
+            encoding=encoding)
+
+        op.execute(None)
+
+        mock_oracle_hook.assert_called_once_with(oracle_conn_id=oracle_conn_id)
+        mock_data_lake_hook.assert_called_once_with(
+            azure_data_lake_conn_id=azure_data_lake_conn_id)
+
+
+if __name__ == '__main__':
+    unittest.main()
diff --git a/tests/contrib/operators/test_oracle_to_oracle_transfer.py b/tests/contrib/operators/test_oracle_to_oracle_transfer.py
index e814b83ea3a12..3764762381634 100644
--- a/tests/contrib/operators/test_oracle_to_oracle_transfer.py
+++ b/tests/contrib/operators/test_oracle_to_oracle_transfer.py
@@ -23,7 +23,7 @@
 from tests.compat import MagicMock
 
 
-class OracleToOracleTransferTest(unittest.TestCase):
+class TestOracleToOracleTransfer(unittest.TestCase):
 
     @staticmethod
     def test_execute():
diff --git a/tests/contrib/operators/test_postgres_to_gcs_operator.py b/tests/contrib/operators/test_postgres_to_gcs_operator.py
index 9852b6d08fe82..c0dfbc54e8ba6 100644
--- a/tests/contrib/operators/test_postgres_to_gcs_operator.py
+++ b/tests/contrib/operators/test_postgres_to_gcs_operator.py
@@ -42,7 +42,7 @@
               b'{"mode": "NULLABLE", "name": "some_num", "type": "INTEGER"}]'
 
 
-class PostgresToGoogleCloudStorageOperatorTest(unittest.TestCase):
+class TestPostgresToGoogleCloudStorageOperator(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
         postgres = PostgresHook()
diff --git a/tests/contrib/operators/test_qubole_check_operator.py b/tests/contrib/operators/test_qubole_check_operator.py
index d0423cc927f83..02ca9c13f6880 100644
--- a/tests/contrib/operators/test_qubole_check_operator.py
+++ b/tests/contrib/operators/test_qubole_check_operator.py
@@ -28,7 +28,7 @@
 from tests.compat import mock
 
 
-class QuboleValueCheckOperatorTest(unittest.TestCase):
+class TestQuboleValueCheckOperator(unittest.TestCase):
 
     def setUp(self):
         self.task_id = 'test_task'
diff --git a/tests/contrib/operators/test_qubole_operator.py b/tests/contrib/operators/test_qubole_operator.py
index fc55f8067e71b..a8ab1ee4fce55 100644
--- a/tests/contrib/operators/test_qubole_operator.py
+++ b/tests/contrib/operators/test_qubole_operator.py
@@ -37,7 +37,7 @@
 DEFAULT_DATE = datetime(2017, 1, 1)
 
 
-class QuboleOperatorTest(unittest.TestCase):
+class TestQuboleOperator(unittest.TestCase):
     def setUp(self):
         db.merge_conn(
             Connection(conn_id=DEFAULT_CONN, conn_type='HTTP'))
diff --git a/tests/contrib/operators/test_s3_list_operator.py b/tests/contrib/operators/test_s3_list_operator.py
index e041fd07545f5..5c418ff67bbdb 100644
--- a/tests/contrib/operators/test_s3_list_operator.py
+++ b/tests/contrib/operators/test_s3_list_operator.py
@@ -29,7 +29,7 @@
 MOCK_FILES = ["TEST1.csv", "TEST2.csv", "TEST3.csv"]
 
 
-class S3ListOperatorTest(unittest.TestCase):
+class TestS3ListOperator(unittest.TestCase):
     @mock.patch('airflow.contrib.operators.s3_list_operator.S3Hook')
     def test_execute(self, mock_hook):
 
diff --git a/tests/contrib/operators/test_s3_to_gcs_operator.py b/tests/contrib/operators/test_s3_to_gcs_operator.py
index 0767a0f13b8b8..57b64974815f0 100644
--- a/tests/contrib/operators/test_s3_to_gcs_operator.py
+++ b/tests/contrib/operators/test_s3_to_gcs_operator.py
@@ -33,7 +33,7 @@
 GCS_CONN_ID = 'google_cloud_default'
 
 
-class S3ToGoogleCloudStorageOperatorTest(unittest.TestCase):
+class TestS3ToGoogleCloudStorageOperator(unittest.TestCase):
     def test_init(self):
         """Test S3ToGoogleCloudStorageOperator instance is properly initialized."""
 
diff --git a/tests/contrib/operators/test_s3_to_sftp_operator.py b/tests/contrib/operators/test_s3_to_sftp_operator.py
index fc78f0c8698d3..c6751cd34f44f 100644
--- a/tests/contrib/operators/test_s3_to_sftp_operator.py
+++ b/tests/contrib/operators/test_s3_to_sftp_operator.py
@@ -57,7 +57,7 @@ def reset(dag_id=TEST_DAG_ID):
 reset()
 
 
-class S3ToSFTPOperatorTest(unittest.TestCase):
+class TestS3ToSFTPOperator(unittest.TestCase):
     @mock_s3
     def setUp(self):
         from airflow.contrib.hooks.ssh_hook import SSHHook
diff --git a/tests/contrib/operators/test_segment_track_event_operator.py b/tests/contrib/operators/test_segment_track_event_operator.py
index e6969cd3171eb..552f79b04add4 100644
--- a/tests/contrib/operators/test_segment_track_event_operator.py
+++ b/tests/contrib/operators/test_segment_track_event_operator.py
@@ -61,7 +61,7 @@ def test_on_error(self):
             self.test_hook.on_error('error', ['items'])
 
 
-class SegmentTrackEventOperatorTest(unittest.TestCase):
+class TestSegmentTrackEventOperator(unittest.TestCase):
 
     @mock.patch('airflow.contrib.operators.segment_track_event_operator.SegmentHook')
     def test_execute(self, mock_hook):
diff --git a/tests/contrib/operators/test_sftp_operator.py b/tests/contrib/operators/test_sftp_operator.py
index b54c328ba5efa..298cdb244bd4c 100644
--- a/tests/contrib/operators/test_sftp_operator.py
+++ b/tests/contrib/operators/test_sftp_operator.py
@@ -45,7 +45,7 @@ def reset(dag_id=TEST_DAG_ID):
 reset()
 
 
-class SFTPOperatorTest(unittest.TestCase):
+class TestSFTPOperator(unittest.TestCase):
     def setUp(self):
         from airflow.contrib.hooks.ssh_hook import SSHHook
         hook = SSHHook(ssh_conn_id='ssh_default')
diff --git a/tests/contrib/operators/test_sftp_to_s3_operator.py b/tests/contrib/operators/test_sftp_to_s3_operator.py
index 02f4e84c010b2..c86c51b8e8a1c 100644
--- a/tests/contrib/operators/test_sftp_to_s3_operator.py
+++ b/tests/contrib/operators/test_sftp_to_s3_operator.py
@@ -58,7 +58,7 @@ def reset(dag_id=TEST_DAG_ID):
 reset()
 
 
-class SFTPToS3OperatorTest(unittest.TestCase):
+class TestSFTPToS3Operator(unittest.TestCase):
 
     @mock_s3
     def setUp(self):
diff --git a/tests/contrib/operators/test_ssh_operator.py b/tests/contrib/operators/test_ssh_operator.py
index a27dc27bc7ca1..f66541d010a13 100644
--- a/tests/contrib/operators/test_ssh_operator.py
+++ b/tests/contrib/operators/test_ssh_operator.py
@@ -43,7 +43,7 @@ def reset(dag_id=TEST_DAG_ID):
 reset()
 
 
-class SSHOperatorTest(unittest.TestCase):
+class TestSSHOperator(unittest.TestCase):
     def setUp(self):
         from airflow.contrib.hooks.ssh_hook import SSHHook
         hook = SSHHook(ssh_conn_id='ssh_default')
diff --git a/tests/contrib/operators/test_vertica_operator.py b/tests/contrib/operators/test_vertica_operator.py
index f1e07b06935d9..79d4127117ded 100644
--- a/tests/contrib/operators/test_vertica_operator.py
+++ b/tests/contrib/operators/test_vertica_operator.py
@@ -23,7 +23,7 @@
 from airflow.contrib.operators.vertica_operator import VerticaOperator
 
 
-class VerticaOperatorTest(unittest.TestCase):
+class TestVerticaOperator(unittest.TestCase):
 
     @mock.patch('airflow.contrib.operators.vertica_operator.VerticaHook')
     def test_execute(self, mock_hook):
diff --git a/tests/contrib/operators/test_winrm_operator.py b/tests/contrib/operators/test_winrm_operator.py
index b39f82b14e976..25e2dc273373e 100644
--- a/tests/contrib/operators/test_winrm_operator.py
+++ b/tests/contrib/operators/test_winrm_operator.py
@@ -24,7 +24,7 @@
 from airflow.exceptions import AirflowException
 
 
-class WinRMOperatorTest(unittest.TestCase):
+class TestWinRMOperator(unittest.TestCase):
     def test_no_winrm_hook_no_ssh_conn_id(self):
         op = WinRMOperator(task_id='test_task_id',
                            winrm_hook=None,
diff --git a/tests/contrib/sensors/test_file_sensor.py b/tests/contrib/sensors/test_file_sensor.py
index 4df698ec0b361..34720f5cbccca 100644
--- a/tests/contrib/sensors/test_file_sensor.py
+++ b/tests/contrib/sensors/test_file_sensor.py
@@ -43,7 +43,7 @@ def reset(dag_id=TEST_DAG_ID):
 reset()
 
 
-class FileSensorTest(unittest.TestCase):
+class TestFileSensor(unittest.TestCase):
     def setUp(self):
         from airflow.contrib.hooks.fs_hook import FSHook
         hook = FSHook()
diff --git a/tests/contrib/sensors/test_gcs_upload_session_sensor.py b/tests/contrib/sensors/test_gcs_upload_session_sensor.py
index cc3f68b1de416..c230835923120 100644
--- a/tests/contrib/sensors/test_gcs_upload_session_sensor.py
+++ b/tests/contrib/sensors/test_gcs_upload_session_sensor.py
@@ -56,7 +56,7 @@ def next_time_side_effect():
 mock_time = mock.Mock(side_effect=next_time_side_effect)
 
 
-class GoogleCloudStorageUploadSessionCompleteSensorTest(unittest.TestCase):
+class TestGoogleCloudStorageUploadSessionCompleteSensor(unittest.TestCase):
 
     def setUp(self):
         args = {
diff --git a/tests/contrib/sensors/test_hdfs_sensor.py b/tests/contrib/sensors/test_hdfs_sensor.py
index b03b738686ed8..f7f7b55d09b15 100644
--- a/tests/contrib/sensors/test_hdfs_sensor.py
+++ b/tests/contrib/sensors/test_hdfs_sensor.py
@@ -26,7 +26,7 @@
 from airflow.exceptions import AirflowSensorTimeout
 
 
-class HdfsSensorFolderTests(unittest.TestCase):
+class TestHdfsSensorFolder(unittest.TestCase):
     def setUp(self):
         from tests.core import FakeHDFSHook
         self.hook = FakeHDFSHook
@@ -122,7 +122,7 @@ def test_should_be_non_empty_directory_fail(self):
             task.execute(None)
 
 
-class HdfsSensorRegexTests(unittest.TestCase):
+class TestHdfsSensorRegex(unittest.TestCase):
     def setUp(self):
         from tests.core import FakeHDFSHook
         self.hook = FakeHDFSHook
diff --git a/tests/contrib/sensors/test_python_sensor.py b/tests/contrib/sensors/test_python_sensor.py
index 1595384be40ba..18b26a8461832 100644
--- a/tests/contrib/sensors/test_python_sensor.py
+++ b/tests/contrib/sensors/test_python_sensor.py
@@ -30,7 +30,7 @@
 TEST_DAG_ID = 'python_sensor_dag'
 
 
-class PythonSensorTests(unittest.TestCase):
+class TestPythonSensor(unittest.TestCase):
 
     def setUp(self):
         self.args = {
diff --git a/tests/contrib/sensors/test_qubole_sensor.py b/tests/contrib/sensors/test_qubole_sensor.py
index 0164147aa742e..2b1c4c51e3b7d 100644
--- a/tests/contrib/sensors/test_qubole_sensor.py
+++ b/tests/contrib/sensors/test_qubole_sensor.py
@@ -35,7 +35,7 @@
 DEFAULT_DATE = datetime(2017, 1, 1)
 
 
-class QuboleSensorTest(unittest.TestCase):
+class TestQuboleSensor(unittest.TestCase):
     def setUp(self):
         db.merge_conn(
             Connection(conn_id=DEFAULT_CONN, conn_type='HTTP'))
diff --git a/tests/contrib/sensors/test_sftp_sensor.py b/tests/contrib/sensors/test_sftp_sensor.py
index 3bb1fddb8493b..22ce89e112ba4 100644
--- a/tests/contrib/sensors/test_sftp_sensor.py
+++ b/tests/contrib/sensors/test_sftp_sensor.py
@@ -23,7 +23,7 @@
 from airflow.contrib.sensors.sftp_sensor import SFTPSensor
 
 
-class SFTPSensorTest(unittest.TestCase):
+class TestSFTPSensor(unittest.TestCase):
     @patch('airflow.contrib.sensors.sftp_sensor.SFTPHook')
     def test_file_present(self, sftp_hook_mock):
         sftp_hook_mock.return_value.get_mod_time.return_value = '19700101000000'
diff --git a/tests/contrib/sensors/test_weekday_sensor.py b/tests/contrib/sensors/test_weekday_sensor.py
index 0fa6f2baaa3d8..536725008d7d8 100644
--- a/tests/contrib/sensors/test_weekday_sensor.py
+++ b/tests/contrib/sensors/test_weekday_sensor.py
@@ -34,7 +34,7 @@
 DEV_NULL = '/dev/null'
 
 
-class DayOfWeekSensorTests(unittest.TestCase):
+class TestDayOfWeekSensor(unittest.TestCase):
 
     def setUp(self):
         self.dagbag = DagBag(
diff --git a/tests/contrib/utils/base_gcp_system_test_case.py b/tests/contrib/utils/base_gcp_system_test_case.py
index 3ca078509c34d..e3001556bb9cf 100644
--- a/tests/contrib/utils/base_gcp_system_test_case.py
+++ b/tests/contrib/utils/base_gcp_system_test_case.py
@@ -89,7 +89,7 @@ def retrieve_variables():
 """.format(__file__)
 
 
-class BaseGcpSystemTestCase(unittest.TestCase, LoggingMixin):
+class TestBaseGcpSystem(unittest.TestCase, LoggingMixin):
     def __init__(self,
                  method_name,
                  gcp_key,
@@ -116,7 +116,7 @@ def tearDown(self):
         self.gcp_authenticator.gcp_restore_authentication()
 
 
-class DagGcpSystemTestCase(BaseGcpSystemTestCase):
+class TestDagGcpSystem(TestBaseGcpSystem):
     def __init__(self,
                  method_name,
                  gcp_key,
diff --git a/tests/contrib/utils/test_sendgrid.py b/tests/contrib/utils/test_sendgrid.py
index 3e75b84b84222..0ee5d2d179a1a 100644
--- a/tests/contrib/utils/test_sendgrid.py
+++ b/tests/contrib/utils/test_sendgrid.py
@@ -27,7 +27,7 @@
 from tests.compat import mock
 
 
-class SendEmailSendGridTest(unittest.TestCase):
+class TestSendEmailSendGrid(unittest.TestCase):
     # Unit test for sendgrid.send_email()
     def setUp(self):
         self.to = ['foo@foo.com', 'bar@bar.com']
diff --git a/tests/contrib/utils/test_weekday.py b/tests/contrib/utils/test_weekday.py
index 961652a4ea8e6..3b4384344cb2c 100644
--- a/tests/contrib/utils/test_weekday.py
+++ b/tests/contrib/utils/test_weekday.py
@@ -23,7 +23,7 @@
 from airflow.contrib.utils.weekday import WeekDay
 
 
-class WeekDayTest(unittest.TestCase):
+class TestWeekDay(unittest.TestCase):
     def test_weekday_enum_length(self):
         self.assertEqual(len(WeekDay), 7)
 
diff --git a/tests/core.py b/tests/core.py
index d71bf30e0e275..d9947d7a6c442 100644
--- a/tests/core.py
+++ b/tests/core.py
@@ -101,7 +101,7 @@ def execute(self, context):
         pass
 
 
-class CoreTest(unittest.TestCase):
+class TestCore(unittest.TestCase):
     TEST_SCHEDULE_WITH_NO_PREVIOUS_RUNS_DAG_ID = TEST_DAG_ID + 'test_schedule_dag_no_previous_runs'
     TEST_SCHEDULE_DAG_FAKE_SCHEDULED_PREVIOUS_DAG_ID = \
         TEST_DAG_ID + 'test_schedule_dag_fake_scheduled_previous'
@@ -1068,7 +1068,7 @@ def test_externally_triggered_dagrun(self):
         self.assertEqual(context['prev_ds_nodash'], EXECUTION_DS_NODASH)
 
 
-class CliTests(unittest.TestCase):
+class TestCli(unittest.TestCase):
 
     TEST_USER1_EMAIL = 'test-user1@example.com'
     TEST_USER2_EMAIL = 'test-user2@example.com'
@@ -2085,7 +2085,7 @@ def get_conn(self):
         return client
 
 
-class ConnectionTest(unittest.TestCase):
+class TestConnection(unittest.TestCase):
     def setUp(self):
         utils.db.initdb()
         os.environ['AIRFLOW_CONN_TEST_URI'] = (
@@ -2164,7 +2164,7 @@ def test_get_connections_env_var(self):
         assert conns[0].port == 5432
 
 
-class WebHDFSHookTest(unittest.TestCase):
+class TestWebHDFSHook(unittest.TestCase):
     def test_simple_init(self):
         from airflow.hooks.webhdfs_hook import WebHDFSHook
         c = WebHDFSHook()
@@ -2181,7 +2181,7 @@ def test_init_proxy_user(self):
 
 @unittest.skipIf(HDFSHook is None,
                  "Skipping test because HDFSHook is not installed")
-class HDFSHookTest(unittest.TestCase):
+class TestHDFSHook(unittest.TestCase):
     def setUp(self):
         os.environ['AIRFLOW_CONN_HDFS_DEFAULT'] = 'hdfs://localhost:8020'
 
@@ -2224,7 +2224,7 @@ def test_get_ha_client(self, mock_get_connections):
 send_email_test = mock.Mock()
 
 
-class EmailTest(unittest.TestCase):
+class TestEmail(unittest.TestCase):
     def setUp(self):
         configuration.conf.remove_option('email', 'EMAIL_BACKEND')
 
@@ -2244,7 +2244,7 @@ def test_custom_backend(self, mock_send_email):
         self.assertFalse(mock_send_email.called)
 
 
-class EmailSmtpTest(unittest.TestCase):
+class TestEmailSmtp(unittest.TestCase):
     def setUp(self):
         configuration.conf.set('smtp', 'SMTP_SSL', 'False')
 
diff --git a/tests/executors/test_base_executor.py b/tests/executors/test_base_executor.py
index 40f72cb01c740..dba3bafeaf471 100644
--- a/tests/executors/test_base_executor.py
+++ b/tests/executors/test_base_executor.py
@@ -26,7 +26,7 @@
 from datetime import datetime
 
 
-class BaseExecutorTest(unittest.TestCase):
+class TestBaseExecutor(unittest.TestCase):
     def test_get_event_buffer(self):
         executor = BaseExecutor()
 
diff --git a/tests/executors/test_celery_executor.py b/tests/executors/test_celery_executor.py
index 8a95c9fbff9ea..52a0f5ab5689d 100644
--- a/tests/executors/test_celery_executor.py
+++ b/tests/executors/test_celery_executor.py
@@ -48,7 +48,7 @@ def _prepare_test_bodies():
     return [(configuration.conf.get('celery', 'BROKER_URL'))]
 
 
-class CeleryExecutorTest(unittest.TestCase):
+class TestCeleryExecutor(unittest.TestCase):
 
     @contextlib.contextmanager
     def _prepare_app(self, broker_url=None, execute=None):
diff --git a/tests/executors/test_dask_executor.py b/tests/executors/test_dask_executor.py
index 347c0e18df613..8e246efb86aff 100644
--- a/tests/executors/test_dask_executor.py
+++ b/tests/executors/test_dask_executor.py
@@ -50,7 +50,7 @@
 DEFAULT_DATE = timezone.datetime(2017, 1, 1)
 
 
-class BaseDaskTest(unittest.TestCase):
+class TestBaseDask(unittest.TestCase):
 
     def assert_tasks_on_executor(self, executor):
         # start the executor
@@ -84,7 +84,7 @@ def assert_tasks_on_executor(self, executor):
         self.assertTrue(fail_future.exception() is not None)
 
 
-class DaskExecutorTest(BaseDaskTest):
+class TestDaskExecutor(TestBaseDask):
 
     def setUp(self):
         self.dagbag = DagBag(include_examples=True)
@@ -127,7 +127,7 @@ def tearDown(self):
         self.cluster.close(timeout=5)
 
 
-class DaskExecutorTLSTest(BaseDaskTest):
+class TestDaskExecutorTLS(TestBaseDask):
 
     def setUp(self):
         self.dagbag = DagBag(include_examples=True)
diff --git a/tests/executors/test_local_executor.py b/tests/executors/test_local_executor.py
index 9329d53d3c39a..dc07b251c1c73 100644
--- a/tests/executors/test_local_executor.py
+++ b/tests/executors/test_local_executor.py
@@ -24,7 +24,7 @@
 from airflow.utils.state import State
 
 
-class LocalExecutorTest(unittest.TestCase):
+class TestLocalExecutor(unittest.TestCase):
 
     TEST_SUCCESS_COMMANDS = 5
 
diff --git a/tests/executors/test_sequential_executor.py b/tests/executors/test_sequential_executor.py
index 098106c17add5..f4b1cf4871457 100644
--- a/tests/executors/test_sequential_executor.py
+++ b/tests/executors/test_sequential_executor.py
@@ -23,7 +23,7 @@
 from airflow.executors.sequential_executor import SequentialExecutor
 
 
-class SequentialExecutorTest(unittest.TestCase):
+class TestSequentialExecutor(unittest.TestCase):
 
     @mock.patch('airflow.executors.sequential_executor.SequentialExecutor.sync')
     @mock.patch('airflow.executors.base_executor.BaseExecutor.trigger_tasks')
diff --git a/tests/gcp/hooks/test_dataflow.py b/tests/gcp/hooks/test_dataflow.py
index facf94084616d..9cb7fe40b6525 100644
--- a/tests/gcp/hooks/test_dataflow.py
+++ b/tests/gcp/hooks/test_dataflow.py
@@ -80,7 +80,7 @@ def mock_init(self, gcp_conn_id, delegate_to=None):  # pylint: disable=unused-ar
     pass
 
 
-class DataFlowHookTest(unittest.TestCase):
+class TestDataFlowHook(unittest.TestCase):
 
     def setUp(self):
         with mock.patch(BASE_STRING.format('GoogleCloudBaseHook.__init__'),
@@ -250,7 +250,7 @@ def test_dataflow_job_regex_check(self):
         )
 
 
-class DataFlowTemplateHookTest(unittest.TestCase):
+class TestDataFlowTemplateHook(unittest.TestCase):
 
     def setUp(self):
         with mock.patch(BASE_STRING.format('GoogleCloudBaseHook.__init__'),
@@ -300,7 +300,7 @@ def test_start_template_dataflow_with_runtime_env(self, mock_conn, mock_dataflow
         )
 
 
-class DataFlowJobTest(unittest.TestCase):
+class TestDataFlowJob(unittest.TestCase):
 
     def setUp(self):
         self.mock_dataflow = MagicMock()
@@ -324,7 +324,7 @@ def test_dataflow_job_init_without_job_id(self):
                                           location=TEST_LOCATION)
 
 
-class DataflowTest(unittest.TestCase):
+class TestDataflow(unittest.TestCase):
 
     def test_data_flow_valid_job_id(self):
         cmd = ['echo', 'additional unit test lines.\n' +
diff --git a/tests/gcp/hooks/test_kms.py b/tests/gcp/hooks/test_kms.py
index bc687798007e8..030e34038dac9 100644
--- a/tests/gcp/hooks/test_kms.py
+++ b/tests/gcp/hooks/test_kms.py
@@ -39,7 +39,7 @@ def mock_init(self, gcp_conn_id, delegate_to=None):  # pylint: disable=unused-ar
     pass
 
 
-class GoogleCloudKMSHookTest(unittest.TestCase):
+class TestGoogleCloudKMSHook(unittest.TestCase):
     def setUp(self):
         with mock.patch(BASE_STRING.format('GoogleCloudBaseHook.__init__'),
                         new=mock_init):
diff --git a/tests/gcp/hooks/test_kubernetes_engine.py b/tests/gcp/hooks/test_kubernetes_engine.py
index f77579f04536b..ce5a585773dd3 100644
--- a/tests/gcp/hooks/test_kubernetes_engine.py
+++ b/tests/gcp/hooks/test_kubernetes_engine.py
@@ -30,7 +30,7 @@
 GKE_ZONE = 'test-zone'
 
 
-class GKEClusterHookDeleteTest(unittest.TestCase):
+class TestGKEClusterHookDelete(unittest.TestCase):
     def setUp(self):
         self.gke_hook = GKEClusterHook(location=GKE_ZONE)
         self.gke_hook._client = mock.Mock()
@@ -84,7 +84,7 @@ def test_delete_cluster_error(self, wait_mock, convert_mock):
             convert_mock.assert_not_called()
 
 
-class GKEClusterHookCreateTest(unittest.TestCase):
+class TestGKEClusterHookCreate(unittest.TestCase):
     def setUp(self):
         self.gke_hook = GKEClusterHook(location=GKE_ZONE)
         self.gke_hook._client = mock.Mock()
@@ -165,7 +165,7 @@ def test_create_cluster_already_exists(self, wait_mock, convert_mock, log_mock):
         log_mock.info.assert_any_call("Assuming Success: %s", message)
 
 
-class GKEClusterHookGetTest(unittest.TestCase):
+class TestGKEClusterHookGet(unittest.TestCase):
     def setUp(self):
         self.gke_hook = GKEClusterHook(location=GKE_ZONE)
         self.gke_hook._client = mock.Mock()
@@ -186,7 +186,7 @@ def test_get_cluster(self):
                                       retry=retry_mock, timeout=timeout_mock)
 
 
-class GKEClusterHookTest(unittest.TestCase):
+class TestGKEClusterHook(unittest.TestCase):
 
     def setUp(self):
         self.gke_hook = GKEClusterHook(location=GKE_ZONE)
diff --git a/tests/gcp/hooks/test_pubsub.py b/tests/gcp/hooks/test_pubsub.py
index 420e27cc16a94..b91e45b76b887 100644
--- a/tests/gcp/hooks/test_pubsub.py
+++ b/tests/gcp/hooks/test_pubsub.py
@@ -50,7 +50,7 @@ def mock_init(self, gcp_conn_id, delegate_to=None):  # pylint: disable=unused-ar
     pass
 
 
-class PubSubHookTest(unittest.TestCase):
+class TestPubSubHook(unittest.TestCase):
     def setUp(self):
         with mock.patch(BASE_STRING.format('GoogleCloudBaseHook.__init__'),
                         new=mock_init):
diff --git a/tests/gcp/hooks/test_video_intelligence.py b/tests/gcp/hooks/test_video_intelligence.py
index 524c6990d1aee..a0d37920ead70 100644
--- a/tests/gcp/hooks/test_video_intelligence.py
+++ b/tests/gcp/hooks/test_video_intelligence.py
@@ -34,7 +34,7 @@
 ANNOTATE_VIDEO_RESPONSE = {'test': 'test'}
 
 
-class CloudVideoIntelligenceHookTestCase(unittest.TestCase):
+class TestCloudVideoIntelligenceHook(unittest.TestCase):
     def setUp(self):
         with mock.patch(
             "airflow.gcp.hooks.video_intelligence.CloudVideoIntelligenceHook.__init__",
diff --git a/tests/gcp/operators/test_bigtable.py b/tests/gcp/operators/test_bigtable.py
index 8d415aa9625b1..f5bd3432aa4cb 100644
--- a/tests/gcp/operators/test_bigtable.py
+++ b/tests/gcp/operators/test_bigtable.py
@@ -44,7 +44,7 @@
 EMPTY_COLUMN_FAMILIES = {}  # type: Dict
 
 
-class BigtableInstanceCreateTest(unittest.TestCase):
+class TestBigtableInstanceCreate(unittest.TestCase):
     @parameterized.expand([
         ('instance_id', PROJECT_ID, '', CLUSTER_ID, CLUSTER_ZONE),
         ('main_cluster_id', PROJECT_ID, INSTANCE_ID, '', CLUSTER_ZONE),
@@ -135,7 +135,7 @@ def test_different_error_reraised(self, mock_hook):
         )
 
 
-class BigtableClusterUpdateTest(unittest.TestCase):
+class TestBigtableClusterUpdate(unittest.TestCase):
     @parameterized.expand([
         ('instance_id', PROJECT_ID, '', CLUSTER_ID, NODES),
         ('cluster_id', PROJECT_ID, INSTANCE_ID, '', NODES),
@@ -274,7 +274,7 @@ def test_different_error_reraised(self, mock_hook):
             instance=instance, cluster_id=CLUSTER_ID, nodes=NODES)
 
 
-class BigtableInstanceDeleteTest(unittest.TestCase):
+class TestBigtableInstanceDelete(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.bigtable.BigtableHook')
     def test_delete_execute(self, mock_hook):
         op = BigtableInstanceDeleteOperator(
@@ -368,7 +368,7 @@ def test_different_error_reraised(self, mock_hook):
             instance_id=INSTANCE_ID)
 
 
-class BigtableTableDeleteTest(unittest.TestCase):
+class TestBigtableTableDelete(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.bigtable.BigtableHook')
     def test_delete_execute(self, mock_hook):
         op = BigtableTableDeleteOperator(
@@ -482,7 +482,7 @@ def test_different_error_reraised(self, mock_hook):
             table_id=TABLE_ID)
 
 
-class BigtableTableCreateTest(unittest.TestCase):
+class TestBigtableTableCreate(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.bigtable.BigtableHook')
     def test_create_execute(self, mock_hook):
         op = BigtableTableCreateOperator(
diff --git a/tests/gcp/operators/test_bigtable_system.py b/tests/gcp/operators/test_bigtable_system.py
index 4d12fc4d0be2b..6cec7ae7dbc4f 100644
--- a/tests/gcp/operators/test_bigtable_system.py
+++ b/tests/gcp/operators/test_bigtable_system.py
@@ -20,13 +20,12 @@
 
 from tests.gcp.operators.test_bigtable_system_helper import \
     GCPBigtableTestHelper
-from tests.contrib.utils.base_gcp_system_test_case import \
-    SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 from tests.contrib.utils.gcp_authenticator import GCP_BIGTABLE_KEY
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_BIGTABLE_KEY), SKIP_TEST_WARNING)
-class BigTableExampleDagsSystemTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_BIGTABLE_KEY), SKIP_TEST_WARNING)
+class BigTableExampleDagsSystemTest(TestDagGcpSystem):
     def __init__(self, method_name='runTest'):
         super().__init__(
             method_name,
diff --git a/tests/gcp/operators/test_cloud_build.py b/tests/gcp/operators/test_cloud_build.py
index 905af057110e2..9067ee8682dca 100644
--- a/tests/gcp/operators/test_cloud_build.py
+++ b/tests/gcp/operators/test_cloud_build.py
@@ -38,7 +38,7 @@
 TEST_PROJECT_ID = "example-id"
 
 
-class BuildProcessorTestCase(TestCase):
+class TestBuildProcessor(TestCase):
     def test_verify_source(self):
         with self.assertRaisesRegex(AirflowException, "The source could not be determined."):
             BuildProcessor(body={"source": {"storageSource": {}, "repoSource": {}}}).process_body()
@@ -112,7 +112,7 @@ def test_do_nothing(self, source_key):
         self.assertEqual(body, expected_body)
 
 
-class GcpCloudBuildCreateBuildOperatorTestCase(TestCase):
+class TestGcpCloudBuildCreateBuildOperator(TestCase):
     @mock.patch(  # type: ignore
         "airflow.gcp.operators.cloud_build.CloudBuildHook",
         **{"return_value.create_build.return_value": TEST_CREATE_BODY}
diff --git a/tests/gcp/operators/test_cloud_build_operator_system.py b/tests/gcp/operators/test_cloud_build_operator_system.py
index d2bc78988d9c1..e2e59cf8fcdf0 100644
--- a/tests/gcp/operators/test_cloud_build_operator_system.py
+++ b/tests/gcp/operators/test_cloud_build_operator_system.py
@@ -20,12 +20,12 @@
 import unittest
 
 from tests.gcp.operators.test_cloud_build_system_helper import GCPCloudBuildTestHelper
-from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 from tests.contrib.utils.gcp_authenticator import GCP_CLOUD_BUILD_KEY
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_CLOUD_BUILD_KEY), SKIP_TEST_WARNING)
-class CloudBuildExampleDagsSystemTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_CLOUD_BUILD_KEY), SKIP_TEST_WARNING)
+class CloudBuildExampleDagsSystemTest(TestDagGcpSystem):
     """
     System tests for Google Cloud Build operators
 
diff --git a/tests/gcp/operators/test_cloud_sql.py b/tests/gcp/operators/test_cloud_sql.py
index a830ad1059de8..4f88f1e0f9070 100644
--- a/tests/gcp/operators/test_cloud_sql.py
+++ b/tests/gcp/operators/test_cloud_sql.py
@@ -160,9 +160,8 @@
 }
 
 
-class CloudSqlTest(unittest.TestCase):
-    @mock.patch("airflow.gcp.operators.cloud_sql"
-                ".CloudSqlInstanceCreateOperator._check_if_instance_exists")
+class TestCloudSql(unittest.TestCase):
+    @mock.patch("airflow.gcp.operators.cloud_sql.CloudSqlInstanceCreateOperator._check_if_instance_exists")
     @mock.patch("airflow.gcp.operators.cloud_sql.CloudSqlHook")
     def test_instance_create(self, mock_hook, _check_if_instance_exists):
         _check_if_instance_exists.return_value = False
@@ -706,7 +705,7 @@ def test_instance_import_missing_project_id(self, mock_hook):
         self.assertTrue(result)
 
 
-class CloudSqlQueryValidationTest(unittest.TestCase):
+class TestCloudSqlQueryValidation(unittest.TestCase):
 
     @staticmethod
     def _setup_connections(get_connections, uri):
diff --git a/tests/gcp/operators/test_cloud_sql_operatorquery_system.py b/tests/gcp/operators/test_cloud_sql_operatorquery_system.py
index 907e6e1e2fdd2..2f7c3d92f6ced 100644
--- a/tests/gcp/operators/test_cloud_sql_operatorquery_system.py
+++ b/tests/gcp/operators/test_cloud_sql_operatorquery_system.py
@@ -26,8 +26,7 @@
 
 from airflow import AirflowException
 from airflow.gcp.hooks.cloud_sql import CloudSqlProxyRunner
-from tests.contrib.utils.base_gcp_system_test_case import BaseGcpSystemTestCase, \
-    DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import TestBaseGcpSystem, TestDagGcpSystem
 from tests.gcp.operators.test_cloud_sql_system_helper import \
     CloudSqlQueryTestHelper
 from tests.contrib.utils.gcp_authenticator import GCP_CLOUDSQL_KEY
@@ -55,7 +54,7 @@
 
 
 @unittest.skipIf(not enable_cloudsql_query_test, SKIP_CLOUDSQL_QUERY_WARNING)
-class CloudSqlProxySystemTest(BaseGcpSystemTestCase):
+class CloudSqlProxySystemTest(TestBaseGcpSystem):
     def __init__(self, method_name='runTest'):
         super().__init__(
             method_name,
@@ -124,7 +123,7 @@ def test_start_proxy_with_all_instances_specific_version(self):
 
 
 @unittest.skipIf(not enable_cloudsql_query_test, SKIP_CLOUDSQL_QUERY_WARNING)
-class CloudSqlQueryExampleDagsSystemTest(DagGcpSystemTestCase):
+class CloudSqlQueryExampleDagsSystemTest(TestDagGcpSystem):
 
     def __init__(self, method_name='runTest'):
         super().__init__(
diff --git a/tests/gcp/operators/test_cloud_sql_system.py b/tests/gcp/operators/test_cloud_sql_system.py
index acdacd7044366..57810ebdfd543 100644
--- a/tests/gcp/operators/test_cloud_sql_system.py
+++ b/tests/gcp/operators/test_cloud_sql_system.py
@@ -20,8 +20,7 @@
 import unittest
 
 from airflow import AirflowException
-from tests.contrib.utils.base_gcp_system_test_case import \
-    SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 from tests.gcp.operators.test_cloud_sql_system_helper import \
     CloudSqlQueryTestHelper
 from tests.contrib.utils.gcp_authenticator import GCP_CLOUDSQL_KEY
@@ -31,8 +30,8 @@
 SQL_QUERY_TEST_HELPER = CloudSqlQueryTestHelper()
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_CLOUDSQL_KEY), SKIP_TEST_WARNING)
-class CloudSqlExampleDagsIntegrationTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_CLOUDSQL_KEY), SKIP_TEST_WARNING)
+class CloudSqlExampleDagsIntegrationTest(TestDagGcpSystem):
     def __init__(self, method_name='runTest'):
         super().__init__(
             method_name,
diff --git a/tests/gcp/operators/test_cloud_storage_transfer_service.py b/tests/gcp/operators/test_cloud_storage_transfer_service.py
index e6be97c3b35ad..65f850390d900 100644
--- a/tests/gcp/operators/test_cloud_storage_transfer_service.py
+++ b/tests/gcp/operators/test_cloud_storage_transfer_service.py
@@ -146,7 +146,7 @@
 VALID_OPERATION = {NAME: "operation-name"}
 
 
-class TransferJobPreprocessorTest(unittest.TestCase):
+class TestTransferJobPreprocessor(unittest.TestCase):
     def test_should_do_nothing_on_empty(self):
         body = {}
         TransferJobPreprocessor(body=body).process_body()
@@ -197,7 +197,7 @@ def test_should_set_default_schedule(self):
         })
 
 
-class TransferJobValidatorTest(unittest.TestCase):
+class TestTransferJobValidator(unittest.TestCase):
     def test_should_raise_exception_when_encounters_aws_credentials(self):
         body = {"transferSpec": {"awsS3DataSource": {"awsAccessKey": TEST_AWS_ACCESS_KEY}}}
         with self.assertRaises(AirflowException) as cm:
@@ -247,7 +247,7 @@ def test_verify_success(self, body):
         self.assertTrue(validated)
 
 
-class GcpStorageTransferJobCreateOperatorTest(unittest.TestCase):
+class TestGcpStorageTransferJobCreateOperator(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.cloud_storage_transfer_service.GCPTransferServiceHook')
     def test_job_create_gcs(self, mock_hook):
         mock_hook.return_value.create_transfer_job.return_value = VALID_TRANSFER_JOB_GCS_RAW
@@ -320,7 +320,7 @@ def test_templates(self, _):
         self.assertEqual(dag_id, getattr(op, 'aws_conn_id'))
 
 
-class GcpStorageTransferJobUpdateOperatorTest(unittest.TestCase):
+class TestGcpStorageTransferJobUpdateOperator(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.cloud_storage_transfer_service.GCPTransferServiceHook')
     def test_job_update(self, mock_hook):
         mock_hook.return_value.update_transfer_job.return_value = VALID_TRANSFER_JOB_GCS
@@ -353,7 +353,7 @@ def test_templates(self, _):
         self.assertEqual(dag_id, getattr(op, 'job_name'))
 
 
-class GcpStorageTransferJobDeleteOperatorTest(unittest.TestCase):
+class TestGcpStorageTransferJobDeleteOperator(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.cloud_storage_transfer_service.GCPTransferServiceHook')
     def test_job_delete(self, mock_hook):
         op = GcpTransferServiceJobDeleteOperator(
@@ -396,7 +396,7 @@ def test_job_delete_should_throw_ex_when_name_none(self, mock_hook):
         mock_hook.assert_not_called()
 
 
-class GpcStorageTransferOperationsGetOperatorTest(unittest.TestCase):
+class TestGpcStorageTransferOperationsGetOperator(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.cloud_storage_transfer_service.GCPTransferServiceHook')
     def test_operation_get(self, mock_hook):
         mock_hook.return_value.get_transfer_operation.return_value = VALID_OPERATION
@@ -431,7 +431,7 @@ def test_operation_get_should_throw_ex_when_operation_name_none(self, mock_hook)
         mock_hook.assert_not_called()
 
 
-class GcpStorageTransferOperationListOperatorTest(unittest.TestCase):
+class TestGcpStorageTransferOperationListOperator(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.cloud_storage_transfer_service.GCPTransferServiceHook')
     def test_operation_list(self, mock_hook):
         mock_hook.return_value.list_transfer_operations.return_value = [VALID_TRANSFER_JOB_GCS]
@@ -465,7 +465,7 @@ def test_templates(self, _):
         self.assertEqual(dag_id, getattr(op, 'gcp_conn_id'))
 
 
-class GcpStorageTransferOperationsPauseOperatorTest(unittest.TestCase):
+class TestGcpStorageTransferOperationsPauseOperator(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.cloud_storage_transfer_service.GCPTransferServiceHook')
     def test_operation_pause(self, mock_hook):
         op = GcpTransferServiceOperationPauseOperator(operation_name=OPERATION_NAME, task_id='task-id')
@@ -504,7 +504,7 @@ def test_operation_pause_should_throw_ex_when_name_none(self, mock_hook):
         mock_hook.assert_not_called()
 
 
-class GcpStorageTransferOperationsResumeOperatorTest(unittest.TestCase):
+class TestGcpStorageTransferOperationsResumeOperator(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.cloud_storage_transfer_service.GCPTransferServiceHook')
     def test_operation_resume(self, mock_hook):
         op = GcpTransferServiceOperationResumeOperator(operation_name=OPERATION_NAME, task_id=TASK_ID)
@@ -546,7 +546,7 @@ def test_operation_resume_should_throw_ex_when_name_none(self, mock_hook):
         mock_hook.assert_not_called()
 
 
-class GcpStorageTransferOperationsCancelOperatorTest(unittest.TestCase):
+class TestGcpStorageTransferOperationsCancelOperator(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.cloud_storage_transfer_service.GCPTransferServiceHook')
     def test_operation_cancel(self, mock_hook):
         op = GcpTransferServiceOperationCancelOperator(operation_name=OPERATION_NAME, task_id=TASK_ID)
@@ -588,7 +588,7 @@ def test_operation_cancel_should_throw_ex_when_name_none(self, mock_hook):
         mock_hook.assert_not_called()
 
 
-class S3ToGoogleCloudStorageTransferOperatorTest(unittest.TestCase):
+class TestS3ToGoogleCloudStorageTransferOperator(unittest.TestCase):
     def test_constructor(self):
         operator = S3ToGoogleCloudStorageTransferOperator(
             task_id=TASK_ID,
@@ -683,7 +683,7 @@ def test_execute_skip_wait(self, mock_aws_hook, mock_transfer_hook):
         self.assertFalse(mock_transfer_hook.return_value.wait_for_transfer_job.called)
 
 
-class GoogleCloudStorageToGoogleCloudStorageTransferOperatorTest(unittest.TestCase):
+class TestGoogleCloudStorageToGoogleCloudStorageTransferOperator(unittest.TestCase):
     def test_constructor(self):
         operator = GoogleCloudStorageToGoogleCloudStorageTransferOperator(
             task_id=TASK_ID,
diff --git a/tests/gcp/operators/test_cloud_storage_transfer_service_system.py b/tests/gcp/operators/test_cloud_storage_transfer_service_system.py
index c8e7fb1a2d4d5..2a0197f1c4c55 100644
--- a/tests/gcp/operators/test_cloud_storage_transfer_service_system.py
+++ b/tests/gcp/operators/test_cloud_storage_transfer_service_system.py
@@ -19,13 +19,13 @@
 import unittest
 
 from tests.gcp.operators.test_cloud_storage_transfer_service_system_helper import GCPTransferTestHelper
-from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 
 from tests.contrib.utils.gcp_authenticator import GCP_GCS_TRANSFER_KEY
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_GCS_TRANSFER_KEY), SKIP_TEST_WARNING)
-class GcpTransferExampleDagsSystemTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_GCS_TRANSFER_KEY), SKIP_TEST_WARNING)
+class GcpTransferExampleDagsSystemTest(TestDagGcpSystem):
     def setUp(self):
         super().setUp()
         self.gcp_authenticator.gcp_authenticate()
diff --git a/tests/gcp/operators/test_compute.py b/tests/gcp/operators/test_compute.py
index 1f42aa08849ca..2c693044befbf 100644
--- a/tests/gcp/operators/test_compute.py
+++ b/tests/gcp/operators/test_compute.py
@@ -47,7 +47,7 @@
 DEFAULT_DATE = timezone.datetime(2017, 1, 1)
 
 
-class GceInstanceStartTest(unittest.TestCase):
+class TestGceInstanceStart(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.compute.GceHook')
     def test_instance_start(self, mock_hook):
         mock_hook.return_value.start_instance.return_value = True
@@ -143,7 +143,7 @@ def test_start_should_throw_ex_when_missing_resource_id(self, mock_hook):
         mock_hook.assert_not_called()
 
 
-class GceInstanceStopTest(unittest.TestCase):
+class TestGceInstanceStop(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.compute.GceHook')
     def test_instance_stop(self, mock_hook):
         op = GceInstanceStopOperator(
@@ -242,7 +242,7 @@ def test_stop_should_throw_ex_when_missing_resource_id(self, mock_hook):
         mock_hook.assert_not_called()
 
 
-class GceInstanceSetMachineTypeTest(unittest.TestCase):
+class TestGceInstanceSetMachineType(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.compute.GceHook')
     def test_set_machine_type(self, mock_hook):
         mock_hook.return_value.set_machine_type.return_value = True
@@ -515,7 +515,7 @@ def test_set_machine_type_should_handle_and_trim_gce_error(
 GCE_INSTANCE_TEMPLATE_BODY_GET_NEW['name'] = GCE_INSTANCE_TEMPLATE_NEW_NAME
 
 
-class GceInstanceTemplateCopyTest(unittest.TestCase):
+class TestGceInstanceTemplateCopy(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.compute.GceHook')
     def test_successful_copy_template(self, mock_hook):
         mock_hook.return_value.get_instance_template.side_effect = [
@@ -926,7 +926,7 @@ def test_missing_name(self, mock_hook):
 }
 
 
-class GceInstanceGroupManagerUpdateTest(unittest.TestCase):
+class TestGceInstanceGroupManagerUpdate(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.compute.GceHook')
     def test_successful_instance_group_update(self, mock_hook):
         mock_hook.return_value.get_instance_group_manager.return_value = \
diff --git a/tests/gcp/operators/test_compute_system.py b/tests/gcp/operators/test_compute_system.py
index 14cbc966a19ad..a019f6ed4de56 100644
--- a/tests/gcp/operators/test_compute_system.py
+++ b/tests/gcp/operators/test_compute_system.py
@@ -18,16 +18,15 @@
 # under the License.
 import unittest
 
-from tests.contrib.utils.base_gcp_system_test_case import \
-    SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 
 from tests.gcp.operators.test_compute_system_helper import \
     GCPComputeTestHelper
 from tests.contrib.utils.gcp_authenticator import GCP_COMPUTE_KEY
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_COMPUTE_KEY), SKIP_TEST_WARNING)
-class GcpComputeExampleDagsSystemTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_COMPUTE_KEY), SKIP_TEST_WARNING)
+class GcpComputeExampleDagsSystemTest(TestDagGcpSystem):
 
     def setUp(self):
         super().setUp()
@@ -53,8 +52,8 @@ def test_run_example_dag_compute(self):
         self._run_dag()
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_COMPUTE_KEY), SKIP_TEST_WARNING)
-class GcpComputeIgmExampleDagsSystemTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_COMPUTE_KEY), SKIP_TEST_WARNING)
+class GcpComputeIgmExampleDagsSystemTest(TestDagGcpSystem):
 
     def setUp(self):
         super().setUp()
diff --git a/tests/gcp/operators/test_dataflow.py b/tests/gcp/operators/test_dataflow.py
index 4a130ac762c07..33a9147640992 100644
--- a/tests/gcp/operators/test_dataflow.py
+++ b/tests/gcp/operators/test_dataflow.py
@@ -62,7 +62,7 @@
 GCS_HOOK_STRING = 'airflow.gcp.operators.dataflow.{}'
 
 
-class DataFlowPythonOperatorTest(unittest.TestCase):
+class TestDataFlowPythonOperator(unittest.TestCase):
 
     def setUp(self):
         self.dataflow = DataFlowPythonOperator(
@@ -109,7 +109,7 @@ def test_exec(self, gcs_hook, dataflow_mock):
         self.assertTrue(self.dataflow.py_file.startswith('/tmp/dataflow'))
 
 
-class DataFlowJavaOperatorTest(unittest.TestCase):
+class TestDataFlowJavaOperator(unittest.TestCase):
 
     def setUp(self):
         self.dataflow = DataFlowJavaOperator(
@@ -208,7 +208,7 @@ def test_check_multiple_job_exec(self, gcs_hook, dataflow_mock):
         dataflow_running.assert_called_once_with(JOB_NAME, mock.ANY)
 
 
-class DataFlowTemplateOperatorTest(unittest.TestCase):
+class TestDataFlowTemplateOperator(unittest.TestCase):
 
     def setUp(self):
         self.dataflow = DataflowTemplateOperator(
@@ -248,7 +248,7 @@ def test_exec(self, dataflow_mock):
                                                     PARAMETERS, TEMPLATE)
 
 
-class GoogleCloudBucketHelperTest(unittest.TestCase):
+class TestGoogleCloudBucketHelper(unittest.TestCase):
 
     @mock.patch(
         'airflow.gcp.operators.dataflow.GoogleCloudBucketHelper.__init__'
diff --git a/tests/gcp/operators/test_dlp.py b/tests/gcp/operators/test_dlp.py
index 76f2b2cc30fa8..f2d73537af131 100644
--- a/tests/gcp/operators/test_dlp.py
+++ b/tests/gcp/operators/test_dlp.py
@@ -67,7 +67,7 @@
 TRIGGER_ID = "trigger123"
 
 
-class CloudDLPCancelDLPJobOperatorTest(unittest.TestCase):
+class TestCloudDLPCancelDLPJobOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_cancel_dlp_job(self, mock_hook):
         mock_hook.return_value.cancel_dlp_job.return_value = {}
@@ -83,7 +83,7 @@ def test_cancel_dlp_job(self, mock_hook):
         )
 
 
-class CloudDLPCreateDeidentifyTemplateOperatorTest(unittest.TestCase):
+class TestCloudDLPCreateDeidentifyTemplateOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_create_deidentify_template(self, mock_hook):
         mock_hook.return_value.create_deidentify_template.return_value = {}
@@ -103,7 +103,7 @@ def test_create_deidentify_template(self, mock_hook):
         )
 
 
-class CloudDLPCreateDLPJobOperatorTest(unittest.TestCase):
+class TestCloudDLPCreateDLPJobOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_create_dlp_job(self, mock_hook):
         mock_hook.return_value.create_dlp_job.return_value = {}
@@ -122,7 +122,7 @@ def test_create_dlp_job(self, mock_hook):
         )
 
 
-class CloudDLPCreateInspectTemplateOperatorTest(unittest.TestCase):
+class TestCloudDLPCreateInspectTemplateOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_create_inspect_template(self, mock_hook):
         mock_hook.return_value.create_inspect_template.return_value = {}
@@ -142,7 +142,7 @@ def test_create_inspect_template(self, mock_hook):
         )
 
 
-class CloudDLPCreateJobTriggerOperatorTest(unittest.TestCase):
+class TestCloudDLPCreateJobTriggerOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_create_job_trigger(self, mock_hook):
         mock_hook.return_value.create_job_trigger.return_value = {}
@@ -159,7 +159,7 @@ def test_create_job_trigger(self, mock_hook):
         )
 
 
-class CloudDLPCreateStoredInfoTypeOperatorTest(unittest.TestCase):
+class TestCloudDLPCreateStoredInfoTypeOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_create_stored_info_type(self, mock_hook):
         mock_hook.return_value.create_stored_info_type.return_value = {}
@@ -179,7 +179,7 @@ def test_create_stored_info_type(self, mock_hook):
         )
 
 
-class CloudDLPDeidentifyContentOperatorTest(unittest.TestCase):
+class TestCloudDLPDeidentifyContentOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_deidentify_content(self, mock_hook):
         mock_hook.return_value.deidentify_content.return_value = {}
@@ -201,7 +201,7 @@ def test_deidentify_content(self, mock_hook):
         )
 
 
-class CloudDLPDeleteDeidentifyTemplateOperatorTest(unittest.TestCase):
+class TestCloudDLPDeleteDeidentifyTemplateOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_delete_deidentify_template(self, mock_hook):
         mock_hook.return_value.delete_deidentify_template.return_value = {}
@@ -220,7 +220,7 @@ def test_delete_deidentify_template(self, mock_hook):
         )
 
 
-class CloudDLPDeleteDlpJobOperatorTest(unittest.TestCase):
+class TestCloudDLPDeleteDlpJobOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_delete_dlp_job(self, mock_hook):
         mock_hook.return_value.delete_dlp_job.return_value = {}
@@ -238,7 +238,7 @@ def test_delete_dlp_job(self, mock_hook):
         )
 
 
-class CloudDLPDeleteInspectTemplateOperatorTest(unittest.TestCase):
+class TestCloudDLPDeleteInspectTemplateOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_delete_inspect_template(self, mock_hook):
         mock_hook.return_value.delete_inspect_template.return_value = {}
@@ -257,7 +257,7 @@ def test_delete_inspect_template(self, mock_hook):
         )
 
 
-class CloudDLPDeleteJobTriggerOperatorTest(unittest.TestCase):
+class TestCloudDLPDeleteJobTriggerOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_delete_job_trigger(self, mock_hook):
         mock_hook.return_value.delete_job_trigger.return_value = {}
@@ -275,7 +275,7 @@ def test_delete_job_trigger(self, mock_hook):
         )
 
 
-class CloudDLPDeleteStoredInfoTypeOperatorTest(unittest.TestCase):
+class TestCloudDLPDeleteStoredInfoTypeOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_delete_stored_info_type(self, mock_hook):
         mock_hook.return_value.delete_stored_info_type.return_value = {}
@@ -296,7 +296,7 @@ def test_delete_stored_info_type(self, mock_hook):
         )
 
 
-class CloudDLPGetDeidentifyTemplateOperatorTest(unittest.TestCase):
+class TestCloudDLPGetDeidentifyTemplateOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_get_deidentify_template(self, mock_hook):
         mock_hook.return_value.get_deidentify_template.return_value = {}
@@ -315,7 +315,7 @@ def test_get_deidentify_template(self, mock_hook):
         )
 
 
-class CloudDLPGetDlpJobOperatorTest(unittest.TestCase):
+class TestCloudDLPGetDlpJobOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_get_dlp_job(self, mock_hook):
         mock_hook.return_value.get_dlp_job.return_value = {}
@@ -333,7 +333,7 @@ def test_get_dlp_job(self, mock_hook):
         )
 
 
-class CloudDLPGetInspectTemplateOperatorTest(unittest.TestCase):
+class TestCloudDLPGetInspectTemplateOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_get_inspect_template(self, mock_hook):
         mock_hook.return_value.get_inspect_template.return_value = {}
@@ -352,7 +352,7 @@ def test_get_inspect_template(self, mock_hook):
         )
 
 
-class CloudDLPGetJobTripperOperatorTest(unittest.TestCase):
+class TestCloudDLPGetJobTripperOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_get_job_trigger(self, mock_hook):
         mock_hook.return_value.get_job_trigger.return_value = {}
@@ -370,7 +370,7 @@ def test_get_job_trigger(self, mock_hook):
         )
 
 
-class CloudDLPGetStoredInfoTypeOperatorTest(unittest.TestCase):
+class TestCloudDLPGetStoredInfoTypeOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_get_stored_info_type(self, mock_hook):
         mock_hook.return_value.get_stored_info_type.return_value = {}
@@ -391,7 +391,7 @@ def test_get_stored_info_type(self, mock_hook):
         )
 
 
-class CloudDLPInspectContentOperatorTest(unittest.TestCase):
+class TestCloudDLPInspectContentOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_inspect_content(self, mock_hook):
         mock_hook.return_value.inspect_content.return_value = {}
@@ -409,7 +409,7 @@ def test_inspect_content(self, mock_hook):
         )
 
 
-class CloudDLPListDeidentifyTemplatesOperatorTest(unittest.TestCase):
+class TestCloudDLPListDeidentifyTemplatesOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_list_deidentify_templates(self, mock_hook):
         mock_hook.return_value.list_deidentify_templates.return_value = {}
@@ -429,7 +429,7 @@ def test_list_deidentify_templates(self, mock_hook):
         )
 
 
-class CloudDLPListDlpJobsOperatorTest(unittest.TestCase):
+class TestCloudDLPListDlpJobsOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_list_dlp_jobs(self, mock_hook):
         mock_hook.return_value.list_dlp_jobs.return_value = {}
@@ -448,7 +448,7 @@ def test_list_dlp_jobs(self, mock_hook):
         )
 
 
-class CloudDLPListInfoTypesOperatorTest(unittest.TestCase):
+class TestCloudDLPListInfoTypesOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_list_info_types(self, mock_hook):
         mock_hook.return_value.list_info_types.return_value = {}
@@ -464,7 +464,7 @@ def test_list_info_types(self, mock_hook):
         )
 
 
-class CloudDLPListInspectTemplatesOperatorTest(unittest.TestCase):
+class TestCloudDLPListInspectTemplatesOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_list_inspect_templates(self, mock_hook):
         mock_hook.return_value.list_inspect_templates.return_value = {}
@@ -484,7 +484,7 @@ def test_list_inspect_templates(self, mock_hook):
         )
 
 
-class CloudDLPListJobTriggersOperatorTest(unittest.TestCase):
+class TestCloudDLPListJobTriggersOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_list_job_triggers(self, mock_hook):
         mock_hook.return_value.list_job_triggers.return_value = {}
@@ -502,7 +502,7 @@ def test_list_job_triggers(self, mock_hook):
         )
 
 
-class CloudDLPListStoredInfoTypesOperatorTest(unittest.TestCase):
+class TestCloudDLPListStoredInfoTypesOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_list_stored_info_types(self, mock_hook):
         mock_hook.return_value.list_stored_info_types.return_value = {}
@@ -522,7 +522,7 @@ def test_list_stored_info_types(self, mock_hook):
         )
 
 
-class CloudDLPRedactImageOperatorTest(unittest.TestCase):
+class TestCloudDLPRedactImageOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_redact_image(self, mock_hook):
         mock_hook.return_value.redact_image.return_value = {}
@@ -541,7 +541,7 @@ def test_redact_image(self, mock_hook):
         )
 
 
-class CloudDLPReidentifyContentOperatorTest(unittest.TestCase):
+class TestCloudDLPReidentifyContentOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_reidentify_content(self, mock_hook):
         mock_hook.return_value.reidentify_content.return_value = {}
@@ -563,7 +563,7 @@ def test_reidentify_content(self, mock_hook):
         )
 
 
-class CloudDLPUpdateDeidentifyTemplateOperatorTest(unittest.TestCase):
+class TestCloudDLPUpdateDeidentifyTemplateOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_update_deidentify_template(self, mock_hook):
         mock_hook.return_value.update_deidentify_template.return_value = {}
@@ -584,7 +584,7 @@ def test_update_deidentify_template(self, mock_hook):
         )
 
 
-class CloudDLPUpdateInspectTemplateOperatorTest(unittest.TestCase):
+class TestCloudDLPUpdateInspectTemplateOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_update_inspect_template(self, mock_hook):
         mock_hook.return_value.update_inspect_template.return_value = {}
@@ -605,7 +605,7 @@ def test_update_inspect_template(self, mock_hook):
         )
 
 
-class CloudDLPUpdateJobTriggerOperatorTest(unittest.TestCase):
+class TestCloudDLPUpdateJobTriggerOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_update_job_trigger(self, mock_hook):
         mock_hook.return_value.update_job_trigger.return_value = {}
@@ -625,7 +625,7 @@ def test_update_job_trigger(self, mock_hook):
         )
 
 
-class CloudDLPUpdateStoredInfoTypeOperatorTest(unittest.TestCase):
+class TestCloudDLPUpdateStoredInfoTypeOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.dlp.CloudDLPHook")
     def test_update_stored_info_type(self, mock_hook):
         mock_hook.return_value.update_stored_info_type.return_value = {}
diff --git a/tests/gcp/operators/test_dlp_system.py b/tests/gcp/operators/test_dlp_system.py
index 2692de8032973..dc70b54a915ef 100644
--- a/tests/gcp/operators/test_dlp_system.py
+++ b/tests/gcp/operators/test_dlp_system.py
@@ -25,14 +25,12 @@
 
 import unittest
 
-from tests.contrib.utils.base_gcp_system_test_case import \
-    SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 from tests.contrib.utils.gcp_authenticator import GCP_DLP_KEY
 
 
-@unittest.skipIf(
-    DagGcpSystemTestCase.skip_check(GCP_DLP_KEY), SKIP_TEST_WARNING)
-class GcpDLPExampleDagsSystemTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_DLP_KEY), SKIP_TEST_WARNING)
+class GcpDLPExampleDagsSystemTest(TestDagGcpSystem):
     def __init__(self, method_name='runTest'):
         super().__init__(
             method_name,
diff --git a/tests/gcp/operators/test_functions.py b/tests/gcp/operators/test_functions.py
index 035bd243b18e6..fa053b8dd22f3 100644
--- a/tests/gcp/operators/test_functions.py
+++ b/tests/gcp/operators/test_functions.py
@@ -69,7 +69,7 @@ def _prepare_test_bodies():
     return body_values
 
 
-class GcfFunctionDeployTest(unittest.TestCase):
+class TestGcfFunctionDeploy(unittest.TestCase):
     @parameterized.expand(_prepare_test_bodies())
     @mock.patch('airflow.gcp.operators.functions.GcfHook')
     def test_body_empty_or_missing_fields(self, body, message, mock_hook):
@@ -545,7 +545,7 @@ def test_extra_parameter(self, mock_hook):
         mock_hook.reset_mock()
 
 
-class GcfFunctionDeleteTest(unittest.TestCase):
+class TestGcfFunctionDelete(unittest.TestCase):
     _FUNCTION_NAME = 'projects/project_name/locations/project_location/functions' \
                      '/function_name'
     _DELETE_FUNCTION_EXPECTED = {
diff --git a/tests/gcp/operators/test_functions_system.py b/tests/gcp/operators/test_functions_system.py
index 4ff23d9e6ed1f..8ed7650df37bc 100644
--- a/tests/gcp/operators/test_functions_system.py
+++ b/tests/gcp/operators/test_functions_system.py
@@ -19,14 +19,12 @@
 
 import unittest
 
-from tests.contrib.utils.base_gcp_system_test_case import \
-    SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 from tests.contrib.utils.gcp_authenticator import GCP_FUNCTION_KEY
 
 
-@unittest.skipIf(
-    DagGcpSystemTestCase.skip_check(GCP_FUNCTION_KEY), SKIP_TEST_WARNING)
-class GcpFunctionExampleDagsSystemTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_FUNCTION_KEY), SKIP_TEST_WARNING)
+class GcpFunctionExampleDagsSystemTest(TestDagGcpSystem):
     def __init__(self, method_name='runTest'):
         super().__init__(
             method_name,
diff --git a/tests/gcp/operators/test_kubernetes_engine.py b/tests/gcp/operators/test_kubernetes_engine.py
index fd57142eae921..47ed61516b357 100644
--- a/tests/gcp/operators/test_kubernetes_engine.py
+++ b/tests/gcp/operators/test_kubernetes_engine.py
@@ -45,7 +45,7 @@
 FILE_NAME = '/tmp/mock_name'
 
 
-class GoogleCloudPlatformContainerOperatorTest(unittest.TestCase):
+class TestGoogleCloudPlatformContainerOperator(unittest.TestCase):
 
     @mock.patch('airflow.gcp.operators.kubernetes_engine.GKEClusterHook')
     def test_create_execute(self, mock_hook):
@@ -135,7 +135,7 @@ def test_delete_execute_error_location(self, mock_hook):
             mock_hook.return_value.delete_cluster.assert_not_called()
 
 
-class GKEPodOperatorTest(unittest.TestCase):
+class TestGKEPodOperator(unittest.TestCase):
     def setUp(self):
         self.gke_op = GKEPodOperator(project_id=TEST_GCP_PROJECT_ID,
                                      location=PROJECT_LOCATION,
diff --git a/tests/gcp/operators/test_mlengine.py b/tests/gcp/operators/test_mlengine.py
index 0c1e1e7b342af..fda5dc2a07c50 100644
--- a/tests/gcp/operators/test_mlengine.py
+++ b/tests/gcp/operators/test_mlengine.py
@@ -32,7 +32,7 @@
 DEFAULT_DATE = datetime.datetime(2017, 6, 6)
 
 
-class MLEngineBatchPredictionOperatorTest(unittest.TestCase):
+class TestMLEngineBatchPredictionOperator(unittest.TestCase):
     INPUT_MISSING_ORIGIN = {
         'dataFormat': 'TEXT',
         'inputPaths': ['gs://legal-bucket/fake-input-path/*'],
@@ -280,7 +280,7 @@ def testFailedJobError(self):
             self.assertEqual('A failure message', str(context.exception))
 
 
-class MLEngineTrainingOperatorTest(unittest.TestCase):
+class TestMLEngineTrainingOperator(unittest.TestCase):
     TRAINING_DEFAULT_ARGS = {
         'project_id': 'test-project',
         'job_id': 'test_training',
@@ -395,7 +395,7 @@ def testFailedJobError(self):
             self.assertEqual('A failure message', str(context.exception))
 
 
-class MLEngineVersionOperatorTest(unittest.TestCase):
+class TestMLEngineVersionOperator(unittest.TestCase):
     VERSION_DEFAULT_ARGS = {
         'project_id': 'test-project',
         'model_name': 'test-model',
diff --git a/tests/gcp/operators/test_mlengine_utils.py b/tests/gcp/operators/test_mlengine_utils.py
index a661337696e24..c6ca1fb0a397d 100644
--- a/tests/gcp/operators/test_mlengine_utils.py
+++ b/tests/gcp/operators/test_mlengine_utils.py
@@ -30,7 +30,7 @@
 TEST_VERSION = 'v{}'.format(version.replace('.', '-').replace('+', '-'))
 
 
-class CreateEvaluateOpsTest(unittest.TestCase):
+class TestCreateEvaluateOps(unittest.TestCase):
     INPUT_MISSING_ORIGIN = {
         'dataFormat': 'TEXT',
         'inputPaths': ['gs://legal-bucket/fake-input-path/*'],
diff --git a/tests/gcp/operators/test_natural_language.py b/tests/gcp/operators/test_natural_language.py
index b224ee3d17a07..3d4dabddb1d0f 100644
--- a/tests/gcp/operators/test_natural_language.py
+++ b/tests/gcp/operators/test_natural_language.py
@@ -48,7 +48,7 @@
 ENCODING_TYPE = "UTF32"
 
 
-class CloudLanguageAnalyzeEntitiesOperatorTestCase(unittest.TestCase):
+class TestCloudLanguageAnalyzeEntitiesOperator(unittest.TestCase):
     @patch("airflow.gcp.operators.natural_language.CloudNaturalLanguageHook")
     def test_minimal_green_path(self, hook_mock):
         hook_mock.return_value.analyze_entities.return_value = ANALYZE_ENTITIES_RESPONSE
@@ -57,7 +57,7 @@ def test_minimal_green_path(self, hook_mock):
         self.assertEqual(resp, {})
 
 
-class CloudLanguageAnalyzeEntitySentimentOperatorTestCase(unittest.TestCase):
+class TestCloudLanguageAnalyzeEntitySentimentOperator(unittest.TestCase):
     @patch("airflow.gcp.operators.natural_language.CloudNaturalLanguageHook")
     def test_minimal_green_path(self, hook_mock):
         hook_mock.return_value.analyze_entity_sentiment.return_value = ANALYZE_ENTITY_SENTIMENT_RESPONSE
@@ -66,7 +66,7 @@ def test_minimal_green_path(self, hook_mock):
         self.assertEqual(resp, {})
 
 
-class CloudLanguageAnalyzeSentimentOperatorTestCase(unittest.TestCase):
+class TestCloudLanguageAnalyzeSentimentOperator(unittest.TestCase):
     @patch("airflow.gcp.operators.natural_language.CloudNaturalLanguageHook")
     def test_minimal_green_path(self, hook_mock):
         hook_mock.return_value.analyze_sentiment.return_value = ANALYZE_SENTIMENT_RESPONSE
@@ -75,7 +75,7 @@ def test_minimal_green_path(self, hook_mock):
         self.assertEqual(resp, {})
 
 
-class CloudLanguageClassifyTextOperatorTestCase(unittest.TestCase):
+class TestCloudLanguageClassifyTextOperator(unittest.TestCase):
     @patch("airflow.gcp.operators.natural_language.CloudNaturalLanguageHook")
     def test_minimal_green_path(self, hook_mock):
         hook_mock.return_value.classify_text.return_value = CLASSIFY_TEXT_RRESPONSE
diff --git a/tests/gcp/operators/test_natural_language_system.py b/tests/gcp/operators/test_natural_language_system.py
index e3b9372aff51f..136ef39a53a09 100644
--- a/tests/gcp/operators/test_natural_language_system.py
+++ b/tests/gcp/operators/test_natural_language_system.py
@@ -18,12 +18,12 @@
 # under the License.
 import unittest
 
-from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 from tests.contrib.utils.gcp_authenticator import GCP_AI_KEY
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_AI_KEY), SKIP_TEST_WARNING)
-class CloudNaturalLanguageExampleDagsTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_AI_KEY), SKIP_TEST_WARNING)
+class CloudNaturalLanguageExampleDagsTest(TestDagGcpSystem):
     def __init__(self, method_name="runTest"):
         super().__init__(
             method_name, dag_id="example_gcp_natural_language", gcp_key=GCP_AI_KEY
diff --git a/tests/gcp/operators/test_pubsub.py b/tests/gcp/operators/test_pubsub.py
index c69d6d488f5f9..065e7aa8b1756 100644
--- a/tests/gcp/operators/test_pubsub.py
+++ b/tests/gcp/operators/test_pubsub.py
@@ -40,7 +40,7 @@
 TEST_POKE_INTERVAl = 0
 
 
-class PubSubTopicCreateOperatorTest(unittest.TestCase):
+class TestPubSubTopicCreateOperator(unittest.TestCase):
 
     @mock.patch('airflow.gcp.operators.pubsub.PubSubHook')
     def test_failifexists(self, mock_hook):
@@ -65,7 +65,7 @@ def test_succeedifexists(self, mock_hook):
             TEST_PROJECT, TEST_TOPIC, fail_if_exists=False)
 
 
-class PubSubTopicDeleteOperatorTest(unittest.TestCase):
+class TestPubSubTopicDeleteOperator(unittest.TestCase):
 
     @mock.patch('airflow.gcp.operators.pubsub.PubSubHook')
     def test_execute(self, mock_hook):
@@ -78,7 +78,7 @@ def test_execute(self, mock_hook):
             TEST_PROJECT, TEST_TOPIC, fail_if_not_exists=False)
 
 
-class PubSubSubscriptionCreateOperatorTest(unittest.TestCase):
+class TestPubSubSubscriptionCreateOperator(unittest.TestCase):
 
     @mock.patch('airflow.gcp.operators.pubsub.PubSubHook')
     def test_execute(self, mock_hook):
@@ -120,7 +120,7 @@ def test_execute_no_subscription(self, mock_hook):
         self.assertEqual(response, TEST_SUBSCRIPTION)
 
 
-class PubSubSubscriptionDeleteOperatorTest(unittest.TestCase):
+class TestPubSubSubscriptionDeleteOperator(unittest.TestCase):
 
     @mock.patch('airflow.gcp.operators.pubsub.PubSubHook')
     def test_execute(self, mock_hook):
@@ -133,7 +133,7 @@ def test_execute(self, mock_hook):
             TEST_PROJECT, TEST_SUBSCRIPTION, fail_if_not_exists=False)
 
 
-class PubSubPublishOperatorTest(unittest.TestCase):
+class TestPubSubPublishOperator(unittest.TestCase):
 
     @mock.patch('airflow.gcp.operators.pubsub.PubSubHook')
     def test_publish(self, mock_hook):
diff --git a/tests/gcp/operators/test_spanner.py b/tests/gcp/operators/test_spanner.py
index 7c64b7f4c89c2..364c1f460f4be 100644
--- a/tests/gcp/operators/test_spanner.py
+++ b/tests/gcp/operators/test_spanner.py
@@ -44,7 +44,7 @@
 DDL_STATEMENTS = [CREATE_QUERY, CREATE_QUERY_2]
 
 
-class CloudSpannerTest(unittest.TestCase):
+class TestCloudSpanner(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.spanner.CloudSpannerHook")
     def test_instance_create(self, mock_hook):
         mock_hook.return_value.get_instance.return_value = None
diff --git a/tests/gcp/operators/test_spanner_system.py b/tests/gcp/operators/test_spanner_system.py
index a353a3d8885de..d8a5d46a76b5f 100644
--- a/tests/gcp/operators/test_spanner_system.py
+++ b/tests/gcp/operators/test_spanner_system.py
@@ -20,13 +20,12 @@
 
 from tests.gcp.operators.test_spanner_system_helper import \
     GCPSpannerTestHelper
-from tests.contrib.utils.base_gcp_system_test_case import \
-    SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 from tests.contrib.utils.gcp_authenticator import GCP_SPANNER_KEY
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_SPANNER_KEY), SKIP_TEST_WARNING)
-class CloudSpannerExampleDagsTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_SPANNER_KEY), SKIP_TEST_WARNING)
+class CloudSpannerExampleDagsTest(TestDagGcpSystem):
     def __init__(self, method_name='runTest'):
         super().__init__(
             method_name,
diff --git a/tests/gcp/operators/test_speech_system.py b/tests/gcp/operators/test_speech_system.py
index 6f944ea2b548c..7f39157683b3d 100644
--- a/tests/gcp/operators/test_speech_system.py
+++ b/tests/gcp/operators/test_speech_system.py
@@ -19,14 +19,14 @@
 
 import unittest
 
-from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 from tests.contrib.utils.gcp_authenticator import GCP_GCS_KEY
 
 from tests.gcp.operators.test_speech_system_helper import GCPTextToSpeechTestHelper
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_GCS_KEY), SKIP_TEST_WARNING)
-class GCPTextToSpeechExampleDagSystemTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_GCS_KEY), SKIP_TEST_WARNING)
+class GCPTextToSpeechExampleDagSystemTest(TestDagGcpSystem):
     def setUp(self):
         super().setUp()
         self.gcp_authenticator.gcp_authenticate()
diff --git a/tests/gcp/operators/test_speech_to_text.py b/tests/gcp/operators/test_speech_to_text.py
index 6df7d9a119b25..3e196be723c33 100644
--- a/tests/gcp/operators/test_speech_to_text.py
+++ b/tests/gcp/operators/test_speech_to_text.py
@@ -29,7 +29,7 @@
 AUDIO = {"uri": "gs://bucket/object"}
 
 
-class CloudSqlTest(unittest.TestCase):
+class TestCloudSql(unittest.TestCase):
     @patch("airflow.gcp.operators.speech_to_text.GCPSpeechToTextHook")
     def test_recognize_speech_green_path(self, mock_hook):
         mock_hook.return_value.recognize_speech.return_value = True
diff --git a/tests/gcp/operators/test_tasks.py b/tests/gcp/operators/test_tasks.py
index d036099827171..b080ece921740 100644
--- a/tests/gcp/operators/test_tasks.py
+++ b/tests/gcp/operators/test_tasks.py
@@ -50,7 +50,7 @@
 )
 
 
-class CloudTasksQueueCreateTest(unittest.TestCase):
+class TestCloudTasksQueueCreate(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_create_queue(self, mock_hook):
         mock_hook.return_value.create_queue.return_value = {}
@@ -70,7 +70,7 @@ def test_create_queue(self, mock_hook):
         )
 
 
-class CloudTasksQueueUpdateTest(unittest.TestCase):
+class TestCloudTasksQueueUpdate(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_update_queue(self, mock_hook):
         mock_hook.return_value.update_queue.return_value = {}
@@ -91,7 +91,7 @@ def test_update_queue(self, mock_hook):
         )
 
 
-class CloudTasksQueueGetTest(unittest.TestCase):
+class TestCloudTasksQueueGet(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_get_queue(self, mock_hook):
         mock_hook.return_value.get_queue.return_value = {}
@@ -110,7 +110,7 @@ def test_get_queue(self, mock_hook):
         )
 
 
-class CloudTasksQueuesListTest(unittest.TestCase):
+class TestCloudTasksQueuesList(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_list_queues(self, mock_hook):
         mock_hook.return_value.list_queues.return_value = {}
@@ -128,7 +128,7 @@ def test_list_queues(self, mock_hook):
         )
 
 
-class CloudTasksQueueDeleteTest(unittest.TestCase):
+class TestCloudTasksQueueDelete(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_delete_queue(self, mock_hook):
         mock_hook.return_value.delete_queue.return_value = {}
@@ -147,7 +147,7 @@ def test_delete_queue(self, mock_hook):
         )
 
 
-class CloudTasksQueuePurgeTest(unittest.TestCase):
+class TestCloudTasksQueuePurge(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_delete_queue(self, mock_hook):
         mock_hook.return_value.purge_queue.return_value = {}
@@ -166,7 +166,7 @@ def test_delete_queue(self, mock_hook):
         )
 
 
-class CloudTasksQueuePauseTest(unittest.TestCase):
+class TestCloudTasksQueuePause(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_pause_queue(self, mock_hook):
         mock_hook.return_value.pause_queue.return_value = {}
@@ -185,7 +185,7 @@ def test_pause_queue(self, mock_hook):
         )
 
 
-class CloudTasksQueueResumeTest(unittest.TestCase):
+class TestCloudTasksQueueResume(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_resume_queue(self, mock_hook):
         mock_hook.return_value.resume_queue.return_value = {}
@@ -204,7 +204,7 @@ def test_resume_queue(self, mock_hook):
         )
 
 
-class CloudTasksTaskCreateTest(unittest.TestCase):
+class TestCloudTasksTaskCreate(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_create_task(self, mock_hook):
         mock_hook.return_value.create_task.return_value = {}
@@ -226,7 +226,7 @@ def test_create_task(self, mock_hook):
         )
 
 
-class CloudTasksTaskGetTest(unittest.TestCase):
+class TestCloudTasksTaskGet(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_get_task(self, mock_hook):
         mock_hook.return_value.get_task.return_value = {}
@@ -247,7 +247,7 @@ def test_get_task(self, mock_hook):
         )
 
 
-class CloudTasksTasksListTest(unittest.TestCase):
+class TestCloudTasksTasksList(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_list_tasks(self, mock_hook):
         mock_hook.return_value.list_tasks.return_value = {}
@@ -268,7 +268,7 @@ def test_list_tasks(self, mock_hook):
         )
 
 
-class CloudTasksTaskDeleteTest(unittest.TestCase):
+class TestCloudTasksTaskDelete(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_delete_task(self, mock_hook):
         mock_hook.return_value.delete_task.return_value = {}
@@ -288,7 +288,7 @@ def test_delete_task(self, mock_hook):
         )
 
 
-class CloudTasksTaskRunTest(unittest.TestCase):
+class TestCloudTasksTaskRun(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.tasks.CloudTasksHook")
     def test_run_task(self, mock_hook):
         mock_hook.return_value.run_task.return_value = {}
diff --git a/tests/gcp/operators/test_tasks_system.py b/tests/gcp/operators/test_tasks_system.py
index f07c5a3419262..04f4531c5a4eb 100644
--- a/tests/gcp/operators/test_tasks_system.py
+++ b/tests/gcp/operators/test_tasks_system.py
@@ -19,14 +19,12 @@
 
 import unittest
 
-from tests.contrib.utils.base_gcp_system_test_case import \
-    SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 from tests.contrib.utils.gcp_authenticator import GCP_TASKS_KEY
 
 
-@unittest.skipIf(
-    DagGcpSystemTestCase.skip_check(GCP_TASKS_KEY), SKIP_TEST_WARNING)
-class GcpTasksExampleDagsSystemTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_TASKS_KEY), SKIP_TEST_WARNING)
+class GcpTasksExampleDagsSystemTest(TestDagGcpSystem):
     def __init__(self, method_name='runTest'):
         super().__init__(
             method_name,
diff --git a/tests/gcp/operators/test_text_to_speech.py b/tests/gcp/operators/test_text_to_speech.py
index 0e8739e1d9727..070ad4816fa65 100644
--- a/tests/gcp/operators/test_text_to_speech.py
+++ b/tests/gcp/operators/test_text_to_speech.py
@@ -34,7 +34,7 @@
 TARGET_FILENAME = "target_filename"
 
 
-class GcpTextToSpeechTest(unittest.TestCase):
+class TestGcpTextToSpeech(unittest.TestCase):
     @patch("airflow.gcp.operators.text_to_speech.GoogleCloudStorageHook")
     @patch("airflow.gcp.operators.text_to_speech.GCPTextToSpeechHook")
     def test_synthesize_text_green_path(self, mock_text_to_speech_hook, mock_gcp_hook):
diff --git a/tests/gcp/operators/test_translate.py b/tests/gcp/operators/test_translate.py
index eea4ed63aedd9..989ee07ca4983 100644
--- a/tests/gcp/operators/test_translate.py
+++ b/tests/gcp/operators/test_translate.py
@@ -25,7 +25,7 @@
 GCP_CONN_ID = 'google_cloud_default'
 
 
-class CloudTranslateTest(unittest.TestCase):
+class TestCloudTranslate(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.translate.CloudTranslateHook')
     def test_minimal_green_path(self, mock_hook):
         mock_hook.return_value.translate.return_value = [
diff --git a/tests/gcp/operators/test_translate_speech.py b/tests/gcp/operators/test_translate_speech.py
index 2942936180830..3d08b0637adb4 100644
--- a/tests/gcp/operators/test_translate_speech.py
+++ b/tests/gcp/operators/test_translate_speech.py
@@ -28,7 +28,7 @@
 GCP_CONN_ID = 'google_cloud_default'
 
 
-class CloudTranslateSpeechTest(unittest.TestCase):
+class TestCloudTranslateSpeech(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.translate_speech.GCPSpeechToTextHook')
     @mock.patch('airflow.gcp.operators.translate_speech.CloudTranslateHook')
     def test_minimal_green_path(self, mock_translate_hook, mock_speech_hook):
diff --git a/tests/gcp/operators/test_translate_system.py b/tests/gcp/operators/test_translate_system.py
index 27a44397b87f7..dd88b339b3680 100644
--- a/tests/gcp/operators/test_translate_system.py
+++ b/tests/gcp/operators/test_translate_system.py
@@ -19,12 +19,12 @@
 
 import unittest
 
-from tests.contrib.utils.base_gcp_system_test_case import DagGcpSystemTestCase, SKIP_TEST_WARNING
+from tests.contrib.utils.base_gcp_system_test_case import TestDagGcpSystem, SKIP_TEST_WARNING
 from tests.contrib.utils.gcp_authenticator import GCP_AI_KEY
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_AI_KEY), SKIP_TEST_WARNING)
-class CloudTranslateExampleDagsSystemTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_AI_KEY), SKIP_TEST_WARNING)
+class CloudTranslateExampleDagsSystemTest(TestDagGcpSystem):
     def __init__(self, method_name='runTest'):
         super().__init__(
             method_name, dag_id='example_gcp_translate', gcp_key=GCP_AI_KEY
diff --git a/tests/gcp/operators/test_video_intelligence.py b/tests/gcp/operators/test_video_intelligence.py
index ab6994cc27b24..45bdd99ba12e8 100644
--- a/tests/gcp/operators/test_video_intelligence.py
+++ b/tests/gcp/operators/test_video_intelligence.py
@@ -36,7 +36,7 @@
 INPUT_URI = "gs://test-bucket//test-video.mp4"
 
 
-class CloudVideoIntelligenceOperatorsTestCase(unittest.TestCase):
+class TestCloudVideoIntelligenceOperators(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.video_intelligence.CloudVideoIntelligenceHook")
     def test_detect_video_labels_green_path(self, mock_hook):
 
diff --git a/tests/gcp/operators/test_video_intelligence_system.py b/tests/gcp/operators/test_video_intelligence_system.py
index af326e604205e..0a7c8edf1dd84 100644
--- a/tests/gcp/operators/test_video_intelligence_system.py
+++ b/tests/gcp/operators/test_video_intelligence_system.py
@@ -21,12 +21,12 @@
 from tests.gcp.operators.test_video_intelligence_system_helper import (
     GCPVideoIntelligenceHelper,
 )
-from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 from tests.contrib.utils.gcp_authenticator import GCP_AI_KEY
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_AI_KEY), SKIP_TEST_WARNING)
-class CloudVideoIntelligenceExampleDagsTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_AI_KEY), SKIP_TEST_WARNING)
+class CloudVideoIntelligenceExampleDagsTest(TestDagGcpSystem):
     def __init__(self, method_name="runTest"):
         super().__init__(
             method_name, dag_id="example_gcp_video_intelligence", gcp_key=GCP_AI_KEY
diff --git a/tests/gcp/operators/test_vision.py b/tests/gcp/operators/test_vision.py
index 68cf947ddb8af..d73de5c3ab0ba 100644
--- a/tests/gcp/operators/test_vision.py
+++ b/tests/gcp/operators/test_vision.py
@@ -59,7 +59,7 @@
 DETECT_TEST_IMAGE = {"source": {"image_uri": "test_uri"}}
 
 
-class CloudVisionProductSetCreateTest(unittest.TestCase):
+class TestCloudVisionProductSetCreate(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.vision.CloudVisionHook')
     def test_minimal_green_path(self, mock_hook):
         mock_hook.return_value.create_product_set.return_value = {}
@@ -95,7 +95,7 @@ def test_already_exists(self, create_product_set_mock, get_conn):
         self.assertEqual(PRODUCTSET_ID_TEST, result)
 
 
-class CloudVisionProductSetUpdateTest(unittest.TestCase):
+class TestCloudVisionProductSetUpdate(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.vision.CloudVisionHook')
     def test_minimal_green_path(self, mock_hook):
         mock_hook.return_value.update_product_set.return_value = {}
@@ -116,7 +116,7 @@ def test_minimal_green_path(self, mock_hook):
         )
 
 
-class CloudVisionProductSetGetTest(unittest.TestCase):
+class TestCloudVisionProductSetGet(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.vision.CloudVisionHook')
     def test_minimal_green_path(self, mock_hook):
         mock_hook.return_value.get_product_set.return_value = {}
@@ -135,7 +135,7 @@ def test_minimal_green_path(self, mock_hook):
         )
 
 
-class CloudVisionProductSetDeleteTest(unittest.TestCase):
+class TestCloudVisionProductSetDelete(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.vision.CloudVisionHook')
     def test_minimal_green_path(self, mock_hook):
         mock_hook.return_value.delete_product_set.return_value = {}
@@ -154,7 +154,7 @@ def test_minimal_green_path(self, mock_hook):
         )
 
 
-class CloudVisionProductCreateTest(unittest.TestCase):
+class TestCloudVisionProductCreate(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.vision.CloudVisionHook')
     def test_minimal_green_path(self, mock_hook):
         mock_hook.return_value.create_product.return_value = {}
@@ -188,7 +188,7 @@ def test_already_exists(self, create_product_mock, get_conn):
         self.assertEqual(PRODUCT_ID_TEST, result)
 
 
-class CloudVisionProductGetTest(unittest.TestCase):
+class TestCloudVisionProductGet(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.vision.CloudVisionHook')
     def test_minimal_green_path(self, mock_hook):
         mock_hook.return_value.get_product.return_value = {}
@@ -205,7 +205,7 @@ def test_minimal_green_path(self, mock_hook):
         )
 
 
-class CloudVisionProductUpdateTest(unittest.TestCase):
+class TestCloudVisionProductUpdate(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.vision.CloudVisionHook')
     def test_minimal_green_path(self, mock_hook):
         mock_hook.return_value.update_product.return_value = {}
@@ -224,7 +224,7 @@ def test_minimal_green_path(self, mock_hook):
         )
 
 
-class CloudVisionProductDeleteTest(unittest.TestCase):
+class TestCloudVisionProductDelete(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.vision.CloudVisionHook')
     def test_minimal_green_path(self, mock_hook):
         mock_hook.return_value.delete_product.return_value = {}
@@ -243,7 +243,7 @@ def test_minimal_green_path(self, mock_hook):
         )
 
 
-class CloudVisionReferenceImageCreateTest(unittest.TestCase):
+class TestCloudVisionReferenceImageCreate(unittest.TestCase):
     @mock.patch(  # type: ignore
         'airflow.gcp.operators.vision.CloudVisionHook',
         **{'return_value.create_reference_image.return_value': {}}
@@ -294,7 +294,7 @@ def test_already_exists(self, mock_hook):
         )
 
 
-class CloudVisionAddProductToProductSetOperatorTest(unittest.TestCase):
+class TestCloudVisionAddProductToProductSetOperator(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.vision.CloudVisionHook')
     def test_minimal_green_path(self, mock_hook):
         op = CloudVisionAddProductToProductSetOperator(
@@ -316,7 +316,7 @@ def test_minimal_green_path(self, mock_hook):
         )
 
 
-class CloudVisionRemoveProductFromProductSetOperatorTest(unittest.TestCase):
+class TestCloudVisionRemoveProductFromProductSetOperator(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.vision.CloudVisionHook')
     def test_minimal_green_path(self, mock_hook):
         op = CloudVisionRemoveProductFromProductSetOperator(
@@ -338,7 +338,7 @@ def test_minimal_green_path(self, mock_hook):
         )
 
 
-class CloudVisionAnnotateImageOperatorTest(unittest.TestCase):
+class TestCloudVisionAnnotateImageOperator(unittest.TestCase):
     @mock.patch('airflow.gcp.operators.vision.CloudVisionHook')
     def test_minimal_green_path_for_one_image(self, mock_hook):
         op = CloudVisionAnnotateImageOperator(request=ANNOTATE_REQUEST_TEST, task_id='id')
@@ -358,7 +358,7 @@ def test_minimal_green_path_for_batch(self, mock_hook):
         )
 
 
-class CloudVisionDetectTextOperatorTest(unittest.TestCase):
+class TestCloudVisionDetectTextOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.vision.CloudVisionHook")
     def test_minimal_green_path(self, mock_hook):
         op = CloudVisionDetectTextOperator(image=DETECT_TEST_IMAGE, task_id="id")
@@ -402,7 +402,7 @@ def test_additional_params(self, mock_hook):
         )
 
 
-class CloudVisionDetectDocumentTextOperatorTest(unittest.TestCase):
+class TestCloudVisionDetectDocumentTextOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.vision.CloudVisionHook")
     def test_minimal_green_path(self, mock_hook):
         op = CloudVisionDetectDocumentTextOperator(image=DETECT_TEST_IMAGE, task_id="id")
@@ -413,7 +413,7 @@ def test_minimal_green_path(self, mock_hook):
         )
 
 
-class CloudVisionDetectImageLabelsOperatorTest(unittest.TestCase):
+class TestCloudVisionDetectImageLabelsOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.vision.CloudVisionHook")
     def test_minimal_green_path(self, mock_hook):
         op = CloudVisionDetectImageLabelsOperator(image=DETECT_TEST_IMAGE, task_id="id")
@@ -424,7 +424,7 @@ def test_minimal_green_path(self, mock_hook):
         )
 
 
-class CloudVisionDetectImageSafeSearchOperatorTest(unittest.TestCase):
+class TestCloudVisionDetectImageSafeSearchOperator(unittest.TestCase):
     @mock.patch("airflow.gcp.operators.vision.CloudVisionHook")
     def test_minimal_green_path(self, mock_hook):
         op = CloudVisionDetectImageSafeSearchOperator(image=DETECT_TEST_IMAGE, task_id="id")
diff --git a/tests/gcp/operators/test_vision_system.py b/tests/gcp/operators/test_vision_system.py
index 9e759ec42c939..444f33a8ebc25 100644
--- a/tests/gcp/operators/test_vision_system.py
+++ b/tests/gcp/operators/test_vision_system.py
@@ -21,13 +21,13 @@
 
 from tests.contrib.utils.gcp_authenticator import GCP_AI_KEY
 from tests.gcp.operators.test_vision_system_helper import GCPVisionTestHelper
-from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, DagGcpSystemTestCase
+from tests.contrib.utils.base_gcp_system_test_case import SKIP_TEST_WARNING, TestDagGcpSystem
 
 VISION_HELPER = GCPVisionTestHelper()
 
 
-@unittest.skipIf(DagGcpSystemTestCase.skip_check(GCP_AI_KEY), SKIP_TEST_WARNING)
-class CloudVisionExampleDagsSystemTest(DagGcpSystemTestCase):
+@unittest.skipIf(TestDagGcpSystem.skip_check(GCP_AI_KEY), SKIP_TEST_WARNING)
+class CloudVisionExampleDagsSystemTest(TestDagGcpSystem):
     def __init__(self, method_name='runTest'):
         super().__init__(
             method_name, dag_name='example_vision.py', gcp_key=GCP_AI_KEY
diff --git a/tests/gcp/sensors/test_pubsub.py b/tests/gcp/sensors/test_pubsub.py
index 5ad5745a73a29..17a4aa3704147 100644
--- a/tests/gcp/sensors/test_pubsub.py
+++ b/tests/gcp/sensors/test_pubsub.py
@@ -38,7 +38,7 @@
     {'attributes': {'foo': ''}}]
 
 
-class PubSubPullSensorTest(unittest.TestCase):
+class TestPubSubPullSensor(unittest.TestCase):
 
     def _generate_messages(self, count):
         messages = []
diff --git a/tests/hooks/test_docker_hook.py b/tests/hooks/test_docker_hook.py
index 1dd5b60d99095..992a1eced27a3 100644
--- a/tests/hooks/test_docker_hook.py
+++ b/tests/hooks/test_docker_hook.py
@@ -31,7 +31,7 @@
 
 
 @mock.patch('airflow.hooks.docker_hook.APIClient', autospec=True)
-class DockerHookTest(unittest.TestCase):
+class TestDockerHook(unittest.TestCase):
     def setUp(self):
         db.merge_conn(
             Connection(
diff --git a/tests/hooks/test_hive_hook.py b/tests/hooks/test_hive_hook.py
index c518617bf1046..83593706249f3 100644
--- a/tests/hooks/test_hive_hook.py
+++ b/tests/hooks/test_hive_hook.py
@@ -43,7 +43,7 @@
 DEFAULT_DATE_DS = DEFAULT_DATE_ISO[:10]
 
 
-class HiveEnvironmentTest(unittest.TestCase):
+class TestHiveEnvironment(unittest.TestCase):
 
     def setUp(self):
         args = {'owner': 'airflow', 'start_date': DEFAULT_DATE}
@@ -222,7 +222,7 @@ def test_load_df_with_data_types(self, mock_run_cli):
         assertEqualIgnoreMultipleSpaces(self, mock_run_cli.call_args_list[0][0][0], query)
 
 
-class TestHiveMetastoreHook(HiveEnvironmentTest):
+class TestHiveMetastoreHook(TestHiveEnvironment):
     VALID_FILTER_MAP = {'key2': 'value2'}
 
     def test_get_max_partition_from_empty_part_specs(self):
diff --git a/tests/hooks/test_slack_hook.py b/tests/hooks/test_slack_hook.py
index d15c5f251258a..46405a8cccd19 100644
--- a/tests/hooks/test_slack_hook.py
+++ b/tests/hooks/test_slack_hook.py
@@ -23,7 +23,7 @@
 from tests.compat import mock
 
 
-class SlackHookTestCase(unittest.TestCase):
+class TestSlackHook(unittest.TestCase):
     def test_init_with_token_only(self):
         test_token = 'test_token'
         slack_hook = SlackHook(token=test_token, slack_conn_id=None)
diff --git a/tests/jobs/test_backfill_job.py b/tests/jobs/test_backfill_job.py
index 40ab78e1fca5a..606af90bc0e6e 100644
--- a/tests/jobs/test_backfill_job.py
+++ b/tests/jobs/test_backfill_job.py
@@ -49,7 +49,7 @@
 DEFAULT_DATE = timezone.datetime(2016, 1, 1)
 
 
-class BackfillJobTest(unittest.TestCase):
+class TestBackfillJob(unittest.TestCase):
 
     def _get_dummy_dag(self, dag_id, pool=Pool.DEFAULT_POOL_NAME, task_concurrency=None):
         dag = DAG(
diff --git a/tests/jobs/test_base_job.py b/tests/jobs/test_base_job.py
index f7b94df0fce43..be2cc63b5761c 100644
--- a/tests/jobs/test_base_job.py
+++ b/tests/jobs/test_base_job.py
@@ -27,7 +27,7 @@
 from airflow.utils.db import create_session
 
 
-class BaseJobTest(unittest.TestCase):
+class TestBaseJob(unittest.TestCase):
     class TestJob(BaseJob):
         __mapper_args__ = {
             'polymorphic_identity': 'TestJob'
diff --git a/tests/jobs/test_local_task_job.py b/tests/jobs/test_local_task_job.py
index 6f96199666293..284b43d43efd8 100644
--- a/tests/jobs/test_local_task_job.py
+++ b/tests/jobs/test_local_task_job.py
@@ -40,7 +40,7 @@
 DEFAULT_DATE = timezone.datetime(2016, 1, 1)
 
 
-class LocalTaskJobTest(unittest.TestCase):
+class TestLocalTaskJob(unittest.TestCase):
     def setUp(self):
         clear_db_runs()
 
diff --git a/tests/jobs/test_scheduler_job.py b/tests/jobs/test_scheduler_job.py
index d896a563d410c..ce9d095cb0735 100644
--- a/tests/jobs/test_scheduler_job.py
+++ b/tests/jobs/test_scheduler_job.py
@@ -63,7 +63,7 @@
 TEMP_DAG_FILENAME = "temp_dag.py"
 
 
-class SchedulerJobTest(unittest.TestCase):
+class TestSchedulerJob(unittest.TestCase):
 
     def setUp(self):
         clear_db_runs()
diff --git a/tests/macros/test_hive.py b/tests/macros/test_hive.py
index c3c4506b0bc61..eb8dc1fc32073 100644
--- a/tests/macros/test_hive.py
+++ b/tests/macros/test_hive.py
@@ -23,7 +23,7 @@
 from airflow.macros import hive
 
 
-class Hive(unittest.TestCase):
+class TestHive(unittest.TestCase):
     def test_closest_ds_partition(self):
         d1 = datetime.strptime('2017-04-24', '%Y-%m-%d')
         d2 = datetime.strptime('2017-04-25', '%Y-%m-%d')
diff --git a/tests/minikube/test_kubernetes_executor.py b/tests/minikube/test_kubernetes_executor.py
index b70b40e78c831..96e2284325466 100644
--- a/tests/minikube/test_kubernetes_executor.py
+++ b/tests/minikube/test_kubernetes_executor.py
@@ -49,7 +49,7 @@ def get_minikube_host():
     return host
 
 
-class KubernetesExecutorTest(unittest.TestCase):
+class TestKubernetesExecutor(unittest.TestCase):
     @staticmethod
     def _delete_airflow_pod():
         air_pod = check_output(['kubectl', 'get', 'pods']).decode()
diff --git a/tests/minikube/test_kubernetes_pod_operator.py b/tests/minikube/test_kubernetes_pod_operator.py
index a17750196da84..1e947e866b691 100644
--- a/tests/minikube/test_kubernetes_pod_operator.py
+++ b/tests/minikube/test_kubernetes_pod_operator.py
@@ -42,7 +42,7 @@
         )
 
 
-class KubernetesPodOperatorTest(unittest.TestCase):
+class TestKubernetesPodOperator(unittest.TestCase):
 
     @staticmethod
     def test_config_path_move():
diff --git a/tests/models/test_baseoperator.py b/tests/models/test_baseoperator.py
index 148343e9ff27e..a2d7eb1a5e3eb 100644
--- a/tests/models/test_baseoperator.py
+++ b/tests/models/test_baseoperator.py
@@ -51,7 +51,7 @@ def execute(self, context):
 TestNamedTuple = namedtuple("TestNamedTuple", ["var1", "var2"])
 
 
-class BaseOperatorTest(unittest.TestCase):
+class TestBaseOperator(unittest.TestCase):
     @parameterized.expand(
         [
             ("{{ foo }}", {"foo": "bar"}, "bar"),
diff --git a/tests/models/test_cleartasks.py b/tests/models/test_cleartasks.py
index 15e8a4e4faf00..d3f7912b31e9b 100644
--- a/tests/models/test_cleartasks.py
+++ b/tests/models/test_cleartasks.py
@@ -29,7 +29,7 @@
 from tests.models import DEFAULT_DATE
 
 
-class ClearTasksTest(unittest.TestCase):
+class TestClearTasks(unittest.TestCase):
 
     def test_clear_task_instances(self):
         dag = DAG('test_clear_task_instances', start_date=DEFAULT_DATE,
diff --git a/tests/models/test_connection.py b/tests/models/test_connection.py
index 55442a22a9847..e1111134beec4 100644
--- a/tests/models/test_connection.py
+++ b/tests/models/test_connection.py
@@ -29,7 +29,7 @@
 ConnectionParts = namedtuple("ConnectionParts", ["conn_type", "login", "password", "host", "port", "schema"])
 
 
-class ConnectionTest(unittest.TestCase):
+class TestConnection(unittest.TestCase):
     def setUp(self):
         crypto._fernet = None
 
diff --git a/tests/models/test_dag.py b/tests/models/test_dag.py
index 8e5acadad7740..f2c6ad34b4456 100644
--- a/tests/models/test_dag.py
+++ b/tests/models/test_dag.py
@@ -40,7 +40,7 @@
 from tests.models import DEFAULT_DATE
 
 
-class DagTest(unittest.TestCase):
+class TestDag(unittest.TestCase):
 
     def _occur_before(self, a, b, list_):
         """
diff --git a/tests/models/test_dagbag.py b/tests/models/test_dagbag.py
index 3994cc999aa77..4fc7ca0e3c56c 100644
--- a/tests/models/test_dagbag.py
+++ b/tests/models/test_dagbag.py
@@ -36,7 +36,7 @@
 import airflow.example_dags
 
 
-class DagBagTest(unittest.TestCase):
+class TestDagBag(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
         cls.empty_dir = mkdtemp()
diff --git a/tests/models/test_dagrun.py b/tests/models/test_dagrun.py
index c90563d75b460..8fd35ead053f6 100644
--- a/tests/models/test_dagrun.py
+++ b/tests/models/test_dagrun.py
@@ -32,7 +32,7 @@
 from tests.models import DEFAULT_DATE
 
 
-class DagRunTest(unittest.TestCase):
+class TestDagRun(unittest.TestCase):
 
     def create_dag_run(self, dag,
                        state=State.RUNNING,
diff --git a/tests/models/test_pool.py b/tests/models/test_pool.py
index cfd494f50f84d..8559e2374fa4d 100644
--- a/tests/models/test_pool.py
+++ b/tests/models/test_pool.py
@@ -31,7 +31,7 @@
 DEFAULT_DATE = timezone.datetime(2016, 1, 1)
 
 
-class PoolTest(unittest.TestCase):
+class TestPool(unittest.TestCase):
 
     def setUp(self):
         clear_db_runs()
diff --git a/tests/models/test_taskinstance.py b/tests/models/test_taskinstance.py
index a205c31476ff4..63234ad6cdeae 100644
--- a/tests/models/test_taskinstance.py
+++ b/tests/models/test_taskinstance.py
@@ -45,7 +45,7 @@
 from tests.test_utils import db
 
 
-class TaskInstanceTest(unittest.TestCase):
+class TestTaskInstance(unittest.TestCase):
 
     def setUp(self):
         db.clear_db_pools()
diff --git a/tests/models/test_variable.py b/tests/models/test_variable.py
index a97351a5d5225..b1250b50e5f34 100644
--- a/tests/models/test_variable.py
+++ b/tests/models/test_variable.py
@@ -26,7 +26,7 @@
 from tests.test_utils.config import conf_vars
 
 
-class VariableTest(unittest.TestCase):
+class TestVariable(unittest.TestCase):
     def setUp(self):
         crypto._fernet = None
 
diff --git a/tests/operators/test_bash_operator.py b/tests/operators/test_bash_operator.py
index 80cbe90a71033..de79e2f3452b3 100644
--- a/tests/operators/test_bash_operator.py
+++ b/tests/operators/test_bash_operator.py
@@ -33,7 +33,7 @@
 INTERVAL = timedelta(hours=12)
 
 
-class BashOperatorTest(unittest.TestCase):
+class TestBashOperator(unittest.TestCase):
 
     def test_echo_env_variables(self):
         """
diff --git a/tests/operators/test_branch_operator.py b/tests/operators/test_branch_operator.py
index 05e2c8bdb11cb..864b0a6abe507 100644
--- a/tests/operators/test_branch_operator.py
+++ b/tests/operators/test_branch_operator.py
@@ -41,7 +41,7 @@ def choose_branch(self, context):
         return ['branch_1', 'branch_2']
 
 
-class BranchOperatorTest(unittest.TestCase):
+class TestBranchOperator(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
         super().setUpClass()
diff --git a/tests/operators/test_check_operator.py b/tests/operators/test_check_operator.py
index f49b1c8153258..92606bb2e7be6 100644
--- a/tests/operators/test_check_operator.py
+++ b/tests/operators/test_check_operator.py
@@ -102,7 +102,7 @@ def test_execute_fail(self, mock_get_db_hook):
             operator.execute()
 
 
-class IntervalCheckOperatorTest(unittest.TestCase):
+class TestIntervalCheckOperator(unittest.TestCase):
 
     def _construct_operator(self, table, metric_thresholds,
                             ratio_formula, ignore_zero):
diff --git a/tests/operators/test_docker_operator.py b/tests/operators/test_docker_operator.py
index 35315c26b8d16..e7016fbef0cae 100644
--- a/tests/operators/test_docker_operator.py
+++ b/tests/operators/test_docker_operator.py
@@ -31,7 +31,7 @@
 from tests.compat import mock
 
 
-class DockerOperatorTestCase(unittest.TestCase):
+class TestDockerOperator(unittest.TestCase):
     @mock.patch('airflow.utils.file.mkdtemp')
     @mock.patch('airflow.operators.docker_operator.APIClient')
     def test_execute(self, client_class_mock, mkdtemp_mock):
diff --git a/tests/operators/test_docker_swarm_operator.py b/tests/operators/test_docker_swarm_operator.py
index b59c664bfde95..d6e6666a37117 100644
--- a/tests/operators/test_docker_swarm_operator.py
+++ b/tests/operators/test_docker_swarm_operator.py
@@ -26,7 +26,7 @@
 from airflow.exceptions import AirflowException
 
 
-class DockerSwarmOperatorTestCase(unittest.TestCase):
+class TestDockerSwarmOperator(unittest.TestCase):
 
     @mock.patch('airflow.operators.docker_operator.APIClient')
     @mock.patch('airflow.contrib.operators.docker_swarm_operator.types')
diff --git a/tests/operators/test_druid_check_operator.py b/tests/operators/test_druid_check_operator.py
index c18b56d97115e..6e7979f15d612 100644
--- a/tests/operators/test_druid_check_operator.py
+++ b/tests/operators/test_druid_check_operator.py
@@ -27,7 +27,7 @@
 from tests.compat import mock
 
 
-class DruidCheckOperatorTest(unittest.TestCase):
+class TestDruidCheckOperator(unittest.TestCase):
 
     def setUp(self):
         self.task_id = 'test_task'
diff --git a/tests/operators/test_hive_operator.py b/tests/operators/test_hive_operator.py
index 344cb60a872a7..7cdd5ff32b1c2 100644
--- a/tests/operators/test_hive_operator.py
+++ b/tests/operators/test_hive_operator.py
@@ -35,7 +35,7 @@
 DEFAULT_DATE_DS = DEFAULT_DATE_ISO[:10]
 
 
-class HiveEnvironmentTest(unittest.TestCase):
+class TestHiveEnvironment(unittest.TestCase):
 
     def setUp(self):
         args = {'owner': 'airflow', 'start_date': DEFAULT_DATE}
@@ -57,7 +57,7 @@ def setUp(self):
         """
 
 
-class HiveCliTest(unittest.TestCase):
+class TestHiveCli(unittest.TestCase):
 
     def setUp(self):
         self.nondefault_schema = "nondefault"
@@ -82,7 +82,7 @@ def test_get_proxy_user_value(self):
         self.assertIn('hive.server2.proxy.user=a_user_proxy', result[2])
 
 
-class HiveOperatorConfigTest(HiveEnvironmentTest):
+class HiveOperatorConfigTest(TestHiveEnvironment):
 
     def test_hive_airflow_default_config_queue(self):
         t = HiveOperator(
@@ -112,7 +112,7 @@ def test_hive_airflow_default_config_queue_override(self):
         self.assertEqual(t.get_hook().mapred_queue, specific_mapred_queue)
 
 
-class HiveOperatorTest(HiveEnvironmentTest):
+class HiveOperatorTest(TestHiveEnvironment):
 
     def test_hiveconf_jinja_translate(self):
         hql = "SELECT ${num_col} FROM ${hiveconf:table};"
@@ -159,7 +159,7 @@ def test_mapred_job_name(self, mock_get_hook):
     import airflow.hooks.hive_hooks
     import airflow.operators.presto_to_mysql
 
-    class HivePrestoTest(HiveEnvironmentTest):
+    class TestHivePresto(TestHiveEnvironment):
 
         def test_hive(self):
             t = HiveOperator(
diff --git a/tests/operators/test_http_operator.py b/tests/operators/test_http_operator.py
index 3656347896b0c..233d4f389d087 100644
--- a/tests/operators/test_http_operator.py
+++ b/tests/operators/test_http_operator.py
@@ -26,7 +26,7 @@
 from tests.compat import mock
 
 
-class SimpleHttpOpTests(unittest.TestCase):
+class TestSimpleHttpOp(unittest.TestCase):
     def setUp(self):
         os.environ['AIRFLOW_CONN_HTTP_EXAMPLE'] = 'http://www.example.com'
 
diff --git a/tests/operators/test_latest_only_operator.py b/tests/operators/test_latest_only_operator.py
index 8ae8b108b12da..94d36a29db866 100644
--- a/tests/operators/test_latest_only_operator.py
+++ b/tests/operators/test_latest_only_operator.py
@@ -44,7 +44,7 @@ def get_task_instances(task_id):
         .all()
 
 
-class LatestOnlyOperatorTest(unittest.TestCase):
+class TestLatestOnlyOperator(unittest.TestCase):
 
     def setUp(self):
         super().setUp()
diff --git a/tests/operators/test_operators.py b/tests/operators/test_operators.py
index af8addf6efd91..7e54bb30fb3ab 100644
--- a/tests/operators/test_operators.py
+++ b/tests/operators/test_operators.py
@@ -32,7 +32,7 @@
 TEST_DAG_ID = 'unit_test_dag'
 
 
-class MySqlTest(unittest.TestCase):
+class TestMySql(unittest.TestCase):
     def setUp(self):
         args = {
             'owner': 'airflow',
@@ -180,7 +180,7 @@ def test_overwrite_schema(self):
             assert "Unknown database 'foobar'" in str(e)
 
 
-class PostgresTest(unittest.TestCase):
+class TestPostgres(unittest.TestCase):
     def setUp(self):
         args = {'owner': 'airflow', 'start_date': DEFAULT_DATE}
         dag = DAG(TEST_DAG_ID, default_args=args)
@@ -289,7 +289,7 @@ def test_overwrite_schema(self):
             assert 'database "foobar" does not exist' in str(e)
 
 
-class TransferTests(unittest.TestCase):
+class TestTransfer(unittest.TestCase):
     def setUp(self):
         args = {'owner': 'airflow', 'start_date': DEFAULT_DATE}
         dag = DAG(TEST_DAG_ID, default_args=args)
diff --git a/tests/operators/test_python_operator.py b/tests/operators/test_python_operator.py
index e5e8049aa1340..3dd8b323fc40d 100644
--- a/tests/operators/test_python_operator.py
+++ b/tests/operators/test_python_operator.py
@@ -62,7 +62,7 @@ def recording_function(*args, **kwargs):
     return recording_function
 
 
-class PythonOperatorTest(unittest.TestCase):
+class TestPythonOperator(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
         super().setUpClass()
@@ -252,7 +252,7 @@ def test_echo_env_variables(self):
         t.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE)
 
 
-class BranchOperatorTest(unittest.TestCase):
+class TestBranchOperator(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
         super().setUpClass()
@@ -426,7 +426,7 @@ def test_with_skip_in_branch_downstream_dependencies2(self):
                 raise Exception
 
 
-class ShortCircuitOperatorTest(unittest.TestCase):
+class TestShortCircuitOperator(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
         super().setUpClass()
diff --git a/tests/operators/test_s3_to_hive_operator.py b/tests/operators/test_s3_to_hive_operator.py
index 5220d6083cdde..ac36ea2a546c8 100644
--- a/tests/operators/test_s3_to_hive_operator.py
+++ b/tests/operators/test_s3_to_hive_operator.py
@@ -39,7 +39,7 @@
     mock_s3 = None
 
 
-class S3ToHiveTransferTest(unittest.TestCase):
+class TestS3ToHiveTransfer(unittest.TestCase):
 
     def setUp(self):
         self.fn = {}
diff --git a/tests/operators/test_slack_operator.py b/tests/operators/test_slack_operator.py
index 08434f9622e72..69789811113e7 100644
--- a/tests/operators/test_slack_operator.py
+++ b/tests/operators/test_slack_operator.py
@@ -24,7 +24,7 @@
 from tests.compat import mock
 
 
-class SlackAPIPostOperatorTestCase(unittest.TestCase):
+class TestSlackAPIPostOperator(unittest.TestCase):
     def setUp(self):
         self.test_username = 'test_username'
         self.test_channel = '#test_slack_channel'
diff --git a/tests/operators/test_subdag_operator.py b/tests/operators/test_subdag_operator.py
index e990ad0b65cd7..af50190b2b80e 100644
--- a/tests/operators/test_subdag_operator.py
+++ b/tests/operators/test_subdag_operator.py
@@ -39,7 +39,7 @@
 )
 
 
-class SubDagOperatorTests(unittest.TestCase):
+class TestSubDagOperator(unittest.TestCase):
 
     def setUp(self):
         clear_db_runs()
diff --git a/tests/plugins/test_plugins_manager.py b/tests/plugins/test_plugins_manager.py
index 8f2bd630650da..b6830842c91b2 100644
--- a/tests/plugins/test_plugins_manager.py
+++ b/tests/plugins/test_plugins_manager.py
@@ -23,7 +23,7 @@
 from airflow.www import app as application
 
 
-class PluginsTestRBAC(unittest.TestCase):
+class TestPluginsRBAC(unittest.TestCase):
     def setUp(self):
         self.app, self.appbuilder = application.create_app(testing=True)
 
diff --git a/tests/security/test_kerberos.py b/tests/security/test_kerberos.py
index ee3541f264691..bf15104bd190a 100644
--- a/tests/security/test_kerberos.py
+++ b/tests/security/test_kerberos.py
@@ -29,7 +29,7 @@
 
 @unittest.skipIf('KRB5_KTNAME' not in os.environ,
                  'Skipping Kerberos API tests due to missing KRB5_KTNAME')
-class KerberosTest(unittest.TestCase):
+class TestKerberos(unittest.TestCase):
     def setUp(self):
         if not configuration.conf.has_section("kerberos"):
             configuration.conf.add_section("kerberos")
diff --git a/tests/sensors/test_base_sensor.py b/tests/sensors/test_base_sensor.py
index 383d5da0023ca..7be6e786e3c2e 100644
--- a/tests/sensors/test_base_sensor.py
+++ b/tests/sensors/test_base_sensor.py
@@ -49,7 +49,7 @@ def poke(self, context):
         return self.return_value
 
 
-class BaseSensorTest(unittest.TestCase):
+class TestBaseSensor(unittest.TestCase):
     def setUp(self):
         args = {
             'owner': 'airflow',
diff --git a/tests/sensors/test_external_task_sensor.py b/tests/sensors/test_external_task_sensor.py
index 649f6bf629f40..f479627b5aadf 100644
--- a/tests/sensors/test_external_task_sensor.py
+++ b/tests/sensors/test_external_task_sensor.py
@@ -36,7 +36,7 @@
 DEV_NULL = '/dev/null'
 
 
-class ExternalTaskSensorTests(unittest.TestCase):
+class TestExternalTaskSensor(unittest.TestCase):
 
     def setUp(self):
         self.dagbag = DagBag(
diff --git a/tests/sensors/test_hdfs_sensor.py b/tests/sensors/test_hdfs_sensor.py
index a827e04680f5a..3ad1ed1f31564 100644
--- a/tests/sensors/test_hdfs_sensor.py
+++ b/tests/sensors/test_hdfs_sensor.py
@@ -29,7 +29,7 @@
 TEST_DAG_ID = 'unit_test_dag'
 
 
-class HdfsSensorTests(unittest.TestCase):
+class TestHdfsSensor(unittest.TestCase):
 
     def setUp(self):
         self.hook = FakeHDFSHook
diff --git a/tests/sensors/test_http_sensor.py b/tests/sensors/test_http_sensor.py
index be098db8c0b41..fe2c570eeea61 100644
--- a/tests/sensors/test_http_sensor.py
+++ b/tests/sensors/test_http_sensor.py
@@ -34,7 +34,7 @@
 TEST_DAG_ID = 'unit_test_dag'
 
 
-class HttpSensorTests(unittest.TestCase):
+class TestHttpSensor(unittest.TestCase):
     def setUp(self):
         args = {
             'owner': 'airflow',
@@ -175,7 +175,7 @@ def prepare_request(self, request):
         return self.response
 
 
-class HttpOpSensorTest(unittest.TestCase):
+class TestHttpOpSensor(unittest.TestCase):
     def setUp(self):
         args = {'owner': 'airflow', 'start_date': DEFAULT_DATE_ISO}
         dag = DAG(TEST_DAG_ID, default_args=args)
diff --git a/tests/sensors/test_named_hive_partition_sensor.py b/tests/sensors/test_named_hive_partition_sensor.py
index d007e8085bd8f..045fa95622414 100644
--- a/tests/sensors/test_named_hive_partition_sensor.py
+++ b/tests/sensors/test_named_hive_partition_sensor.py
@@ -30,7 +30,7 @@
 DEFAULT_DATE_DS = DEFAULT_DATE_ISO[:10]
 
 
-class NamedHivePartitionSensorTests(unittest.TestCase):
+class TestNamedHivePartitionSensor(unittest.TestCase):
     def setUp(self):
         args = {'owner': 'airflow', 'start_date': DEFAULT_DATE}
         self.dag = DAG('test_dag_id', default_args=args)
diff --git a/tests/sensors/test_s3_key_sensor.py b/tests/sensors/test_s3_key_sensor.py
index 320fff3a1f564..b849be71fbf99 100644
--- a/tests/sensors/test_s3_key_sensor.py
+++ b/tests/sensors/test_s3_key_sensor.py
@@ -25,7 +25,7 @@
 from airflow.sensors.s3_key_sensor import S3KeySensor
 
 
-class S3KeySensorTests(unittest.TestCase):
+class TestS3KeySensor(unittest.TestCase):
 
     def test_bucket_name_None_and_bucket_key_as_relative_path(self):
         """
diff --git a/tests/sensors/test_s3_prefix_sensor.py b/tests/sensors/test_s3_prefix_sensor.py
index e5a6614d84787..e6f7a790f869f 100644
--- a/tests/sensors/test_s3_prefix_sensor.py
+++ b/tests/sensors/test_s3_prefix_sensor.py
@@ -23,7 +23,7 @@
 from airflow.sensors.s3_prefix_sensor import S3PrefixSensor
 
 
-class S3PrefixSensorTests(unittest.TestCase):
+class TestS3PrefixSensor(unittest.TestCase):
 
     @mock.patch('airflow.hooks.S3_hook.S3Hook')
     def test_poke(self, mock_hook):
diff --git a/tests/sensors/test_sql_sensor.py b/tests/sensors/test_sql_sensor.py
index ebc3d67c6278b..2b607f3bb31a2 100644
--- a/tests/sensors/test_sql_sensor.py
+++ b/tests/sensors/test_sql_sensor.py
@@ -29,7 +29,7 @@
 TEST_DAG_ID = 'unit_test_sql_dag'
 
 
-class SqlSensorTests(unittest.TestCase):
+class TestSqlSensor(unittest.TestCase):
 
     def setUp(self):
         args = {
diff --git a/tests/sensors/test_timedelta_sensor.py b/tests/sensors/test_timedelta_sensor.py
index f4d7ceb157350..1ce1aed720ba4 100644
--- a/tests/sensors/test_timedelta_sensor.py
+++ b/tests/sensors/test_timedelta_sensor.py
@@ -29,7 +29,7 @@
 TEST_DAG_ID = 'unit_tests'
 
 
-class TimedeltaSensorTest(unittest.TestCase):
+class TestTimedeltaSensor(unittest.TestCase):
     def setUp(self):
         self.dagbag = models.DagBag(
             dag_folder=DEV_NULL, include_examples=True)
diff --git a/tests/sensors/test_timeout_sensor.py b/tests/sensors/test_timeout_sensor.py
index f08534cce753d..438b9329a5f27 100644
--- a/tests/sensors/test_timeout_sensor.py
+++ b/tests/sensors/test_timeout_sensor.py
@@ -66,7 +66,7 @@ def execute(self, context):
         self.log.info("Success criteria met. Exiting.")
 
 
-class SensorTimeoutTest(unittest.TestCase):
+class TestSensorTimeout(unittest.TestCase):
     def setUp(self):
         args = {
             'owner': 'airflow',
diff --git a/tests/test_configuration.py b/tests/test_configuration.py
index 4183ad0d41284..2b5b2d79db8d7 100644
--- a/tests/test_configuration.py
+++ b/tests/test_configuration.py
@@ -45,7 +45,7 @@ def env_vars(**vars):
             os.environ.pop(key, None)
 
 
-class ConfTest(unittest.TestCase):
+class TestConf(unittest.TestCase):
 
     @classmethod
     def setUpClass(cls):
diff --git a/tests/test_impersonation.py b/tests/test_impersonation.py
index 8aa4a636f778e..31c84096f4567 100644
--- a/tests/test_impersonation.py
+++ b/tests/test_impersonation.py
@@ -38,7 +38,7 @@
 logger = logging.getLogger(__name__)
 
 
-class ImpersonationTest(unittest.TestCase):
+class TestImpersonation(unittest.TestCase):
 
     @staticmethod
     def grant_permissions():
diff --git a/tests/test_local_settings.py b/tests/test_local_settings.py
index 6229bdabefdc1..8ab9155b928eb 100644
--- a/tests/test_local_settings.py
+++ b/tests/test_local_settings.py
@@ -64,7 +64,7 @@ def __exit__(self, *exc_info):
         sys.path.remove(self.settings_root)
 
 
-class LocalSettingsTest(unittest.TestCase):
+class TestLocalSettings(unittest.TestCase):
     # Make sure that the configure_logging is not cached
     def setUp(self):
         self.old_modules = dict(sys.modules)
diff --git a/tests/ti_deps/deps/test_dag_ti_slots_available_dep.py b/tests/ti_deps/deps/test_dag_ti_slots_available_dep.py
index df3831aeb0c5e..0c03baa603430 100644
--- a/tests/ti_deps/deps/test_dag_ti_slots_available_dep.py
+++ b/tests/ti_deps/deps/test_dag_ti_slots_available_dep.py
@@ -24,7 +24,7 @@
 from airflow.ti_deps.deps.dag_ti_slots_available_dep import DagTISlotsAvailableDep
 
 
-class DagTISlotsAvailableDepTest(unittest.TestCase):
+class TestDagTISlotsAvailableDep(unittest.TestCase):
 
     def test_concurrency_reached(self):
         """
diff --git a/tests/ti_deps/deps/test_dag_unpaused_dep.py b/tests/ti_deps/deps/test_dag_unpaused_dep.py
index 5c033b056bb52..6bb4266ceb7d6 100644
--- a/tests/ti_deps/deps/test_dag_unpaused_dep.py
+++ b/tests/ti_deps/deps/test_dag_unpaused_dep.py
@@ -24,7 +24,7 @@
 from airflow.ti_deps.deps.dag_unpaused_dep import DagUnpausedDep
 
 
-class DagUnpausedDepTest(unittest.TestCase):
+class TestDagUnpausedDep(unittest.TestCase):
 
     def test_concurrency_reached(self):
         """
diff --git a/tests/ti_deps/deps/test_dagrun_exists_dep.py b/tests/ti_deps/deps/test_dagrun_exists_dep.py
index 5a2b08503428e..42e5cde6b58f0 100644
--- a/tests/ti_deps/deps/test_dagrun_exists_dep.py
+++ b/tests/ti_deps/deps/test_dagrun_exists_dep.py
@@ -25,7 +25,7 @@
 from airflow.ti_deps.deps.dagrun_exists_dep import DagrunRunningDep
 
 
-class DagrunRunningDepTest(unittest.TestCase):
+class TestDagrunRunningDep(unittest.TestCase):
 
     @patch('airflow.models.DagRun.find', return_value=())
     def test_dagrun_doesnt_exist(self, mock_dagrun_find):
diff --git a/tests/ti_deps/deps/test_dagrun_id_dep.py b/tests/ti_deps/deps/test_dagrun_id_dep.py
index 56f15fb9d473f..7d2eee44cbbfd 100644
--- a/tests/ti_deps/deps/test_dagrun_id_dep.py
+++ b/tests/ti_deps/deps/test_dagrun_id_dep.py
@@ -26,7 +26,7 @@
 from airflow.ti_deps.deps.dagrun_id_dep import DagrunIdDep
 
 
-class DagrunRunningDepTest(unittest.TestCase):
+class TestDagrunRunningDep(unittest.TestCase):
     def test_dagrun_id_is_backfill(self):
         """
         Task instances whose dagrun ID is a backfill dagrun ID should fail this dep.
diff --git a/tests/ti_deps/deps/test_not_in_retry_period_dep.py b/tests/ti_deps/deps/test_not_in_retry_period_dep.py
index 592a155b0f360..9d587e9aecef5 100644
--- a/tests/ti_deps/deps/test_not_in_retry_period_dep.py
+++ b/tests/ti_deps/deps/test_not_in_retry_period_dep.py
@@ -28,7 +28,7 @@
 from airflow.utils.timezone import datetime
 
 
-class NotInRetryPeriodDepTest(unittest.TestCase):
+class TestNotInRetryPeriodDep(unittest.TestCase):
 
     def _get_task_instance(self, state, end_date=None,
                            retry_delay=timedelta(minutes=15)):
diff --git a/tests/ti_deps/deps/test_pool_slots_available_dep.py b/tests/ti_deps/deps/test_pool_slots_available_dep.py
index 58d9317c841d1..b63538e1ee0f6 100644
--- a/tests/ti_deps/deps/test_pool_slots_available_dep.py
+++ b/tests/ti_deps/deps/test_pool_slots_available_dep.py
@@ -27,7 +27,7 @@
 from tests.test_utils import db
 
 
-class PoolSlotsAvailableDepTest(unittest.TestCase):
+class TestPoolSlotsAvailableDep(unittest.TestCase):
     def setUp(self):
         db.clear_db_pools()
         with create_session() as session:
diff --git a/tests/ti_deps/deps/test_prev_dagrun_dep.py b/tests/ti_deps/deps/test_prev_dagrun_dep.py
index b1a7493093bb0..3ecb9c33d3533 100644
--- a/tests/ti_deps/deps/test_prev_dagrun_dep.py
+++ b/tests/ti_deps/deps/test_prev_dagrun_dep.py
@@ -27,7 +27,7 @@
 from airflow.utils.state import State
 
 
-class PrevDagrunDepTest(unittest.TestCase):
+class TestPrevDagrunDep(unittest.TestCase):
 
     def _get_task(self, **kwargs):
         return BaseOperator(task_id='test_task', dag=DAG('test_dag'), **kwargs)
diff --git a/tests/ti_deps/deps/test_ready_to_reschedule_dep.py b/tests/ti_deps/deps/test_ready_to_reschedule_dep.py
index f6e299fc52e54..73b1228d41171 100644
--- a/tests/ti_deps/deps/test_ready_to_reschedule_dep.py
+++ b/tests/ti_deps/deps/test_ready_to_reschedule_dep.py
@@ -28,7 +28,7 @@
 from airflow.utils.timezone import utcnow
 
 
-class NotInReschedulePeriodDepTest(unittest.TestCase):
+class TestNotInReschedulePeriodDep(unittest.TestCase):
 
     def _get_task_instance(self, state):
         dag = DAG('test_dag')
diff --git a/tests/ti_deps/deps/test_runnable_exec_date_dep.py b/tests/ti_deps/deps/test_runnable_exec_date_dep.py
index 680eb4c6917f2..9925f2e40ad74 100644
--- a/tests/ti_deps/deps/test_runnable_exec_date_dep.py
+++ b/tests/ti_deps/deps/test_runnable_exec_date_dep.py
@@ -26,7 +26,7 @@
 from airflow.utils.timezone import datetime
 
 
-class RunnableExecDateDepTest(unittest.TestCase):
+class TestRunnableExecDateDep(unittest.TestCase):
 
     def _get_task_instance(self, execution_date, dag_end_date=None, task_end_date=None):
         dag = Mock(end_date=dag_end_date)
diff --git a/tests/ti_deps/deps/test_task_concurrency.py b/tests/ti_deps/deps/test_task_concurrency.py
index c7a0f198ad39c..53793ec359b44 100644
--- a/tests/ti_deps/deps/test_task_concurrency.py
+++ b/tests/ti_deps/deps/test_task_concurrency.py
@@ -26,7 +26,7 @@
 from airflow.ti_deps.deps.task_concurrency_dep import TaskConcurrencyDep
 
 
-class TaskConcurrencyDepTest(unittest.TestCase):
+class TestTaskConcurrencyDep(unittest.TestCase):
 
     def _get_task(self, **kwargs):
         return BaseOperator(task_id='test_task', dag=DAG('test_dag'), **kwargs)
diff --git a/tests/ti_deps/deps/test_trigger_rule_dep.py b/tests/ti_deps/deps/test_trigger_rule_dep.py
index c149026944450..0da0d2b7e3f10 100644
--- a/tests/ti_deps/deps/test_trigger_rule_dep.py
+++ b/tests/ti_deps/deps/test_trigger_rule_dep.py
@@ -27,7 +27,7 @@
 from airflow.utils.state import State
 
 
-class TriggerRuleDepTest(unittest.TestCase):
+class TestTriggerRuleDep(unittest.TestCase):
 
     def _get_task_instance(self, trigger_rule=TriggerRule.ALL_SUCCESS,
                            state=None, upstream_task_ids=None):
diff --git a/tests/ti_deps/deps/test_valid_state_dep.py b/tests/ti_deps/deps/test_valid_state_dep.py
index 22f44f2641a68..3b4499d881b65 100644
--- a/tests/ti_deps/deps/test_valid_state_dep.py
+++ b/tests/ti_deps/deps/test_valid_state_dep.py
@@ -26,7 +26,7 @@
 from airflow.utils.state import State
 
 
-class ValidStateDepTest(unittest.TestCase):
+class TestValidStateDep(unittest.TestCase):
 
     def test_valid_state(self):
         """
diff --git a/tests/utils/test_cli_util.py b/tests/utils/test_cli_util.py
index 6a411faba7ed5..867827c0c40e6 100644
--- a/tests/utils/test_cli_util.py
+++ b/tests/utils/test_cli_util.py
@@ -27,7 +27,7 @@
 from airflow.utils import cli, cli_action_loggers
 
 
-class CliUtilTest(unittest.TestCase):
+class TestCliUtil(unittest.TestCase):
 
     def test_metrics_build(self):
         func_name = 'test'
diff --git a/tests/utils/test_compression.py b/tests/utils/test_compression.py
index 8914310c07629..a2b39c60f659e 100644
--- a/tests/utils/test_compression.py
+++ b/tests/utils/test_compression.py
@@ -29,7 +29,7 @@
 from airflow.utils import compression
 
 
-class Compression(unittest.TestCase):
+class TestCompression(unittest.TestCase):
 
     def setUp(self):
         self.fn = {}
diff --git a/tests/utils/test_dates.py b/tests/utils/test_dates.py
index 85613d079139d..fdd73fd4a6fae 100644
--- a/tests/utils/test_dates.py
+++ b/tests/utils/test_dates.py
@@ -25,7 +25,7 @@
 from airflow.utils import timezone
 
 
-class Dates(unittest.TestCase):
+class TestDates(unittest.TestCase):
 
     def test_days_ago(self):
         today = pendulum.today()
diff --git a/tests/utils/test_db.py b/tests/utils/test_db.py
index 6ebc4b2086b96..b762247f94c4f 100644
--- a/tests/utils/test_db.py
+++ b/tests/utils/test_db.py
@@ -27,7 +27,7 @@
 from sqlalchemy import MetaData
 
 
-class DbTest(unittest.TestCase):
+class TestDb(unittest.TestCase):
 
     def test_database_schema_and_sqlalchemy_model_are_in_sync(self):
         all_meta_data = MetaData()
diff --git a/tests/utils/test_decorators.py b/tests/utils/test_decorators.py
index fbed556228f29..00745b6cad348 100644
--- a/tests/utils/test_decorators.py
+++ b/tests/utils/test_decorators.py
@@ -37,7 +37,7 @@ def __init__(self, test_sub_param, *args, **kwargs):
         self.test_sub_param = test_sub_param
 
 
-class ApplyDefaultTest(unittest.TestCase):
+class TestApplyDefault(unittest.TestCase):
 
     def test_apply(self):
         dc = DummyClass(test_param=True)
diff --git a/tests/utils/test_email.py b/tests/utils/test_email.py
index 6dae967c4abb9..024bddd55c1f8 100644
--- a/tests/utils/test_email.py
+++ b/tests/utils/test_email.py
@@ -23,7 +23,7 @@
 EMAILS = ['test1@example.com', 'test2@example.com']
 
 
-class EmailTest(unittest.TestCase):
+class TestEmail(unittest.TestCase):
 
     def test_get_email_address_comma_sep_string(self):
         emails_string = 'test1@example.com, test2@example.com'
diff --git a/tests/utils/test_helpers.py b/tests/utils/test_helpers.py
index 8e50dcdf6f4b4..d5bcb715eea7f 100644
--- a/tests/utils/test_helpers.py
+++ b/tests/utils/test_helpers.py
@@ -148,6 +148,11 @@ def test_is_container(self):
         self.assertFalse(helpers.is_container("a string is not a container"))
         self.assertTrue(helpers.is_container(["a", "list", "is", "a", "container"]))
 
+        self.assertTrue(helpers.is_container(['test_list']))
+        self.assertFalse(helpers.is_container('test_str_not_iterable'))
+        # Pass an object that is not iter nor a string.
+        self.assertFalse(helpers.is_container(10))
+
     def test_as_tuple(self):
         self.assertEqual(
             helpers.as_tuple("a string is not a container"),
@@ -159,8 +164,6 @@ def test_as_tuple(self):
             ("a", "list", "is", "a", "container")
         )
 
-
-class HelpersTest(unittest.TestCase):
     def test_as_tuple_iter(self):
         test_list = ['test_str']
         as_tup = helpers.as_tuple(test_list)
@@ -171,12 +174,6 @@ def test_as_tuple_no_iter(self):
         as_tup = helpers.as_tuple(test_str)
         self.assertTupleEqual((test_str,), as_tup)
 
-    def test_is_container(self):
-        self.assertTrue(helpers.is_container(['test_list']))
-        self.assertFalse(helpers.is_container('test_str_not_iterable'))
-        # Pass an object that is not iter nor a string.
-        self.assertFalse(helpers.is_container(10))
-
     def test_cross_downstream(self):
         """Test if all dependencies between tasks are all set correctly."""
         dag = DAG(dag_id="test_dag", start_date=datetime.now())
diff --git a/tests/utils/test_module_loading.py b/tests/utils/test_module_loading.py
index 136c38379aafd..0f9ab67f1dc82 100644
--- a/tests/utils/test_module_loading.py
+++ b/tests/utils/test_module_loading.py
@@ -22,7 +22,7 @@
 from airflow.utils.module_loading import import_string
 
 
-class ModuleImportTestCase(unittest.TestCase):
+class TestModuleImport(unittest.TestCase):
     def test_import_string(self):
         cls = import_string('airflow.utils.module_loading.import_string')
         self.assertEqual(cls, import_string)
diff --git a/tests/utils/test_net.py b/tests/utils/test_net.py
index 985dac35db023..b87bdab3f80f5 100644
--- a/tests/utils/test_net.py
+++ b/tests/utils/test_net.py
@@ -27,7 +27,7 @@ def get_hostname():
     return 'awesomehostname'
 
 
-class GetHostname(unittest.TestCase):
+class TestGetHostname(unittest.TestCase):
 
     @mock.patch('airflow.utils.net.socket')
     @mock.patch('airflow.utils.net.conf')
diff --git a/tests/utils/test_tests.py b/tests/utils/test_tests.py
index 8ef5b5ce22262..793d0f77060ad 100644
--- a/tests/utils/test_tests.py
+++ b/tests/utils/test_tests.py
@@ -21,7 +21,7 @@
 from airflow.utils.tests import assertEqualIgnoreMultipleSpaces
 
 
-class UtilsTestsTest(unittest.TestCase):
+class TestTestUtils(unittest.TestCase):
 
     def test_assertEqualIgnoreMultipleSpaces_raises(self):
         str1 = 'w oo f'
diff --git a/tests/utils/test_timezone.py b/tests/utils/test_timezone.py
index e31895e2df521..10446304add40 100644
--- a/tests/utils/test_timezone.py
+++ b/tests/utils/test_timezone.py
@@ -29,7 +29,7 @@
 UTC = timezone.utc
 
 
-class TimezoneTest(unittest.TestCase):
+class TestTimezone(unittest.TestCase):
     def test_is_aware(self):
         self.assertTrue(timezone.is_localized(datetime.datetime(2011, 9, 1, 13, 20, 30, tzinfo=EAT)))
         self.assertFalse(timezone.is_localized(datetime.datetime(2011, 9, 1, 13, 20, 30)))
diff --git a/tests/www/api/experimental/test_kerberos_endpoints.py b/tests/www/api/experimental/test_kerberos_endpoints.py
index 3ca6398ce75af..8505c9cbdfd9d 100644
--- a/tests/www/api/experimental/test_kerberos_endpoints.py
+++ b/tests/www/api/experimental/test_kerberos_endpoints.py
@@ -32,7 +32,7 @@
 
 @unittest.skipIf('KRB5_KTNAME' not in os.environ,
                  'Skipping Kerberos API tests due to missing KRB5_KTNAME')
-class ApiKerberosTests(unittest.TestCase):
+class TestApiKerberos(unittest.TestCase):
     def setUp(self):
         try:
             configuration.conf.add_section("api")
diff --git a/tests/www/test_utils.py b/tests/www/test_utils.py
index e5d51494c2c78..07a482ada56c2 100644
--- a/tests/www/test_utils.py
+++ b/tests/www/test_utils.py
@@ -27,7 +27,7 @@
 from airflow.www import utils
 
 
-class UtilsTest(unittest.TestCase):
+class TestUtils(unittest.TestCase):
     def test_empty_variable_should_not_be_hidden(self):
         self.assertFalse(utils.should_hide_value_for_key(""))
         self.assertFalse(utils.should_hide_value_for_key(None))
@@ -212,7 +212,7 @@ def test_dag_run_link(self):
         self.assertNotIn('<b2>', html)
 
 
-class AttrRendererTest(unittest.TestCase):
+class TestAttrRenderer(unittest.TestCase):
 
     def setUp(self):
         self.attr_renderer = utils.get_attr_renderer()
