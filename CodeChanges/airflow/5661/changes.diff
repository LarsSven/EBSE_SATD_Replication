diff --git a/airflow/api/common/experimental/dag_runs.py b/airflow/api/common/experimental/dag_runs.py
new file mode 100644
index 0000000000000..5b6b366d6a866
--- /dev/null
+++ b/airflow/api/common/experimental/dag_runs.py
@@ -0,0 +1,99 @@
+# -*- coding: utf-8 -*-
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#   http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+"""DAG runs APIs."""
+from typing import Optional, List, Dict, Any
+from flask import url_for
+
+from airflow.api.common.experimental import check_and_get_dag
+from airflow.models import DagRun
+from airflow.utils import timezone
+
+
+def get_dag_runs(dag_id: str, state: Optional[str] = None, state_ne: Optional[str] = None,
+                 execution_date_before: Optional[str] = None, execution_date_after: Optional[str] = None,
+                 execution_date: Optional[str] = None) -> List[Dict[str, Any]]:
+    """
+    Returns a list of Dag Runs for a specific DAG ID.
+
+    :param dag_id: String identifier of a DAG
+    :param state: queued|running|success...
+    :param state_ne: queued|running|success...
+    :param execution_date_before: a query string parameter to find all runs before provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15".
+    :param execution_date_after: a query string parameter to find all runs after provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15".
+    :param execution_date: a query string parameter to find all runs on the provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15".
+    :return: List of DAG runs of a DAG with requested state,
+        or all runs if the state is not specified
+    :rtype: list[dict]
+    """
+    check_and_get_dag(dag_id=dag_id)
+
+    return get_all_dag_runs(dag_id=dag_id, state=state, state_ne=state_ne,
+                            execution_date_before=execution_date_before,
+                            execution_date_after=execution_date_after,
+                            execution_date=execution_date)
+
+
+def get_all_dag_runs(dag_id: Optional[str], state: Optional[str] = None,
+                     state_ne: Optional[str] = None,
+                     execution_date_before: Optional[str] = None,
+                     execution_date_after: Optional[str] = None,
+                     execution_date: Optional[str] = None) -> List[Dict[str, Any]]:
+    """
+    Returns a list of Dag Runs which out a need for specific DAG ID.
+
+    :param dag_id: String identifier of a DAG
+    :param state: queued|running|success...
+    :param state_ne: queued|running|success...
+    :param execution_date_before: a query string parameter to find all runs before provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15".
+    :param execution_date_after: a query string parameter to find all runs after provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15".
+    :param execution_date: a query string parameter to find all runs on the provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15".
+    :return: List of DAG runs of a DAG with requested state,
+        or all runs if the state is not specified
+    :rtype: list[dict]
+    """
+
+    dag_runs = list()
+    state = state.lower() if state else None
+    state_ne = state_ne.lower() if state_ne else None
+    execution_date_before = timezone.parse(execution_date_before) if execution_date_before else None
+    execution_date_after = timezone.parse(execution_date_after) if execution_date_after else None
+    execution_date = timezone.parse(execution_date) if execution_date else None
+    for run in DagRun.find(dag_id=dag_id, state=state, state_ne=state_ne,
+                           execution_date_before=execution_date_before,
+                           execution_date_after=execution_date_after,
+                           execution_date=execution_date):
+        dag_runs.append({
+            'id': run.id,
+            'run_id': run.run_id,
+            'state': run.state,
+            'dag_id': run.dag_id,
+            'execution_date': run.execution_date.isoformat(),
+            'start_date': ((run.start_date or '') and run.start_date.isoformat()),
+            'end_date': ((run.end_date or '') and run.end_date.isoformat()),
+            'dag_run_url': url_for('Airflow.graph', dag_id=run.dag_id,
+                                   execution_date=run.execution_date)
+        })
+
+    return dag_runs
diff --git a/airflow/api/common/experimental/dags.py b/airflow/api/common/experimental/dags.py
new file mode 100644
index 0000000000000..1a0c5c2da1ebe
--- /dev/null
+++ b/airflow/api/common/experimental/dags.py
@@ -0,0 +1,72 @@
+# -*- coding: utf-8 -*-
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#   http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+"""DAG API Helpers"""
+from flask import url_for
+from airflow.models import DagModel
+from airflow.exceptions import DagNotFound
+
+
+def get_dag_as_dict(dag):
+    """
+    Returns a DAG as a dictionary
+
+    :return: DAG as a dictionary
+    """
+    dag_dict = {'dag_id': dag.dag_id,
+                'is_paused': dag.is_paused,
+                'is_subdag': dag.is_subdag,
+                'is_active': dag.is_active,
+                'last_scheduler_run': dag.last_scheduler_run,
+                'last_pickled': dag.last_pickled,
+                'last_expired': dag.last_expired,
+                'pickle_id': dag.pickle_id,
+                'fileloc': dag.fileloc,
+                'owners': dag.owners,
+                'resources': {'dag_runs': url_for('api_experimental.dag_runs', dag_id=dag.dag_id)}}
+    return dag_dict
+
+
+def get_dags(is_paused=None, is_subdag=None, is_active=None, scheduler_lock=None):
+    """
+    Returns a list of all Dags
+
+    :return: List of all DAGs
+    """
+    dag_list = list()
+
+    for dag in DagModel.find(is_paused=is_paused, is_subdag=is_subdag, is_active=is_active,
+                             scheduler_lock=scheduler_lock):
+        dag_list.append(get_dag_as_dict(dag))
+
+    return dag_list
+
+
+def get_dag(dag_id):
+    """
+    Returns DAG info for a specific DAG ID.
+
+    :param dag_id: String identifier of a DAG
+    :return: DAG info for a specific DAG ID.
+    """
+    dag = DagModel.get_dagmodel(dag_id)
+    if dag is not None:
+        return get_dag_as_dict(dag)
+
+    error_message = "Dag id {} not found".format(dag_id)
+    raise DagNotFound(error_message)
diff --git a/airflow/api/common/experimental/get_dag_runs.py b/airflow/api/common/experimental/get_dag_runs.py
deleted file mode 100644
index 79539b3445162..0000000000000
--- a/airflow/api/common/experimental/get_dag_runs.py
+++ /dev/null
@@ -1,53 +0,0 @@
-# -*- coding: utf-8 -*-
-#
-# Licensed to the Apache Software Foundation (ASF) under one
-# or more contributor license agreements.  See the NOTICE file
-# distributed with this work for additional information
-# regarding copyright ownership.  The ASF licenses this file
-# to you under the Apache License, Version 2.0 (the
-# "License"); you may not use this file except in compliance
-# with the License.  You may obtain a copy of the License at
-#
-#   http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing,
-# software distributed under the License is distributed on an
-# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-# KIND, either express or implied.  See the License for the
-# specific language governing permissions and limitations
-# under the License.
-"""DAG runs APIs."""
-from typing import Optional, List, Dict, Any
-
-from flask import url_for
-
-from airflow.api.common.experimental import check_and_get_dag
-from airflow.models import DagRun
-
-
-def get_dag_runs(dag_id: str, state: Optional[str] = None) -> List[Dict[str, Any]]:
-    """
-    Returns a list of Dag Runs for a specific DAG ID.
-    :param dag_id: String identifier of a DAG
-    :param state: queued|running|success...
-    :return: List of DAG runs of a DAG with requested state,
-    or all runs if the state is not specified
-    """
-    check_and_get_dag(dag_id=dag_id)
-
-    dag_runs = list()
-    state = state.lower() if state else None
-    for run in DagRun.find(dag_id=dag_id, state=state):
-        dag_runs.append({
-            'id': run.id,
-            'run_id': run.run_id,
-            'state': run.state,
-            'dag_id': run.dag_id,
-            'execution_date': run.execution_date.isoformat(),
-            'start_date': ((run.start_date or '') and
-                           run.start_date.isoformat()),
-            'dag_run_url': url_for('Airflow.graph', dag_id=run.dag_id,
-                                   execution_date=run.execution_date)
-        })
-
-    return dag_runs
diff --git a/airflow/api/common/experimental/get_task.py b/airflow/api/common/experimental/get_task.py
index 2a154c98c85b0..274874d2c8c54 100644
--- a/airflow/api/common/experimental/get_task.py
+++ b/airflow/api/common/experimental/get_task.py
@@ -23,7 +23,31 @@
 
 def get_task(dag_id: str, task_id: str) -> TaskInstance:
     """Return the task object identified by the given dag_id and task_id."""
+
     dag = check_and_get_dag(dag_id, task_id)
 
     # Return the task.
     return dag.get_task(task_id)
+
+
+def get_tasks(dag_id: str):
+    """Return all tasks identified by the given dag_id."""
+
+    dag = check_and_get_dag(dag_id)
+
+    # Return the task ids.
+    return dag.task_ids
+
+
+def get_task_as_dict(dag_id, task_id):
+    """Return the task object as a dictionary identified by the given dag_id and task_id"""
+
+    task = get_task(dag_id, task_id)
+    fields = {k: str(v)
+              for k, v in vars(task).items()
+              if not k.startswith('_')}
+    fields.update({
+        'upstream_task_ids': list(task.upstream_task_ids),
+        'downstream_task_ids': list(task.downstream_task_ids)})
+
+    return fields
diff --git a/airflow/api/common/experimental/get_task_logs.py b/airflow/api/common/experimental/get_task_logs.py
new file mode 100644
index 0000000000000..4bd0b248d8bb4
--- /dev/null
+++ b/airflow/api/common/experimental/get_task_logs.py
@@ -0,0 +1,61 @@
+# -*- coding: utf-8 -*-
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#   http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+
+"""Tasks APIs Helper"""
+import logging
+from io import BytesIO
+from flask import send_file
+from airflow import configuration as conf
+from airflow.models import DagBag
+from airflow.utils.helpers import render_log_filename
+from airflow.api.common.experimental.task_instance import get_task_instance
+
+
+def get_task_logs(dag_id, task_id, execution_date):
+    """Return the logs for the task instance identified by the given dag_id, execution_date and task_id."""
+
+    dagbag = DagBag()
+    ti = get_task_instance(dag_id, task_id, execution_date)
+
+    try_number = ti.try_number
+    metadata = {}
+
+    logger = logging.getLogger('airflow.task')
+    task_log_reader = conf.get('core', 'task_log_reader')
+    handler = next((handler for handler in logger.handlers
+                    if handler.name == task_log_reader), None)
+
+    if ti is None:
+        logs = ["*** Task instance did not exist in the DB\n"]
+        metadata['end_of_log'] = True
+    else:
+        dag = dagbag.get_dag(dag_id)
+        ti.task = dag.get_task(ti.task_id)
+        logs, metadatas = handler.read(ti, try_number, metadata=metadata)
+        metadata = metadatas[0]
+
+    file_obj = BytesIO(b'\n'.join(
+        log.encode('utf-8') for log in logs
+    ))
+    filename_template = conf.get('core', 'LOG_FILENAME_TEMPLATE')
+    attachment_filename = render_log_filename(
+        ti=ti,
+        try_number="all" if try_number is None else try_number,
+        filename_template=filename_template)
+    return send_file(file_obj, as_attachment=True, attachment_filename=attachment_filename)
diff --git a/airflow/api/common/experimental/task_instance.py b/airflow/api/common/experimental/task_instance.py
new file mode 100644
index 0000000000000..1e206a666111e
--- /dev/null
+++ b/airflow/api/common/experimental/task_instance.py
@@ -0,0 +1,98 @@
+# -*- coding: utf-8 -*-
+#
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#   http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+"""Task Instance APIs Helper"""
+
+from airflow.exceptions import (DagNotFound, TaskNotFound,
+                                DagRunNotFound, TaskInstanceNotFound)
+from airflow.models import DagBag
+from airflow.models import TaskInstance
+from airflow.utils import timezone
+
+
+def get_task_instance(dag_id, task_id, execution_date):
+    """
+    Return the task object identified by the given dag_id and task_id.
+
+    :param dag_id: String identifier of a DAG
+    :param task_id: String identifier of a task
+    :param execution_date: date to identify dag run
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15".
+    """
+
+    dagbag = DagBag()
+
+    # Check DAG exists.
+    if dag_id not in dagbag.dags:
+        error_message = "Dag id {} not found".format(dag_id)
+        raise DagNotFound(error_message)
+
+    # Get DAG object and check Task Exists
+    dag = dagbag.get_dag(dag_id)
+    if not dag.has_task(task_id):
+        error_message = 'Task {} not found in dag {}'.format(task_id, dag_id)
+        raise TaskNotFound(error_message)
+
+    # Get DagRun object and check that it exists
+    dagrun = dag.get_dagrun(execution_date=execution_date)
+    if not dagrun:
+        error_message = ('Dag Run for date {} not found in dag {}'
+                         .format(execution_date, dag_id))
+        raise DagRunNotFound(error_message)
+
+    # Get task instance object and check that it exists
+    task_instance = dagrun.get_task_instance(task_id)
+    if not task_instance:
+        error_message = ('Task {} instance for date {} not found'
+                         .format(task_id, execution_date))
+        raise TaskInstanceNotFound(error_message)
+
+    return task_instance
+
+
+def get_all_task_instances(dag_id=None, state=None, state_ne=None, execution_date_before=None,
+                           execution_date_after=None, task_id=None):
+    """
+    Returns a list of Dag Runs for a specific DAG ID.
+
+    :param dag_id: String identifier of a DAG
+    :param task_id: String identifier of a task
+    :param state: queued|running|success...
+    :param state_ne: queued|running|success...
+    :param execution_date_before: a query string parameter to find all runs before provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15".
+    :param execution_date_after: a query string parameter to find all runs after provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15".
+    :return: List of task instances
+    """
+
+    task_instances = list()
+    state = state.lower() if state else None
+    state_ne = state_ne.lower() if state_ne else None
+    execution_date_before = timezone.parse(execution_date_before) if execution_date_before else None
+    execution_date_after = timezone.parse(execution_date_after) if execution_date_after else None
+    for instance in TaskInstance.find(dag_id=dag_id, state=state, state_ne=state_ne,
+                                      execution_date_before=execution_date_before,
+                                      execution_date_after=execution_date_after, task_id=task_id):
+        fields = {k: str(v)
+                  for k, v in vars(instance).items()
+                  if not k.startswith('_')}
+        fields.update({'try_number': instance.try_number})
+        task_instances.append(fields)
+
+    return task_instances
diff --git a/airflow/models/dag.py b/airflow/models/dag.py
index 2469b48013f6b..4c46843610c43 100644
--- a/airflow/models/dag.py
+++ b/airflow/models/dag.py
@@ -1560,3 +1560,28 @@ def set_is_paused(self,
         except Exception:
             session.rollback()
             raise
+
+    @staticmethod
+    @provide_session
+    def find(dag_id=None, is_paused=None, is_subdag=None, is_active=None,
+             scheduler_lock=None, session=None):
+        """
+        Find a set of dags known to the system for the given search criteria.
+
+        """
+
+        DM = DagModel
+        query = session.query(DM)
+
+        if dag_id:
+            query = query.filter(DM.dag_id == dag_id)
+        if is_paused:
+            query = query.filter(DM.is_paused == is_paused)
+        if is_subdag:
+            query = query.filter(DM.is_subdag == is_subdag)
+        if is_active:
+            query = query.filter(DM.is_active == is_active)
+        if scheduler_lock:
+            query = query.filter(DM.scheduler_lock == scheduler_lock)
+
+        return query.order_by(DM.last_scheduler_run).all()
diff --git a/airflow/models/dagrun.py b/airflow/models/dagrun.py
index 994ea1b111ac3..431dad1640a48 100644
--- a/airflow/models/dagrun.py
+++ b/airflow/models/dagrun.py
@@ -114,8 +114,9 @@ def refresh_from_db(self, session=None):
     @staticmethod
     @provide_session
     def find(dag_id=None, run_id=None, execution_date=None,
+             execution_date_before=None, execution_date_after=None,
              state=None, external_trigger=None, no_backfills=False,
-             session=None):
+             state_ne=None, session=None):
         """
         Returns a set of dag runs for the given search criteria.
 
@@ -125,6 +126,12 @@ def find(dag_id=None, run_id=None, execution_date=None,
         :type run_id: str
         :param execution_date: the execution date
         :type execution_date: datetime.datetime
+        :param execution_before: to find dag runs with execution date before the provided one
+        :type execution_before: datetime.datetime
+        :param execution_after: to find dag runs with execution date after the provided one
+        :type execution_after: datetime.datetime
+        :param state_ne: the state of the dag run not to be in the results
+        :type state_ne: airflow.utils.state.State
         :param state: the state of the dag run
         :type state: str
         :param external_trigger: whether this dag run is externally triggered
@@ -147,8 +154,14 @@ def find(dag_id=None, run_id=None, execution_date=None,
                 qry = qry.filter(DR.execution_date.in_(execution_date))
             else:
                 qry = qry.filter(DR.execution_date == execution_date)
+        if execution_date_before:
+            qry = qry.filter(DR.execution_date <= execution_date_before)
+        if execution_date_after:
+            qry = qry.filter(DR.execution_date >= execution_date_after)
         if state:
             qry = qry.filter(DR.state == state)
+        if state_ne:
+            qry = qry.filter(DR.state != state_ne)
         if external_trigger is not None:
             qry = qry.filter(DR.external_trigger == external_trigger)
         if no_backfills:
diff --git a/airflow/models/taskinstance.py b/airflow/models/taskinstance.py
index 641b751fa2798..608b5837e07c5 100644
--- a/airflow/models/taskinstance.py
+++ b/airflow/models/taskinstance.py
@@ -220,6 +220,49 @@ def try_number(self, value):
     def next_try_number(self):
         return self._try_number + 1
 
+    @staticmethod
+    @provide_session
+    def find(dag_id=None, task_id=None, execution_date=None,
+             execution_date_before=None, execution_date_after=None,
+             state=None, state_ne=None, session=None):
+        """
+        Returns a set of dag runs for the given search criteria.
+
+        :param dag_id: the dag_id to find task instance for
+        :type dag_id: int
+        :param task_id: the task_id to find task instance for
+        :type task_id: int
+        :param execution_date_before: filter on execution date before the provided one
+        :type execution_date_before: datetime.datetime
+        :param execution_date_after: filter on execution date after the provided one
+        :type execution_date_after: datetime.datetime
+        :param state_ne: the state of the task instance not to be in the results
+        :type state: airflow.utils.state.State
+        :param state: the state of the task instance
+        :type state: airflow.utils.state.State
+        :param session: database session
+        :type session: sqlalchemy.orm.session.Session
+        """
+        TI = TaskInstance
+
+        query = session.query(TI)
+        if dag_id:
+            query = query.filter(TI.dag_id == dag_id)
+        if task_id:
+            query = query.filter(TI.task_id == task_id)
+        if state:
+            query = query.filter(TI.state == state)
+        if state_ne:
+            query = query.filter(TI.state != state_ne)
+        if execution_date_before:
+            query = query.filter(TI.execution_date <= execution_date_before)
+        if execution_date_after:
+            query = query.filter(TI.execution_date >= execution_date_after)
+
+        result = query.order_by(TI.execution_date).all()
+
+        return result
+
     def command(
             self,
             mark_success=False,
diff --git a/airflow/www/api/experimental/endpoints.py b/airflow/www/api/experimental/endpoints.py
index 5a3b10eea9447..9a7a08b15542a 100644
--- a/airflow/www/api/experimental/endpoints.py
+++ b/airflow/www/api/experimental/endpoints.py
@@ -20,12 +20,14 @@
 from airflow.api.common.experimental import delete_dag as delete
 from airflow.api.common.experimental import pool as pool_api
 from airflow.api.common.experimental import trigger_dag as trigger
-from airflow.api.common.experimental.get_dag_runs import get_dag_runs
-from airflow.api.common.experimental.get_task import get_task
-from airflow.api.common.experimental.get_task_instance import get_task_instance
+from airflow.api.common.experimental.dag_runs import get_all_dag_runs, get_dag_runs
+from airflow.api.common.experimental.task_instance import get_task_instance, get_all_task_instances
+from airflow.api.common.experimental.dags import get_dags, get_dag
+from airflow.api.common.experimental.get_task import get_task, get_task_as_dict, get_tasks
 from airflow.api.common.experimental.get_code import get_code
-from airflow.api.common.experimental.get_dag_run_state import get_dag_run_state
+from airflow.api.common.experimental.get_task_logs import get_task_logs
 from airflow.exceptions import AirflowException
+from airflow.exceptions import DagNotFound
 from airflow.utils.log.logging_mixin import LoggingMixin
 from airflow.utils import timezone
 from airflow.www.app import csrf
@@ -40,6 +42,152 @@
 api_experimental = Blueprint('api_experimental', __name__)
 
 
+@api_experimental.route(
+    '/dags/<string:dag_id>/dag_runs/<string:execution_date>/tasks/<string:task_id>/logs',
+    methods=['GET'])
+@requires_authentication
+def logs(dag_id, execution_date, task_id):
+    """
+    Return logs for the specified task identified by dag_id, execution_date and task_id
+    """
+
+    try:
+        execution_date = timezone.parse(execution_date)
+    except ValueError:
+        error_message = (
+            'Given execution date, {}, could not be identified '
+            'as a date. Example date format: 2015-11-16T14:34:15+00:00'
+            .format(execution_date))
+        response = jsonify({'error': error_message})
+        response.status_code = 400
+        return response
+
+    try:
+        log = get_task_logs(dag_id, task_id, execution_date)
+    except AirflowException as err:
+        _log.info(err)
+        response = jsonify(error="{}".format(err))
+        response.status_code = err.status_code
+        return response
+    except AttributeError as e:
+        error_message = ["Unable to read logs.\n{}\n".format(str(e))]
+        metadata = {}
+        metadata['end_of_log'] = True
+        return jsonify(message=error_message, error=True, metadata=metadata)
+
+    return log
+
+
+@api_experimental.route('/dag_runs', methods=['GET'])
+@requires_authentication
+def dag_runs_filter():
+    """
+    Return the list of all dag_runs
+
+    :query param state: a query string parameter '?state=queued|running|success...'
+    :query param state_ne: a query string parameter '?state_ne=queued|running|success...'
+    :query param execution_date_before: a query string parameter to find all runs before provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15"
+    :query param execution_date_after: a query string parameter to find all runs after provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15"
+    :query param dag_id: String identifier of a DAG
+    :return: List of DAG runs of a DAG with requested state,
+    """
+    state = request.args.get('state')
+    state_ne = request.args.get('state_ne')
+    execution_date_before = request.args.get('execution_date_before')
+    execution_date_after = request.args.get('execution_date_after')
+    dag_id = request.args.get('dag_id')
+
+    dagruns = get_all_dag_runs(dag_id=dag_id, state=state, state_ne=state_ne,
+                               execution_date_before=execution_date_before,
+                               execution_date_after=execution_date_after)
+
+    return jsonify(dagruns)
+
+
+@api_experimental.route('/task_instances', methods=['GET'])
+@requires_authentication
+def task_instances_filter():
+    """
+    Return the list of all dag_runs
+
+    :query param state: a query string parameter '?state=queued|running|success...'
+    :query param state_ne: a query string parameter '?state_ne=queued|running|success...'
+    :query param execution_date_before: a query string parameter to find all runs before provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15".'
+    :query param execution_date_after: a query string parameter to find all runs after provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15".'
+    :query param dag_id: String identifier of a DAG
+    :query param task_id: String identifier of a task
+    :return: List of task instances
+    """
+    state = request.args.get('state')
+    state_ne = request.args.get('state_ne')
+    execution_date_before = request.args.get('execution_date_before')
+    execution_date_after = request.args.get('execution_date_after')
+    dag_id = request.args.get('dag_id')
+    task_id = request.args.get('task_id')
+
+    task_instances = get_all_task_instances(dag_id=dag_id, state=state, state_ne=state_ne,
+                                            execution_date_before=execution_date_before,
+                                            execution_date_after=execution_date_after, task_id=task_id)
+
+    return jsonify(task_instances)
+
+
+@api_experimental.route('/dags', methods=['GET'])
+@requires_authentication
+def get_all_dags():
+    """
+    Returns a list of Dags
+
+    :query param is_paused: a query string parameter '?is_paused=true|false'
+    :return: List of all DAGs
+    """
+    is_paused = request.args.get('is_paused')
+    if is_paused:
+        is_paused = is_paused.lower()
+        is_paused = 1 if is_paused == 'true' else 0
+
+    is_subdag = request.args.get('is_subdag')
+    if is_subdag:
+        is_subdag = is_subdag.lower()
+        is_subdag = 1 if is_subdag == 'true' else 0
+
+    is_active = request.args.get('is_active')
+    if is_active:
+        is_active = is_active.lower()
+        is_active = 1 if is_active == 'true' else 0
+
+    scheduler_lock = request.args.get('scheduler_lock')
+    if scheduler_lock:
+        scheduler_lock = scheduler_lock.lower()
+        scheduler_lock = 1 if scheduler_lock == 'true' else 0
+
+    dag_list = get_dags(is_paused=is_paused, is_subdag=is_subdag, is_active=is_active,
+                        scheduler_lock=scheduler_lock)
+
+    return jsonify(dag_list)
+
+
+@api_experimental.route('/dags/<string:dag_id>', methods=['GET'])
+@requires_authentication
+def get_dag_info(dag_id):
+    """
+    Returns information for a single dag
+    """
+    dag = None
+    try:
+        dag = get_dag(dag_id)
+    except DagNotFound as err:
+        _log.info(err)
+        response = jsonify(error="{}".format(err))
+        response.status_code = 404
+        return response
+    return jsonify(dag)
+
+
 @csrf.exempt
 @api_experimental.route('/dags/<string:dag_id>/dag_runs', methods=['POST'])
 @requires_authentication
@@ -113,14 +261,25 @@ def delete_dag(dag_id):
 def dag_runs(dag_id):
     """
     Returns a list of Dag Runs for a specific DAG ID.
+
     :query param state: a query string parameter '?state=queued|running|success...'
+    :query param state_ne: a query string parameter '?state_ne=queued|running|success...'
+    :query param execution_date_before: a query string parameter to find all runs before provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15"'
+    :query param execution_date_after: a query string parameter to find all runs after provided date,
+        should be in format "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15"'
     :param dag_id: String identifier of a DAG
     :return: List of DAG runs of a DAG with requested state,
-    or all runs if the state is not specified
+        or all runs if the state is not specified
     """
     try:
         state = request.args.get('state')
-        dagruns = get_dag_runs(dag_id, state)
+        state_ne = request.args.get('state_ne')
+        execution_date_before = request.args.get('execution_date_before')
+        execution_date_after = request.args.get('execution_date_after')
+        dagruns = get_dag_runs(dag_id, state=state, state_ne=state_ne,
+                               execution_date_before=execution_date_before,
+                               execution_date_after=execution_date_after)
     except AirflowException as err:
         _log.info(err)
         response = jsonify(error="{}".format(err))
@@ -149,12 +308,32 @@ def get_dag_code(dag_id):
         return response
 
 
+@api_experimental.route('/dags/<string:dag_id>/tasks', methods=['GET'])
+@requires_authentication
+def tasks(dag_id):
+    """Returns a JSON with all tasks associated with the dag_id. """
+
+    task_list = list()
+    try:
+        task_ids = get_tasks(dag_id)
+        for task_id in task_ids:
+            task_list.append(get_task_as_dict(dag_id, task_id))
+
+    except AirflowException as err:
+        _log.info(err)
+        response = jsonify(error="{}".format(err))
+        response.status_code = err.status_code
+        return response
+
+    return jsonify(task_list)
+
+
 @api_experimental.route('/dags/<string:dag_id>/tasks/<string:task_id>', methods=['GET'])
 @requires_authentication
 def task_info(dag_id, task_id):
     """Returns a JSON with a task's public instance variables. """
     try:
-        info = get_task(dag_id, task_id)
+        info = get_task_as_dict(dag_id, task_id)
     except AirflowException as err:
         _log.info(err)
         response = jsonify(error="{}".format(err))
@@ -162,10 +341,7 @@ def task_info(dag_id, task_id):
         return response
 
     # JSONify and return.
-    fields = {k: str(v)
-              for k, v in vars(info).items()
-              if not k.startswith('_')}
-    return jsonify(fields)
+    return jsonify(info)
 
 
 # ToDo: Shouldn't this be a PUT method?
@@ -210,7 +386,8 @@ def task_instance_info(dag_id, execution_date, task_id):
         return response
 
     try:
-        info = get_task_instance(dag_id, task_id, execution_date)
+        task_instance = get_task_instance(dag_id, task_id, execution_date)
+        task = get_task(dag_id, task_id)
     except AirflowException as err:
         _log.info(err)
         response = jsonify(error="{}".format(err))
@@ -219,8 +396,12 @@ def task_instance_info(dag_id, execution_date, task_id):
 
     # JSONify and return.
     fields = {k: str(v)
-              for k, v in vars(info).items()
+              for k, v in vars(task_instance).items()
               if not k.startswith('_')}
+    fields.update({
+        'try_number': task_instance._try_number,
+        'upstream_task_ids': list(task._upstream_task_ids),
+        'downstream_task_ids': list(task._downstream_task_ids)})
     return jsonify(fields)
 
 
@@ -228,17 +409,21 @@ def task_instance_info(dag_id, execution_date, task_id):
     '/dags/<string:dag_id>/dag_runs/<string:execution_date>',
     methods=['GET'])
 @requires_authentication
-def dag_run_status(dag_id, execution_date):
+def dag_run(dag_id, execution_date):
     """
     Returns a JSON with a dag_run's public instance variables.
+
     The format for the exec_date is expected to be
     "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15". This will
     of course need to have been encoded for URL in the request.
     """
-
-    # Convert string datetime into actual datetime
     try:
-        execution_date = timezone.parse(execution_date)
+        dagruns = get_dag_runs(dag_id, execution_date=execution_date)
+    except AirflowException as err:
+        _log.info(err)
+        response = jsonify(error="{}".format(err))
+        response.status_code = 404
+        return response
     except ValueError:
         error_message = (
             'Given execution date, {}, could not be identified '
@@ -247,18 +432,14 @@ def dag_run_status(dag_id, execution_date):
         _log.info(error_message)
         response = jsonify({'error': error_message})
         response.status_code = 400
-
         return response
 
-    try:
-        info = get_dag_run_state(dag_id, execution_date)
-    except AirflowException as err:
-        _log.info(err)
-        response = jsonify(error="{}".format(err))
-        response.status_code = err.status_code
+    if not dagruns:
+        error_message = "No Dag run found with provided execution date"
+        response = jsonify(error=error_message)
+        response.status_code = 404
         return response
-
-    return jsonify(info)
+    return jsonify(dagruns[0])
 
 
 @api_experimental.route('/latest_runs', methods=['GET'])
diff --git a/tests/www/api/experimental/test_endpoints.py b/tests/www/api/experimental/test_endpoints.py
index e28d58db7c5de..7ef9041d60eab 100644
--- a/tests/www/api/experimental/test_endpoints.py
+++ b/tests/www/api/experimental/test_endpoints.py
@@ -21,8 +21,6 @@
 import json
 import unittest
 from urllib.parse import quote_plus
-
-
 from airflow import settings
 from airflow.api.common.experimental.trigger_dag import trigger_dag
 from airflow.models import DagBag, DagRun, Pool, TaskInstance
@@ -70,6 +68,69 @@ def tearDown(self):
         session.close()
         super().tearDown()
 
+    def test_dags_list(self):
+        url_template = '/api/experimental/dags'
+        response = self.client.get(url_template)
+        response_content = json.loads(response.data.decode('utf-8'))
+        self.assertIsInstance(response_content, list)
+        self.assertEqual(200, response.status_code)
+
+    def test_dag_runs(self):
+        url_template = '/api/experimental/dag_runs'
+        response = self.client.get(url_template)
+        response_content = json.loads(response.data.decode('utf-8'))
+        self.assertIsInstance(response_content, list)
+        self.assertEqual(200, response.status_code)
+
+    def test_task_instances(self):
+        url_template = '/api/experimental/task_instances'
+        response = self.client.get(url_template)
+        response_content = json.loads(response.data.decode('utf-8'))
+        self.assertIsInstance(response_content, list)
+        self.assertEqual(200, response.status_code)
+
+    def test_dagid_details(self):
+        url_template = '/api/experimental/dags/{}'
+
+        # Check for valid response
+        dag_id = 'example_bash_operator'
+        response = self.client.get(
+            url_template.format(dag_id)
+        )
+        self.assertIn('dag_id', response.data.decode('utf-8'))
+        self.assertNotIn('error', response.data.decode('utf-8'))
+        self.assertEqual(200, response.status_code)
+
+        # Check for invalid response
+        dag_id = 'DNE'
+        response = self.client.get(
+            url_template.format(dag_id)
+        )
+        self.assertIn('error', response.data.decode('utf-8'))
+        self.assertEqual(404, response.status_code)
+
+    def test_dagid_tasks(self):
+        url_template = '/api/experimental/dags/{}/tasks'
+
+        # Check for valid response
+        dag_id = 'example_bash_operator'
+        response = self.client.get(
+            url_template.format(dag_id)
+        )
+        response_content = json.loads(response.data.decode('utf-8'))
+        self.assertIsInstance(response_content, list)
+        self.assertNotIn('error', response.data.decode('utf-8'))
+        self.assertEqual(200, response.status_code)
+
+        # Check for invalid response
+        dag_id = 'DNE'
+        response = self.client.get(
+            url_template.format(dag_id)
+        )
+        response_content = json.loads(response.data.decode('utf-8'))
+        self.assertIn('error', response.data.decode('utf-8'))
+        self.assertEqual(404, response.status_code)
+
     def test_task_info(self):
         url_template = '/api/experimental/dags/{}/tasks/{}'
 
@@ -80,6 +141,24 @@ def test_task_info(self):
         self.assertNotIn('error', response.data.decode('utf-8'))
         self.assertEqual(200, response.status_code)
 
+        # Check for upstearm and downstearm task list
+        response = self.client.get(
+            url_template.format('example_bash_operator', 'run_after_loop')
+        )
+        self.assertNotIn('error', response.data.decode('utf-8'))
+        self.assertEqual(200, response.status_code)
+        response_content = json.loads(response.data.decode('utf-8'))
+
+        self.assertIn('"upstream_task_ids"', response.data.decode('utf-8'))
+        expected_upstream_task_list = ["runme_2", "runme_1", "runme_0"]
+        self.assertListEqual(sorted(response_content['upstream_task_ids']),
+                             sorted(expected_upstream_task_list))
+
+        self.assertIn('"downstream_task_ids"', response.data.decode('utf-8'))
+        expected_downstream_task_list = ["run_this_last"]
+        self.assertListEqual(sorted(response_content['downstream_task_ids']),
+                             sorted(expected_downstream_task_list))
+
         response = self.client.get(
             url_template.format('example_bash_operator', 'DNE')
         )
@@ -147,6 +226,22 @@ def test_trigger_dag(self):
         )
         self.assertEqual(404, response.status_code)
 
+    def test_dag_runs_response_for_dag_id(self):
+        url_template = '/api/experimental/dags/{}/dag_runs'
+        dag_id = 'example_bash_operator'
+        response = self.client.get(
+            url_template.format(dag_id)
+        )
+        response_content = json.loads(response.data.decode('utf-8'))
+        self.assertIsInstance(response_content, list)
+        self.assertEqual(200, response.status_code)
+
+        response = self.client.get(
+            url_template.format('DNE')
+        )
+        self.assertIn('error', response.data.decode('utf-8'))
+        self.assertEqual(400, response.status_code)
+
     def test_trigger_dag_for_date(self):
         url_template = '/api/experimental/dags/{}/dag_runs'
         dag_id = 'example_bash_operator'
@@ -210,6 +305,9 @@ def test_task_instance_info(self):
         )
         self.assertEqual(200, response.status_code)
         self.assertIn('state', response.data.decode('utf-8'))
+        self.assertIn('try_number', response.data.decode('utf-8'))
+        self.assertIn('upstream_task_ids', response.data.decode('utf-8'))
+        self.assertIn('downstream_task_ids', response.data.decode('utf-8'))
         self.assertNotIn('error', response.data.decode('utf-8'))
 
         # Test error for nonexistent dag
@@ -261,6 +359,7 @@ def test_dagrun_status(self):
         )
         self.assertEqual(200, response.status_code)
         self.assertIn('state', response.data.decode('utf-8'))
+        self.assertIn('run_id', response.data.decode('utf-8'))
         self.assertNotIn('error', response.data.decode('utf-8'))
 
         # Test error for nonexistent dag
