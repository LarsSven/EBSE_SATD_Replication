diff --git a/airflow/bin/cli.py b/airflow/bin/cli.py
index 876d765f89a26..ad141df3b7664 100755
--- a/airflow/bin/cli.py
+++ b/airflow/bin/cli.py
@@ -489,7 +489,7 @@ def worker(args):
 
         worker.run(**options)
         sp.kill()
-        
+
 
 def initdb(args):  # noqa
     print("DB: " + repr(settings.engine.url))
diff --git a/airflow/jobs.py b/airflow/jobs.py
index a95b6453836dc..3a08de61ae680 100644
--- a/airflow/jobs.py
+++ b/airflow/jobs.py
@@ -422,7 +422,8 @@ def schedule_dag(self, dag):
 
             # don't ever schedule prior to the dag's start_date
             if dag.start_date:
-                next_run_date = max(next_run_date, dag.start_date)
+                next_run_date = (max(next_run_date, dag.start_date) if next_run_date else
+                                 dag.start_date)
 
             # this structure is necessary to avoid a TypeError from concatenating
             # NoneType
@@ -509,7 +510,7 @@ def process_dag(self, dag, executor):
             if ti.state in (
                     State.RUNNING, State.QUEUED, State.SUCCESS, State.FAILED):
                 continue
-            elif ti.is_runnable(flag_upstream_failed=True):
+            elif ti.are_dependencies_met(flag_upstream_failed=True):
                 self.logger.debug('Firing task: {}'.format(ti))
                 executor.queue_task_instance(ti, pickle_id=pickle_id)
             else:
@@ -599,7 +600,6 @@ def prioritize_queued(self, session, executor, dagbag):
 
         self.queued_tis.clear()
 
-        dag_blacklist = set(dagbag.paused_dags())
         for pool, tis in list(d.items()):
             if not pool:
                 # Arbitrary:
@@ -642,11 +642,6 @@ def prioritize_queued(self, session, executor, dagbag):
                     self.logger.info("Pickling DAG {}".format(dag))
                     pickle_id = dag.pickle(session).id
 
-                if dag.dag_id in dag_blacklist:
-                    continue
-                if dag.concurrency_reached:
-                    dag_blacklist.add(dag.dag_id)
-                    continue
                 if ti.are_dependencies_met():
                     executor.queue_task_instance(ti, pickle_id=pickle_id)
                     open_slots -= 1
@@ -835,7 +830,7 @@ def _execute(self):
                         continue
 
                 # Is the task runnable? -- then run it
-                if ti.is_queueable(
+                if ti.are_dependencies_met(
                         include_queued=True,
                         ignore_depends_on_past=ignore_depends_on_past,
                         flag_upstream_failed=True):
diff --git a/airflow/models.py b/airflow/models.py
index 590b95c3e3142..f11f01ed9df77 100644
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -45,10 +45,10 @@
 from sqlalchemy import (
     Column, Integer, String, DateTime, Text, Boolean, ForeignKey, PickleType,
     Index, Float)
-from sqlalchemy import case, func, or_, and_
+from sqlalchemy import func, or_, and_
 from sqlalchemy.ext.declarative import declarative_base, declared_attr
 from sqlalchemy.dialects.mysql import LONGTEXT
-from sqlalchemy.orm import relationship, synonym
+from sqlalchemy.orm import reconstructor, relationship, synonym
 
 from croniter import croniter
 import six
@@ -57,6 +57,19 @@
 from airflow.executors import DEFAULT_EXECUTOR, LocalExecutor
 from airflow import configuration
 from airflow.exceptions import AirflowException, AirflowSkipException
+from airflow.ti_deps.ti_deps import (
+    DagUnpausedDep,
+    EndDateAfterExecutionDateDep,
+    ExecDateNotInFutureDep,
+    InRunnableStateDep,
+    MaxConcurrencyNotReachedDep,
+    MaxDagrunsNotReachedDep,
+    NotAlreadyQueuedDep,
+    NotInRetryPeriodDep,
+    NotSkippedDep,
+    PastDagrunDep,
+    PoolHasSpaceDep,
+    TriggerRuleDep)
 from airflow.utils.dates import cron_presets, date_range as utils_date_range
 from airflow.utils.db import provide_session
 from airflow.utils.decorators import apply_defaults
@@ -652,6 +665,23 @@ class TaskInstance(Base):
         Index('ti_pool', pool, state, priority_weight),
     )
 
+    # The dependencies for each task instance that need to be met before the instance is
+    # run
+    TI_DEPS = [
+        PoolHasSpaceDep,
+        ExecDateNotInFutureDep,
+        NotInRetryPeriodDep,
+        EndDateAfterExecutionDateDep,
+        NotAlreadyQueuedDep,
+        InRunnableStateDep,
+        DagUnpausedDep,
+        MaxConcurrencyNotReachedDep,
+        MaxDagrunsNotReachedDep,
+        NotSkippedDep,
+        PastDagrunDep,
+        TriggerRuleDep,
+    ]
+
     def __init__(self, task, execution_date, state=None):
         self.dag_id = task.dag_id
         self.task_id = task.task_id
@@ -661,11 +691,16 @@ def __init__(self, task, execution_date, state=None):
         self.pool = task.pool
         self.priority_weight = task.priority_weight_total
         self.try_number = 0
-        self.test_mode = False  # can be changed when calling 'run'
-        self.force = False  # can be changed when calling 'run'
         self.unixname = getpass.getuser()
         if state:
             self.state = state
+        self.init_on_load()
+
+    @reconstructor
+    def init_on_load(self):
+        """ Initialize the attributes that aren't stored in the DB. """
+        self.test_mode = False  # can be changed when calling 'run'
+        self.force = False  # can be changed when calling 'run'
 
     def command(
             self,
@@ -807,78 +842,6 @@ def set_state(self, state, session):
         self.end_date = datetime.now()
         session.merge(self)
 
-    def is_queueable(
-            self,
-            include_queued=False,
-            ignore_depends_on_past=False,
-            flag_upstream_failed=False):
-        """
-        Returns a boolean on whether the task instance has met all dependencies
-        and is ready to run. It considers the task's state, the state
-        of its dependencies, depends_on_past and makes sure the execution
-        isn't in the future. It doesn't take into
-        account whether the pool has a slot for it to run.
-
-        :param include_queued: If True, tasks that have already been queued
-            are included. Defaults to False.
-        :type include_queued: boolean
-        :param ignore_depends_on_past: if True, ignores depends_on_past
-            dependencies. Defaults to False.
-        :type ignore_depends_on_past: boolean
-        :param flag_upstream_failed: This is a hack to generate
-            the upstream_failed state creation while checking to see
-            whether the task instance is runnable. It was the shortest
-            path to add the feature
-        :type flag_upstream_failed: boolean
-        """
-        # is the execution date in the future?
-        if self.execution_date > datetime.now():
-            return False
-        # is the task still in the retry waiting period?
-        elif self.state == State.UP_FOR_RETRY and not self.ready_for_retry():
-            return False
-        # does the task have an end_date prior to the execution date?
-        elif self.task.end_date and self.execution_date > self.task.end_date:
-            return False
-        # has the task been skipped?
-        elif self.state == State.SKIPPED:
-            return False
-        # has the task already been queued (and are we excluding queued tasks)?
-        elif self.state == State.QUEUED and not include_queued:
-            return False
-        # is the task runnable and have its dependencies been met?
-        elif (
-                self.state in State.runnable() and
-                self.are_dependencies_met(
-                    ignore_depends_on_past=ignore_depends_on_past,
-                    flag_upstream_failed=flag_upstream_failed)):
-            return True
-        # anything else
-        else:
-            return False
-
-    def is_runnable(
-            self,
-            include_queued=False,
-            ignore_depends_on_past=False,
-            flag_upstream_failed=False):
-        """
-        Returns whether a task is ready to run AND there's room in the
-        queue.
-
-        :param include_queued: If True, tasks that are already QUEUED are
-            considered "runnable". Defaults to False.
-        :type include_queued: boolean
-        :param ignore_depends_on_past: if True, ignores depends_on_past
-            dependencies. Defaults to False.
-        :type ignore_depends_on_past: boolean
-        """
-        queueable = self.is_queueable(
-            include_queued=include_queued,
-            ignore_depends_on_past=ignore_depends_on_past,
-            flag_upstream_failed=flag_upstream_failed)
-        return queueable and not self.pool_full()
-
     @provide_session
     def are_dependents_done(self, session=None):
         """
@@ -903,78 +866,38 @@ def are_dependents_done(self, session=None):
         count = ti[0][0]
         return count == len(task.downstream_task_ids)
 
+    @property
     @provide_session
-    def evaluate_trigger_rule(self, successes, skipped, failed,
-                              upstream_failed, done,
-                              flag_upstream_failed, session=None):
-        """
-        Returns a boolean on whether the current task can be scheduled
-        for execution based on its trigger_rule.
-
-        :param flag_upstream_failed: This is a hack to generate
-            the upstream_failed state creation while checking to see
-            whether the task instance is runnable. It was the shortest
-            path to add the feature
-        :type flag_upstream_failed: boolean
-        :param successes: Number of successful upstream tasks
-        :type successes: boolean
-        :param skipped: Number of skipped upstream tasks
-        :type skipped: boolean
-        :param failed: Number of failed upstream tasks
-        :type failed: boolean
-        :param upstream_failed: Number of upstream_failed upstream tasks
-        :type upstream_failed: boolean
-        :param done: Number of completed upstream tasks
-        :type done: boolean
-        """
-        TR = TriggerRule
-
-        task = self.task
-        upstream = len(task.upstream_task_ids)
-        tr = task.trigger_rule
-        upstream_done = done >= upstream
-
-        # handling instant state assignment based on trigger rules
-        if flag_upstream_failed:
-            if tr == TR.ALL_SUCCESS:
-                if upstream_failed or failed:
-                    self.set_state(State.UPSTREAM_FAILED, session)
-                elif skipped:
-                    self.set_state(State.SKIPPED, session)
-            elif tr == TR.ALL_FAILED:
-                if successes or skipped:
-                    self.set_state(State.SKIPPED, session)
-            elif tr == TR.ONE_SUCCESS:
-                if upstream_done and not successes:
-                    self.set_state(State.SKIPPED, session)
-            elif tr == TR.ONE_FAILED:
-                if upstream_done and not (failed or upstream_failed):
-                    self.set_state(State.SKIPPED, session)
+    def previous_ti(self, session=None):
+        """ The task instance for the task that ran before this task instance """
+        TI = TaskInstance
 
-        return (
-             (tr == TR.ONE_SUCCESS and successes > 0) or
-             (tr == TR.ONE_FAILED and (failed or upstream_failed)) or
-             (tr == TR.ALL_SUCCESS and successes >= upstream) or
-             (tr == TR.ALL_FAILED and failed + upstream_failed >= upstream) or
-             (tr == TR.ALL_DONE and upstream_done)
-        )
+        return session.query(TI).filter(
+            TI.dag_id == self.dag_id,
+            TI.task_id == self.task.task_id,
+            TI.execution_date ==
+            self.task.dag.previous_schedule(self.execution_date),
+        ).first()
 
     @provide_session
     def are_dependencies_met(
             self,
             session=None,
-            flag_upstream_failed=False,
+            include_queued=False,
             ignore_depends_on_past=False,
+            flag_upstream_failed=False,
             verbose=False):
         """
-        Returns a boolean on whether the upstream tasks are in a SUCCESS state
-        and considers depends_on_past and the previous run's state.
+        Returns whether or not all the conditions are met for this task instance to be run
 
         :param flag_upstream_failed: This is a hack to generate
             the upstream_failed state creation while checking to see
             whether the task instance is runnable. It was the shortest
             path to add the feature
         :type flag_upstream_failed: boolean
+        :param include_queued: If True, tasks that have already been queued
+            are included. Defaults to False.
+        :type include_queued: boolean
         :param ignore_depends_on_past: if True, ignores depends_on_past
             dependencies. Defaults to False.
         :type ignore_depends_on_past: boolean
@@ -984,70 +907,41 @@ def are_dependencies_met(
             logging would be way too verbose.
         :type verbose: boolean
         """
-        TI = TaskInstance
-        TR = TriggerRule
-
-        task = self.task
-
-        # Checking that the depends_on_past is fulfilled
-        if (task.depends_on_past and not ignore_depends_on_past and
-                not self.execution_date == task.start_date):
-            previous_ti = session.query(TI).filter(
-                TI.dag_id == self.dag_id,
-                TI.task_id == task.task_id,
-                TI.execution_date ==
-                    self.task.dag.previous_schedule(self.execution_date),
-                TI.state.in_({State.SUCCESS, State.SKIPPED}),
-            ).first()
-            if not previous_ti:
-                if verbose:
-                    logging.warning("depends_on_past not satisfied")
-                return False
-
-            # Applying wait_for_downstream
-            previous_ti.task = self.task
-            if task.wait_for_downstream and not \
-                    previous_ti.are_dependents_done(session=session):
+        verbose = True
+        for dep in self.TI_DEPS:
+            for dep_status in dep.get_failed_dep_statuses(
+                                  self,
+                                  session,
+                                  include_queued,
+                                  ignore_depends_on_past,
+                                  flag_upstream_failed):
                 if verbose:
-                    logging.warning("wait_for_downstream not satisfied")
+                    logging.warning(
+                        "Task instance {0} dependencies not met, dependency {1} failed: "
+                        "{2}".format(self, dep_status.dep_name, dep_status.reason))
+                session.commit()
                 return False
 
-        # Checking that all upstream dependencies have succeeded
-        if not task.upstream_list or task.trigger_rule == TR.DUMMY:
-            return True
+        session.commit()
+        return True
 
-        qry = (
-            session
-            .query(
-                func.coalesce(func.sum(
-                    case([(TI.state == State.SUCCESS, 1)], else_=0)), 0),
-                func.coalesce(func.sum(
-                    case([(TI.state == State.SKIPPED, 1)], else_=0)), 0),
-                func.coalesce(func.sum(
-                    case([(TI.state == State.FAILED, 1)], else_=0)), 0),
-                func.coalesce(func.sum(
-                    case([(TI.state == State.UPSTREAM_FAILED, 1)], else_=0)), 0),
-                func.count(TI.task_id),
-            )
-            .filter(
-                TI.dag_id == self.dag_id,
-                TI.task_id.in_(task.upstream_task_ids),
-                TI.execution_date == self.execution_date,
-                TI.state.in_([
-                    State.SUCCESS, State.FAILED,
-                    State.UPSTREAM_FAILED, State.SKIPPED]),
-            )
-        )
+    @provide_session
+    def get_failed_dep_statuses(
+            self,
+            session=None,
+            include_queued=False,
+            ignore_depends_on_past=False,
+            flag_upstream_failed=False):
 
-        successes, skipped, failed, upstream_failed, done = qry.first()
-        satisfied = self.evaluate_trigger_rule(
-            session=session, successes=successes, skipped=skipped,
-            failed=failed, upstream_failed=upstream_failed, done=done,
-            flag_upstream_failed=flag_upstream_failed)
-        session.commit()
-        if verbose and not satisfied:
-            logging.warning("Trigger rule `{}` not satisfied".format(task.trigger_rule))
-        return satisfied
+        for dep in self.TI_DEPS:
+            for dep_status in dep.get_dep_statuses(
+                                  self,
+                                  session,
+                                  include_queued,
+                                  ignore_depends_on_past,
+                                  flag_upstream_failed):
+                if not dep_status.passed:
+                    yield dep_status
 
     def __repr__(self):
         return (
@@ -1113,134 +1007,120 @@ def run(
         self.hostname = socket.gethostname()
         self.operator = task.__class__.__name__
 
-        if self.state == State.RUNNING:
-            logging.warning("Another instance is running, skipping.")
-        elif not force and self.state == State.SUCCESS:
-            logging.info(
-                "Task {self} previously succeeded"
-                " on {self.end_date}".format(**locals())
-            )
-        elif (
-                not ignore_dependencies and
-                not self.are_dependencies_met(
-                    session=session,
-                    ignore_depends_on_past=ignore_depends_on_past,
-                    verbose=True)):
+        if (not ignore_dependencies and
+            not self.are_dependencies_met(
+                session=session,
+                ignore_depends_on_past=ignore_depends_on_past,
+                verbose=True)):
             logging.warning("Dependencies not met yet")
-        elif (
-                self.state == State.UP_FOR_RETRY and
-                not self.ready_for_retry()):
-            next_run = (self.end_date + task.retry_delay).isoformat()
-            logging.info(
-                "Not ready for retry yet. " +
-                "Next run after {0}".format(next_run)
-            )
-        elif force or self.state in State.runnable():
-            HR = "\n" + ("-" * 80) + "\n"  # Line break
+            session.commit()
+            return
+
+        HR = "\n" + ("-" * 80) + "\n"  # Line break
 
-            # For reporting purposes, we report based on 1-indexed,
-            # not 0-indexed lists (i.e. Attempt 1 instead of
-            # Attempt 0 for the first attempt).
-            msg = "Starting attempt {attempt} of {total}".format(
+        # For reporting purposes, we report based on 1-indexed,
+        # not 0-indexed lists (i.e. Attempt 1 instead of
+        # Attempt 0 for the first attempt).
+        msg = "Starting attempt {attempt} of {total}".format(
+            attempt=self.try_number % (task.retries + 1) + 1,
+            total=task.retries + 1)
+        self.start_date = datetime.now()
+
+        if not mark_success and self.state != State.QUEUED and (
+                self.pool or self.task.dag.concurrency_reached):
+            # If a pool is set for this task, marking the task instance
+            # as QUEUED
+            self.state = State.QUEUED
+            msg = "Queuing attempt {attempt} of {total}".format(
                 attempt=self.try_number % (task.retries + 1) + 1,
                 total=task.retries + 1)
-            self.start_date = datetime.now()
-
-            if not mark_success and self.state != State.QUEUED and (
-                    self.pool or self.task.dag.concurrency_reached):
-                # If a pool is set for this task, marking the task instance
-                # as QUEUED
-                self.state = State.QUEUED
-                msg = "Queuing attempt {attempt} of {total}".format(
-                    attempt=self.try_number % (task.retries + 1) + 1,
-                    total=task.retries + 1)
-                logging.info(HR + msg + HR)
-
-                self.queued_dttm = datetime.now()
-                session.merge(self)
-                session.commit()
-                logging.info("Queuing into pool {}".format(self.pool))
-                return
-
-            # print status message
             logging.info(HR + msg + HR)
-            self.try_number += 1
-
-            if not test_mode:
-                session.add(Log(State.RUNNING, self))
-            self.state = State.RUNNING
-            self.end_date = None
-            if not test_mode:
-                session.merge(self)
+
+            self.queued_dttm = datetime.now()
+            session.merge(self)
             session.commit()
+            logging.info("Queuing into pool {}".format(self.pool))
+            return
 
-            # Closing all pooled connections to prevent
-            # "max number of connections reached"
-            settings.engine.dispose()
-            if verbose:
-                if mark_success:
-                    msg = "Marking success for "
-                else:
-                    msg = "Executing "
-                msg += "{self.task} on {self.execution_date}"
+        # print status message
+        logging.info(HR + msg + HR)
+        self.try_number += 1
 
-            context = {}
-            try:
-                logging.info(msg.format(self=self))
-                if not mark_success:
-                    context = self.get_template_context()
-
-                    task_copy = copy.copy(task)
-                    self.task = task_copy
-
-                    def signal_handler(signum, frame):
-                        '''Setting kill signal handler'''
-                        logging.error("Killing subprocess")
-                        task_copy.on_kill()
-                        raise AirflowException("Task received SIGTERM signal")
-                    signal.signal(signal.SIGTERM, signal_handler)
-
-                    self.render_templates()
-                    task_copy.pre_execute(context=context)
-
-                    # If a timout is specified for the task, make it fail
-                    # if it goes beyond
-                    result = None
-                    if task_copy.execution_timeout:
-                        with timeout(int(
-                                task_copy.execution_timeout.total_seconds())):
-                            result = task_copy.execute(context=context)
-
-                    else:
+        if not test_mode:
+            session.add(Log(State.RUNNING, self))
+        self.state = State.RUNNING
+        self.end_date = None
+        if not test_mode:
+            session.merge(self)
+        session.commit()
+
+        # Closing all pooled connections to prevent
+        # "max number of connections reached"
+        settings.engine.dispose()
+        if verbose:
+            if mark_success:
+                msg = "Marking success for "
+            else:
+                msg = "Executing "
+            msg += "{self.task} on {self.execution_date}"
+
+        context = {}
+        try:
+            logging.info(msg.format(self=self))
+            if not mark_success:
+                context = self.get_template_context()
+
+                task_copy = copy.copy(task)
+                self.task = task_copy
+
+                def signal_handler(signum, frame):
+                    '''Setting kill signal handler'''
+                    logging.error("Killing subprocess")
+                    task_copy.on_kill()
+                    raise AirflowException("Task received SIGTERM signal")
+                signal.signal(signal.SIGTERM, signal_handler)
+
+                self.render_templates()
+                task_copy.pre_execute(context=context)
+
+                # If a timout is specified for the task, make it fail
+                # if it goes beyond
+                result = None
+                if task_copy.execution_timeout:
+                    with timeout(int(
+                            task_copy.execution_timeout.total_seconds())):
                         result = task_copy.execute(context=context)
 
-                    # If the task returns a result, push an XCom containing it
-                    if result is not None:
-                        self.xcom_push(key=XCOM_RETURN_KEY, value=result)
-
-                    task_copy.post_execute(context=context)
-                self.state = State.SUCCESS
-            except AirflowSkipException:
-                self.state = State.SKIPPED
-            except (Exception, KeyboardInterrupt) as e:
-                self.handle_failure(e, test_mode, context)
-                raise
-
-            # Recording SUCCESS
-            self.end_date = datetime.now()
-            self.set_duration()
-            if not test_mode:
-                session.add(Log(self.state, self))
-                session.merge(self)
-            session.commit()
+                else:
+                    result = task_copy.execute(context=context)
 
-            # Success callback
-            try:
-                if task.on_success_callback:
-                    task.on_success_callback(context)
-            except Exception as e3:
-                logging.error("Failed when executing success callback")
-                logging.exception(e3)
+                # If the task returns a result, push an XCom containing it
+                if result is not None:
+                    self.xcom_push(key=XCOM_RETURN_KEY, value=result)
+
+                task_copy.post_execute(context=context)
+            self.state = State.SUCCESS
+        except AirflowSkipException:
+            self.state = State.SKIPPED
+        except (Exception, KeyboardInterrupt) as e:
+            self.handle_failure(e, test_mode, context)
+            raise
+
+        # Recording SUCCESS
+        self.end_date = datetime.now()
+        self.set_duration()
+        if not test_mode:
+            session.add(Log(self.state, self))
+            session.merge(self)
+        session.commit()
+
+        # Success callback
+        try:
+            if task.on_success_callback:
+                task.on_success_callback(context)
+        except Exception as e3:
+            logging.error("Failed when executing success callback")
+            logging.exception(e3)
 
         session.commit()
 
@@ -1607,7 +1487,7 @@ class derived from this one results in the creation of a task object,
         this represents the ``timedelta`` after the period is closed. For
         example if you set an SLA of 1 hour, the scheduler would send dan email
         soon after 1:00AM on the ``2016-01-02`` if the ``2016-01-01`` instance
-        has not succeede yet.
+        has not succeeded yet.
         The scheduler pays special attention for jobs with an SLA and
         sends alert
         emails for sla misses. SLA misses are also recorded in the database
@@ -2259,7 +2139,8 @@ class DagModel(Base):
     dag_id = Column(String(ID_LEN), primary_key=True)
     # A DAG can be paused from the UI / DB
     # Set this default value of is_paused based on a configuration value!
-    is_paused_at_creation = configuration.getboolean('core', 'dags_are_paused_at_creation')
+    is_paused_at_creation = configuration.getboolean('core',
+                                                     'dags_are_paused_at_creation')
     is_paused = Column(Boolean, default=is_paused_at_creation)
     # Whether the DAG is a subdag
     is_subdag = Column(Boolean, default=False)
@@ -3113,7 +2994,6 @@ def set(cls, key, value, serialize_json=False, session=None):
         session.flush()
 
 
-
 class XCom(Base):
     """
     Base class for XCom objects.
diff --git a/airflow/ti_deps/__init__.py b/airflow/ti_deps/__init__.py
new file mode 100644
index 0000000000000..e69de29bb2d1d
diff --git a/airflow/ti_deps/ti_deps.py b/airflow/ti_deps/ti_deps.py
new file mode 100644
index 0000000000000..e499629c5fc45
--- /dev/null
+++ b/airflow/ti_deps/ti_deps.py
@@ -0,0 +1,491 @@
+from collections import namedtuple
+from datetime import datetime
+from sqlalchemy import case, func
+
+import airflow
+from airflow.utils.db import provide_session
+from airflow.utils.state import State
+
+
+class BaseTIDep(object):
+    """
+    A dependency that must be satisfied in order for task instances to run. For example, a
+    task can only run if a certain number of its upstream tasks succeed.
+    """
+
+    # TODO(aoen): All of the parameters other than the task instance should be replaced
+    # with an single context object parameter.
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        """
+        Returns an iterable of TIDepStatus objects that describe whether the given task
+        instance has this dependency met.
+
+        For example a subclass could return an iterable of TIDepStatus objects, each one
+        representing if each of the passed in task's upstream tasks succeeded or not.
+
+        :param ti: the task instance to get the dependency status for
+        :type ti: TaskInstance
+        """
+        raise NotImplementedError
+
+    @classmethod
+    def is_met(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        """
+        Returns whether or not this dependency is met for a given task instance. A
+        dependency is considered met if all of the dependency statuses it reports are
+        passing.
+
+        :param ti: the task instance to see if this dependency is met for
+        :type ti: TaskInstance
+        """
+        return all(status.passed for status in
+                   cls.get_dep_statuses(
+                       ti,
+                       session,
+                       include_queued,
+                       ignore_depends_on_past,
+                       flag_upstream_failed))
+
+    @classmethod
+    def get_dep_name(cls):
+        return cls.__name__
+
+    @classmethod
+    def get_failure_reasons(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        """
+        Returns an iterable of strings that explain why this dependency wasn't met.
+
+        :param ti: the task instance to get the dependency failure reasons for
+        :type ti: TaskInstance
+        """
+        for dep_status in cls.get_dep_statuses(
+                              ti,
+                              session,
+                              include_queued,
+                              ignore_depends_on_past,
+                              flag_upstream_failed):
+            if not dep_status.passed:
+                yield dep_status.reason
+
+    @classmethod
+    def passing_status(cls, dep_name=None, reason=''):
+        if dep_name is None:
+            dep_name = cls.get_dep_name()
+        yield TIDepStatus(dep_name, True, reason)
+
+    @classmethod
+    def failing_status(cls, dep_name=None, reason=''):
+        if dep_name is None:
+            dep_name = cls.get_dep_name()
+        yield TIDepStatus(dep_name, False, reason)
+
+
+"""
+Status of a task instance dependency is met and reasons why it isn't met.
+"""
+TIDepStatus = namedtuple('TIDepStatus', ['dep_name', 'passed', 'reason'])
+
+
+class EndDateAfterExecutionDateDep(BaseTIDep):
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        if ti.task.end_date and ti.execution_date > ti.task.end_date:
+            return cls.failing_status(
+                reason="The execution date is {0} but this is after the task's end date "
+                "{1}.".format(
+                    ti.task.end_date.isoformat(),
+                    ti.execution_date().isoformat()))
+        return cls.passing_status()
+
+
+class ExecDateNotInFutureDep(BaseTIDep):
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        cur_date = datetime.now()
+        if ti.execution_date > cur_date:
+            return cls.failing_status(
+                reason="Execution date {0} is in the future (the current "
+                       "date is {1}).".format(ti.execution_date.isoformat(),
+                                              cur_date.isoformat()))
+        return cls.passing_status()
+
+
+class InRunnableStateDep(BaseTIDep):
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        if not ti.force and ti.state not in State.runnable():
+            if ti.state == State.SUCCESS:
+                return cls.failing_status(
+                    reason="Task previously succeeded on {0}. It must be cleared to be "
+                           "rerun.".format(ti.end_date))
+            if ti.state == State.FAILED:
+                return cls.failing_status(
+                    reason="Task previously failed on {0}. It must be cleared to be "
+                           "rerun.".format(ti.end_date))
+            elif ti.state == State.RUNNING:
+                return cls.failing_status(
+                    reason="Task is already running, it started on "
+                           "{0}.".format(ti.start_date))
+            else:
+                return cls.failing_status(
+                    reason="Task is in the '{0}' state which is not a runnable "
+                           "state.".format(ti.state))
+
+        return cls.passing_status()
+
+
+class DagUnpausedDep(BaseTIDep):
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        if ti.task.dag.is_paused:
+            return cls.failing_status(
+                reason="Task's DAG '{0}' is paused.".format(ti.dag_id))
+        else:
+            return cls.passing_status()
+
+
+class MaxConcurrencyNotReachedDep(BaseTIDep):
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        if ti.task.dag.concurrency_reached:
+            return cls.failing_status(
+                reason="The maximum number of running tasks ({0}) for this task's DAG '{1}' has "
+                       "been reached.".format(ti.dag_id, ti.task.dag.concurrency))
+        else:
+            return cls.passing_status()
+
+
+class MaxDagrunsNotReachedDep(BaseTIDep):
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        if ti.task.dag.concurrency_reached:
+            return cls.failing_status(
+                reason="The maximum number of active dag runs ({0}) for this task's DAG '{1}' has "
+                       "been reached.".format(ti.dag_id, ti.task.dag.max_active_runs))
+        else:
+            return cls.passing_status()
+
+
+class NotAlreadyQueuedDep(BaseTIDep):
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        if ti.state == State.QUEUED and not include_queued:
+            return cls.failing_status(
+                reason="The task instance has already been queued and will run shortly.")
+        return cls.passing_status()
+
+
+class NotInRetryPeriodDep(BaseTIDep):
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        # Calculate the date first so that it is always smaller than the timestamp
+        # used by ready_for_retry
+        if ti.state == State.UP_FOR_RETRY:
+            cur_date = datetime.now()
+            next_task_retry_date = ti.end_date + ti.task.retry_delay
+            if not ti.ready_for_retry():
+                return cls.failing_status(
+                    reason="Task is not ready for retry yet but will be retried automatically. "
+                           "Current date is {0} and task will be retried at {1}.".format(
+                               cur_date.isoformat(), next_task_retry_date.isoformat()))
+        return cls.passing_status()
+
+
+class NotSkippedDep(BaseTIDep):
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        if ti.state == State.SKIPPED:
+            return cls.failing_status(reason="The task instance has been skipped.")
+        return cls.passing_status()
+
+
+class PastDagrunDep(BaseTIDep):
+    """
+    Is the past dagrun in a state that allows this task instance to run, e.g. did
+    this task instance's task in the previous dagrun complete if we are depending on past
+    """
+
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+
+        # Are we still waiting for the previous task instance to succeed?
+
+        if ignore_depends_on_past or not ti.task.depends_on_past:
+            return cls.passing_status()
+
+        # The first task instance for a task shouldn't depend on the  task instance before
+        # it because there won't be one
+        if ti.execution_date == ti.task.start_date:
+            return cls.passing_status()
+
+        previous_ti = ti.previous_ti
+        if not ti.previous_ti:
+            return cls.failing_status(
+                reason="depends_on_past is true for this task, but the previous task "
+                       "instance has not run yet.")
+
+        if previous_ti.state not in [State.SUCCESS, State.SKIPPED]:
+            return cls.failing_status(
+                reason="depends_on_past is true for this task, but the previous task "
+                       "instance is in the state '{0}' which is not a successful state."
+                       .format(previous_ti.state))
+
+        previous_ti.task = ti.task
+        if (ti.task.wait_for_downstream and
+                not previous_ti.are_dependents_done(session=session)):
+            return cls.failing_status(
+                reason="The tasks downstream of the previous task instance haven't "
+                       "completed.")
+
+        return cls.passing_status()
+
+
+class PoolHasSpaceDep(BaseTIDep):
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        if ti.pool_full():
+            return cls.failing_status(reason="Task's pool '{0}' is full.".format(ti.pool))
+        return cls.passing_status()
+
+
+class TriggerRuleDep(BaseTIDep):
+    """
+    Determines if a task's upstream tasks are in a state that allows a given task instance
+    to run.
+    """
+
+    @classmethod
+    def get_dep_statuses(
+            cls,
+            ti,
+            session,
+            include_queued,
+            ignore_depends_on_past,
+            flag_upstream_failed):
+        TI = airflow.models.TaskInstance
+        TR = airflow.models.TriggerRule
+
+        # Checking that all upstream dependencies have succeeded
+        if not ti.task.upstream_list or ti.task.trigger_rule == TR.DUMMY:
+            return cls.passing_status()
+
+        qry = (
+            session
+            .query(
+                func.coalesce(func.sum(
+                    case([(TI.state == State.SUCCESS, 1)], else_=0)), 0),
+                func.coalesce(func.sum(
+                    case([(TI.state == State.SKIPPED, 1)], else_=0)), 0),
+                func.coalesce(func.sum(
+                    case([(TI.state == State.FAILED, 1)], else_=0)), 0),
+                func.coalesce(func.sum(
+                    case([(TI.state == State.UPSTREAM_FAILED, 1)], else_=0)), 0),
+                func.count(TI.task_id),
+            )
+            .filter(
+                TI.dag_id == ti.dag_id,
+                TI.task_id.in_(ti.task.upstream_task_ids),
+                TI.execution_date == ti.execution_date,
+                TI.state.in_([
+                    State.SUCCESS, State.FAILED,
+                    State.UPSTREAM_FAILED, State.SKIPPED]),
+            )
+        )
+
+        successes, skipped, failed, upstream_failed, done = qry.first()
+
+        return cls._evaluate_trigger_rule(
+                   ti=ti,
+                   successes=successes,
+                   skipped=skipped,
+                   failed=failed,
+                   upstream_failed=upstream_failed,
+                   done=done,
+                   flag_upstream_failed=flag_upstream_failed,
+                   session=session)
+    @classmethod
+    @provide_session
+    def _evaluate_trigger_rule(
+            cls,
+            ti,
+            successes,
+            skipped,
+            failed,
+            upstream_failed,
+            done,
+            flag_upstream_failed,
+            session):
+            """
+        TODODAN: this docstring was from the old stuff, make it work with the new stuff
+        :param flag_upstream_failed: This is a hack to generate
+            the upstream_failed state creation while checking to see
+            whether the task instance is runnable. It was the shortest
+            path to add the feature
+        :type flag_upstream_failed: boolean
+        :param successes: Number of successful upstream tasks
+        :type successes: boolean
+        :param skipped: Number of skipped upstream tasks
+        :type skipped: boolean
+        :param failed: Number of failed upstream tasks
+        :type failed: boolean
+        :param upstream_failed: Number of upstream_failed upstream tasks
+        :type upstream_failed: boolean
+        :param done: Number of completed upstream tasks
+        :type done: boolean
+        """
+
+        TR = airflow.models.TriggerRule
+
+        task = ti.task
+        upstream = len(task.upstream_task_ids)
+        tr = task.trigger_rule
+        upstream_done = done >= upstream
+
+        # handling instant state assignment based on trigger rules
+        # TODO(aoen): trigger rules should probably be rewritten as a subclass of
+        # BaseTIDep or contain a BaseTIDep, and then the logic could be broken up per each
+        # trigger rule class
+        if flag_upstream_failed:
+            if tr == TR.ALL_SUCCESS:
+                if upstream_failed or failed:
+                    ti.set_state(State.UPSTREAM_FAILED, session)
+                elif skipped:
+                    ti.set_state(State.SKIPPED, session)
+            elif tr == TR.ALL_FAILED:
+                if successes or skipped:
+                    ti.set_state(State.SKIPPED, session)
+            elif tr == TR.ONE_SUCCESS:
+                if upstream_done and not successes:
+                    ti.set_state(State.SKIPPED, session)
+            elif tr == TR.ONE_FAILED:
+                if upstream_done and not (failed or upstream_failed):
+                    ti.set_state(State.SKIPPED, session)
+
+        if tr == TR.ONE_SUCCESS:
+            if successes > 0:
+                return cls.passing_status()
+            else:
+                return cls.failing_status(
+                    reason="Task's trigger rule '{0}' requires one upstream task "
+                           "success, but none were found.".format(tr))
+        elif tr == TR.ONE_FAILED:
+            if failed or upstream_failed:
+                return cls.passing_status()
+            else:
+                return cls.failing_status(
+                    reason="Task's trigger rule '{0}' requires one upstream task failure "
+                           "but none, were found.").format(tr)
+        elif tr == TR.ALL_SUCCESS:
+            num_failures = upstream - successes
+            if num_failures <= 0:
+                return cls.passing_status()
+            else:
+                return cls.failing_status(
+                    reason="Task's trigger rule '{0}' requires all upstream tasks to "
+                           "have succeeded, but found {1} non-success(es)."
+                           .format(tr, num_failures))
+        elif tr == TR.ALL_FAILED:
+            num_successes = upstream - failed - upstream_failed
+            if num_successes <= 0:
+                return cls.passing_status()
+            else:
+                return cls.failing_status(
+                    reason="Task's trigger rule '{0}' requires all upstream tasks to "
+                           "have failed, but found {1} non-faliure(s)."
+                           .format(tr, num_successes))
+        elif tr == TR.ALL_DONE:
+            if upstream_done:
+                return cls.passing_status()
+            else:
+                return cls.failing_status(
+                    reason="Task's trigger rule '{0}' requires all upstream tasks to "
+                           "have completed, but found '{1}' task(s) that weren't done"
+                           .format(tr, upstream - done))
+        else:
+            return cls.failing_status(
+                reason="No strategy to evaluate trigger rule '{0}'.".format(tr))
diff --git a/airflow/utils/state.py b/airflow/utils/state.py
index 169f5b6d5911f..772dd99c0b385 100644
--- a/airflow/utils/state.py
+++ b/airflow/utils/state.py
@@ -62,7 +62,6 @@ def color_fg(cls, state):
     def runnable(cls):
         return [
             cls.NONE,
-            cls.FAILED,
             cls.UP_FOR_RETRY,
             cls.UPSTREAM_FAILED,
             cls.SKIPPED,
diff --git a/airflow/www/templates/airflow/task.html b/airflow/www/templates/airflow/task.html
index 50a98ebb9d48c..a8e465fabc93d 100644
--- a/airflow/www/templates/airflow/task.html
+++ b/airflow/www/templates/airflow/task.html
@@ -4,6 +4,22 @@
 {% block body %}
     {{ super() }}
     <h4>{{ title }}</h4>
+    <div>
+        <h5>Blocking Dependencies</h5>
+        <table class="table table-striped table-bordered">
+            <tr>
+                <th>Dependency</th>
+                <th>Reason</th>
+            </tr>
+            {% for dependency, reason in failed_dep_reasons %}
+                <tr>
+                    <td>{{ dependency }}</td>
+                    <td class='code'>{{ reason }}</td>
+                </tr>
+            {% endfor %}
+        </table>
+        {{ html_code|safe }}
+    </div>
     <div>
         {% for attr, value in special_attrs_rendered.items() %}
             <h5>Attribute: {{ attr }}</h5>
diff --git a/airflow/www/views.py b/airflow/www/views.py
index 19cdea76fe6e7..383162fe481ac 100644
--- a/airflow/www/views.py
+++ b/airflow/www/views.py
@@ -28,6 +28,7 @@
 from past.builtins import basestring
 
 import inspect
+from textwrap import dedent
 import traceback
 
 import sqlalchemy as sqla
@@ -859,6 +860,8 @@ def log(self):
     @login_required
     @wwwutils.action_logging
     def task(self):
+        TI = models.TaskInstance
+
         dag_id = request.args.get('dag_id')
         task_id = request.args.get('task_id')
         # Carrying execution_date through, even though it's irrelevant for
@@ -867,15 +870,17 @@ def task(self):
         dttm = dateutil.parser.parse(execution_date)
         form = DateTimeForm(data={'execution_date': dttm})
         dag = dagbag.get_dag(dag_id)
+
         if not dag or task_id not in dag.task_ids:
             flash(
                 "Task [{}.{}] doesn't seem to exist"
                 " at the moment".format(dag_id, task_id),
                 "error")
             return redirect('/admin/')
-        task = dag.get_task(task_id)
-        task = copy.copy(task)
+        task = copy.copy(dag.get_task(task_id))
         task.resolve_template_files()
+        ti = TI(task=task, execution_date=dttm)
+        ti.refresh_from_db()
 
         attributes = []
         for attr_name in dir(task):
@@ -885,7 +890,6 @@ def task(self):
                                 attr_name not in attr_renderer:
                     attributes.append((attr_name, str(attr)))
 
-        title = "Task Details"
         # Color coding the special attributes that are code
         special_attrs_rendered = {}
         for attr_name in attr_renderer:
@@ -893,9 +897,22 @@ def task(self):
                 source = getattr(task, attr_name)
                 special_attrs_rendered[attr_name] = attr_renderer[attr_name](source)
 
+        no_failed_deps = [(
+            "Unknown",
+            dedent("""\
+            All dependencies are met but the task instance is not running. In most cases this just means that the task will probably be scheduled soon unless:
+            - This task instance already ran and had it's status changed manually
+            - The scheduler is down or under heavy load
+            If this task instance does not start soon please contact your Airflow administrator for more information."""))]
+
+        failed_dep_reasons = [(dep.dep_name, dep.reason) for dep in
+                              ti.get_failed_dep_statuses()] or NO_FAILED_DEPS
+
+        title = "Task Details"
         return self.render(
             'airflow/task.html',
             attributes=attributes,
+            failed_dep_reasons=failed_dep_reasons,
             task_id=task_id,
             execution_date=execution_date,
             special_attrs_rendered=special_attrs_rendered,
