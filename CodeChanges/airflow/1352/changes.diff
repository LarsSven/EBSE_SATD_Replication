diff --git a/.rat-excludes b/.rat-excludes
index 5219bcede0d25..bc796d912305c 100644
--- a/.rat-excludes
+++ b/.rat-excludes
@@ -18,3 +18,4 @@ metastore_db
 .*sql
 .*csv
 CHANGELOG.txt
+.*zip
diff --git a/airflow/models.py b/airflow/models.py
index d331cd6e577e6..9909947cd10ab 100644
--- a/airflow/models.py
+++ b/airflow/models.py
@@ -27,6 +27,8 @@
 import functools
 import getpass
 import imp
+import importlib
+import zipfile
 import jinja2
 import json
 import logging
@@ -201,53 +203,95 @@ def get_dag(self, dag_id):
 
     def process_file(self, filepath, only_if_updated=True, safe_mode=True):
         """
-        Given a path to a python module, this method imports the module and
-        look for dag objects within it.
+        Given a path to a python module or zip file, this method imports
+        the module and look for dag objects within it.
         """
         found_dags = []
+
+        # todo: raise exception?
+        if not os.path.isfile(filepath):
+            return found_dags
+
         try:
             # This failed before in what may have been a git sync
             # race condition
             dttm = datetime.fromtimestamp(os.path.getmtime(filepath))
-            mod_name, file_ext = os.path.splitext(os.path.split(filepath)[-1])
-            mod_name = 'unusual_prefix_' + mod_name
+            if only_if_updated \
+                    and filepath in self.file_last_changed \
+                    and dttm == self.file_last_changed[filepath]:
+                return found_dags
+
         except Exception as e:
             logging.exception(e)
             return found_dags
 
-        if safe_mode and os.path.isfile(filepath):
-            # Skip file if no obvious references to airflow or DAG are found.
-            with open(filepath, 'rb') as f:
-                content = f.read()
-                if not all([s in content for s in (b'DAG', b'airflow')]):
-                    return found_dags
+        mods = []
+        if not zipfile.is_zipfile(filepath):
+            if safe_mode and os.path.isfile(filepath):
+                with open(filepath, 'rb') as f:
+                    content = f.read()
+                    if not all([s in content for s in (b'DAG', b'airflow')]):
+                        return found_dags
 
-        if (not only_if_updated or
-                filepath not in self.file_last_changed or
-                dttm != self.file_last_changed[filepath]):
-            try:
-                self.logger.debug("Importing " + filepath)
-                if mod_name in sys.modules:
-                    del sys.modules[mod_name]
-                with timeout(
-                        configuration.getint('core', "DAGBAG_IMPORT_TIMEOUT")):
+            self.logger.debug("Importing {}".format(filepath))
+            org_mod_name, file_ext = os.path.splitext(os.path.split(filepath)[-1])
+            mod_name = 'unusual_prefix_' + org_mod_name
+
+            if mod_name in sys.modules:
+                del sys.modules[mod_name]
+
+            with timeout(configuration.getint('core', "DAGBAG_IMPORT_TIMEOUT")):
+                try:
                     m = imp.load_source(mod_name, filepath)
-            except Exception as e:
-                self.logger.exception("Failed to import: " + filepath)
-                self.import_errors[filepath] = str(e)
-                self.file_last_changed[filepath] = dttm
-                return
+                    mods.append(m)
+                except Exception as e:
+                    self.logger.exception("Failed to import: " + filepath)
+                    self.import_errors[filepath] = str(e)
+                    self.file_last_changed[filepath] = dttm
+
+        else:
+            zip_file = zipfile.ZipFile(filepath)
+            for mod in zip_file.infolist():
+                head, tail = os.path.split(mod.filename)
+                mod_name, ext = os.path.splitext(mod.filename)
+                if not head and (ext == '.py' or ext == '.pyc'):
+                    if mod_name == '__init__':
+                        self.logger.warning("Found __init__.{0} at root of {1}".
+                                            format(ext, filepath))
+
+                    if safe_mode:
+                        with zip_file.open(mod.filename) as zf:
+                            self.logger.debug("Reading {} from {}".
+                                              format(mod.filename, filepath))
+                            content = zf.read()
+                            if not all([s in content for s in (b'DAG', b'airflow')]):
+                                # todo: create ignore list
+                                return found_dags
+
+                    if mod_name in sys.modules:
+                        del sys.modules[mod_name]
+
+                    try:
+                        sys.path.insert(0, filepath)
+                        m = importlib.import_module(mod_name)
+                        mods.append(m)
+                    except Exception as e:
+                        self.logger.exception("Failed to import: " + filepath)
+                        self.import_errors[filepath] = str(e)
+                        self.file_last_changed[filepath] = dttm
 
+        for m in mods:
             for dag in list(m.__dict__.values()):
                 if isinstance(dag, DAG):
                     if not dag.full_filepath:
                         dag.full_filepath = filepath
                     dag.is_subdag = False
+                    dag.module_name = m.__name__
                     self.bag_dag(dag, parent_dag=dag, root_dag=dag)
                     found_dags.append(dag)
                     found_dags += dag.subdags
 
-            self.file_last_changed[filepath] = dttm
+        self.file_last_changed[filepath] = dttm
         return found_dags
 
     @provide_session
@@ -2765,6 +2809,7 @@ def __deepcopy__(self, memo):
         memo[id(self)] = result
         for k, v in list(self.__dict__.items()):
             if k not in ('user_defined_macros', 'params'):
+                print("K: {} V: {}".format(k, v))
                 setattr(result, k, copy.deepcopy(v, memo))
 
         result.user_defined_macros = self.user_defined_macros
diff --git a/airflow/www/views.py b/airflow/www/views.py
index f34c3e9d5fd98..ebcecd2261a88 100644
--- a/airflow/www/views.py
+++ b/airflow/www/views.py
@@ -16,6 +16,7 @@
 
 import os
 import socket
+import importlib
 
 from functools import wraps
 from datetime import datetime, timedelta
@@ -633,10 +634,15 @@ def dag_stats(self):
     def code(self):
         dag_id = request.args.get('dag_id')
         dag = dagbag.get_dag(dag_id)
-        code = "".join(open(dag.full_filepath, 'r').readlines())
-        title = dag.filepath
-        html_code = highlight(
-            code, lexers.PythonLexer(), HtmlFormatter(linenos=True))
+        title = dag_id
+        try:
+            m = importlib.import_module(dag.module_name)
+            code = inspect.getsource(m)
+            html_code = highlight(
+                code, lexers.PythonLexer(), HtmlFormatter(linenos=True))
+        except IOError as e:
+            html_code = str(e)
+
         return self.render(
             'airflow/dag_code.html', html_code=html_code, dag=dag, title=title,
             root=request.args.get('root'),
diff --git a/docs/concepts.rst b/docs/concepts.rst
index 6951cf770b10e..1a3e4502e3ed0 100644
--- a/docs/concepts.rst
+++ b/docs/concepts.rst
@@ -699,3 +699,53 @@ as an environment variable named ``EXECUTION_DATE`` in your Bash script.
 
 You can use Jinja templating with every parameter that is marked as "templated"
 in the documentation.
+
+Packaged dags
+'''''''''''''
+While often you will specify dags in a single ``.py`` file it might sometimes
+be required to combine dag and its dependencies. For example, you might want
+to combine several dags together to version them together or you might want
+to manage them together or you might need an extra module that is not available
+by default on the system you are running airflow on. To allow this you can create
+a zip file that contains the dag(s) in the root of the zip file and have the extra
+modules unpacked in directories.
+
+For instance you can create a zip file that looks like this:
+
+.. code-block:: bash
+
+    my_dag1.py
+    my_dag2.py
+    package1/__init__.py
+    package1/functions.py
+
+Airflow will scan the zip file and try to load ``my_dag1.py`` and ``my_dag2.py``.
+It will not go into subdirectories as these are considered to be potential
+packages.
+
+In case you would like to add module dependencies to your DAG you basically would
+do the same, but then it is more to use a virtualenv and pip.
+
+.. code-block:: bash
+
+    virtualenv zip_dag
+    source zip_dag/bin/activate
+
+    mkdir zip_dag_contents
+    cd zip_dag_contents
+
+    pip install --install-option="--install-lib=$PWD" my_useful_package
+    cp ~/my_dag.py .
+
+    zip -r zip_dag.zip *
+
+.. note:: the zip file will be inserted at the beginning of module search list
+   (sys.path) and as such it will be available to any other code that resides
+   within the same interpreter.
+
+.. note:: packaged dags cannot be used with pickling turned on.
+
+.. note:: packaged dags cannot contain dynamic libraries (eg. libz.so) these need
+   to be available on the system if a module needs those. In other words only
+   pure python modules can be packaged.
+
diff --git a/docs/tutorial.rst b/docs/tutorial.rst
index 160e6b396a06a..e9d382bd24b01 100644
--- a/docs/tutorial.rst
+++ b/docs/tutorial.rst
@@ -411,7 +411,6 @@ which are used to populate the run schedule with task instances from this dag.
     # start your backfill on a date range
     airflow backfill tutorial -s 2015-06-01 -e 2015-06-07
 
-
 What's Next?
 -------------
 That's it, you've written, tested and backfilled your very first Airflow
diff --git a/tests/core.py b/tests/core.py
index 1013d339db09d..8c4bd499e5b5e 100644
--- a/tests/core.py
+++ b/tests/core.py
@@ -1,3 +1,16 @@
+# -*- coding: utf-8 -*-
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 from __future__ import print_function
 
 import doctest
diff --git a/tests/dags/test_zip.zip b/tests/dags/test_zip.zip
new file mode 100644
index 0000000000000..f6ab3190e5c1e
Binary files /dev/null and b/tests/dags/test_zip.zip differ
diff --git a/tests/models.py b/tests/models.py
index 6d51846ba2097..bc3f1e182b97d 100644
--- a/tests/models.py
+++ b/tests/models.py
@@ -162,6 +162,14 @@ def test_process_file_that_contains_multi_bytes_char(self):
         dagbag = models.DagBag(include_examples=True)
         assert dagbag.process_file(f.name) == []
 
+    def test_zip(self):
+        """
+        test the loading of a DAG within a zip file that includes dependencies
+        """
+        dagbag = models.DagBag()
+        dagbag.process_file(os.path.join(TEST_DAGS_FOLDER, "test_zip.zip"))
+        assert dagbag.get_dag("test_zip_dag")
+
     @patch.object(DagModel,'get_current')
     def test_get_dag_without_refresh(self, mock_dagmodel):
         """
@@ -189,6 +197,7 @@ def process_file(self, filepath, only_if_updated=True, safe_mode=True):
         assert dagbag.get_dag(dag_id) != None
         assert dagbag.process_file_calls == 1
 
+
 class TaskInstanceTest(unittest.TestCase):
 
     def test_set_dag(self):
