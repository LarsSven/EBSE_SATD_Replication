diff --git a/src/backend/executor/execDML.c b/src/backend/executor/execDML.c
index d36e9edafd..d6f05de516 100644
--- a/src/backend/executor/execDML.c
+++ b/src/backend/executor/execDML.c
@@ -158,10 +158,11 @@ reconstructMatchingTupleSlot(TupleTableSlot *slot, ResultRelInfo *resultRelInfo)
  */
 void
 ExecInsert(TupleTableSlot *slot,
-		   DestReceiver *dest,
-		   EState *estate,
-		   PlanGenerator planGen,
-		   bool isUpdate)
+		DestReceiver *dest,
+		EState *estate,
+		PlanGenerator planGen,
+		bool isUpdate,
+		bool isInputSorted)
 {
 	void		*tuple = NULL;
 	ResultRelInfo *resultRelInfo = NULL;
@@ -184,7 +185,7 @@ ExecInsert(TupleTableSlot *slot,
 		resultRelInfo = slot_get_partition(slot, estate);
 		estate->es_result_relation_info = resultRelInfo;
 
-		if (NULL != resultRelInfo->ri_parquetSendBack)
+		if (NULL != resultRelInfo->ri_insertSendBack)
 		{
 			/*
 			 * The Parquet part we are about to insert into
@@ -203,59 +204,82 @@ ExecInsert(TupleTableSlot *slot,
 		 * inserted into (GPSQL-2291).
 		 */
 		Oid new_part_oid = resultRelInfo->ri_RelationDesc->rd_id;
-		if (gp_parquet_insert_sort &&
+
+		if (isInputSorted &&
 				PLANGEN_OPTIMIZER == planGen &&
-				InvalidOid != estate->es_last_parq_part &&
-				new_part_oid != estate->es_last_parq_part)
+				InvalidOid != estate->es_last_inserted_part &&
+				new_part_oid != estate->es_last_inserted_part)
 		{
 
 			Assert(NULL != estate->es_partition_state->result_partition_hash);
 
 			ResultPartHashEntry *entry = hash_search(estate->es_partition_state->result_partition_hash,
-									&estate->es_last_parq_part,
-									HASH_FIND,
-									NULL /* found */);
+					&estate->es_last_inserted_part,
+					HASH_FIND,
+					NULL /* found */);
 
 			Assert(NULL != entry);
 			Assert(entry->offset < estate->es_num_result_relations);
 
 			ResultRelInfo *oldResultRelInfo = & estate->es_result_relations[entry->offset];
+			Assert(NULL != oldResultRelInfo);
 
-			elog(DEBUG1, "Switching from old part oid=%d name=[%s] to new part oid=%d name=[%s]",
-					estate->es_last_parq_part,
-					oldResultRelInfo->ri_RelationDesc->rd_rel->relname.data,
-					new_part_oid,
-					resultRelInfo->ri_RelationDesc->rd_rel->relname.data);
-
-			/*
-			 * We are opening a new partition, and the last partition we
-			 * inserted into was a Parquet part. Let's close the old
-			 * parquet insert descriptor to free the memory before
-			 * opening the new one.
-			 */
-			ParquetInsertDescData *oldInsertDesc = oldResultRelInfo->ri_parquetInsertDesc;
 
 			/*
 			 * We need to preserve the "sendback" information that needs to be
 			 * sent back to the QD process from this part.
 			 * Compute it here, and store it for later use.
 			 */
-			QueryContextDispatchingSendBack sendback =
-					CreateQueryContextDispatchingSendBack(1);
+			QueryContextDispatchingSendBack sendback = CreateQueryContextDispatchingSendBack(1);
 			sendback->relid = RelationGetRelid(oldResultRelInfo->ri_RelationDesc);
-			oldInsertDesc->sendback = sendback;
-			parquet_insert_finish(oldInsertDesc);
 
-			/* Store the sendback information in the resultRelInfo for this part */
-			oldResultRelInfo->ri_parquetSendBack = sendback;
+			Relation oldRelation = oldResultRelInfo->ri_RelationDesc;
+			if (RelationIsAoRows(oldRelation))
+			{
+				AppendOnlyInsertDescData *oldInsertDesc = oldResultRelInfo->ri_aoInsertDesc;
+				Assert(NULL != oldInsertDesc);
+
+				elog(DEBUG1, "AO: Switching from old part oid=%d name=[%s] to new part oid=%d name=[%s]",
+						estate->es_last_inserted_part,
+						oldResultRelInfo->ri_RelationDesc->rd_rel->relname.data,
+						new_part_oid,
+						resultRelInfo->ri_RelationDesc->rd_rel->relname.data);
 
-			/* Record in the resultRelInfo that we closed the parquet insert descriptor */
-			oldResultRelInfo->ri_parquetInsertDesc = NULL;
+				oldInsertDesc->sendback = sendback;
 
-			/* Reset the last parquet part Oid, it's now closed */
-			estate->es_last_parq_part = InvalidOid;
+				appendonly_insert_finish(oldInsertDesc);
+				oldResultRelInfo->ri_aoInsertDesc = NULL;
+
+			}
+			else if (RelationIsParquet(oldRelation))
+			{
+				ParquetInsertDescData *oldInsertDesc = oldResultRelInfo->ri_parquetInsertDesc;
+				Assert(NULL != oldInsertDesc);
+
+				elog(DEBUG1, "PARQ: Switching from old part oid=%d name=[%s] to new part oid=%d name=[%s]",
+						estate->es_last_inserted_part,
+						oldResultRelInfo->ri_RelationDesc->rd_rel->relname.data,
+						new_part_oid,
+						resultRelInfo->ri_RelationDesc->rd_rel->relname.data);
+
+				oldInsertDesc->sendback = sendback;
+
+				parquet_insert_finish(oldInsertDesc);
+				oldResultRelInfo->ri_parquetInsertDesc = NULL;
+
+			}
+			else
+			{
+				Assert(false && "Unreachable");
+			}
+
+			/* Store the sendback information in the resultRelInfo for this part */
+			oldResultRelInfo->ri_insertSendBack = sendback;
+
+			estate->es_last_inserted_part = InvalidOid;
 		}
-	}
+
+  }
 	else
 	{
 		resultRelInfo = estate->es_result_relation_info;
@@ -362,7 +386,7 @@ ExecInsert(TupleTableSlot *slot,
 			resultRelInfo->ri_aoInsertDesc =
 				appendonly_insert_init(resultRelationDesc,
 									   segfileinfo);
-
+			estate->es_last_inserted_part = resultRelationDesc->rd_id;
 		}
 
 		appendonly_insert(resultRelInfo->ri_aoInsertDesc, tuple, &newId, &aoTupleId);
@@ -391,8 +415,7 @@ ExecInsert(TupleTableSlot *slot,
 			 * in estate, so that we can close it when switching to a
 			 * new partition (GPSQL-2291)
 			 */
-			elog(DEBUG1, "Saving es_last_parq_part. Old=%d, new=%d", estate->es_last_parq_part, resultRelationDesc->rd_id);
-			estate->es_last_parq_part = resultRelationDesc->rd_id;
+			estate->es_last_inserted_part = resultRelationDesc->rd_id;
 		}
 
 		newId = parquet_insert(resultRelInfo->ri_parquetInsertDesc, partslot);
diff --git a/src/backend/executor/execMain.c b/src/backend/executor/execMain.c
index 1c215b0e9f..6fa5cd2859 100644
--- a/src/backend/executor/execMain.c
+++ b/src/backend/executor/execMain.c
@@ -2927,7 +2927,7 @@ ExecEndPlan(PlanState *planstate, EState *estate)
 	{
 		if (resultRelInfo->ri_aoInsertDesc)
 			++aocount;
-		if (resultRelInfo->ri_parquetInsertDesc || resultRelInfo->ri_parquetSendBack)
+		if (resultRelInfo->ri_parquetInsertDesc || resultRelInfo->ri_insertSendBack)
 			++aocount;
 		resultRelInfo++;
 	}
@@ -2946,6 +2946,7 @@ ExecEndPlan(PlanState *planstate, EState *estate)
 		/* end (flush) the INSERT operation in the access layer */
 		if (resultRelInfo->ri_aoInsertDesc)
 		{
+
 			sendback = CreateQueryContextDispatchingSendBack(1);
 			resultRelInfo->ri_aoInsertDesc->sendback = sendback;
 			sendback->relid = RelationGetRelid(resultRelInfo->ri_RelationDesc);
@@ -2956,9 +2957,9 @@ ExecEndPlan(PlanState *planstate, EState *estate)
 		/*need add processing for parquet insert desc*/
 		if (resultRelInfo->ri_parquetInsertDesc){
 
-			AssertImply(resultRelInfo->ri_parquetSendBack, gp_parquet_insert_sort);
+			AssertImply(resultRelInfo->ri_insertSendBack, gp_parquet_insert_sort);
 
-			if (NULL != resultRelInfo->ri_parquetSendBack)
+			if (NULL != resultRelInfo->ri_insertSendBack)
 			{
 				/*
 				 * The Parquet part we just finished inserting into already
@@ -2984,10 +2985,10 @@ ExecEndPlan(PlanState *planstate, EState *estate)
 		 * in the resultRelInfo, since the ri_parquetInsertDesc is freed
 		 * (GPSQL-2291)
 		 */
-		if (NULL != resultRelInfo->ri_parquetSendBack)
+		if (NULL != resultRelInfo->ri_insertSendBack)
 		{
 			Assert(NULL == sendback);
-			sendback = resultRelInfo->ri_parquetSendBack;
+			sendback = resultRelInfo->ri_insertSendBack;
 		}
 
 		if (resultRelInfo->ri_extInsertDesc)
@@ -3390,7 +3391,7 @@ lmark:	;
 				break;
 
 			case CMD_INSERT:
-				ExecInsert(slot, dest, estate, PLANGEN_PLANNER, false /* isUpdate */);
+				ExecInsert(slot, dest, estate, PLANGEN_PLANNER, false /* isUpdate */, false /* isInputSorted */);
 				result = NULL;
 				break;
 
diff --git a/src/backend/executor/execUtils.c b/src/backend/executor/execUtils.c
index eb1124ddc6..780fa725f6 100644
--- a/src/backend/executor/execUtils.c
+++ b/src/backend/executor/execUtils.c
@@ -278,7 +278,7 @@ InternalCreateExecutorState(MemoryContext qcontext, bool is_subquery)
 	estate->es_result_relations = NULL;
 	estate->es_num_result_relations = 0;
 	estate->es_result_relation_info = NULL;
-	estate->es_last_parq_part = InvalidOid;
+	estate->es_last_inserted_part = InvalidOid;
 
 	estate->es_junkFilter = NULL;
 
diff --git a/src/backend/executor/nodeDML.c b/src/backend/executor/nodeDML.c
index db103ce815..5ba48dffba 100644
--- a/src/backend/executor/nodeDML.c
+++ b/src/backend/executor/nodeDML.c
@@ -120,7 +120,7 @@ ExecDML(DMLState *node)
 		 */
 		ExecInsert(node->cleanedUpSlot, NULL /* destReceiver */,
 				node->ps.state, PLANGEN_OPTIMIZER /* Plan origin */, 
-				isUpdate);
+				isUpdate, plannode->inputSorted);
 	}
 	else /* DML_DELETE */
 	{
diff --git a/src/backend/gpopt/ivy.xml b/src/backend/gpopt/ivy.xml
index db5c89fc95..d8fcb859b0 100644
--- a/src/backend/gpopt/ivy.xml
+++ b/src/backend/gpopt/ivy.xml
@@ -38,7 +38,7 @@ under the License.
     </configurations>
 
     <dependencies>
-      <dependency org="emc"             name="optimizer"       rev="1.617"          conf="osx106_x86->osx106_x86_32;osx106_x86_32->osx106_x86_32;rhel5_x86_64->rhel5_x86_64;suse10_x86_64->suse10_x86_64" />
+      <dependency org="emc"             name="optimizer"       rev="1.623"          conf="osx106_x86->osx106_x86_32;osx106_x86_32->osx106_x86_32;rhel5_x86_64->rhel5_x86_64;suse10_x86_64->suse10_x86_64" />
       <dependency org="emc"             name="libgpos"         rev="1.133"          conf="osx106_x86->osx106_x86_32;osx106_x86_32->osx106_x86_32;rhel5_x86_64->rhel5_x86_64;suse10_x86_64->suse10_x86_64" />
       <dependency org="xerces"          name="xerces-c"        rev="3.1.1-p1"       conf="osx106_x86->osx106_x86_32;osx106_x86_32->osx106_x86_32;rhel5_x86_64->rhel5_x86_64;suse10_x86_64->suse10_x86_64" />
     </dependencies>
diff --git a/src/backend/gpopt/translate/CTranslatorDXLToPlStmt.cpp b/src/backend/gpopt/translate/CTranslatorDXLToPlStmt.cpp
index 12ef75f01e..21da4fd89c 100644
--- a/src/backend/gpopt/translate/CTranslatorDXLToPlStmt.cpp
+++ b/src/backend/gpopt/translate/CTranslatorDXLToPlStmt.cpp
@@ -4518,6 +4518,8 @@ CTranslatorDXLToPlStmt::PplanDML
 		plTargetListDML = plTargetListWithDroppedCols;
 	}
 	
+	pdml->inputSorted = pdxlop->FInputSorted();
+
 	// add ctid, action and oid columns to target list
 	pdml->oidColIdx = UlAddTargetEntryForColId(&plTargetListDML, &dxltrctxChild, pdxlop->UlOid(), true /*fResjunk*/);
 	pdml->actionColIdx = UlAddTargetEntryForColId(&plTargetListDML, &dxltrctxChild, pdxlop->UlAction(), true /*fResjunk*/);
diff --git a/src/backend/gpopt/translate/CTranslatorRelcacheToDXL.cpp b/src/backend/gpopt/translate/CTranslatorRelcacheToDXL.cpp
index 80a81ee6c9..8cb468a4e9 100644
--- a/src/backend/gpopt/translate/CTranslatorRelcacheToDXL.cpp
+++ b/src/backend/gpopt/translate/CTranslatorRelcacheToDXL.cpp
@@ -597,6 +597,7 @@ CTranslatorRelcacheToDXL::Pmdrel
 	DrgPmdid *pdrgpmdidIndexes = NULL;
 	DrgPmdid *pdrgpmdidTriggers = NULL;
 	DrgPul *pdrgpulPartKeys = NULL;
+	ULONG ulLeafPartitions = 0;
 	BOOL fConvertHashToRandom = false;
 	DrgPdrgPul *pdrgpdrgpulKeys = NULL;
 	DrgPmdid *pdrgpmdidCheckConstraints = NULL;
@@ -652,6 +653,13 @@ CTranslatorRelcacheToDXL::Pmdrel
 				erelstorage = IMDRelation::ErelstorageAppendOnlyParquet;
 			}
 		}
+
+		// get number of leaf partitions
+		if (gpdb::FRelPartIsRoot(oid))
+		{
+		   ulLeafPartitions = gpdb::UlLeafPartitions(oid);
+		}
+
 		// get key sets
 		BOOL fAddDefaultKeys = FHasSystemColumns(rel->rd_rel->relkind);
 		pdrgpdrgpulKeys = PdrgpdrgpulKeys(pmp, oid, fAddDefaultKeys, fPartitioned, pulAttnoMapping);
@@ -722,6 +730,7 @@ CTranslatorRelcacheToDXL::Pmdrel
 							pdrgpmdcol,
 							pdrpulDistrCols,
 							pdrgpulPartKeys,
+							ulLeafPartitions,
 							fConvertHashToRandom,
 							pdrgpdrgpulKeys,
 							pdrgpmdidIndexes,
diff --git a/src/backend/gpopt/utils/COptTasks.cpp b/src/backend/gpopt/utils/COptTasks.cpp
index 893cde2aa8..4d10d395f4 100644
--- a/src/backend/gpopt/utils/COptTasks.cpp
+++ b/src/backend/gpopt/utils/COptTasks.cpp
@@ -774,13 +774,15 @@ COptTasks::PoconfCreate
 	DOUBLE dDampingFactorGroupBy = (DOUBLE) optimizer_damping_factor_groupby;
 
 	ULONG ulCTEInliningCutoff =  (ULONG) optimizer_cte_inlining_bound;
+	ULONG ulPartsToForceSortOnInsert =  (ULONG) optimizer_parts_to_force_sort_on_insert;
 
 	return GPOS_NEW(pmp) COptimizerConfig
 						(
 						GPOS_NEW(pmp) CEnumeratorConfig(pmp, ullPlanId, ullSamples, dCostThreshold),
 						GPOS_NEW(pmp) CStatisticsConfig(pmp, dDampingFactorFilter, dDampingFactorJoin, dDampingFactorGroupBy),
 						GPOS_NEW(pmp) CCTEConfig(ulCTEInliningCutoff),
-						pcm
+						pcm,
+						GPOS_NEW(pmp) CHint(ulPartsToForceSortOnInsert)
 						);
 }
 
diff --git a/src/backend/nodes/copyfuncs.c b/src/backend/nodes/copyfuncs.c
index 6792e452aa..7082dac17e 100644
--- a/src/backend/nodes/copyfuncs.c
+++ b/src/backend/nodes/copyfuncs.c
@@ -1119,6 +1119,7 @@ _copyDML(const DML *from)
 	COPY_SCALAR_FIELD(actionColIdx);
 	COPY_SCALAR_FIELD(ctidColIdx);
 	COPY_SCALAR_FIELD(tupleoidColIdx);
+	COPY_SCALAR_FIELD(inputSorted);
 
 	return newnode;
 }
diff --git a/src/backend/nodes/outfast.c b/src/backend/nodes/outfast.c
index ac943c9b87..348bb2c3e5 100644
--- a/src/backend/nodes/outfast.c
+++ b/src/backend/nodes/outfast.c
@@ -981,6 +981,7 @@ _outDML(StringInfo str, DML *node)
 	WRITE_INT_FIELD(actionColIdx);
 	WRITE_INT_FIELD(ctidColIdx);
 	WRITE_INT_FIELD(tupleoidColIdx);
+	WRITE_BOOL_FIELD(inputSorted);
 
 	_outPlanInfo(str, (Plan *) node);
 }
diff --git a/src/backend/nodes/outfuncs.c b/src/backend/nodes/outfuncs.c
index 0f356103da..03a255034a 100644
--- a/src/backend/nodes/outfuncs.c
+++ b/src/backend/nodes/outfuncs.c
@@ -987,6 +987,7 @@ _outDML(StringInfo str, DML *node)
 	WRITE_INT_FIELD(actionColIdx);
 	WRITE_INT_FIELD(ctidColIdx);
 	WRITE_INT_FIELD(tupleoidColIdx);
+	WRITE_BOOL_FIELD(inputSorted);
 
 	_outPlanInfo(str, (Plan *) node);
 }
diff --git a/src/backend/nodes/readfast.c b/src/backend/nodes/readfast.c
index cfdcc06a48..a77a21733b 100644
--- a/src/backend/nodes/readfast.c
+++ b/src/backend/nodes/readfast.c
@@ -3604,6 +3604,7 @@ _readDML(const char ** str)
 	READ_INT_FIELD(actionColIdx);
 	READ_INT_FIELD(ctidColIdx);
 	READ_INT_FIELD(tupleoidColIdx);
+	READ_BOOL_FIELD(inputSorted);
 
 	readPlanInfo(str, (Plan *)local_node);
 
diff --git a/src/backend/utils/misc/guc.c b/src/backend/utils/misc/guc.c
index a8f3f37ce1..b9a52043a5 100644
--- a/src/backend/utils/misc/guc.c
+++ b/src/backend/utils/misc/guc.c
@@ -762,6 +762,7 @@ bool 		optimizer_multilevel_partitioning;
 bool        optimizer_enable_derive_stats_all_groups;
 bool		optimizer_explain_show_status;
 bool		optimizer_prefer_scalar_dqa_multistage_agg;
+int		optimizer_parts_to_force_sort_on_insert;
 
 /* Security */
 bool		gp_reject_internal_tcp_conn = true;
@@ -6145,6 +6146,16 @@ static struct config_int ConfigureNamesInt[] =
 		0, 0, INT_MAX, NULL, NULL
 	},
 
+	{
+		{"optimizer_parts_to_force_sort_on_insert", PGC_USERSET, DEVELOPER_OPTIONS,
+			gettext_noop("Minimum number of partitions required to force sorting tuples during insertion in an append only row-oriented partitioned table"),
+			NULL,
+			GUC_NOT_IN_SAMPLE | GUC_GPDB_ADDOPT
+		},
+		&optimizer_parts_to_force_sort_on_insert,
+		INT_MAX, 0, INT_MAX, NULL, NULL
+	},
+
 	{
 		{"pxf_stat_max_fragments", PGC_USERSET, EXTERNAL_TABLES,
 			gettext_noop("Max number of fragments to be sampled during ANALYZE on a PXF table."),
diff --git a/src/include/executor/execDML.h b/src/include/executor/execDML.h
index f1f45c82b1..886b5850cf 100644
--- a/src/include/executor/execDML.h
+++ b/src/include/executor/execDML.h
@@ -54,7 +54,8 @@ ExecInsert(TupleTableSlot *slot,
 		   DestReceiver *dest,
 		   EState *estate,
 		   PlanGenerator planGen,
-		   bool isUpdate);
+		   bool isUpdate,
+		   bool isInputSorted);
 
 extern void
 ExecDelete(ItemPointer tupleid,
diff --git a/src/include/gpopt/translate/CTranslatorUtils.h b/src/include/gpopt/translate/CTranslatorUtils.h
index 1f8776abfb..d0a0f715e0 100644
--- a/src/include/gpopt/translate/CTranslatorUtils.h
+++ b/src/include/gpopt/translate/CTranslatorUtils.h
@@ -70,10 +70,6 @@ namespace gpdxl
 {
 	using namespace gpopt;
 
-	// hash maps mapping INT -> ULONG
-	typedef CHashMap<INT, ULONG, gpos::UlHash<INT>, gpos::FEqual<INT>,
-					CleanupDelete<INT>, CleanupDelete<ULONG> > HMIUl;
-
 	//---------------------------------------------------------------------------
 	//	@class:
 	//		CTranslatorUtils
diff --git a/src/include/nodes/execnodes.h b/src/include/nodes/execnodes.h
index 98c2ee6b45..7a2e733779 100644
--- a/src/include/nodes/execnodes.h
+++ b/src/include/nodes/execnodes.h
@@ -278,7 +278,7 @@ typedef struct JunkFilter
  *  aoInsertDesc        context for appendonly relation buffered INSERT
  *  extInsertDesc       context for external table INSERT
  *  parquetInsertDesc   context for parquet table INSERT
- *  parquetSendBack     information to be sent back to dispatch after INSERT in a parquet table
+ *  insertSendBack      information to be sent back to dispatch after INSERT in a parquet or AO table
  *  aosegno             the AO segfile we inserted into.
  *  aoprocessed         tuples processed for AO
  *  partInsertMap       map input attrno to target attrno
@@ -307,7 +307,8 @@ typedef struct ResultRelInfo
 
 	struct ExternalInsertDescData   *ri_extInsertDesc;
 	struct ParquetInsertDescData    *ri_parquetInsertDesc;
-	struct QueryContextDispatchingSendBackData *ri_parquetSendBack;
+
+	struct QueryContextDispatchingSendBackData *ri_insertSendBack;
 
 	List *ri_aosegnos;
 
@@ -501,7 +502,7 @@ typedef struct EState
 	ResultRelInfo *es_result_relation_info;                /* currently active array elt */
 	JunkFilter *es_junkFilter;        /* currently active junk filter */
 
-	Oid es_last_parq_part; /* The Oid of the last parquet partition we opened for insertion */
+	Oid es_last_inserted_part; /* The Oid of the last partition we opened for insertion */
 
 	/* partitioning info for target relation */
 	PartitionNode *es_result_partitions;
diff --git a/src/include/nodes/plannodes.h b/src/include/nodes/plannodes.h
index 842795e576..ebccb9d562 100644
--- a/src/include/nodes/plannodes.h
+++ b/src/include/nodes/plannodes.h
@@ -1149,6 +1149,7 @@ typedef struct DML
 	AttrNumber	actionColIdx;	/* index of action column into the target list */
 	AttrNumber	ctidColIdx;		/* index of ctid column into the target list */
 	AttrNumber	tupleoidColIdx;	/* index of tuple oid column into the target list */
+	bool		inputSorted;		/* needs the data to be sorted */
 
 } DML;
 
diff --git a/src/include/utils/guc.h b/src/include/utils/guc.h
index befeaf606f..475cae183b 100644
--- a/src/include/utils/guc.h
+++ b/src/include/utils/guc.h
@@ -434,6 +434,7 @@ extern bool optimizer_multilevel_partitioning;
 extern bool optimizer_enable_derive_stats_all_groups;
 extern bool optimizer_explain_show_status;
 extern bool optimizer_prefer_scalar_dqa_multistage_agg;
+extern int  optimizer_parts_to_force_sort_on_insert;
 
 /**
  * Enable logging of DPE match in optimizer.
diff --git a/src/test/regress/expected/goh_partition.out b/src/test/regress/expected/goh_partition.out
index d63612642f..b26a76da8d 100755
--- a/src/test/regress/expected/goh_partition.out
+++ b/src/test/regress/expected/goh_partition.out
@@ -2197,3 +2197,129 @@ NOTICE:  CREATE TABLE will create partition "rank3_1_prt_girls_2_prt_jan04_3_prt
 NOTICE:  CREATE TABLE will create partition "rank3_1_prt_girls_2_prt_jan05_3_prt_mass" for table "rank3_1_prt_girls_2_prt_jan05"
 NOTICE:  CREATE TABLE will create partition "rank3_1_prt_girls_2_prt_jan05_3_prt_cali" for table "rank3_1_prt_girls_2_prt_jan05"
 NOTICE:  CREATE TABLE will create partition "rank3_1_prt_girls_2_prt_jan05_3_prt_ohio" for table "rank3_1_prt_girls_2_prt_jan05"
+-- Tests for sort operator before insert with AO and PARQUET tables (HAWQ-404)
+-- A GUC's value is set to less than the number of partitions in the example table, so that sort is activated.
+DROP TABLE IF EXISTS ch_sort_src, ch_sort_aodest, ch_sort_pqdest, ch_sort_aopqdest, ch_sort__pq_table;
+SET optimizer_parts_to_force_sort_on_insert = 5;
+CREATE TABLE ch_sort_src (id int, year int, month int, day int, region text)
+DISTRIBUTED BY (month); 
+INSERT INTO ch_sort_src select i, 2000 + i, i % 12, (2*i) % 30, i::text from generate_series(0, 99) i; 
+-- AO partitioned table
+CREATE TABLE ch_sort_aodest (id int, year int, month int, day int, region text)
+WITH (APPENDONLY=TRUE)
+DISTRIBUTED BY (id)
+PARTITION BY RANGE (year)
+( 
+    START (2002) END (2010) EVERY (1),
+    DEFAULT PARTITION outlying_years
+);
+NOTICE:  CREATE TABLE will create partition "ch_sort_aodest_1_prt_outlying_years" for table "ch_sort_aodest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aodest_1_prt_2" for table "ch_sort_aodest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aodest_1_prt_3" for table "ch_sort_aodest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aodest_1_prt_4" for table "ch_sort_aodest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aodest_1_prt_5" for table "ch_sort_aodest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aodest_1_prt_6" for table "ch_sort_aodest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aodest_1_prt_7" for table "ch_sort_aodest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aodest_1_prt_8" for table "ch_sort_aodest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aodest_1_prt_9" for table "ch_sort_aodest"
+-- PARQUET partitioned table
+CREATE TABLE ch_sort_pqdest (id int, year int, month int, day int, region text)
+WITH (APPENDONLY=TRUE, ORIENTATION = PARQUET)
+DISTRIBUTED BY (id)
+PARTITION BY RANGE (year)
+( 
+    START (2002) END (2010) EVERY (1),
+    DEFAULT PARTITION outlying_years
+);
+NOTICE:  CREATE TABLE will create partition "ch_sort_pqdest_1_prt_outlying_years" for table "ch_sort_pqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_pqdest_1_prt_2" for table "ch_sort_pqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_pqdest_1_prt_3" for table "ch_sort_pqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_pqdest_1_prt_4" for table "ch_sort_pqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_pqdest_1_prt_5" for table "ch_sort_pqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_pqdest_1_prt_6" for table "ch_sort_pqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_pqdest_1_prt_7" for table "ch_sort_pqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_pqdest_1_prt_8" for table "ch_sort_pqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_pqdest_1_prt_9" for table "ch_sort_pqdest"
+-- AO/PARQUET mixed table
+CREATE TABLE ch_sort_aopqdest (id int, year int, month int, day int, region text)
+WITH (APPENDONLY=TRUE)
+DISTRIBUTED BY (id)
+PARTITION BY RANGE (year)
+( 
+    START (2002) END (2010) EVERY (1),
+    DEFAULT PARTITION outlying_years
+);
+NOTICE:  CREATE TABLE will create partition "ch_sort_aopqdest_1_prt_outlying_years" for table "ch_sort_aopqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aopqdest_1_prt_2" for table "ch_sort_aopqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aopqdest_1_prt_3" for table "ch_sort_aopqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aopqdest_1_prt_4" for table "ch_sort_aopqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aopqdest_1_prt_5" for table "ch_sort_aopqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aopqdest_1_prt_6" for table "ch_sort_aopqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aopqdest_1_prt_7" for table "ch_sort_aopqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aopqdest_1_prt_8" for table "ch_sort_aopqdest"
+NOTICE:  CREATE TABLE will create partition "ch_sort_aopqdest_1_prt_9" for table "ch_sort_aopqdest"
+CREATE TABLE ch_sort__pq_table (id int, year int, month int, day int, region text)
+WITH (APPENDONLY=TRUE, ORIENTATION = PARQUET)
+DISTRIBUTED BY (id);
+ALTER TABLE ch_sort_aopqdest
+EXCHANGE PARTITION FOR(2006)
+WITH TABLE ch_sort__pq_table;
+-- Test that inserts work
+INSERT INTO ch_sort_aodest SELECT * FROM ch_sort_src;
+SELECT COUNT(*) FROM ch_sort_aodest;
+ count 
+-------
+   100
+(1 row)
+
+SELECT COUNT(*) FROM ch_sort_aodest_1_prt_6;
+ count 
+-------
+     1
+(1 row)
+
+SELECT COUNT(*) FROM ch_sort_aodest_1_prt_outlying_years;
+ count 
+-------
+    92
+(1 row)
+
+INSERT INTO ch_sort_pqdest SELECT * FROM ch_sort_src;
+SELECT COUNT(*) FROM ch_sort_pqdest;
+ count 
+-------
+   100
+(1 row)
+
+SELECT COUNT(*) FROM ch_sort_pqdest_1_prt_6;
+ count 
+-------
+     1
+(1 row)
+
+SELECT COUNT(*) FROM ch_sort_pqdest_1_prt_outlying_years;
+ count 
+-------
+    92
+(1 row)
+
+INSERT INTO ch_sort_aopqdest SELECT * FROM ch_sort_src;
+SELECT COUNT(*) FROM ch_sort_aopqdest;
+ count 
+-------
+   100
+(1 row)
+
+SELECT COUNT(*) FROM ch_sort_aopqdest_1_prt_6;
+ count 
+-------
+     1
+(1 row)
+
+SELECT COUNT(*) FROM ch_sort_aopqdest_1_prt_outlying_years;
+ count 
+-------
+    92
+(1 row)
+
+RESET optimizer_parts_to_force_sort_on_insert;
diff --git a/src/test/regress/expected/gpsql_alter_table_optimizer.out b/src/test/regress/expected/gpsql_alter_table_optimizer.out
index 8a107749d2..cc1705797c 100644
--- a/src/test/regress/expected/gpsql_alter_table_optimizer.out
+++ b/src/test/regress/expected/gpsql_alter_table_optimizer.out
@@ -41,7 +41,7 @@ SELECT a, b, c FROM altable WHERE a = 12;
 ROLLBACK;
 ALTER TABLE altable ALTER COLUMN c SET NOT NULL;
 INSERT INTO altable(a, b) VALUES(13, '13');
-ERROR:  NULL value in column "c" violates not-null constraint (COptTasks.cpp:1294)
+ERROR:  null value in column "c" violates not-null constraint (COptTasks.cpp:1756)
 ALTER TABLE altable ALTER COLUMN c DROP NOT NULL;
 INSERT INTO altable(a, b) VALUES(13, '13');
 SELECT a, b, c FROM altable WHERE a = 13;
diff --git a/src/test/regress/expected/insert_optimizer.out b/src/test/regress/expected/insert_optimizer.out
index 58121e5667..f5f263a8ba 100755
--- a/src/test/regress/expected/insert_optimizer.out
+++ b/src/test/regress/expected/insert_optimizer.out
@@ -5,7 +5,7 @@ create table inserttest (col1 int4, col2 int4 NOT NULL, col3 text default 'testi
 NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'col1' as the Greenplum Database data distribution key for this table.
 HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
 insert into inserttest (col1, col2, col3) values (DEFAULT, DEFAULT, DEFAULT);
-ERROR:  NULL value in column "col2" violates not-null constraint (COptTasks.cpp:1688)
+ERROR:  null value in column "col2" violates not-null constraint (COptTasks.cpp:1756)
 insert into inserttest (col2, col3) values (3, DEFAULT);
 insert into inserttest (col1, col2, col3) values (DEFAULT, 5, DEFAULT);
 insert into inserttest values (DEFAULT, 5, 'test');
diff --git a/src/test/regress/sql/goh_partition.sql b/src/test/regress/sql/goh_partition.sql
index 8cea409a82..4c04bd85ac 100644
--- a/src/test/regress/sql/goh_partition.sql
+++ b/src/test/regress/sql/goh_partition.sql
@@ -1227,3 +1227,71 @@ subpartition ohio values ('OH')
 )
 )
 );
+
+-- Tests for sort operator before insert with AO and PARQUET tables (HAWQ-404)
+-- A GUC's value is set to less than the number of partitions in the example table, so that sort is activated.
+
+DROP TABLE IF EXISTS ch_sort_src, ch_sort_aodest, ch_sort_pqdest, ch_sort_aopqdest, ch_sort__pq_table;
+
+SET optimizer_parts_to_force_sort_on_insert = 5;
+
+CREATE TABLE ch_sort_src (id int, year int, month int, day int, region text)
+DISTRIBUTED BY (month); 
+INSERT INTO ch_sort_src select i, 2000 + i, i % 12, (2*i) % 30, i::text from generate_series(0, 99) i; 
+
+-- AO partitioned table
+CREATE TABLE ch_sort_aodest (id int, year int, month int, day int, region text)
+WITH (APPENDONLY=TRUE)
+DISTRIBUTED BY (id)
+PARTITION BY RANGE (year)
+( 
+    START (2002) END (2010) EVERY (1),
+    DEFAULT PARTITION outlying_years
+);
+
+-- PARQUET partitioned table
+CREATE TABLE ch_sort_pqdest (id int, year int, month int, day int, region text)
+WITH (APPENDONLY=TRUE, ORIENTATION = PARQUET)
+DISTRIBUTED BY (id)
+PARTITION BY RANGE (year)
+( 
+    START (2002) END (2010) EVERY (1),
+    DEFAULT PARTITION outlying_years
+);
+
+-- AO/PARQUET mixed table
+CREATE TABLE ch_sort_aopqdest (id int, year int, month int, day int, region text)
+WITH (APPENDONLY=TRUE)
+DISTRIBUTED BY (id)
+PARTITION BY RANGE (year)
+( 
+    START (2002) END (2010) EVERY (1),
+    DEFAULT PARTITION outlying_years
+);
+
+CREATE TABLE ch_sort__pq_table (id int, year int, month int, day int, region text)
+WITH (APPENDONLY=TRUE, ORIENTATION = PARQUET)
+DISTRIBUTED BY (id);
+
+ALTER TABLE ch_sort_aopqdest
+EXCHANGE PARTITION FOR(2006)
+WITH TABLE ch_sort__pq_table;
+
+
+-- Test that inserts work
+INSERT INTO ch_sort_aodest SELECT * FROM ch_sort_src;
+SELECT COUNT(*) FROM ch_sort_aodest;
+SELECT COUNT(*) FROM ch_sort_aodest_1_prt_6;
+SELECT COUNT(*) FROM ch_sort_aodest_1_prt_outlying_years;
+
+INSERT INTO ch_sort_pqdest SELECT * FROM ch_sort_src;
+SELECT COUNT(*) FROM ch_sort_pqdest;
+SELECT COUNT(*) FROM ch_sort_pqdest_1_prt_6;
+SELECT COUNT(*) FROM ch_sort_pqdest_1_prt_outlying_years;
+
+INSERT INTO ch_sort_aopqdest SELECT * FROM ch_sort_src;
+SELECT COUNT(*) FROM ch_sort_aopqdest;
+SELECT COUNT(*) FROM ch_sort_aopqdest_1_prt_6;
+SELECT COUNT(*) FROM ch_sort_aopqdest_1_prt_outlying_years;
+
+RESET optimizer_parts_to_force_sort_on_insert;
